{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from medpy.io import load\n",
    "import os\n",
    "import itk\n",
    "import skimage\n",
    "import SimpleITK as sitk\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input, Maximum, concatenate, Activation, Conv3D, MaxPooling3D, Conv2DTranspose\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "'''\n",
    "from keras import layers\n",
    "from keras.layers import Input, Conv2D, Maximum, MaxPooling2D, concatenate, Activation, Conv3D, MaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam'''\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../patients/'\n",
    "IMG_H = 64\n",
    "IMG_W = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CengJia',\n",
       " 'GangZu',\n",
       " 'JiaHuiQiong',\n",
       " 'KongDan',\n",
       " 'LanDingKun',\n",
       " 'LiangChengJun',\n",
       " 'LiuGuangQiong',\n",
       " 'LiuQuanXing',\n",
       " 'LiuYanMu',\n",
       " 'ShenXin',\n",
       " 'TanHongJun',\n",
       " 'XiaGang',\n",
       " 'XiaoChangLun',\n",
       " 'YangChuanFu',\n",
       " 'YangXia',\n",
       " 'YangYunFei',\n",
       " 'ZhangJianMing',\n",
       " 'ZhouDaoMing',\n",
       " 'ZhouLiangYong']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = next(os.walk(data_path))[1]\n",
    "train_ids.sort()\n",
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bak_CengJiaT1SegRAIROIResampling.mha',\n",
       " 'CengJiaT1RAIROIResamplingNormalize.mha',\n",
       " 'CengJiaT1SegDistanceMap.mha',\n",
       " 'CengJiaT1SegRAIROIResampling.mha']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_prof = next(os.walk(data_path + '/' + train_ids[0]))[2]\n",
    "ind_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CengJiaT1RAIROIResamplingNormalize.mha'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "#ind_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pylab import has clobbered these variables: ['imshow', 'load', 'resize', 'imread', 'concatenate']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMMAAABmCAYAAAB2riX3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztvXmMbNl93/c599y1lq7q/XVPv33ezJAzXEwON5OhJRmSRUEwbSOx6cCwEjhg/pCABHCMMDCCOEACJAEcIAkSwwosWzZsykksxTQh0aJELRETSpwhR8M3y+Pbl+l+vVd3rXc7J3/87r1V/RbOkPOWHr7+AYWqunWrzrm3zu/8tu/v91PWWo7oiI4InMc9gSM6osNCR8xwREdU0BEzHNERFXTEDEd0RAUdMcMRHVFBR8xwREdU0ENhBqXUzyqlLiilLimlvvQwxjiiI3rQpB50nEEppYHvAz8N3AK+Dfx1a+3rD3SgIzqiB0wPQzJ8HLhkrb1irU2AXwM+/xDGOaIjeqDkPoTffAq4OfH+FvCJH/QFX4U2choPYSrvjGwUYDyFk4mUVJnBOgqV5mANNvQxnoNVoGODyg3G1ygLViHPAEoeVoEyxY8rwIJ15DyVWXAUtvyo3I4sWF3MITdY10FZMLr8HYXKLM4wBnMPae442MADR4G1qMyAtVjfxWiZt3UUeeigcnDy4jesxTpqfC8mtkdVDlNO1owvSWUG8hwTeHLvUjnZyQykGTbwsK7CSQzGdVDlnLJcfsQYHhUNTY/EjtTbnfcwmOFeg9717ymlvgh8ESBUdT7Z+IsPYSrvjEZ/9lm8XobxHPzNPgAm8nCurqLCENtu0nu6RdJ0iDYzaudX6X/4KfLAIVqPMZ5DHjg4mSUPZTUZd5K5LNZV1WsdG5zUsH86ROXgDWRhhFsJacPF62W4b97AnF7GubmBHQxlogqo/eBrUb5Hfm6FeDYgrTmEOxnB9R3Wf+oY+2dg7k8t3sDgZBa3n5MHjjCKVtW8y7ke+N2sXOwWPcrR/QRnt0vn48vEUw61rRw9MtTOr2KzDHN8gf6JOs0LHZL5utyrl67AdAt297BJ+q7+sx+GvtX7yjs672GoSbeA4xPvV4DVO0+y1v6ytfZFa+2LvgofwjTeOVlX4cSZvIkTrCfbsU1SzH6XrB2hR4YsUIxmZP8I14eo3KJyWcjlwi+pfJ8HDlldo0dGdvbMYrXC3eoR7uZsfBzWPqVZ+5SmeyIk2B4xXAxQjTrq/CXIsgO/q3zvB1+M66IyQ+3aPlMXu6QNTfeDC6RNRd6UuZZzKRkAhAnMPZjAuKpihGoOuUGlOdZz7/qO2e9Wc9axqe5ldX8C/57TftvregT0MCTDt4FzSqnTwFvAF4B//yGM80OT8r0DO5KqRdjBEOMq9OYe0JLjaY7qDVFTTcx+l6TtkQeybyRNhW3UcLoj/D2fpCV/brmbuv38wC6rC92ilBTl8/BUG4Cn/+WArO4R3O6RzNdZ+8wUUzdytv+dp/AGy9Rv9DGBi371soxTzL9cPJPvbZJCsw5A99k2WaDwBoa3fgLab1jO/bMh8WxQzQOoJNnkNeiRqT73RqY6x+3nOKlcj+oNsKOY3D/IDMr3UGGI3txDzYZY10GPMgbLEWGjTh55qHtIhUcpKe5HD5wZrLWZUuqXgH8LaOBXrLWvPehxfhS684Yr1wXfq3YtZ5ii0gxb7l6ulj83s5gauLElaSpMM8TpjqpFXy6iPHDuUo9UoTp5I4PKLTZ0yF0lTJMpkpaPdRXxsQbGVTTeyukvOnRPQvO6QseRqFaT876DqWWuLiQpaM3mR5rsfsigu4qpK5qFpzfZaE0x84Zb7fLWVRhkx55Ui8r5lqqdKY45mSUPRB30ehl2FANgXLkvlb3juthGDVwtTBfIEnP7YiuYwD1wLYeJHoZkwFr7m8BvPozffpBkRyNUo47fScWwixPIclSnC678ZdlzJ4iudbBPTwMOrlbEsyHRMGU04xLuZKjYkAcO/mis0kzuvM7EAit33TxwqkUoEkQorTmkTYXVsmjr529je/0DRtdd0gCwg6FIusjH71pslGMSxWDJId6cQmlLbyWgcSshq4+XYzmfci53MkY599xVBNuxGMHlNR5fwBY/5fZzgts9mJsmbwY4r10liOdELYoT+ssLhNNN0oaLey9mPgT0xEagKzXDc1G5wWaZGHaj0YHzhosBbO0QbMfkgcLJx0ZyHihUbnFSU0kDc8eisloWfrmwjCsenUmDujxuXUXaVBgNM+dh7tUhZqdzt0S7Q0UqyQ6GqN6Q9ldf49n/bVTM0aLXArQ26FjmWkqsyflOHivnX85Lj0y1s2eNQmoWdkHJDE5msZ7GRB66K1KD3T3ZXNIMJx//Lq57KGyEO+mJZYaSbCNCd2OU64532dEI2xOv0mDOwR4/ht7qAmAKdUD1BngDS9JyMZ7cRlUwStrQ1eIWV6yoHGlDy7HReHctmcjrZajM0l+21Fct879/C+/W9ju6hsmFZde35NiF6yz/P5b6quLk12JO/ENNtJmKi/hOhr2P9+hOz5LVDknLxen0YbpF/0QdVSzytKHpnWnidEcQJ6haJN+JfLKl6eIeOHLt7al3dF2Pmp5YZrBJCq5LXvexnhbJAKJ7F5+b6SY6ht6ZJsOzs3iDsYfIhgE6NqS1QkqEpT4tLsbSY1PaECqzeL282n3LnVgV/n4nzsTrFCvCTo4NA5FavnfXLnqXRLjDKVBS40qX5s1yB1fVY3JO5Vyq7xfHS8mgS1tHK/rLAbW3Btj1LfK5Jlmg0IUQSGsOw2mH3nMz7H5sUeyx6ZY4IzJzYAOw0b09So+bnlhmKCltuDibHVQYoGoRKgyqz0aLNfJgvOOXCzetKbK5BtEfvkmwn9Nb8av4QbnQJh/AXSqS18twMpEseeCQNXy2369pf9/QfGVNvDXrW9gkvad+fS81ozxWMpCz28Xr5fSXfNKGRuUyB3+vYJCJXT8PJd5QztnvpBhX4fZT1j4VcvWvuOjEoi5cB2D/dI2kOSk1wMmEKarjWmM9jTNM0bEha/iyadSPmOHQULVoXHfsWiwjo1BJBx0bvIEl91XlOXJyi8ohD0VZrp+/TevSgDyUeMKkmjTpg1e5xetleL1cgl2hrnbcYEcW3Imfuk6wn0OW32W73En3NEBdV3T5QuUz00123hfgxhZ/L8NqUdtKN3FJpQTI6rqwEXKStoe/lzBcDMn/TBfddWi8tinXUosqW6Ekb2DRicVqRFoUDgiJR8jr0nbKQ13d48NEh29GD5lKD4zyPWy7SVpzxKsUFoG/LIe5aVQ2RdJyUTmVKhR2hGFGsw5O5hJONTE7HZydDo2tOQBMu451HXrHI3RiK/VgMvgGheFa7NLbL4QYH0Z/fxnjKuJzx/BevnjPuZcLvvIoFbGSkmySiosV4PJNjgHXf75N67KivpYAYp+kDfeAEe1kFgNkdU1W1wQ7Kc4oo369x5n/OodszAgqDEhrqrIXdCxSMW66mGJF5fOtInYDNGq4vYSkVSNaHxHPjqXvYaInTjJUO6rrkrVlh7NJis0yMaLbTaynGTw9DciumTYVeQC5LwvAuBBPORKHqEU4M20xXHf3SFsBVjs0r/axWhV2wDhwpfLCX1+83/howGgW5l/JKlvD64wq3V8tzh2cf7HwK4/SBCOowkujalH14PJNog1L3FZ4nRF6lJGH+p6qHIC/l9F8dQP/1i5qmKDSnPhYg2SpMHqzrLCX5K03MHgDQzylyWpj71L/RJ10ZVa+0o6qe6myuyXTYaEnTjJMUtL20LFFLS9CnsMwJm8GuGu7BKGL89pVlO+R/vyz4vJ0ldgLEbgDsGEAvT5mZ4gz1cSORnh7MWkrwN3qEez43PiZgOa1gIU/2cOELnqri0qzSi07/kphuBcGfPKBU6JTP72M7icwTLDPnkRduD6WaHeoSM5MW4JghWpSqUoDmdfCl8+jahHZ08vVd0oVbfK14JVSCHzypjC1u9UjuLUnv727V6k3ebG554EiDzRpTZEHimjL0Lo0wL25RXpqARsGDBcDGlcSkUDdEVCHLLt38PAx0hPJDOWuGk9p0dFdLQZrQ1BwZqeDm+VQwDFmXuvSPV1nsKhxEkvatOQRDE+1iTr7UGCYAJybG/gXhljAvXyNpzfPkjcDVJrj7so5ZDlmvyu7eKMunqPVdZwZgWi4Wz1ufn6B3K+x8nsDRnM+9Qvy1XstHrPTkc8mpESpKlVesizDu7WNmW4CPklb7oEeGZKWLAOvN7abVGbI6h4uYFfXx8enW+TTcp+sFlczgPEVTgYz393F3ljFLs6h+wk28jEarOsUiNxijNK+4T4R9cdATxQzVDe93DUzS+3C1viEPEfvDqpob2nEqgvXaV31aM3NkCxNsfAnI1Sas/XiDPufP4vfLVyuBU5nNKfoncmxvmFqvkf2xw1O/dMtzHwb64qK4ESBeIuKhezMtLFhgL+2z94HZ/G6lqktw1ufrZF+sE/w7AeYfS2l/spb4Gpsry+I2tEI2x9gRiP04gIqDERKzE1jb6zKDlyLxNWJLEq3M8Rd36uiw167jnNVsJTDF8+w/8E6xle0rqZkcw2SQmVMaw711Zg81JWbOa0pkraivmqYPr8PW7tyz9IMekOSlWl0IufqkYFun2BnrKpSeMsOA0M8UcxQ3exigTg50O1De0p2UF2rdi7bqMFodMBAtavrBL0BZl52cONC9xQ0rymsFpXB+JKD0LyoAc3+c02c54ds/+QJZn7r+6jpFrYRicoxQfl8S/BOq+u0gPgz8/Se0sQzFrMTkp7JiNsu87XjRJspbq9FPBuyd8bDHcDmp3JmvqNZ/FcXyM+tkIcu/m2vul7CALIcpzuSnb1Qg3aem6F9OSZo1Ln4H68Qvb/D/u0mKlHEbY+g4xF0DNGmRJHdzhAn8vBaLv5eRn/JwxtYZr69JdK1VH/CADWK0aMMH8F90QrE5ijVM9cdbzxHkuHxkE1S7GlBhKowwG7tiDdpFGN7fZypJmZ1HXVCdGynF5DPt+ierhNPObjx2OAMtxVJG/yOxeta8QrNKtyBJaspavN9Bjs10r+2w/pfm6P2j6dpvrpR/fnm+dNsfbCON7BEmyH+dA29O6B3Evw9mP+OZf+UJvyzW3QadfLXA5KWy3Deo3FziN912fjpBBJN0lbsfO4ZZr5+hcGnT2M/fBo9ylG5qDzB+ZuwtYNqhmQNH7eX0LqWsPu3ezw1lZJeTsmvtmjectAx6KG4SuO2w877PYwHKm9VEnCwIIygY0O80sLbC3E6ffK5JoPliMaVLrob44wyrKfx9mJwXZmT61Yq3GGQCvCEMoMz1aT7VI3mS7cKCTBhfE78Sd1n2xgNaW2GPIBw1+DGlrjtoIeWPFLkPkQbluGCSIVwG7ye6NDuwKJ/Z4owh+HCHFnNMnpWoeM5ovUtOHuc3vGI2pahv+gALp1zPrX1iKf+IGHtUwGbH1H4e7DzVpupY12+/N/+L3y19zz//PrHCOo90v0p1F4dve3SuGkYzTp0P32aqZdXxRaJfJzNDs58u1Kd1IXreMDtX/gAcRviSx67epr5l53CNSpMnUeqyNmwNK9B532WpOngdw39RblfSVOhctkgslM+xm+icqiv56ibtyUKHYvLWWUG5bo4cTa2ZTgcUgGeUGawUVDtbqYZonsDgT4MC4xSFMBgSBYocl9VvvPRtCBKSwmwf9bQuO6QRwq/S2FcC0RB5SIZQCKzpctxcC5hJ/FZ+ZZHPBsRTzk4GQQdS/PGiKTtYVxFd8XH+JZoU+EOYLgC3RtT/Lu/+XdI2orBkmFwa4HhvOXUi29xpXcMqx1q6zm9ZU3cXGH+dyRabLOM0WKN7Rd8mjfaTH3tdVQtYv+sgfkYNgOaVzSjOUgbwtAgkgGEKZzEEm44ZIHFL/wAVoOTyPUZLapi0LGkNfFM2SSVNNWJAByurpji7QKLj5qeKGYog1bxyRnyQGGjAGeYFrvUOBBUgt3qawmdswFOBmQSfQ53DfGUMEXr+5A2wfgQbFvcWD7PA1V4WawgXRNJInYyUD0tjDE3Qx46GF/yAfZPOcTtCL9rMVrRPaVImwY9VGQ1eOafjNBXb1dQbbIM1ahXnqTn2IWzx9k/1yQPQA/F7snmGnQ/MkdtI8UdWDpPa1q1iN4nT9F+eof+d2fRw9LFKtfvFAZvFU0umMLJhTEGc7o63xTICqvlfe4rkSiZlXm6Guu5VQDOeq44Edw7QtiHgA5n9OMhUSmO04ZGx1YM2SyvssNslh3YrbK6vgt24ORUNoNAuItFECmyQNE9oekvO2Q1+TzYFfiG1RYnUTixQ9qwZHMNAfxpiV3EM8I43sDSPaWIZ3NUptCJxDTy0B17hAZDccl6bmXXlDScc8SYjxTxSos81OS+KrBJoBNI3rcCwO6N6UrqWQ1JS+aZ1dR4cQfjBe93RGUyvnzmdy2OBLWlyMBEhmqwPcIOhuL1GsbV8ep1lh86SMYTxQwlJU0Hb2CK9M4B6GKnCwNUGFZxCL+TVpgbbyA50GlN0XlGXIlPfX0bq8HrWrIaJO0iQq0hbSrSBvSOKwZLCidRuEUYINhRjOZ89k/IuKNZ+azxVo7R4A7B7Tm4Q1FbjAv+Zr+KZahaJIyQZpKIBOx+/nlu/JeK3Y9kUmSgK6C8pOWyfxY2PiqMbTXsnwzQI0N0S2MdSJuW3pkcrwfRxhhPtXdOHmlT8izCXcNgCQZLEOyL/eQNLE4mjODkljyQsdWF6zhTTbHB2k2BxBeBxrQViDS+I7/7cdPhYs2HTJNIz2A7lkSUTnFAayh2LRWG2CTFvbRK1DhB/5hXJPJDFiimLkNtI2W40ix2/fEYVlPp1F7X4g4k7qBjee91ASy3P6GxjqV5Hfyugq4irTnkgUiC0YwsUq8LSUsxODVFdGNVAnWui+1K9psKA/IPnmX/lCNlSXJFuGWrUjBpTRjR68m4XlfsmmSg8bti6EcblnxD4w7GEi+rieHuDgV7ZLVCJ5aVb8S4vUSCkHMOtS1D7kvSk45FxZu6Hh8AQ9pSCrgaO4rvWXjgMNCTxQxFkMobWPTFWzA3IzuUqw+iVhGXZ+94hL+fY1wxnr2B5EC3L8d4L18k/ei5agGV6lK5cOI2uEPFcAFReWYSTM9DRRk2d3D23OJ7YlPEswongcU/2CxwQKEsygiSluX2J1xOdM7iXduQ6HURSLOjmO4JKTmTXpiiua2obQn8OpnS+F1DuC0Sa7igyGqW9gXLaNohacpit4XxW1LJTJsfBT1UNK9B0DGM2oJp8tdGtF5P0U+36C1r3EFxz1xF81aCv9mvoOfOTHscu/Fc8Nxxll+x6RwWeqLUJFtgdvy9CdRnqbdWMAFJ9CmrXgiQbWxcAngdsSv8712jvm6I27LzT+rMpcQIt6FxXVN7NaJ93iW8GBJe93FihR6OF6HR0F+B2z81z/7JgNZVMXhHSzkmMMx+z+Bd2zgAryjtm+aNEUHHSmLQluQigCzO/qImn0jCqe6FhjyyDOctcVsMZeOLRHBy8Qj5HYfGzfG1GFfQtyV8JdxKKptBF3ZU0nLv2lgqmiwTk2UH4gyHgZ4oZgCgWcfbiwWch7hZyXLo9gXaEEqUNLq8TR4o+kseTm4ro9kdIMlAhWdq7VMOvLiHk9jKC+Mk4n70O2JLqLxQfQTEidcTQ7ZkHqvFSPX3xI2aB7D9vMdgCXTXIVorUjaLmkQHglRZxvrHaqTNQt0JYP1jNfZOu+S+EmkQUSQpQdAp3L0JOImidRFqa5bRrCz2UtXRsRx3BxRRdfESGU0FuYCxraATyfuI1uMDWCYbBuKyLpOmJhiiiuwfEunwZDFDllXBHxv5Ig20ludJY851Me06RqvqAWNQWkl2MMTrKQZ74hItpYeoTCVjFLtwIK+DDrgDi3FlMZbqFcBodqxy9VdyskjKVPpdqvyGe5WImbqRV6qK1TA4ZklaMFxUpA1LuC0uX52MjX3jF8b0Gdg/WxQOqLxkssDr67ks8kAg7I3VnMbNoezqnkvacKv5QiE5woPuNzWKRYIV1UfyZiBppYeEASbpiWIGm6RkDR81FNlu2nWxF7RkXqlGHTWKyU8fo/Ncg6wo5ZjVxowQT0t8wiYpqhZx/HcGtL/j0zsuwbOsJjsoiNpRLjAdS6RaD8V1GW2IUet3LQvf2iHasBgP+suK3Rcs06d3yZs5xhvDpSdpMp+h+eoGtfWc0axisARTz2+TnBsSty0msLQvJ4Q7WRUkcwfyHG6LXeN1xS5wB2I/dE/B1ocUa5/S7J11aLyVU1/Pqd/o496UGIxd3yK61cW4ktNQ2h3GVQfdvRPGM1qTh1I+81653Y+bnihmUL5UxlO9gRT2LWoAqVE8Ln0yktpAjVtJteNNpnw6WYHIBGhP4b55g6Wvb+B3bOFRoYAwjMfNfYnmRrum8tlnEURbknOczNdZ+HaX+luFfz9TeNrgNFKse/C3ShXJJuk4O293j+bVPq3LhrRpyXKN3fOxDtTWHNy+1HiSxT4u/BV0DOG2RMX3zsHu+2D/k0O8Z/cxgaFxSxFuW/z9nMGcZu9cQ4z3YlzVGxDtmqr0JkAypYmPjYtIj20cuYg8cKqSnCVa9bDQu/ImKaWuAV0gBzJr7YtKqRngXwKngGvAX7XW7t7vNx4lTYpmE7g4ZFK+pCdJNf7aPmZe0KDVee5Y5Ynb4oEpy8io3gBz/BiXvtCicUsx843bDM/OkocOSdOBgeCY8qgAvDUd3IH8nqvB70p1jf2TAVktELUoByeFnb06S3N7JF9fZPbXv1dFnQ9cQxF3sEmKunCd/Z/+AHZmxPD1NuFAsfjthOilKwxfPIOTw+z5Eb0Vn7Qmqp9OxNXaeNOv1Dl1O8LrhkRIAE7iEh5+1zL9jSuomTZmR2wmqTllDwQnvYGRerQff4bwzTWZ32iEWZpD9YZSKqc7tuYPk7r0ICTDT1prP2ytfbF4/yXgd62154DfLd4/cvpB1SNAdFsTCDTAhgFZXTM81a4YwetJ8KoMpDm5GMhlMSzle9gsw9nssPCyYfnf3MSub1E7v0rjzR0A6mtpYSso/EJXd+6QGvW1BG9gaF1JaV/KMT7oWJFthuz2I/rLSnId7kj3hINlYUhTkpbFJpqgIyqYdRX5uRU653x6yxp/bb/KQ/AGRmIQucUU0ef2payQVhJUA8EaLf7BJtOv7oort9gI5ENfUlVjg9Fyn/xOir9fuFInPUapOClANpHyWn5sJMN96PPATxSvfxX4feA/fwjj/EC6X/UIqegmlSl0P8GEhRGYWfw9sSWyuofxCqh2R4zNtCYRWL+rYG4GOvtikC/N0Xq9U2GEANjaYea7muGK1F3yOxKfcJKxCzKOHPqLmsYfXcJLUpypJlGWsX/6aQZLhnBDM6RBI0Gy03Y6VVJSdY2D4Xgx1SLR/697DOctU1ek5OP283WO/er35JwTy0VRMwcnHwPsog2RAGlNejeMFhVprFn6Py8dlEYnlrE3uuPCBIhaVAbRnEwqEJY9JcIi0cgmKXgahczpwL06RPRuJYMFflsp9XLRbwFg0Vq7BlA8L9zri0qpLyqlXlJKvZTYR4deLCtC5IGDGiZSKa8okqsygzPKqlqoJRLTSYqAWmKrNNESKKeG4xL2ANnxOezxY+TNgP2TnpSfLFCrbiwQiSwQJKzVSL8CqH6z9AqpHJzYYTRrx3WG7uOXF/shEI9QAiYQg9b71uvMv7xXnZ/M1xlN6yJdU75bZqGpXKLqAMN5S2M1rzBQzkxbcjwirwDfjXFSxlVVBNpMbK1pzZEgW3nfhwk067i95N39gQ+R3i0zfNpa+xHgc8AvKqU++06/+LD7M9xT/E64T6v+CXPNCt9jApfemWZVFhLKYJQ8Rm3NYG7iH89yyV3e7KBOLKOWF7HaIW2H7D5bJ6spgs44EaiChBdruwK5+Z4UF07SA8A5dwjpfMbWB4tSjROVPVQtqsq/A3Q/vCRjRBLV7i9bnNkZuHxTQH3PniSe8SSY1rUCHc9LuLUwan/Jw40tCy8baqtSTMDsdOQ6o0CKEgyG8ijupZPZiqHKWIyTw9xLOxX615lqwtaOpIBu7h1U7w4RvStmsNauFs8bwG8g/dzWlVJLAMXzxrud5I80tzv6GNxJplSXMoMdjXD7KbqfEK3HpDWH3opfRFzHksHJLUFXWjFN/r7Z72Iij2RpCpWbonS7qES5r6rfEMkg4+tYAnklirN01cYzFhMZ0oYlaRucKCNu3x3fsIPhuMTN4hydp128rtgKeigLvIRJW08amGSBwviqAuzpWKSWcYVRjVbETUfiCqHkdajFOakrlWZ3LWLrSXS7JCk3aYjWY1RvIPe+gLvYJBWU7uiOUPghoh+ZGZRSdaVUs3wN/AxwHvgK8AvFab8A/Ot3O8l3Q5O2g03Syi4ou8qYwJVUxG5M2g7JQ83UxS6NW0m1g5cUt6WeKFBh9VWjLgvGlSJhziirsDdBEYGGgwkw4rkRBCxQ6d/Z08vkPtSuy3u/42CGLqPnixyGVK7FmWrKboswxsX/6BjJJ7qCPj2ZkzUMSduw+RMrqOVFWchpXqlBZaCvLI5WXmfJ/HHbob/kky22yBZbMN2qFrEz1RwXEmtPeN20wo2lwIJ+9fLY49aoYxs1kZquEuY4ZGjVkt6NAb0I/IZSqvydf2Gt/ZpS6tvA/6GU+lvADeDfe/fTfHA02WTPug5OXBQPu72Jbkp0S61tkS+eAAo1yR1Hla1mDDwbxaJXL86hdwdEI3HVGneMBXImYBdwMFpbqkk06yjE+Mxrhlg75LMpeU+j/BytDYMXT1I/f3ussqSZeJkaNfKaIduJmL4JWU3TfS7FayTsvq9G0J1l6uVVifwWHrFJUJ6gW9UBxq+uE6TCeOBj17fGkiHLsF5dihhrhTPZPULfI2knyzHNgnEmSsQcNvqRmcFaewX40D2ObwN//t1M6kHSJI5H1SJUp49tNwVZ6WlxrbabsJXhvHZVvuR7hddFFq3xSyyPvM4WW3jDeJwIpLUY4Zsdui+uSIwBihqtQBl3qo3hGcYH1ZVYgWrUGH74BFsf0NIvLYfGmz53KzCmAAAYtUlEQVRe19I9GZA1Dbc/4TA1t0IeSNQ6bqvK2A43xK3ZPWlRxuJuu7jXPdKGZf1Fh6mX5bzg4m1qM8dJa6pC4Jq8cPsGqkrvVLlIhxIha549iTp7HNa2KlshW2wxmnErqLhObNWey5troF+9LMxaGNHxbFj1eDhMsYVJ+rGPQE/q9sqVhBjrCWS7jEJbT49LMxZuQ7eXVNlbZeS2pEn8jTPVhM4+w5Wm1EXSAsHIalT50KWBWc1Jj20ItbyIjXz2znjEC3mh9yvitsA2lAGViDrVX5YaRfunHEazYotkNQi3Jf4RbSraFwTPlDYs7lCRR5Z8vlWNXSYopbWx9MoCUXGcxFbFwLyurRb+aDHChG4FtrNJStpwK3tBYOtFdb1wQo0E0FrwSa461J4keAKYoaTS2LS9PnndL/6gQmcOXVnISQrTLfLTxyQgV2SswUEId3/JIz0lHmPbqGEHQ8L1Aao3ZDjtMJouei0nYnCnNUU8rarFI5Bqy9TVkRjdN2/TPSkIVZUXjQW7B3MMsqiQSkV+Q1azDJYkAy1uCzLVagHdSdBNpEX9lsOVv9Ikq4sjwY2FyYwv9sG4lLyqysPkATRvJcQvHGf/Z98vjQ1fu1oheoEDrbDSmrihvYHkcpTV+iYDdGUTyQOxkUNGTwwzVOS6JG2vEt8laM+6jhiou3tS6yfO8Aa2KBQsX60MTa3G0iHPRaKk0q4p2DcH0Ktxs0j6H9gqEQhE1XG3euhRJkkummoBQ5F8P6HHOyViO7JksxlZw5BFltznLkM/KzZlryfj5pFl75QPriZaLwzhSl076KlyY8FXpQ0pr+/k4/wNkE2lNN4nySlKymQT3qUKO4VU0yuN8CM16RHR/XYd5XuyK7nSu9i067JbuhqrC9FeF9dP1o6wrtQHcgdU6sSk8Zs2CqTrMBaPyY3VKrJaJsw7GUUFb1UlzuSRqnZiXI3e6jJ6TmIEOgHjC8NkUaHqDBROrMhPjBitpJjA4vQ0TuzQuKUk52AoizttFEUHCldw0pL8apUJEtb2+lUL3UkSSLc68D5pOtQu7dL85lWpuzTTlgJkRSn/bKIYgkA6iuBb0WwdqJKA8vkW0a3uoZYK8GPIDAdaOk32OpsoxKtHhrQVoEc5JvLGDdFdF+ZmRHJo5260aj7O+irdkiBepbJosJOLGuTGttot3YGtqkyUkqa+XhQj2N1j75RfFRJQucL4ljwQphiuZGSzGeeWN3jq+DYmMjixqEGlcT+ct4wWDF5P4gxp0xb5CqJOlYUIysaCTjZ2CuihrZ6hdP8WEqqzL/CPMi3WFTd0Ml+vVLgyLxwg3Mnw94te0UXOA0gBANWRVNXDKhXgx4AZftBOc78bH2yPSBsad6uHCSQgZV1HIAZ5TjylGc35uP1ceg+0JYhWMkRWEz3dLknvBOW62DDAmWpKQ8QqlVNVzOMOLMG26Os6hsa3rkkWWKNOPKsId6QQmdgahWGaQLjmEl33SI3mE/PXaFxxJUuu8Gx1XjC4Q5i6PI4Z6Lj4/lDyJtKmxfpWduYwZLgwLgdT2gxQSAh3zBjVffTcqpqFOb5Af8mvjGaVS9ceb1DAsl2Fu9UT/Fbgkx2fk9Zdd8QXDqOEeM8zww+902RZ0SNgTGUTvrIHgVsl5BjpYzbhdy/LouSBEsN7v1t5XWyWUV/Pqa0LinMSq1NKGXcgeQR2b78qg5/7Yh9kNchqtlKxjCv1VlUOG7+9wm9882Ms/2EPryeMM5qxqETRuA5JUySL0ZK1VkoWJwMnLvpKp5I6OmmbWD2WfFaP4w1lxUFViyRoV3iSyta3xlVVoK1M6ilL26veoMgezEla0u9uslfej/S/PQJ6oqpjQPEnrK5Ta4bYyJeGIFmOyjRmuokaxTRf2yZeaeGkhsalPXK/zWjaqfKIVW5xUCQtn9JEVKO4YorSMzPpDdJDWXBSoUIR/bkXsK5i+3mPeNYQbBel6idKUepYFqc7hOXf76Bu3sYeP8b0hYxwK+HYr4r+f/XvvEC8kBFsaEkkKvKbpQiyvLddjarXxABOpB5TsFsUCSsYt5xj2lQ4XTtOePLqqKGgT91egjdwGbU1OrEMp6W8ZvOmqJ+186tVRXPVG5CHMzRe26ywV3B4Cg3fSU8cM0ARc+j0GZ6dJbrWwUaSCmqaIU4YYAuId/dESNhwiTZT0prsbII2LfowzLhMQgxVQyrzGb8s2Ds2pkuwXx5Z0iZ0V0R3H83YKokmi0RCGPdgRY54xrL+qRZLu10sAo4bzfnUzx4nr/skJ2OcnYMupaxmK/VH5TKf3meeJloXqaiTcTqpLspflimcozkNqPHi7fbHLYELd7Q3MIXHS+FtG/y9DCc1mP2ueJuKYs7+XnZX+f3DyAjwhDFD1WvBdWF3jzycJ5trCCQjF1XJTDfh8k18lklakv/g3+ozBew+U8A1irZPk61fyw6demTQQwHhlVgklYtXJ21a5r9riDZT1j8utY5qtyFp6Wrhu0Xd0yyyZJHFupbamsOxX7+EGQxhp0MtXSZrR6i1LfRgyMl/8Sw773MYHCvh2AKRMK5ImiwSaHd/UTNq15m+KKC5wZxTdTOFsWMg94uqeJN6vatRvsdwMRxjmlwKVVARXLxd1XMqKT49T3DxNpbDywCT9J63GX4omqg5pMIQr5dXFR5sI5JsLAoxfmMVPTKMpsU96N/axRtYiQ8MxnnOZTqm2e+C6xKuDwj2TZWzUKJEdQL1VUW0mdI5GzCclxiBGLFW6q/W5DltWPKawdQMJjISbyjqwYpU6x5wkUav3JAKGUNFtFkGCVVlSKuiH3kZRIze6lO/0a/aUJWLunQhV3GLooWu3LNxbdTS8C5fA2NoSpZhowAz3ZRWusV9eS/Qe2OWD4gmE9DtaET45hqDF5alErenJa8hKuqthiHh/3uBWtG4kOkWOrYMFjV6aAk6gsVRrospGgnaLEOtbeEv1qootB6Km7O2bpj57i5rPznL/lnD1GWnMrD9Penz4HchbkuswaSSO93+vsPCt/flxLPHyUMXvTvAKcu8uy6DF5YZzI1rszpJoQb5VG5SlUvFcIBrn29LH4mi1GQ5x1Kazbye03q9M26BVWSsqXCilL9WmLIUUtdU91Y16pBmxLMRwXYsORFFrvZhpyeKGQ6A9nwPOxpRe3OdwXOLhOsDQYMO4woVWuYqqFpEPteUaGxX1I8ywFTuiHY0kh2wWSeri9pTlprPapZw2yH+yVn2nsnxjw3oZg38vbEaldWk1pEpvEBeV+FtiNG+83yT2lZEWpOCybWtrqhlmXh5nMwydT1lHw+VK3onc6xv0V1hGK83hpTkhQ2TNKXRiJNL+XonoSoSAEj8pZQEpfE7N10gci3ptMx9/rtSPsaWKlWBCFa5lRL6hxShei96opjhXgW4zE6HPFwir/toijIwWhdFfYuSKK6Le3OLIDyGyl36ixpT/saxebixWjUjz5+WXVrHsrji54aEUcLwovRRto2ceC9EUwSsIqltVHqTiuo1ou8X8Ymp61Lbtba8SDYnZVhsFDA8u8xw3iXazPB6Gcb3RSUbOJh8HCsoYx2lpwnG77lHJcg8UEX1EO6CW5fxBOMLwtVd2606l0JRBGBpDreXHOw++h6gJ4oZ7qSy8UftrQHd03Var/aqxnxAlbxTqgj+967hT7foHl8qjFNHVKsJiTNcFN0hD6SyRuOlCONHMCMo0tqrPmmjhDEAKJxCQpQeIJVLXCDctix+4zZ0++TPn8YZZehXL5M/fxq9O8DrZWR1zf5Jj+GCXyFVvZ5C7QliVVyswhhT1+R5NOsU0k0ewwVVVdtzcmHi/nJA683sgGqZzNfx92TM2fMjgqubAFUPbACadUaLNaKXrkDhsDisrtQ76YlmBgCyDL22g3OiTl40F7S9vjBB2V52cofr9gm3pdiwk9sD+rBaXiQLpIpGt+i9YIoF5++pqqRj1XeBsjaRKip4j9UZJ5EK3ht/7hhubOk8I6Xlw+0WeaCorddov7GP23dR0w7RhmW0ZMibMPMdAQf2muOaqgLJEM+RHlpMU5G0LE4qTRqBqu2WBOKKuRR51jZJiWekwMGorQldRZDlVaFmoCrL+V6lJ5YZKqxS0Re6+c2rdD99mnpm0L2wYgizIyA1syNJ/2Q5U1cHxLMB8ZRm/W+8IC7SLYPRsH/KqQJlWTRGh056XybBf0lTduVsIr1YQHaWbCElDzzCbafKipt5IyZpuQzmNJe+0CJbSAluSQOU5kUtWKUFiWd4XYlU7z2TE25oyWNoKomQ+4KEdQeq8mq5Q2EIr1vUXZ2bqYoIm+dPk9YUWSDX1/jqJclvm8hcs4Mhg6dqhFtJdfy9IhXgSXOt3oPKpHU7GEoL19nw7n5jWV75z/PpmtgP2zHBvhT89buWYCel95RmuJSLQRyNdXXZ/QUiIYjSoh2UK3nS4ZatPD5ZVHTarIlu7nWlA1DQgdnXc/y1fQZzGje2tC6C6ukCRSso1TLAl0UlaBBsZDD+uMOONzDCXKcHDFdkIZeqVAnii6ccCUYWyU556FK26/K79kBzeWACBCjQ9LLe0nuFEQCUtfbtz3rI1NJz9pONv/hY5+BMSaZa70yT5oWOlF3PMkmGX98aB6COzUvHn7UdaZvb2Yf2FG99TpJ9SrWodG1mtRLnVGCThkVAqzBcdSzFjOMZ0e9L5tHPizs1vTBV2RFZZMmbBpUo6rdkH0sbgkUyxfQmcUclM9bWxlUwyud4Vip0g6hw0sxEejx4PaivGtpv7JO2Q4bz8uNlUlLruxviaCgCjSAS1jx/Wjp5Xrj+8P6oH4G+1fsKe/nW27YLeuIlQ0l2NELdvC0GYntcp2iyOR8AW7vEs6EwQlEYQPUGUnWvUcKw5VTjW7KGIY/GG07asIxmx7bBaK7sl1BkuPXkvNGNJqMbzYqJ4tmcrJ3jbztYbek+nzCct4TbovN7PVV04ZGgXdmMxB1C61qCTmwFKy+z98o4R5lF53WldVUWQdxWqN6QeMZjOCflY9KaYupiV3pZhIHcs9LjVotIWr7URTqEiNR3QkfMwDj+oMKQ4JWrdE+ExC8crwJGJQ6//OOD7RHZXAO7vkV++hgACy/HkllWaA1GC4RaDxxpXxuJmlTmK5TQab8j+rk7FFWovyJlXs7+XyNOfTUlaRupmt1zKiDewp8o5v/Aq6LNZawiaRvihRwTiOQJduTzrQ8ExG1BmZadRdOGrfKtjW8ZLBmGSzn9p0pmUtCVSLU7gHA3Z/Ebt6V48NIcdnW9SqXFdcmeXiaZ0gdrsb7H6IgZCioLCUNRlLcxmYCcVZ8rV3oaq9zgzLRRmSE9tUB4aYOpG9JgRCelR2aMNZIWtqKCeD3JftOJ5DHvfigXN2eA5B34FifOCM7fxOsqjCdqVqlGhbs5YScnaUkLKhBVaOV3LYt/5BBuOITbtupE2ngrl6CaW8YHhAmcIqHI31PU1hz8joPXU8z9qWXmjRhzfAGVFTD2zMLunjR7GSYH7g1ZRtpwJQbxHoFe3IuOmIEJz1JhDDZe20SPDGa+fUAq2MFQcDc7HfTV28Sn53G6I3Q/YfDcIvsnNPGMrTxDZW4BUC3kpFXgkCLoHXdo3LQs/+5E3nCieOrUFlf+tuaN/+YkP/W579J6TpqPmA92OfN/D6ld2sXJLGnTMjyTMJqx9E6O0bRJS1ShKthW9Jc2vkSey6w6EIYtPV3BjqSMJk3F3imfznMN1DBh6uqAcH1A/OHTYiutro+7eRbSMqtrwvXhoa2J9E7oiBkKKoNLNpGiAMH2iNFibVwepSz6O4yrfGqrFeQ5zm6Xnff57D+fkrczjD9pICvptdwYq0kqF3dq2XQ8rTlVDEIPFavrbZyLNVZ+y+Fr/9+H8LR4lqI/bKJffpNkaQrjKqbPK2a/6Unvh5W0KgNTQTyiceP2kvTEpl528CkhGiXMHKgkkOoNcNd2UcMEt58eMJjL+6JCqYmkN/fecx6kSXpbmaaU+hXg54ENa+0LxbF7NiRRUl7vfwJ+DhgA/4G19jsPZ+oPh8ogk3N1Fad1mnRlFr3TqXa8CqacpPjbQ0y7jl7b4anf2qC2PsfWh1RlDDu5BNaUERWp6prpW8ItqkbqTgLJuSHpWkj7Taj9sUvjzU1s5PPs128CME3RNNDzBEHbiWj80W0AFgoXp/I9hi+eASQ4tn8WYFzGsjScy7hHWQm8xCzpRNSt4YKUqQ/Xh+RLM0XpTI/g/E1xoSISodwgBi8sE13ergoivJdiC5P0TiTDPwF+9o5j92tI8jngXPH4IvAPHsw0Hx3ZZLz7wRheca8SKSXk2zZq4Gqmv3GFld9L8Xplh8wixuCIi1US9YvyLq7AIAZLRrw5PQ+vJ0XCBnNaVJGbt8djFQXOpCxNBpdvVrvwpK/f30sqkKA7UJX9cq/6TzoeS7BSXcpq0is6KYodO8O0agM82Z2zBAnapTnp3DPpfn6P0tsyg7X2D4GdOw5/HmlEQvH8lyaO/1Mr9C2gXVbkPsxUgcwmVSUgfHMNt5+P2+QWhnRFW7uS+ZXncHsTFQZ0zvkkrbFXSQ8l2d94YB2qaG8eKeKFHL/jHCxbH0HnOUg+/swBY7Sc0+2/+ixrP7dC76fff9c12KU5rvwlqVzhDSyty4b6qqG/IgG5MhruDuWRB6oqdTkZAfe6imDbin3gafy9hOCVq4JBKvBcAGanQ/9kA3/vYKT5vSgV4Ee3Ge7XkOQp4ObEebeKY3fR42pWci86kOdwR880fy+RqndFEk+5QKv3UOFxbK8vYLequYn4+rOoXIAKE1jp4umCu+eQtKXoWHTLxd+T8+zSiP6Sd9AYPXuc3meeJm0qOu8z3Pr5XKAgBaMy3WLzoy3ypbhqRjJ1dUDzxmgiBjH+uXF0fMwcUPSj7kLjtpSSz+u+4LXuWOCTTOFvv7fQqfejB+0Hu1eU754hbmvtLwO/DBKBfsDz+KHpznpLJYPoi7fY/5lngBW8ly+iJiLSNkmrso1hoUPPfe0y7aeXuf1JqXoR7BSJ+TNl9FmRx5r5V0YM5z1W/7wlq7mc/sfXsO0mtz87Q+ubIRsfN/SXn+Opb+yz83yTeFoR7FpWfrtDMhuRtFw2PwyXfmGecHuBY98a0PsLPeyepJPGUw56MaS3rKtK4HG7AAEW11n1nSh4Lg8EMj736hD30ipmaY6k7aFfLfBJBVRbuS74HvnpYzQu7WFvrN77T36P0TuCYyilTgFfnTCgLwA/Ya1dK9Sg37fWPquU+ofF6y/fed7b/H4XuPCuruTd0xywdTSHH8s5nLTWzr/dST+qZCgbkvx3HGxI8hXgl5RSvwZ8Ath7O0Yo6MJEt9DHQkqpl47m8GTP4Z24Vr+MdO+cU0rdAv4rhAnu1ZDkNxG36iXEtfofPoQ5H9ERPRR6W2aw1v71+3x0V0MSKzrXL77bSR3RET0OOiwR6F9+3BPgaA4lPbFzOBT5DEd0RIeBDotkOKIjeuz02JlBKfWzSqkLSqlLSqkvvf03Hti415RS31NKvaKUeqk4NqOU+rpS6mLxPP2Ax/wVpdSGUur8xLF7jqmE/ufivryqlPrIQxr/7yml3iruwytKqZ+b+Oy/KMa/oJT6C+92/OI3jyulfk8p9YZS6jWl1H9SHH9k9+G+ZK19bA9AA5eBM4AP/Cnw/kc09jVg7o5j/wPwpeL1l4D//gGP+VngI8D5txsT8cr9FhLI/CTwxw9p/L8H/Gf3OPf9xf8RAKeL/0k/gDksAR8pXjeB7xdjPbL7cL/H45YMHwcuWWuvWGsT4NcQfNPjovthrh4I2ceM87rP+PejzwO/Zq2NrbVXEXf5x9/N+MUc1myBZLbWdoE3EMjOY8e7PW5meMdYpodAFvhtpdTLSqkvFsfuh7l6mPSucV4PgH6pUEF+ZUI1fOjjF8iGPwP8MYfgPjxuZnjHWKaHQJ+21n4EgZ3/olLqs49o3HdKj+re/APgLPBhYA34+49ifKVUA/hXwH9qrd3/Qac+zHlM0uNmhlvA8Yn3K8DqoxjYWrtaPG8Av4GoAOulCC6eNx7BVO435iO5N9badWttbq01wP/OWBV6aOMrpTyEEf65tfbXi8OP9T7A42eGbwPnlFKnlVI+8AUE3/RQSSlVV0o1y9fAzwDnGWOu4CDm6mHS/cb8CvA3C2/KJ3nnOK8fiu7Qv/8ych/K8b+glAqUUqeRhK0/eQDjKeAfAW9Ya//HiY8e630AHq83acJb8H3EW/F3H9GYZxBPyZ8Cr5XjArNI5t7F4nnmAY/7ZUQVSZEd72/db0xEPfhfi/vyPeDFhzT+Pyt+/1Vk4S1NnP93i/EvAJ97QPfgM4ia8yrwSvH4uUd5H+73OIpAH9ERFfS41aQjOqJDQ0fMcERHVNARMxzRERV0xAxHdEQFHTHDER1RQUfMcERHVNARMxzRERV0xAxHdEQF/f++64hlKjwEqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "img = sitk.ReadImage(data_path + train_ids[0] + '/' + img_name)\n",
    "msk = sitk.ReadImage(data_path + train_ids[0] + '/' + msk_b)\n",
    "img_array = sitk.GetArrayFromImage(img)\n",
    "msk_array = sitk.GetArrayFromImage(msk)\n",
    "\n",
    "%pylab inline\n",
    "subplot(121)\n",
    "imgplot = plt.imshow(np.flip(np.flip(img_array[:,136,:]), 1))\n",
    "plt.show()\n",
    "subplot(122)\n",
    "plt.imshow(np.flip(np.flip(msk_array[:,136,:]), 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n"
     ]
    }
   ],
   "source": [
    "#Trying to break the data and then concate to a 1.2w*64*64 data set.\n",
    "\n",
    "train_z = np.ndarray((103 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y = np.ndarray((320 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x = np.ndarray((232 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_z = np.ndarray((103 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_y = np.ndarray((320 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_x = np.ndarray((232 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "for i in range(len(train_ids)):\n",
    "    ind_prof = next(os.walk(data_path + '/' + train_ids[i]))[2]\n",
    "    img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "    msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "    img = sitk.ReadImage(data_path + train_ids[i] + '/' + img_name)\n",
    "    msk = sitk.ReadImage(data_path + train_ids[i] + '/' + msk_b)\n",
    "    img_array = sitk.GetArrayFromImage(img)\n",
    "    msk_array = sitk.GetArrayFromImage(msk)\n",
    "    \n",
    "    #z = np.ndarray((103, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #y = np.ndarray((320, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #x = np.ndarray((232, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    for z in range(img_array.shape[0]):\n",
    "        train_z[z + i*103,:,:,0] = resize(img_array[z,:,:], (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
    "    for y in range(img_array.shape[1]):\n",
    "        train_y[y + i*320,:,:,0] = np.flip(np.flip(resize(img_array[:,y,:], (IMG_H, IMG_W),\n",
    "                                            mode='constant', preserve_range=True), 1))\n",
    "    for x in range(img_array.shape[2]):\n",
    "        train_x[x + i*232,:,:,0] = np.flip(np.flip(resize(img_array[:,:,x], (IMG_H, IMG_W),\n",
    "                                            mode='constant', preserve_range=True), 1))\n",
    "    \n",
    "    #z_msk = np.ndarray((103, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #y_msk = np.ndarray((320, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #x_msk = np.ndarray((232, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    for z in range(msk_array.shape[0]):\n",
    "        mask_z[z + i*103,:,:,0] = resize(msk_array[z,:,:], (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
    "    for y in range(msk_array.shape[1]):\n",
    "        mask_y[y + i*320,:,:,0] = np.flip(np.flip(resize(msk_array[:,y,:], (IMG_H, IMG_W),\n",
    "                                                mode='constant', preserve_range=True), 1))\n",
    "    for x in range(msk_array.shape[2]):\n",
    "        mask_x[x + i*232,:,:,0] = np.flip(np.flip(resize(msk_array[:,:,x], (IMG_H, IMG_W),\n",
    "                                                mode='constant', preserve_range=True), 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12445, 64, 64, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = np.concatenate((train_x, train_y, train_z), axis=0)\n",
    "tmp2 = np.concatenate((mask_x, mask_y, mask_z), axis=0)\n",
    "tmp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 103, 320, 232, 1) (19, 103, 320, 232, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Trying to directly obtrain data with shape of (# of patients)*original\n",
    "#size of the image.\n",
    "\n",
    "X_data = np.ndarray((len(train_ids), img_array.shape[0], img_array.shape[1], img_array.shape[2], 1), dtype=np.uint8)\n",
    "Y_mask = np.ndarray((len(train_ids), msk_array.shape[0], msk_array.shape[1], msk_array.shape[2], 1), dtype=np.uint8)\n",
    "for i in range(len(train_ids)):\n",
    "    ind_prof = next(os.walk(data_path + '/' + train_ids[i]))[2]\n",
    "    img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "    msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "    img = sitk.ReadImage(data_path + train_ids[i] + '/' + img_name)\n",
    "    msk = sitk.ReadImage(data_path + train_ids[i] + '/' + msk_b)\n",
    "    img_array = sitk.GetArrayFromImage(img)\n",
    "    msk_array = sitk.GetArrayFromImage(msk)\n",
    "    for z in range(img_array.shape[0]):\n",
    "        X_data[i,z,:,:,0] = img_array[z,:,:]\n",
    "    for y in range(img_array.shape[1]):\n",
    "        X_data[i,:,y,:,0] = img_array[:,y,:]\n",
    "    for x in range(img_array.shape[0]):\n",
    "        X_data[i,:,:,x,0] = img_array[:,:,x]\n",
    "        \n",
    "    for z in range(msk_array.shape[0]):\n",
    "        Y_mask[i,z,:,:,0] = msk_array[z,:,:]\n",
    "    for y in range(msk_array.shape[1]):\n",
    "        Y_mask[i,:,y,:,0] = msk_array[:,y,:]\n",
    "    for x in range(msk_array.shape[0]):\n",
    "        Y_mask[i,:,:,x,0] = msk_array[:,:,x]\n",
    "        \n",
    "\n",
    "subplot(121)\n",
    "imshow(X_data[18,51,:,:,0])\n",
    "subplot(122)\n",
    "imshow(Y_mask[18,51,:,:,0])\n",
    "print(X_data.shape, Y_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the input, due to err:\"expected input_3 to have\n",
    "#shape (65, 65, 65, 1) but got array with shape (103, 320, 232, 1)\"\n",
    "def preprocessing(arch_name):\n",
    "    #X_global = []\n",
    "    #X_local = []\n",
    "    #Y = []\n",
    "    \n",
    "    if arch_name == 'input':\n",
    "        s = 65\n",
    "        X2 = np.ndarray((s, s, s, 1), dtype=np.uint8)\n",
    "        X1 = np.ndarray((33, 33, 33, 1), dtype=np.uint8)\n",
    "        Y = np.ndarray((s, s, s, 1), dtype=np.uint8)\n",
    "        for i in range(1):\n",
    "            print(str(i+1)+'/19 data processed')\n",
    "            for z in range(0, X_data.shape[1]-s, 5):\n",
    "                for y in range(0, X_data.shape[2]-s, 25):\n",
    "                    for x in range(0, X_data.shape[3]-s, 20):\n",
    "                        if X_data[i,z+16:z+49,y+16:y+49,x+16:x+49,0].any() != 0:\n",
    "                            print(X2[:,:,:,0].shape)\n",
    "                            print(X_data[i,z:z+s,y:y+s,x:x+s,0].shape)\n",
    "                            break\n",
    "                            X2[:,:,:,0] = np.concatenate((X2[:,:,:,0], X_data[i,z:z+s,y:y+s,x:x+s,0]))\n",
    "                            X1[:,:,:,0] = np.concatenate((X1[:,:,:,0], X_data[i,z+16:z+49,y+16:y+49,x+16:x+49,0]))\n",
    "                            Y[:,:,:,0] = np.concatenate((Y[:,:,:,0], Y_mask[i,z:z+s,y:y+s,x:x+s,0]))\n",
    "    \n",
    "    #X1 = np.asarray(X_global)\n",
    "    #X2 = np.asarray(X_local)\n",
    "    #Y_out = np.asarray(Y)\n",
    "    \n",
    "    return [X1, X2, Y]    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/19 data processed\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n"
     ]
    }
   ],
   "source": [
    "f_data = preprocessing('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4f01630add47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "a = ndarray((1, 65,65,1))\n",
    "b = ndarray((65,65,1))\n",
    "c = np.concatenate((a,b))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_path3D(X_input, arch_type):\n",
    "    if arch_type == 'input':\n",
    "        #upper path\n",
    "        X = Conv3D(64, (7, 7, 7), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X1 = Conv3D(64, (7, 7, 7), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X1 = Maximum()([X,X1])\n",
    "        X1 = MaxPooling3D((4,4,4), strides=(1,1,1), padding='valid')(X1)\n",
    "        \n",
    "        X = Conv3D(64, (3,3,3), strides=(1,1,1), padding='valid')(X1)\n",
    "        X1 = Conv3D(64, (3,3,3), strides=(1,1,1), padding='valid')(X1)\n",
    "        X1 = Maximum()([X,X1])\n",
    "        X1 = MaxPooling3D((2,2,2), strides=(1,1,1), padding='valid')(X1)\n",
    "        \n",
    "        #lower path\n",
    "        X = Conv3D(160, (13, 13, 13), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X2 = Conv3D(160, (13, 13, 13), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X2 = Maximum()([X,X2])\n",
    "        \n",
    "        #concatenation\n",
    "        X = concatenate([X1,X2], axis=4)\n",
    "        X = Conv3D(5, (21, 21, 21), strides=(1,1,1), padding='valid')(X)\n",
    "        #X = Activation('softmax')(X)\n",
    "    \n",
    "        #model = Model(inputs=X_input, outputs=X)\n",
    "        return X\n",
    "def InputCascadeCNN(shape1, shape2):\n",
    "    #concatenate input and output of the 1st two path network\n",
    "    X1 = Input(shape1)\n",
    "    X = two_path3D(X1, 'input')\n",
    "    \n",
    "    X2 = Input(shape2)\n",
    "    X = concatenate([X, X2], axis=4)\n",
    "    X = two_path3D(X, 'input')\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=[X1,X2], outputs=X)\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 65, 65, 65, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 59, 59, 59, 6 22016       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 59, 59, 59, 6 22016       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_4 (Maximum)             (None, 59, 59, 59, 6 0           conv3d_7[0][0]                   \n",
      "                                                                 conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 56, 56, 56, 6 0           maximum_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 54, 54, 54, 6 110656      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 54, 54, 54, 6 110656      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_5 (Maximum)             (None, 54, 54, 54, 6 0           conv3d_9[0][0]                   \n",
      "                                                                 conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 53, 53, 53, 1 351680      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 53, 53, 53, 1 351680      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 53, 53, 53, 6 0           maximum_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_6 (Maximum)             (None, 53, 53, 53, 1 0           conv3d_11[0][0]                  \n",
      "                                                                 conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 53, 53, 53, 2 0           max_pooling3d_4[0][0]            \n",
      "                                                                 maximum_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 33, 33, 33, 5 10372325    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 33, 33, 33, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 33, 33, 33, 6 0           conv3d_13[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 27, 27, 27, 6 131776      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 27, 27, 27, 6 131776      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maximum_7 (Maximum)             (None, 27, 27, 27, 6 0           conv3d_14[0][0]                  \n",
      "                                                                 conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 24, 24, 24, 6 0           maximum_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_8 (Maximum)             (None, 22, 22, 22, 6 0           conv3d_16[0][0]                  \n",
      "                                                                 conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3D)  (None, 21, 21, 21, 6 0           maximum_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_9 (Maximum)             (None, 21, 21, 21, 1 0           conv3d_18[0][0]                  \n",
      "                                                                 conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 21, 21, 21, 2 0           max_pooling3d_6[0][0]            \n",
      "                                                                 maximum_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 1, 1, 1, 5)   10372325    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 1, 5)   0           conv3d_20[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,416,778\n",
      "Trainable params: 26,416,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1 = InputCascadeCNN((65,65,65,1), (33,33,33,1))\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0,0:64,0:64,0:64,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 65, 65, 65, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 59, 59, 59, 6 22016       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 59, 59, 59, 6 22016       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_10 (Maximum)            (None, 59, 59, 59, 6 0           conv3d_21[0][0]                  \n",
      "                                                                 conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3D)  (None, 56, 56, 56, 6 0           maximum_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 54, 54, 54, 6 110656      max_pooling3d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 54, 54, 54, 6 110656      max_pooling3d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_11 (Maximum)            (None, 54, 54, 54, 6 0           conv3d_23[0][0]                  \n",
      "                                                                 conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 53, 53, 53, 1 351680      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)              (None, 53, 53, 53, 1 351680      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3D)  (None, 53, 53, 53, 6 0           maximum_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maximum_12 (Maximum)            (None, 53, 53, 53, 1 0           conv3d_25[0][0]                  \n",
      "                                                                 conv3d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 53, 53, 53, 2 0           max_pooling3d_8[0][0]            \n",
      "                                                                 maximum_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 33, 33, 33, 5 10372325    concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 33, 33, 33, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 33, 33, 33, 6 0           conv3d_27[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)              (None, 27, 27, 27, 6 131776      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)              (None, 27, 27, 27, 6 131776      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maximum_13 (Maximum)            (None, 27, 27, 27, 6 0           conv3d_28[0][0]                  \n",
      "                                                                 conv3d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3D)  (None, 24, 24, 24, 6 0           maximum_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_30 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_31 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_14 (Maximum)            (None, 22, 22, 22, 6 0           conv3d_30[0][0]                  \n",
      "                                                                 conv3d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_32 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_33 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling3D) (None, 21, 21, 21, 6 0           maximum_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maximum_15 (Maximum)            (None, 21, 21, 21, 1 0           conv3d_32[0][0]                  \n",
      "                                                                 conv3d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 21, 21, 21, 2 0           max_pooling3d_10[0][0]           \n",
      "                                                                 maximum_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_34 (Conv3D)              (None, 1, 1, 1, 5)   10372325    concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 1, 1, 5)   0           conv3d_34[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,416,778\n",
      "Trainable params: 26,416,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_4 to have 5 dimensions, but got array with shape (29640, 33, 33, 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c3de9d579bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m m1.fit([f_data[1],f_data[0]], f_data[2], batch_size=8, epochs=50, verbose=1, shuffle=True,\n\u001b[1;32m     13\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         callbacks=[model_checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_4 to have 5 dimensions, but got array with shape (29640, 33, 33, 33)"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "m1 = InputCascadeCNN((65,65,65,1), (33,33,33,1))\n",
    "#m1 = get_unet()\n",
    "print(m1.summary())\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "m1.fit([f_data[1],f_data[0]], f_data[2], batch_size=8, epochs=50, verbose=1, shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Processed_Data/img_z', oz)\n",
    "np.save('../Processed_Data/img_y', oy)\n",
    "np.save('../Processed_Data/img_x', ox)\n",
    "np.save('../Processed_Data/msk_z', oz_msk)\n",
    "np.save('../Processed_Data/msk_y', oy_msk)\n",
    "np.save('../Processed_Data/msk_x', ox_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_z = np.ndarray((len(oz), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y = np.ndarray((len(oy), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x = np.ndarray((len(ox), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_z_m = np.ndarray((len(oz_msk), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y_m = np.ndarray((len(oy_msk), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x_m = np.ndarray((len(ox_msk), IMG_H, IMG_W, 1), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n"
     ]
    }
   ],
   "source": [
    "for n, img in enumerate(oz):\n",
    "    train_z[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oy):\n",
    "    train_y[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(ox):\n",
    "    train_x[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oz_msk):\n",
    "    train_z_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oy_msk):\n",
    "    train_y_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(ox_msk):\n",
    "    train_x_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 128, 128, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 1)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 32) 320         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 32)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 16, 16, 256)  524544      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 512)  0           conv2d_transpose_13[0][0]        \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 256)  0           conv2d_transpose_14[0][0]        \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 128)  0           conv2d_transpose_15[0][0]        \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 128, 128, 64) 0           conv2d_transpose_16[0][0]        \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 128, 128, 1)  33          conv2d_75[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,759,521\n",
      "Trainable params: 7,759,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Train on 92 samples, validate on 11 samples\n",
      "Epoch 1/3000\n",
      "92/92 [==============================] - 6s 61ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1107e-05 - val_dice_coef: 1.1107e-05\n",
      "Epoch 2/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1105e-05 - val_dice_coef: 1.1105e-05\n",
      "Epoch 3/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1103e-05 - val_dice_coef: 1.1103e-05\n",
      "Epoch 4/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1101e-05 - val_dice_coef: 1.1101e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1099e-05 - val_dice_coef: 1.1099e-05\n",
      "Epoch 6/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1098e-05 - val_dice_coef: 1.1098e-05\n",
      "Epoch 7/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1096e-05 - val_dice_coef: 1.1096e-05\n",
      "Epoch 8/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1094e-05 - val_dice_coef: 1.1094e-05\n",
      "Epoch 9/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1092e-05 - val_dice_coef: 1.1092e-05\n",
      "Epoch 10/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1091e-05 - val_dice_coef: 1.1091e-05\n",
      "Epoch 11/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1089e-05 - val_dice_coef: 1.1089e-05\n",
      "Epoch 12/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1088e-05 - val_dice_coef: 1.1088e-05\n",
      "Epoch 13/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1087e-05 - val_dice_coef: 1.1087e-05\n",
      "Epoch 14/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1085e-05 - val_dice_coef: 1.1085e-05\n",
      "Epoch 15/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1084e-05 - val_dice_coef: 1.1084e-05\n",
      "Epoch 16/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1082e-05 - val_dice_coef: 1.1082e-05\n",
      "Epoch 17/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1081e-05 - val_dice_coef: 1.1081e-05\n",
      "Epoch 18/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 19/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1079e-05 - val_dice_coef: 1.1079e-05\n",
      "Epoch 20/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 21/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 22/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1076e-05 - val_dice_coef: 1.1076e-05\n",
      "Epoch 23/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 24/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1074e-05 - val_dice_coef: 1.1074e-05\n",
      "Epoch 25/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 26/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 27/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 28/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 29/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 30/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 31/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 32/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 33/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 34/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 35/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 36/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 37/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 38/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 39/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 40/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 41/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 42/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 43/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 44/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 45/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 46/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1074e-05 - val_dice_coef: 1.1074e-05\n",
      "Epoch 47/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 48/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 49/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1076e-05 - val_dice_coef: 1.1076e-05\n",
      "Epoch 50/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 51/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 52/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1078e-05 - val_dice_coef: 1.1078e-05\n",
      "Epoch 53/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1078e-05 - val_dice_coef: 1.1078e-05\n",
      "Epoch 54/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1079e-05 - val_dice_coef: 1.1079e-05\n",
      "Epoch 55/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 56/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 57/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1081e-05 - val_dice_coef: 1.1081e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1082e-05 - val_dice_coef: 1.1082e-05\n",
      "Epoch 59/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1083e-05 - val_dice_coef: 1.1083e-05\n",
      "Epoch 60/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1083e-05 - val_dice_coef: 1.1083e-05\n",
      "Epoch 61/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1084e-05 - val_dice_coef: 1.1084e-05\n",
      "Epoch 62/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1085e-05 - val_dice_coef: 1.1085e-05\n",
      "Epoch 63/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1086e-05 - val_dice_coef: 1.1086e-05\n",
      "Epoch 64/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1087e-05 - val_dice_coef: 1.1087e-05\n",
      "Epoch 65/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1088e-05 - val_dice_coef: 1.1088e-05\n",
      "Epoch 66/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1089e-05 - val_dice_coef: 1.1089e-05\n",
      "Epoch 67/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1090e-05 - val_dice_coef: 1.1090e-05\n",
      "Epoch 68/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1091e-05 - val_dice_coef: 1.1091e-05\n",
      "Epoch 69/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1092e-05 - val_dice_coef: 1.1092e-05\n",
      "Epoch 70/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1093e-05 - val_dice_coef: 1.1093e-05\n",
      "Epoch 71/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1094e-05 - val_dice_coef: 1.1094e-05\n",
      "Epoch 72/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1096e-05 - val_dice_coef: 1.1096e-05\n",
      "Epoch 73/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1097e-05 - val_dice_coef: 1.1097e-05\n",
      "Epoch 74/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1098e-05 - val_dice_coef: 1.1098e-05\n",
      "Epoch 75/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1100e-05 - val_dice_coef: 1.1100e-05\n",
      "Epoch 76/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1101e-05 - val_dice_coef: 1.1101e-05\n",
      "Epoch 77/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1102e-05 - val_dice_coef: 1.1102e-05\n",
      "Epoch 78/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1104e-05 - val_dice_coef: 1.1104e-05\n",
      "Epoch 79/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1105e-05 - val_dice_coef: 1.1105e-05\n",
      "Epoch 80/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1106e-05 - val_dice_coef: 1.1106e-05\n",
      "Epoch 81/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1108e-05 - val_dice_coef: 1.1108e-05\n",
      "Epoch 82/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1109e-05 - val_dice_coef: 1.1109e-05\n",
      "Epoch 83/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1110e-05 - val_dice_coef: 1.1110e-05\n",
      "Epoch 84/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1112e-05 - val_dice_coef: 1.1112e-05\n",
      "Epoch 85/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1113e-05 - val_dice_coef: 1.1113e-05\n",
      "Epoch 86/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1115e-05 - val_dice_coef: 1.1115e-05\n",
      "Epoch 87/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1116e-05 - val_dice_coef: 1.1116e-05\n",
      "Epoch 88/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1117e-05 - val_dice_coef: 1.1117e-05\n",
      "Epoch 89/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1118e-05 - val_dice_coef: 1.1118e-05\n",
      "Epoch 90/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1120e-05 - val_dice_coef: 1.1120e-05\n",
      "Epoch 91/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1121e-05 - val_dice_coef: 1.1121e-05\n",
      "Epoch 92/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1123e-05 - val_dice_coef: 1.1123e-05\n",
      "Epoch 93/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1125e-05 - val_dice_coef: 1.1125e-05\n",
      "Epoch 94/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1126e-05 - val_dice_coef: 1.1126e-05\n",
      "Epoch 95/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1128e-05 - val_dice_coef: 1.1128e-05\n",
      "Epoch 96/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1130e-05 - val_dice_coef: 1.1130e-05\n",
      "Epoch 97/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0111 - dice_coef: 0.0111 - val_loss: -1.1133e-05 - val_dice_coef: 1.1133e-05\n",
      "Epoch 98/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0111 - dice_coef: 0.0111 - val_loss: -1.1135e-05 - val_dice_coef: 1.1135e-05\n",
      "Epoch 99/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0112 - dice_coef: 0.0112 - val_loss: -1.1138e-05 - val_dice_coef: 1.1138e-05\n",
      "Epoch 100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0112 - dice_coef: 0.0112 - val_loss: -1.1140e-05 - val_dice_coef: 1.1140e-05\n",
      "Epoch 101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0113 - dice_coef: 0.0113 - val_loss: -1.1144e-05 - val_dice_coef: 1.1144e-05\n",
      "Epoch 102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0114 - dice_coef: 0.0114 - val_loss: -1.1148e-05 - val_dice_coef: 1.1148e-05\n",
      "Epoch 103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0115 - dice_coef: 0.0115 - val_loss: -1.1151e-05 - val_dice_coef: 1.1151e-05\n",
      "Epoch 104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0115 - dice_coef: 0.0115 - val_loss: -1.1156e-05 - val_dice_coef: 1.1156e-05\n",
      "Epoch 105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0116 - dice_coef: 0.0116 - val_loss: -1.1162e-05 - val_dice_coef: 1.1162e-05\n",
      "Epoch 106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0117 - dice_coef: 0.0117 - val_loss: -1.1167e-05 - val_dice_coef: 1.1167e-05\n",
      "Epoch 107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0118 - dice_coef: 0.0118 - val_loss: -1.1175e-05 - val_dice_coef: 1.1175e-05\n",
      "Epoch 108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0119 - dice_coef: 0.0119 - val_loss: -1.1183e-05 - val_dice_coef: 1.1183e-05\n",
      "Epoch 109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0121 - dice_coef: 0.0121 - val_loss: -1.1193e-05 - val_dice_coef: 1.1193e-05\n",
      "Epoch 110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0122 - dice_coef: 0.0122 - val_loss: -1.1207e-05 - val_dice_coef: 1.1207e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0124 - dice_coef: 0.0124 - val_loss: -1.1224e-05 - val_dice_coef: 1.1224e-05\n",
      "Epoch 112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0125 - dice_coef: 0.0125 - val_loss: -1.1242e-05 - val_dice_coef: 1.1242e-05\n",
      "Epoch 113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0128 - dice_coef: 0.0128 - val_loss: -1.1271e-05 - val_dice_coef: 1.1271e-05\n",
      "Epoch 114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0130 - dice_coef: 0.0130 - val_loss: -1.1302e-05 - val_dice_coef: 1.1302e-05\n",
      "Epoch 115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0133 - dice_coef: 0.0133 - val_loss: -1.1336e-05 - val_dice_coef: 1.1336e-05\n",
      "Epoch 116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0136 - dice_coef: 0.0136 - val_loss: -1.1398e-05 - val_dice_coef: 1.1398e-05\n",
      "Epoch 117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0139 - dice_coef: 0.0139 - val_loss: -1.1497e-05 - val_dice_coef: 1.1497e-05\n",
      "Epoch 118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0143 - dice_coef: 0.0143 - val_loss: -1.1565e-05 - val_dice_coef: 1.1565e-05\n",
      "Epoch 119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0149 - dice_coef: 0.0149 - val_loss: -1.1802e-05 - val_dice_coef: 1.1802e-05\n",
      "Epoch 120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0155 - dice_coef: 0.0155 - val_loss: -1.1994e-05 - val_dice_coef: 1.1994e-05\n",
      "Epoch 121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0161 - dice_coef: 0.0161 - val_loss: -1.2419e-05 - val_dice_coef: 1.2419e-05\n",
      "Epoch 122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0172 - dice_coef: 0.0172 - val_loss: -1.2878e-05 - val_dice_coef: 1.2878e-05\n",
      "Epoch 123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0185 - dice_coef: 0.0185 - val_loss: -1.4198e-05 - val_dice_coef: 1.4198e-05\n",
      "Epoch 124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0202 - dice_coef: 0.0202 - val_loss: -1.5069e-05 - val_dice_coef: 1.5069e-05\n",
      "Epoch 125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0230 - dice_coef: 0.0230 - val_loss: -1.8830e-05 - val_dice_coef: 1.8830e-05\n",
      "Epoch 126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0277 - dice_coef: 0.0277 - val_loss: -2.5383e-05 - val_dice_coef: 2.5383e-05\n",
      "Epoch 127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0338 - dice_coef: 0.0338 - val_loss: -3.0613e-05 - val_dice_coef: 3.0613e-05\n",
      "Epoch 128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0440 - dice_coef: 0.0440 - val_loss: -3.7309e-05 - val_dice_coef: 3.7309e-05\n",
      "Epoch 129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0589 - dice_coef: 0.0589 - val_loss: -5.4508e-05 - val_dice_coef: 5.4508e-05\n",
      "Epoch 130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0796 - dice_coef: 0.0796 - val_loss: -8.9018e-05 - val_dice_coef: 8.9018e-05\n",
      "Epoch 131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0968 - dice_coef: 0.0968 - val_loss: -7.3245e-05 - val_dice_coef: 7.3245e-05\n",
      "Epoch 132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1158 - dice_coef: 0.1158 - val_loss: -1.5367e-04 - val_dice_coef: 1.5367e-04\n",
      "Epoch 133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1511 - dice_coef: 0.1511 - val_loss: -2.6846e-04 - val_dice_coef: 2.6846e-04\n",
      "Epoch 134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1832 - dice_coef: 0.1832 - val_loss: -3.1565e-04 - val_dice_coef: 3.1565e-04\n",
      "Epoch 135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1991 - dice_coef: 0.1991 - val_loss: -1.4018e-04 - val_dice_coef: 1.4018e-04\n",
      "Epoch 136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1806 - dice_coef: 0.1806 - val_loss: -4.9281e-04 - val_dice_coef: 4.9281e-04\n",
      "Epoch 137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2291 - dice_coef: 0.2291 - val_loss: -2.9947e-04 - val_dice_coef: 2.9947e-04\n",
      "Epoch 138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2629 - dice_coef: 0.2629 - val_loss: -2.4638e-04 - val_dice_coef: 2.4638e-04\n",
      "Epoch 139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2359 - dice_coef: 0.2359 - val_loss: -7.2372e-04 - val_dice_coef: 7.2372e-04\n",
      "Epoch 140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2803 - dice_coef: 0.2803 - val_loss: -2.6312e-04 - val_dice_coef: 2.6312e-04\n",
      "Epoch 141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2769 - dice_coef: 0.2769 - val_loss: -0.0012 - val_dice_coef: 0.0012\n",
      "Epoch 142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3336 - dice_coef: 0.3336 - val_loss: -4.0191e-04 - val_dice_coef: 4.0191e-04\n",
      "Epoch 143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3543 - dice_coef: 0.3543 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 144/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3593 - dice_coef: 0.3593 - val_loss: -3.4966e-04 - val_dice_coef: 3.4966e-04\n",
      "Epoch 145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3690 - dice_coef: 0.3690 - val_loss: -0.0038 - val_dice_coef: 0.0038\n",
      "Epoch 146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3731 - dice_coef: 0.3731 - val_loss: -5.3135e-04 - val_dice_coef: 5.3135e-04\n",
      "Epoch 147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3957 - dice_coef: 0.3957 - val_loss: -0.0028 - val_dice_coef: 0.0028\n",
      "Epoch 148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4610 - dice_coef: 0.4610 - val_loss: -0.0023 - val_dice_coef: 0.0023\n",
      "Epoch 149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4710 - dice_coef: 0.4710 - val_loss: -0.0014 - val_dice_coef: 0.0014\n",
      "Epoch 150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4698 - dice_coef: 0.4698 - val_loss: -0.0074 - val_dice_coef: 0.0074\n",
      "Epoch 151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4465 - dice_coef: 0.4465 - val_loss: -0.0016 - val_dice_coef: 0.0016\n",
      "Epoch 152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4922 - dice_coef: 0.4922 - val_loss: -0.0030 - val_dice_coef: 0.0030\n",
      "Epoch 153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5099 - dice_coef: 0.5099 - val_loss: -0.0074 - val_dice_coef: 0.0074\n",
      "Epoch 154/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5115 - dice_coef: 0.5115 - val_loss: -0.0033 - val_dice_coef: 0.0033\n",
      "Epoch 155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5275 - dice_coef: 0.5275 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5467 - dice_coef: 0.5467 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5057 - dice_coef: 0.5057 - val_loss: -0.0020 - val_dice_coef: 0.0020\n",
      "Epoch 158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5405 - dice_coef: 0.5405 - val_loss: -0.0041 - val_dice_coef: 0.0041\n",
      "Epoch 159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5680 - dice_coef: 0.5680 - val_loss: -0.0095 - val_dice_coef: 0.0095\n",
      "Epoch 160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5403 - dice_coef: 0.5403 - val_loss: -0.0082 - val_dice_coef: 0.0082\n",
      "Epoch 161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5418 - dice_coef: 0.5418 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5725 - dice_coef: 0.5725 - val_loss: -0.0022 - val_dice_coef: 0.0022\n",
      "Epoch 163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5570 - dice_coef: 0.5570 - val_loss: -0.0157 - val_dice_coef: 0.0157\n",
      "Epoch 164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5478 - dice_coef: 0.5478 - val_loss: -0.0057 - val_dice_coef: 0.0057\n",
      "Epoch 165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5625 - dice_coef: 0.5625 - val_loss: -0.0017 - val_dice_coef: 0.0017\n",
      "Epoch 166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5734 - dice_coef: 0.5734 - val_loss: -0.0263 - val_dice_coef: 0.0263\n",
      "Epoch 167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5060 - dice_coef: 0.5060 - val_loss: -0.0012 - val_dice_coef: 0.0012\n",
      "Epoch 168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5289 - dice_coef: 0.5289 - val_loss: -0.0095 - val_dice_coef: 0.0095\n",
      "Epoch 169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5431 - dice_coef: 0.5431 - val_loss: -0.0043 - val_dice_coef: 0.0043\n",
      "Epoch 170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5746 - dice_coef: 0.5746 - val_loss: -0.0021 - val_dice_coef: 0.0021\n",
      "Epoch 171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5672 - dice_coef: 0.5672 - val_loss: -0.0185 - val_dice_coef: 0.0185\n",
      "Epoch 172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5998 - dice_coef: 0.5998 - val_loss: -0.0021 - val_dice_coef: 0.0021\n",
      "Epoch 173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5934 - dice_coef: 0.5934 - val_loss: -0.0227 - val_dice_coef: 0.0227\n",
      "Epoch 174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5620 - dice_coef: 0.5620 - val_loss: -0.0024 - val_dice_coef: 0.0024\n",
      "Epoch 175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5871 - dice_coef: 0.5871 - val_loss: -0.0051 - val_dice_coef: 0.0051\n",
      "Epoch 176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6136 - dice_coef: 0.6136 - val_loss: -0.0080 - val_dice_coef: 0.0080\n",
      "Epoch 177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6234 - dice_coef: 0.6234 - val_loss: -0.0028 - val_dice_coef: 0.0028\n",
      "Epoch 178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6085 - dice_coef: 0.6085 - val_loss: -0.0268 - val_dice_coef: 0.0268\n",
      "Epoch 179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6012 - dice_coef: 0.6012 - val_loss: -0.0029 - val_dice_coef: 0.0029\n",
      "Epoch 180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6337 - dice_coef: 0.6337 - val_loss: -0.0189 - val_dice_coef: 0.0189\n",
      "Epoch 181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6154 - dice_coef: 0.6154 - val_loss: -0.0062 - val_dice_coef: 0.0062\n",
      "Epoch 182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6435 - dice_coef: 0.6435 - val_loss: -0.0052 - val_dice_coef: 0.0052\n",
      "Epoch 183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6477 - dice_coef: 0.6477 - val_loss: -0.0080 - val_dice_coef: 0.0080\n",
      "Epoch 184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6506 - dice_coef: 0.6506 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6532 - dice_coef: 0.6532 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6516 - dice_coef: 0.6516 - val_loss: -0.0236 - val_dice_coef: 0.0236\n",
      "Epoch 187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6464 - dice_coef: 0.6464 - val_loss: -0.0035 - val_dice_coef: 0.0035\n",
      "Epoch 188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6166 - dice_coef: 0.6166 - val_loss: -0.0066 - val_dice_coef: 0.0066\n",
      "Epoch 189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6000 - dice_coef: 0.6000 - val_loss: -0.0093 - val_dice_coef: 0.0093\n",
      "Epoch 190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6448 - dice_coef: 0.6448 - val_loss: -0.0034 - val_dice_coef: 0.0034\n",
      "Epoch 191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6118 - dice_coef: 0.6118 - val_loss: -0.0278 - val_dice_coef: 0.0278\n",
      "Epoch 192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6444 - dice_coef: 0.6444 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6396 - dice_coef: 0.6396 - val_loss: -0.0102 - val_dice_coef: 0.0102\n",
      "Epoch 194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6707 - dice_coef: 0.6707 - val_loss: -0.0072 - val_dice_coef: 0.0072\n",
      "Epoch 195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6327 - dice_coef: 0.6327 - val_loss: -0.0024 - val_dice_coef: 0.0024\n",
      "Epoch 196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6094 - dice_coef: 0.6094 - val_loss: -0.0249 - val_dice_coef: 0.0249\n",
      "Epoch 197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6616 - dice_coef: 0.6616 - val_loss: -0.0029 - val_dice_coef: 0.0029\n",
      "Epoch 198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6442 - dice_coef: 0.6442 - val_loss: -0.0407 - val_dice_coef: 0.0407\n",
      "Epoch 199/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6436 - dice_coef: 0.6436 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6376 - dice_coef: 0.6376 - val_loss: -0.0210 - val_dice_coef: 0.0210\n",
      "Epoch 201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6463 - dice_coef: 0.6463 - val_loss: -0.0057 - val_dice_coef: 0.0057\n",
      "Epoch 202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6588 - dice_coef: 0.6588 - val_loss: -0.0055 - val_dice_coef: 0.0055\n",
      "Epoch 203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6548 - dice_coef: 0.6548 - val_loss: -0.0221 - val_dice_coef: 0.0221\n",
      "Epoch 204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6466 - dice_coef: 0.6466 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6399 - dice_coef: 0.6399 - val_loss: -0.0501 - val_dice_coef: 0.0501\n",
      "Epoch 206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6406 - dice_coef: 0.6406 - val_loss: -0.0042 - val_dice_coef: 0.0042\n",
      "Epoch 207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6891 - dice_coef: 0.6891 - val_loss: -0.0334 - val_dice_coef: 0.0334\n",
      "Epoch 208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6813 - dice_coef: 0.6813 - val_loss: -0.0030 - val_dice_coef: 0.0030\n",
      "Epoch 209/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6654 - dice_coef: 0.6654 - val_loss: -0.0236 - val_dice_coef: 0.0236\n",
      "Epoch 210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6557 - dice_coef: 0.6557 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6867 - dice_coef: 0.6867 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6828 - dice_coef: 0.6828 - val_loss: -0.0213 - val_dice_coef: 0.0213\n",
      "Epoch 213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6963 - dice_coef: 0.6963 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6900 - dice_coef: 0.6900 - val_loss: -0.0160 - val_dice_coef: 0.0160\n",
      "Epoch 215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7085 - dice_coef: 0.7085 - val_loss: -0.0060 - val_dice_coef: 0.0060\n",
      "Epoch 216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7012 - dice_coef: 0.7012 - val_loss: -0.0172 - val_dice_coef: 0.0172\n",
      "Epoch 217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7031 - dice_coef: 0.7031 - val_loss: -0.0050 - val_dice_coef: 0.0050\n",
      "Epoch 218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7066 - dice_coef: 0.7066 - val_loss: -0.0333 - val_dice_coef: 0.0333\n",
      "Epoch 219/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7029 - dice_coef: 0.7029 - val_loss: -0.0038 - val_dice_coef: 0.0038\n",
      "Epoch 220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6974 - dice_coef: 0.6974 - val_loss: -0.0762 - val_dice_coef: 0.0762\n",
      "Epoch 221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6840 - dice_coef: 0.6840 - val_loss: -0.0042 - val_dice_coef: 0.0042\n",
      "Epoch 222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7095 - dice_coef: 0.7095 - val_loss: -0.0456 - val_dice_coef: 0.0456\n",
      "Epoch 223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6927 - dice_coef: 0.6927 - val_loss: -0.0048 - val_dice_coef: 0.0048\n",
      "Epoch 224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6993 - dice_coef: 0.6993 - val_loss: -0.0125 - val_dice_coef: 0.0125\n",
      "Epoch 225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7147 - dice_coef: 0.7147 - val_loss: -0.0098 - val_dice_coef: 0.0098\n",
      "Epoch 226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7212 - dice_coef: 0.7212 - val_loss: -0.0073 - val_dice_coef: 0.0073\n",
      "Epoch 227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7165 - dice_coef: 0.7165 - val_loss: -0.0154 - val_dice_coef: 0.0154\n",
      "Epoch 228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7287 - dice_coef: 0.7287 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7251 - dice_coef: 0.7251 - val_loss: -0.0087 - val_dice_coef: 0.0087\n",
      "Epoch 230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7258 - dice_coef: 0.7258 - val_loss: -0.0120 - val_dice_coef: 0.0120\n",
      "Epoch 231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7331 - dice_coef: 0.7331 - val_loss: -0.0119 - val_dice_coef: 0.0119\n",
      "Epoch 232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7328 - dice_coef: 0.7328 - val_loss: -0.0118 - val_dice_coef: 0.0118\n",
      "Epoch 233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7270 - dice_coef: 0.7270 - val_loss: -0.0081 - val_dice_coef: 0.0081\n",
      "Epoch 234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7355 - dice_coef: 0.7355 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7344 - dice_coef: 0.7344 - val_loss: -0.0076 - val_dice_coef: 0.0076\n",
      "Epoch 236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7305 - dice_coef: 0.7305 - val_loss: -0.0531 - val_dice_coef: 0.0531\n",
      "Epoch 237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7165 - dice_coef: 0.7165 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7345 - dice_coef: 0.7345 - val_loss: -0.0081 - val_dice_coef: 0.0081\n",
      "Epoch 239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7349 - dice_coef: 0.7349 - val_loss: -0.0205 - val_dice_coef: 0.0205\n",
      "Epoch 240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7402 - dice_coef: 0.7402 - val_loss: -0.0069 - val_dice_coef: 0.0069\n",
      "Epoch 241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7214 - dice_coef: 0.7214 - val_loss: -0.0201 - val_dice_coef: 0.0201\n",
      "Epoch 242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7329 - dice_coef: 0.7329 - val_loss: -0.0245 - val_dice_coef: 0.0245\n",
      "Epoch 243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7348 - dice_coef: 0.7348 - val_loss: -0.0086 - val_dice_coef: 0.0086\n",
      "Epoch 244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7320 - dice_coef: 0.7320 - val_loss: -0.0145 - val_dice_coef: 0.0145\n",
      "Epoch 245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7330 - dice_coef: 0.7330 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7447 - dice_coef: 0.7447 - val_loss: -0.0222 - val_dice_coef: 0.0222\n",
      "Epoch 247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7501 - dice_coef: 0.7501 - val_loss: -0.0142 - val_dice_coef: 0.0142\n",
      "Epoch 248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7491 - dice_coef: 0.7491 - val_loss: -0.0147 - val_dice_coef: 0.0147\n",
      "Epoch 249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7529 - dice_coef: 0.7529 - val_loss: -0.0142 - val_dice_coef: 0.0142\n",
      "Epoch 250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7491 - dice_coef: 0.7491 - val_loss: -0.0514 - val_dice_coef: 0.0514\n",
      "Epoch 251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7485 - dice_coef: 0.7485 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7539 - dice_coef: 0.7539 - val_loss: -0.0343 - val_dice_coef: 0.0343\n",
      "Epoch 253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7467 - dice_coef: 0.7467 - val_loss: -0.0375 - val_dice_coef: 0.0375\n",
      "Epoch 254/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7548 - dice_coef: 0.7548 - val_loss: -0.0094 - val_dice_coef: 0.0094\n",
      "Epoch 255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7531 - dice_coef: 0.7531 - val_loss: -0.0179 - val_dice_coef: 0.0179\n",
      "Epoch 256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7568 - dice_coef: 0.7568 - val_loss: -0.0368 - val_dice_coef: 0.0368\n",
      "Epoch 257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7534 - dice_coef: 0.7534 - val_loss: -0.0270 - val_dice_coef: 0.0270\n",
      "Epoch 258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7571 - dice_coef: 0.7571 - val_loss: -0.0097 - val_dice_coef: 0.0097\n",
      "Epoch 259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7560 - dice_coef: 0.7560 - val_loss: -0.0201 - val_dice_coef: 0.0201\n",
      "Epoch 260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7627 - dice_coef: 0.7627 - val_loss: -0.0293 - val_dice_coef: 0.0293\n",
      "Epoch 261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7637 - dice_coef: 0.7637 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7538 - dice_coef: 0.7538 - val_loss: -0.0205 - val_dice_coef: 0.0205\n",
      "Epoch 263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7650 - dice_coef: 0.7650 - val_loss: -0.0238 - val_dice_coef: 0.0238\n",
      "Epoch 264/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7660 - dice_coef: 0.7660 - val_loss: -0.0292 - val_dice_coef: 0.0292\n",
      "Epoch 265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.0419 - val_dice_coef: 0.0419\n",
      "Epoch 266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7528 - dice_coef: 0.7528 - val_loss: -0.0428 - val_dice_coef: 0.0428\n",
      "Epoch 267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7596 - dice_coef: 0.7596 - val_loss: -0.0121 - val_dice_coef: 0.0121\n",
      "Epoch 268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7546 - dice_coef: 0.7546 - val_loss: -0.0121 - val_dice_coef: 0.0121\n",
      "Epoch 269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7489 - dice_coef: 0.7489 - val_loss: -0.0822 - val_dice_coef: 0.0822\n",
      "Epoch 270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7523 - dice_coef: 0.7523 - val_loss: -0.0180 - val_dice_coef: 0.0180\n",
      "Epoch 271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7621 - dice_coef: 0.7621 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7515 - dice_coef: 0.7515 - val_loss: -0.0182 - val_dice_coef: 0.0182\n",
      "Epoch 273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7665 - dice_coef: 0.7665 - val_loss: -0.1468 - val_dice_coef: 0.1468\n",
      "Epoch 274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7493 - dice_coef: 0.7493 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7508 - dice_coef: 0.7508 - val_loss: -0.0054 - val_dice_coef: 0.0054\n",
      "Epoch 276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7320 - dice_coef: 0.7320 - val_loss: -0.0317 - val_dice_coef: 0.0317\n",
      "Epoch 277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7667 - dice_coef: 0.7667 - val_loss: -0.0886 - val_dice_coef: 0.0886\n",
      "Epoch 278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7651 - dice_coef: 0.7651 - val_loss: -0.0332 - val_dice_coef: 0.0332\n",
      "Epoch 279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7680 - dice_coef: 0.7680 - val_loss: -0.0117 - val_dice_coef: 0.0117\n",
      "Epoch 280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7641 - dice_coef: 0.7641 - val_loss: -0.0450 - val_dice_coef: 0.0450\n",
      "Epoch 281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7727 - dice_coef: 0.7727 - val_loss: -0.0529 - val_dice_coef: 0.0529\n",
      "Epoch 282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7684 - dice_coef: 0.7684 - val_loss: -0.0181 - val_dice_coef: 0.0181\n",
      "Epoch 283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7581 - dice_coef: 0.7581 - val_loss: -0.0128 - val_dice_coef: 0.0128\n",
      "Epoch 284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7690 - dice_coef: 0.7690 - val_loss: -0.1661 - val_dice_coef: 0.1661\n",
      "Epoch 285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7511 - dice_coef: 0.7511 - val_loss: -0.0575 - val_dice_coef: 0.0575\n",
      "Epoch 286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7490 - dice_coef: 0.7490 - val_loss: -0.0060 - val_dice_coef: 0.0060\n",
      "Epoch 287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7464 - dice_coef: 0.7464 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.1159 - val_dice_coef: 0.1159\n",
      "Epoch 289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7589 - dice_coef: 0.7589 - val_loss: -0.0304 - val_dice_coef: 0.0304\n",
      "Epoch 290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7723 - dice_coef: 0.7723 - val_loss: -0.0227 - val_dice_coef: 0.0227\n",
      "Epoch 291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.1234 - val_dice_coef: 0.1234\n",
      "Epoch 292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7605 - dice_coef: 0.7605 - val_loss: -0.0438 - val_dice_coef: 0.0438\n",
      "Epoch 293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7657 - dice_coef: 0.7657 - val_loss: -0.0111 - val_dice_coef: 0.0111\n",
      "Epoch 294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7631 - dice_coef: 0.7631 - val_loss: -0.0315 - val_dice_coef: 0.0315\n",
      "Epoch 295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7672 - dice_coef: 0.7672 - val_loss: -0.1202 - val_dice_coef: 0.1202\n",
      "Epoch 296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7644 - dice_coef: 0.7644 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7772 - dice_coef: 0.7772 - val_loss: -0.0368 - val_dice_coef: 0.0368\n",
      "Epoch 298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7811 - dice_coef: 0.7811 - val_loss: -0.0406 - val_dice_coef: 0.0406\n",
      "Epoch 299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7793 - dice_coef: 0.7793 - val_loss: -0.0366 - val_dice_coef: 0.0366\n",
      "Epoch 300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7765 - dice_coef: 0.7765 - val_loss: -0.0462 - val_dice_coef: 0.0462\n",
      "Epoch 301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7801 - dice_coef: 0.7801 - val_loss: -0.0380 - val_dice_coef: 0.0380\n",
      "Epoch 302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7843 - dice_coef: 0.7843 - val_loss: -0.0308 - val_dice_coef: 0.0308\n",
      "Epoch 303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.0704 - val_dice_coef: 0.0704\n",
      "Epoch 304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7836 - dice_coef: 0.7836 - val_loss: -0.0287 - val_dice_coef: 0.0287\n",
      "Epoch 305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7746 - dice_coef: 0.7746 - val_loss: -0.0166 - val_dice_coef: 0.0166\n",
      "Epoch 306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7803 - dice_coef: 0.7803 - val_loss: -0.0775 - val_dice_coef: 0.0775\n",
      "Epoch 307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7800 - dice_coef: 0.7800 - val_loss: -0.1300 - val_dice_coef: 0.1300\n",
      "Epoch 308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7711 - dice_coef: 0.7711 - val_loss: -0.0263 - val_dice_coef: 0.0263\n",
      "Epoch 309/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.0347 - val_dice_coef: 0.0347\n",
      "Epoch 310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7814 - dice_coef: 0.7814 - val_loss: -0.1873 - val_dice_coef: 0.1873\n",
      "Epoch 311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7737 - dice_coef: 0.7737 - val_loss: -0.0234 - val_dice_coef: 0.0234\n",
      "Epoch 312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7865 - dice_coef: 0.7865 - val_loss: -0.0305 - val_dice_coef: 0.0305\n",
      "Epoch 313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7862 - dice_coef: 0.7862 - val_loss: -0.1655 - val_dice_coef: 0.1655\n",
      "Epoch 314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7647 - dice_coef: 0.7647 - val_loss: -0.0500 - val_dice_coef: 0.0500\n",
      "Epoch 315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7715 - dice_coef: 0.7715 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7758 - dice_coef: 0.7758 - val_loss: -0.0337 - val_dice_coef: 0.0337\n",
      "Epoch 317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7726 - dice_coef: 0.7726 - val_loss: -0.3706 - val_dice_coef: 0.3706\n",
      "Epoch 318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7635 - dice_coef: 0.7635 - val_loss: -0.0253 - val_dice_coef: 0.0253\n",
      "Epoch 319/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7743 - dice_coef: 0.7743 - val_loss: -0.0220 - val_dice_coef: 0.0220\n",
      "Epoch 320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7790 - dice_coef: 0.7790 - val_loss: -0.3092 - val_dice_coef: 0.3092\n",
      "Epoch 321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7765 - dice_coef: 0.7765 - val_loss: -0.0460 - val_dice_coef: 0.0460\n",
      "Epoch 322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.0553 - val_dice_coef: 0.0553\n",
      "Epoch 323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7894 - dice_coef: 0.7894 - val_loss: -0.0739 - val_dice_coef: 0.0739\n",
      "Epoch 324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7897 - dice_coef: 0.7897 - val_loss: -0.0448 - val_dice_coef: 0.0448\n",
      "Epoch 325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7875 - dice_coef: 0.7875 - val_loss: -0.1956 - val_dice_coef: 0.1956\n",
      "Epoch 326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7813 - dice_coef: 0.7813 - val_loss: -0.0695 - val_dice_coef: 0.0695\n",
      "Epoch 327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7855 - dice_coef: 0.7855 - val_loss: -0.0172 - val_dice_coef: 0.0172\n",
      "Epoch 328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7796 - dice_coef: 0.7796 - val_loss: -0.1357 - val_dice_coef: 0.1357\n",
      "Epoch 329/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.0997 - val_dice_coef: 0.0997\n",
      "Epoch 330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7906 - dice_coef: 0.7906 - val_loss: -0.0891 - val_dice_coef: 0.0891\n",
      "Epoch 331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0921 - val_dice_coef: 0.0921\n",
      "Epoch 332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0405 - val_dice_coef: 0.0405\n",
      "Epoch 333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7855 - dice_coef: 0.7855 - val_loss: -0.0510 - val_dice_coef: 0.0510\n",
      "Epoch 334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7910 - dice_coef: 0.7910 - val_loss: -0.1837 - val_dice_coef: 0.1837\n",
      "Epoch 335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7908 - dice_coef: 0.7908 - val_loss: -0.0455 - val_dice_coef: 0.0455\n",
      "Epoch 336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7915 - dice_coef: 0.7915 - val_loss: -0.0512 - val_dice_coef: 0.0512\n",
      "Epoch 337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7943 - dice_coef: 0.7943 - val_loss: -0.0565 - val_dice_coef: 0.0565\n",
      "Epoch 338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7922 - dice_coef: 0.7922 - val_loss: -0.1822 - val_dice_coef: 0.1822\n",
      "Epoch 339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7888 - dice_coef: 0.7888 - val_loss: -0.1480 - val_dice_coef: 0.1480\n",
      "Epoch 340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0323 - val_dice_coef: 0.0323\n",
      "Epoch 341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7877 - dice_coef: 0.7877 - val_loss: -0.0631 - val_dice_coef: 0.0631\n",
      "Epoch 342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7904 - dice_coef: 0.7904 - val_loss: -0.2945 - val_dice_coef: 0.2945\n",
      "Epoch 343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7871 - dice_coef: 0.7871 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7925 - dice_coef: 0.7925 - val_loss: -0.0235 - val_dice_coef: 0.0235\n",
      "Epoch 345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.2343 - val_dice_coef: 0.2343\n",
      "Epoch 346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.3386 - val_dice_coef: 0.3386\n",
      "Epoch 347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7806 - dice_coef: 0.7806 - val_loss: -0.0261 - val_dice_coef: 0.0261\n",
      "Epoch 348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7710 - dice_coef: 0.7710 - val_loss: -0.0138 - val_dice_coef: 0.0138\n",
      "Epoch 349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7821 - dice_coef: 0.7821 - val_loss: -0.1816 - val_dice_coef: 0.1816\n",
      "Epoch 350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7889 - dice_coef: 0.7889 - val_loss: -0.1050 - val_dice_coef: 0.1050\n",
      "Epoch 351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.0298 - val_dice_coef: 0.0298\n",
      "Epoch 352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0611 - val_dice_coef: 0.0611\n",
      "Epoch 353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7945 - dice_coef: 0.7945 - val_loss: -0.2319 - val_dice_coef: 0.2319\n",
      "Epoch 354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7917 - dice_coef: 0.7917 - val_loss: -0.0280 - val_dice_coef: 0.0280\n",
      "Epoch 355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7923 - dice_coef: 0.7923 - val_loss: -0.0318 - val_dice_coef: 0.0318\n",
      "Epoch 356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7939 - dice_coef: 0.7939 - val_loss: -0.3564 - val_dice_coef: 0.3564\n",
      "Epoch 357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7757 - dice_coef: 0.7757 - val_loss: -0.2784 - val_dice_coef: 0.2784\n",
      "Epoch 358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.0262 - val_dice_coef: 0.0262\n",
      "Epoch 359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.0401 - val_dice_coef: 0.0401\n",
      "Epoch 360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7981 - dice_coef: 0.7981 - val_loss: -0.1451 - val_dice_coef: 0.1451\n",
      "Epoch 361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7965 - dice_coef: 0.7965 - val_loss: -0.1857 - val_dice_coef: 0.1857\n",
      "Epoch 362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7975 - dice_coef: 0.7975 - val_loss: -0.1279 - val_dice_coef: 0.1279\n",
      "Epoch 363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7960 - dice_coef: 0.7960 - val_loss: -0.0669 - val_dice_coef: 0.0669\n",
      "Epoch 364/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7950 - dice_coef: 0.7950 - val_loss: -0.0174 - val_dice_coef: 0.0174\n",
      "Epoch 365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7857 - dice_coef: 0.7857 - val_loss: -0.2840 - val_dice_coef: 0.2840\n",
      "Epoch 366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7901 - dice_coef: 0.7901 - val_loss: -0.1057 - val_dice_coef: 0.1057\n",
      "Epoch 367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7978 - dice_coef: 0.7978 - val_loss: -0.0326 - val_dice_coef: 0.0326\n",
      "Epoch 368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8003 - dice_coef: 0.8003 - val_loss: -0.2679 - val_dice_coef: 0.2679\n",
      "Epoch 369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7977 - dice_coef: 0.7977 - val_loss: -0.0832 - val_dice_coef: 0.0832\n",
      "Epoch 370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7953 - dice_coef: 0.7953 - val_loss: -0.0212 - val_dice_coef: 0.0212\n",
      "Epoch 371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7756 - dice_coef: 0.7756 - val_loss: -0.0832 - val_dice_coef: 0.0832\n",
      "Epoch 372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7952 - dice_coef: 0.7952 - val_loss: -0.2984 - val_dice_coef: 0.2984\n",
      "Epoch 373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7982 - dice_coef: 0.7982 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 374/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7899 - dice_coef: 0.7899 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7938 - dice_coef: 0.7938 - val_loss: -0.4212 - val_dice_coef: 0.4212\n",
      "Epoch 376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7856 - dice_coef: 0.7856 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0200 - val_dice_coef: 0.0200\n",
      "Epoch 378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.1871 - val_dice_coef: 0.1871\n",
      "Epoch 379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8004 - dice_coef: 0.8004 - val_loss: -0.0478 - val_dice_coef: 0.0478\n",
      "Epoch 380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7945 - dice_coef: 0.7945 - val_loss: -0.1252 - val_dice_coef: 0.1252\n",
      "Epoch 381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8001 - dice_coef: 0.8001 - val_loss: -0.0781 - val_dice_coef: 0.0781\n",
      "Epoch 382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8039 - dice_coef: 0.8039 - val_loss: -0.0673 - val_dice_coef: 0.0673\n",
      "Epoch 383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8036 - dice_coef: 0.8036 - val_loss: -0.2480 - val_dice_coef: 0.2480\n",
      "Epoch 384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8073 - dice_coef: 0.8073 - val_loss: -0.1304 - val_dice_coef: 0.1304\n",
      "Epoch 385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.0706 - val_dice_coef: 0.0706\n",
      "Epoch 386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8046 - dice_coef: 0.8046 - val_loss: -0.1223 - val_dice_coef: 0.1223\n",
      "Epoch 387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7970 - dice_coef: 0.7970 - val_loss: -0.0542 - val_dice_coef: 0.0542\n",
      "Epoch 388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.0396 - val_dice_coef: 0.0396\n",
      "Epoch 389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.0432 - val_dice_coef: 0.0432\n",
      "Epoch 390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8010 - dice_coef: 0.8010 - val_loss: -0.0633 - val_dice_coef: 0.0633\n",
      "Epoch 391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7970 - dice_coef: 0.7970 - val_loss: -0.2965 - val_dice_coef: 0.2965\n",
      "Epoch 392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8006 - dice_coef: 0.8006 - val_loss: -0.0632 - val_dice_coef: 0.0632\n",
      "Epoch 393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.0993 - val_dice_coef: 0.0993\n",
      "Epoch 394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8019 - dice_coef: 0.8019 - val_loss: -0.1495 - val_dice_coef: 0.1495\n",
      "Epoch 395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8043 - dice_coef: 0.8043 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.1207 - val_dice_coef: 0.1207\n",
      "Epoch 397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8080 - dice_coef: 0.8080 - val_loss: -0.2400 - val_dice_coef: 0.2400\n",
      "Epoch 398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.0589 - val_dice_coef: 0.0589\n",
      "Epoch 399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7983 - dice_coef: 0.7983 - val_loss: -0.0306 - val_dice_coef: 0.0306\n",
      "Epoch 400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7974 - dice_coef: 0.7974 - val_loss: -0.2292 - val_dice_coef: 0.2292\n",
      "Epoch 401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7948 - dice_coef: 0.7948 - val_loss: -0.1820 - val_dice_coef: 0.1820\n",
      "Epoch 402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.0473 - val_dice_coef: 0.0473\n",
      "Epoch 403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7961 - dice_coef: 0.7961 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8052 - dice_coef: 0.8052 - val_loss: -0.1058 - val_dice_coef: 0.1058\n",
      "Epoch 405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.1093 - val_dice_coef: 0.1093\n",
      "Epoch 407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8056 - dice_coef: 0.8056 - val_loss: -0.1696 - val_dice_coef: 0.1696\n",
      "Epoch 408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7967 - dice_coef: 0.7967 - val_loss: -0.2107 - val_dice_coef: 0.2107\n",
      "Epoch 409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.2258 - val_dice_coef: 0.2258\n",
      "Epoch 410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.0673 - val_dice_coef: 0.0673\n",
      "Epoch 411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8081 - dice_coef: 0.8081 - val_loss: -0.0421 - val_dice_coef: 0.0421\n",
      "Epoch 412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7927 - dice_coef: 0.7927 - val_loss: -0.0356 - val_dice_coef: 0.0356\n",
      "Epoch 413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7405 - dice_coef: 0.7405 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7844 - dice_coef: 0.7844 - val_loss: -0.6107 - val_dice_coef: 0.6107\n",
      "Epoch 415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7791 - dice_coef: 0.7791 - val_loss: -0.0159 - val_dice_coef: 0.0159\n",
      "Epoch 416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0370 - val_dice_coef: 0.0370\n",
      "Epoch 417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8034 - dice_coef: 0.8034 - val_loss: -0.2351 - val_dice_coef: 0.2351\n",
      "Epoch 418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8086 - dice_coef: 0.8086 - val_loss: -0.1190 - val_dice_coef: 0.1190\n",
      "Epoch 419/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.0477 - val_dice_coef: 0.0477\n",
      "Epoch 420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8046 - dice_coef: 0.8046 - val_loss: -0.2101 - val_dice_coef: 0.2101\n",
      "Epoch 421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8109 - dice_coef: 0.8109 - val_loss: -0.2076 - val_dice_coef: 0.2076\n",
      "Epoch 422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8069 - dice_coef: 0.8069 - val_loss: -0.0993 - val_dice_coef: 0.0993\n",
      "Epoch 423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.0434 - val_dice_coef: 0.0434\n",
      "Epoch 424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8075 - dice_coef: 0.8075 - val_loss: -0.1762 - val_dice_coef: 0.1762\n",
      "Epoch 425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8059 - dice_coef: 0.8059 - val_loss: -0.1748 - val_dice_coef: 0.1748\n",
      "Epoch 426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.0394 - val_dice_coef: 0.0394\n",
      "Epoch 427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8040 - dice_coef: 0.8040 - val_loss: -0.1564 - val_dice_coef: 0.1564\n",
      "Epoch 428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8008 - dice_coef: 0.8008 - val_loss: -0.4271 - val_dice_coef: 0.4271\n",
      "Epoch 429/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7984 - dice_coef: 0.7984 - val_loss: -0.1725 - val_dice_coef: 0.1725\n",
      "Epoch 430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8074 - dice_coef: 0.8074 - val_loss: -0.0370 - val_dice_coef: 0.0370\n",
      "Epoch 431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8131 - dice_coef: 0.8131 - val_loss: -0.1404 - val_dice_coef: 0.1404\n",
      "Epoch 433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8154 - dice_coef: 0.8154 - val_loss: -0.0652 - val_dice_coef: 0.0652\n",
      "Epoch 434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8114 - dice_coef: 0.8114 - val_loss: -0.2139 - val_dice_coef: 0.2139\n",
      "Epoch 435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8117 - dice_coef: 0.8117 - val_loss: -0.1163 - val_dice_coef: 0.1163\n",
      "Epoch 436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8121 - dice_coef: 0.8121 - val_loss: -0.0403 - val_dice_coef: 0.0403\n",
      "Epoch 437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8067 - dice_coef: 0.8067 - val_loss: -0.1288 - val_dice_coef: 0.1288\n",
      "Epoch 438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8150 - dice_coef: 0.8150 - val_loss: -0.1334 - val_dice_coef: 0.1334\n",
      "Epoch 439/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8177 - dice_coef: 0.8177 - val_loss: -0.1014 - val_dice_coef: 0.1014\n",
      "Epoch 440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8152 - dice_coef: 0.8152 - val_loss: -0.2299 - val_dice_coef: 0.2299\n",
      "Epoch 441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.1904 - val_dice_coef: 0.1904\n",
      "Epoch 442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8164 - dice_coef: 0.8164 - val_loss: -0.0625 - val_dice_coef: 0.0625\n",
      "Epoch 443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.1399 - val_dice_coef: 0.1399\n",
      "Epoch 444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8148 - dice_coef: 0.8148 - val_loss: -0.1434 - val_dice_coef: 0.1434\n",
      "Epoch 445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.3043 - val_dice_coef: 0.3043\n",
      "Epoch 446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8101 - dice_coef: 0.8101 - val_loss: -0.0396 - val_dice_coef: 0.0396\n",
      "Epoch 447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8028 - dice_coef: 0.8028 - val_loss: -0.0283 - val_dice_coef: 0.0283\n",
      "Epoch 448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8115 - dice_coef: 0.8115 - val_loss: -0.0963 - val_dice_coef: 0.0963\n",
      "Epoch 449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8078 - dice_coef: 0.8078 - val_loss: -0.4016 - val_dice_coef: 0.4016\n",
      "Epoch 450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.0483 - val_dice_coef: 0.0483\n",
      "Epoch 451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.0221 - val_dice_coef: 0.0221\n",
      "Epoch 452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.1492 - val_dice_coef: 0.1492\n",
      "Epoch 453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8146 - dice_coef: 0.8146 - val_loss: -0.5575 - val_dice_coef: 0.5575\n",
      "Epoch 454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8078 - dice_coef: 0.8078 - val_loss: -0.1795 - val_dice_coef: 0.1795\n",
      "Epoch 455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7962 - dice_coef: 0.7962 - val_loss: -0.0179 - val_dice_coef: 0.0179\n",
      "Epoch 456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.0442 - val_dice_coef: 0.0442\n",
      "Epoch 457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8024 - dice_coef: 0.8024 - val_loss: -0.6116 - val_dice_coef: 0.6116\n",
      "Epoch 458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8017 - dice_coef: 0.8017 - val_loss: -0.3085 - val_dice_coef: 0.3085\n",
      "Epoch 459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8160 - dice_coef: 0.8160 - val_loss: -0.0279 - val_dice_coef: 0.0279\n",
      "Epoch 460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8097 - dice_coef: 0.8097 - val_loss: -0.0992 - val_dice_coef: 0.0992\n",
      "Epoch 461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8141 - dice_coef: 0.8141 - val_loss: -0.5515 - val_dice_coef: 0.5515\n",
      "Epoch 462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8051 - dice_coef: 0.8051 - val_loss: -0.3915 - val_dice_coef: 0.3915\n",
      "Epoch 463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8133 - dice_coef: 0.8133 - val_loss: -0.0291 - val_dice_coef: 0.0291\n",
      "Epoch 464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.1182 - val_dice_coef: 0.1182\n",
      "Epoch 465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8176 - dice_coef: 0.8176 - val_loss: -0.2284 - val_dice_coef: 0.2284\n",
      "Epoch 466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8167 - dice_coef: 0.8167 - val_loss: -0.0484 - val_dice_coef: 0.0484\n",
      "Epoch 467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8147 - dice_coef: 0.8147 - val_loss: -0.1196 - val_dice_coef: 0.1196\n",
      "Epoch 468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.5032 - val_dice_coef: 0.5032\n",
      "Epoch 469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8130 - dice_coef: 0.8130 - val_loss: -0.0393 - val_dice_coef: 0.0393\n",
      "Epoch 470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.0320 - val_dice_coef: 0.0320\n",
      "Epoch 471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8117 - dice_coef: 0.8117 - val_loss: -0.5914 - val_dice_coef: 0.5914\n",
      "Epoch 472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.6983 - val_dice_coef: 0.6983\n",
      "Epoch 473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7959 - dice_coef: 0.7959 - val_loss: -0.0990 - val_dice_coef: 0.0990\n",
      "Epoch 474/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8124 - dice_coef: 0.8124 - val_loss: -0.0336 - val_dice_coef: 0.0336\n",
      "Epoch 475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8132 - dice_coef: 0.8132 - val_loss: -0.4476 - val_dice_coef: 0.4476\n",
      "Epoch 476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.1058 - val_dice_coef: 0.1058\n",
      "Epoch 477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.1145 - val_dice_coef: 0.1145\n",
      "Epoch 478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.2891 - val_dice_coef: 0.2891\n",
      "Epoch 479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8193 - dice_coef: 0.8193 - val_loss: -0.1217 - val_dice_coef: 0.1217\n",
      "Epoch 480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8199 - dice_coef: 0.8199 - val_loss: -0.2064 - val_dice_coef: 0.2064\n",
      "Epoch 481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8178 - dice_coef: 0.8178 - val_loss: -0.2016 - val_dice_coef: 0.2016\n",
      "Epoch 482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8206 - dice_coef: 0.8206 - val_loss: -0.2538 - val_dice_coef: 0.2538\n",
      "Epoch 483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8219 - dice_coef: 0.8219 - val_loss: -0.2956 - val_dice_coef: 0.2956\n",
      "Epoch 484/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8207 - dice_coef: 0.8207 - val_loss: -0.1771 - val_dice_coef: 0.1771\n",
      "Epoch 485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.2624 - val_dice_coef: 0.2624\n",
      "Epoch 486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8105 - dice_coef: 0.8105 - val_loss: -0.4911 - val_dice_coef: 0.4911\n",
      "Epoch 487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8167 - dice_coef: 0.8167 - val_loss: -0.0686 - val_dice_coef: 0.0686\n",
      "Epoch 488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8197 - dice_coef: 0.8197 - val_loss: -0.0760 - val_dice_coef: 0.0760\n",
      "Epoch 489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8223 - dice_coef: 0.8223 - val_loss: -0.0500 - val_dice_coef: 0.0500\n",
      "Epoch 490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.0601 - val_dice_coef: 0.0601\n",
      "Epoch 491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8160 - dice_coef: 0.8160 - val_loss: -0.4535 - val_dice_coef: 0.4535\n",
      "Epoch 492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.2184 - val_dice_coef: 0.2184\n",
      "Epoch 493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0320 - val_dice_coef: 0.0320\n",
      "Epoch 494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7959 - dice_coef: 0.7959 - val_loss: -0.0186 - val_dice_coef: 0.0186\n",
      "Epoch 495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8054 - dice_coef: 0.8054 - val_loss: -0.3697 - val_dice_coef: 0.3697\n",
      "Epoch 496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7997 - dice_coef: 0.7997 - val_loss: -0.7929 - val_dice_coef: 0.7929\n",
      "Epoch 497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.0672 - val_dice_coef: 0.0672\n",
      "Epoch 498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.0293 - val_dice_coef: 0.0293\n",
      "Epoch 499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.9266 - val_dice_coef: 0.9266\n",
      "Epoch 500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7841 - dice_coef: 0.7841 - val_loss: -0.1199 - val_dice_coef: 0.1199\n",
      "Epoch 501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8165 - dice_coef: 0.8165 - val_loss: -0.0417 - val_dice_coef: 0.0417\n",
      "Epoch 502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.4505 - val_dice_coef: 0.4505\n",
      "Epoch 503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8198 - dice_coef: 0.8198 - val_loss: -0.2722 - val_dice_coef: 0.2722\n",
      "Epoch 504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8236 - dice_coef: 0.8236 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8252 - dice_coef: 0.8252 - val_loss: -0.2344 - val_dice_coef: 0.2344\n",
      "Epoch 506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8219 - dice_coef: 0.8219 - val_loss: -0.3935 - val_dice_coef: 0.3935\n",
      "Epoch 507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8250 - dice_coef: 0.8250 - val_loss: -0.0641 - val_dice_coef: 0.0641\n",
      "Epoch 508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.4545 - val_dice_coef: 0.4545\n",
      "Epoch 509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8205 - dice_coef: 0.8205 - val_loss: -0.3286 - val_dice_coef: 0.3286\n",
      "Epoch 510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8140 - dice_coef: 0.8140 - val_loss: -0.1836 - val_dice_coef: 0.1836\n",
      "Epoch 511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8239 - dice_coef: 0.8239 - val_loss: -0.2571 - val_dice_coef: 0.2571\n",
      "Epoch 512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8244 - dice_coef: 0.8244 - val_loss: -0.1180 - val_dice_coef: 0.1180\n",
      "Epoch 513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.2087 - val_dice_coef: 0.2087\n",
      "Epoch 514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8267 - dice_coef: 0.8267 - val_loss: -0.1494 - val_dice_coef: 0.1494\n",
      "Epoch 515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8282 - dice_coef: 0.8282 - val_loss: -0.1149 - val_dice_coef: 0.1149\n",
      "Epoch 516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8282 - dice_coef: 0.8282 - val_loss: -0.4932 - val_dice_coef: 0.4932\n",
      "Epoch 517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8136 - dice_coef: 0.8136 - val_loss: -0.5778 - val_dice_coef: 0.5778\n",
      "Epoch 518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8171 - dice_coef: 0.8171 - val_loss: -0.1004 - val_dice_coef: 0.1004\n",
      "Epoch 519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8237 - dice_coef: 0.8237 - val_loss: -0.1345 - val_dice_coef: 0.1345\n",
      "Epoch 520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.1655 - val_dice_coef: 0.1655\n",
      "Epoch 521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8269 - dice_coef: 0.8269 - val_loss: -0.7545 - val_dice_coef: 0.7545\n",
      "Epoch 522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8210 - dice_coef: 0.8210 - val_loss: -0.3689 - val_dice_coef: 0.3689\n",
      "Epoch 523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.2003 - val_dice_coef: 0.2003\n",
      "Epoch 524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.0712 - val_dice_coef: 0.0712\n",
      "Epoch 525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8176 - dice_coef: 0.8176 - val_loss: -0.0582 - val_dice_coef: 0.0582\n",
      "Epoch 526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8188 - dice_coef: 0.8188 - val_loss: -0.0770 - val_dice_coef: 0.0770\n",
      "Epoch 527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8180 - dice_coef: 0.8180 - val_loss: -0.2046 - val_dice_coef: 0.2046\n",
      "Epoch 528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8192 - dice_coef: 0.8192 - val_loss: -0.9066 - val_dice_coef: 0.9066\n",
      "Epoch 529/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7969 - dice_coef: 0.7969 - val_loss: -0.0630 - val_dice_coef: 0.0630\n",
      "Epoch 530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.0144 - val_dice_coef: 0.0144\n",
      "Epoch 531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.6773 - val_dice_coef: 0.6773\n",
      "Epoch 532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.4786 - val_dice_coef: 0.4786\n",
      "Epoch 533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8136 - dice_coef: 0.8136 - val_loss: -0.0916 - val_dice_coef: 0.0916\n",
      "Epoch 534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8265 - dice_coef: 0.8265 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.2900 - val_dice_coef: 0.2900\n",
      "Epoch 536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8082 - dice_coef: 0.8082 - val_loss: -0.0148 - val_dice_coef: 0.0148\n",
      "Epoch 537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.0460 - val_dice_coef: 0.0460\n",
      "Epoch 538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8138 - dice_coef: 0.8138 - val_loss: -0.7499 - val_dice_coef: 0.7499\n",
      "Epoch 539/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8153 - dice_coef: 0.8153 - val_loss: -0.0671 - val_dice_coef: 0.0671\n",
      "Epoch 540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8169 - dice_coef: 0.8169 - val_loss: -0.0314 - val_dice_coef: 0.0314\n",
      "Epoch 541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8112 - dice_coef: 0.8112 - val_loss: -0.7243 - val_dice_coef: 0.7243\n",
      "Epoch 542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8226 - dice_coef: 0.8226 - val_loss: -0.0891 - val_dice_coef: 0.0891\n",
      "Epoch 543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8200 - dice_coef: 0.8200 - val_loss: -0.0178 - val_dice_coef: 0.0178\n",
      "Epoch 544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.6045 - val_dice_coef: 0.6045\n",
      "Epoch 545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8159 - dice_coef: 0.8159 - val_loss: -0.5087 - val_dice_coef: 0.5087\n",
      "Epoch 546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8215 - dice_coef: 0.8215 - val_loss: -0.1051 - val_dice_coef: 0.1051\n",
      "Epoch 547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8251 - dice_coef: 0.8251 - val_loss: -0.3124 - val_dice_coef: 0.3124\n",
      "Epoch 548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8321 - dice_coef: 0.8321 - val_loss: -0.2700 - val_dice_coef: 0.2700\n",
      "Epoch 549/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8308 - dice_coef: 0.8308 - val_loss: -0.3569 - val_dice_coef: 0.3569\n",
      "Epoch 550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8291 - dice_coef: 0.8291 - val_loss: -0.2589 - val_dice_coef: 0.2589\n",
      "Epoch 551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8312 - dice_coef: 0.8312 - val_loss: -0.4501 - val_dice_coef: 0.4501\n",
      "Epoch 552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8288 - dice_coef: 0.8288 - val_loss: -0.2028 - val_dice_coef: 0.2028\n",
      "Epoch 553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8296 - dice_coef: 0.8296 - val_loss: -0.0799 - val_dice_coef: 0.0799\n",
      "Epoch 554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8302 - dice_coef: 0.8302 - val_loss: -0.5327 - val_dice_coef: 0.5327\n",
      "Epoch 555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8187 - dice_coef: 0.8187 - val_loss: -0.6675 - val_dice_coef: 0.6675\n",
      "Epoch 556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.1430 - val_dice_coef: 0.1430\n",
      "Epoch 557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.2106 - val_dice_coef: 0.2106\n",
      "Epoch 558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.2974 - val_dice_coef: 0.2974\n",
      "Epoch 559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8298 - dice_coef: 0.8298 - val_loss: -0.4039 - val_dice_coef: 0.4039\n",
      "Epoch 560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8331 - dice_coef: 0.8331 - val_loss: -0.6531 - val_dice_coef: 0.6531\n",
      "Epoch 561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.2544 - val_dice_coef: 0.2544\n",
      "Epoch 562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.0751 - val_dice_coef: 0.0751\n",
      "Epoch 563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.2586 - val_dice_coef: 0.2586\n",
      "Epoch 564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.5444 - val_dice_coef: 0.5444\n",
      "Epoch 565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.1186 - val_dice_coef: 0.1186\n",
      "Epoch 566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8259 - dice_coef: 0.8259 - val_loss: -0.1178 - val_dice_coef: 0.1178\n",
      "Epoch 567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.9145 - val_dice_coef: 0.9145\n",
      "Epoch 568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7752 - dice_coef: 0.7752 - val_loss: -0.6345 - val_dice_coef: 0.6345\n",
      "Epoch 569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7562 - dice_coef: 0.7562 - val_loss: -0.0040 - val_dice_coef: 0.0040\n",
      "Epoch 570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6895 - dice_coef: 0.6895 - val_loss: -0.1639 - val_dice_coef: 0.1639\n",
      "Epoch 571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7304 - dice_coef: 0.7304 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7258 - dice_coef: 0.7258 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7116 - dice_coef: 0.7116 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7699 - dice_coef: 0.7699 - val_loss: -0.0039 - val_dice_coef: 0.0039\n",
      "Epoch 575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7622 - dice_coef: 0.7622 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7658 - dice_coef: 0.7658 - val_loss: -0.0136 - val_dice_coef: 0.0136\n",
      "Epoch 577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7974 - dice_coef: 0.7974 - val_loss: -0.9098 - val_dice_coef: 0.9098\n",
      "Epoch 578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8113 - dice_coef: 0.8113 - val_loss: -0.0898 - val_dice_coef: 0.0898\n",
      "Epoch 579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.2365 - val_dice_coef: 0.2365\n",
      "Epoch 580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8177 - dice_coef: 0.8177 - val_loss: -0.6985 - val_dice_coef: 0.6985\n",
      "Epoch 581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8187 - dice_coef: 0.8187 - val_loss: -0.0752 - val_dice_coef: 0.0752\n",
      "Epoch 582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8180 - dice_coef: 0.8180 - val_loss: -0.7295 - val_dice_coef: 0.7295\n",
      "Epoch 583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.3519 - val_dice_coef: 0.3519\n",
      "Epoch 584/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.1809 - val_dice_coef: 0.1809\n",
      "Epoch 585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8238 - dice_coef: 0.8238 - val_loss: -0.6086 - val_dice_coef: 0.6086\n",
      "Epoch 586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8228 - dice_coef: 0.8228 - val_loss: -0.0682 - val_dice_coef: 0.0682\n",
      "Epoch 587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.3823 - val_dice_coef: 0.3823\n",
      "Epoch 588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8308 - dice_coef: 0.8308 - val_loss: -0.4799 - val_dice_coef: 0.4799\n",
      "Epoch 589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.1169 - val_dice_coef: 0.1169\n",
      "Epoch 590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8199 - dice_coef: 0.8199 - val_loss: -0.3753 - val_dice_coef: 0.3753\n",
      "Epoch 591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.4125 - val_dice_coef: 0.4125\n",
      "Epoch 592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8271 - dice_coef: 0.8271 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.6504 - val_dice_coef: 0.6504\n",
      "Epoch 594/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.3559 - val_dice_coef: 0.3559\n",
      "Epoch 595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8261 - dice_coef: 0.8261 - val_loss: -0.1354 - val_dice_coef: 0.1354\n",
      "Epoch 596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8276 - dice_coef: 0.8276 - val_loss: -0.6209 - val_dice_coef: 0.6209\n",
      "Epoch 597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8263 - dice_coef: 0.8263 - val_loss: -0.6462 - val_dice_coef: 0.6462\n",
      "Epoch 598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.2361 - val_dice_coef: 0.2361\n",
      "Epoch 599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.4628 - val_dice_coef: 0.4628\n",
      "Epoch 600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8351 - dice_coef: 0.8351 - val_loss: -0.3246 - val_dice_coef: 0.3246\n",
      "Epoch 601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.2202 - val_dice_coef: 0.2202\n",
      "Epoch 602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8328 - dice_coef: 0.8328 - val_loss: -0.2158 - val_dice_coef: 0.2158\n",
      "Epoch 603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.3146 - val_dice_coef: 0.3146\n",
      "Epoch 604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.6112 - val_dice_coef: 0.6112\n",
      "Epoch 605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8333 - dice_coef: 0.8333 - val_loss: -0.2770 - val_dice_coef: 0.2770\n",
      "Epoch 606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8330 - dice_coef: 0.8330 - val_loss: -0.1664 - val_dice_coef: 0.1664\n",
      "Epoch 607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.4966 - val_dice_coef: 0.4966\n",
      "Epoch 608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.2649 - val_dice_coef: 0.2649\n",
      "Epoch 609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8364 - dice_coef: 0.8364 - val_loss: -0.5426 - val_dice_coef: 0.5426\n",
      "Epoch 610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.2237 - val_dice_coef: 0.2237\n",
      "Epoch 611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8365 - dice_coef: 0.8365 - val_loss: -0.3087 - val_dice_coef: 0.3087\n",
      "Epoch 612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8360 - dice_coef: 0.8360 - val_loss: -0.6877 - val_dice_coef: 0.6877\n",
      "Epoch 613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8360 - dice_coef: 0.8360 - val_loss: -0.2832 - val_dice_coef: 0.2832\n",
      "Epoch 614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8373 - dice_coef: 0.8373 - val_loss: -0.2565 - val_dice_coef: 0.2565\n",
      "Epoch 615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8374 - dice_coef: 0.8374 - val_loss: -0.4029 - val_dice_coef: 0.4029\n",
      "Epoch 616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8396 - dice_coef: 0.8396 - val_loss: -0.4864 - val_dice_coef: 0.4864\n",
      "Epoch 617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8393 - dice_coef: 0.8393 - val_loss: -0.3034 - val_dice_coef: 0.3034\n",
      "Epoch 618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.2535 - val_dice_coef: 0.2535\n",
      "Epoch 619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.2476 - val_dice_coef: 0.2476\n",
      "Epoch 620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.6186 - val_dice_coef: 0.6186\n",
      "Epoch 621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.4832 - val_dice_coef: 0.4832\n",
      "Epoch 622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8194 - dice_coef: 0.8194 - val_loss: -0.0482 - val_dice_coef: 0.0482\n",
      "Epoch 623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8163 - dice_coef: 0.8163 - val_loss: -0.0297 - val_dice_coef: 0.0297\n",
      "Epoch 624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8084 - dice_coef: 0.8084 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7976 - dice_coef: 0.7976 - val_loss: -0.0325 - val_dice_coef: 0.0325\n",
      "Epoch 626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8020 - dice_coef: 0.8020 - val_loss: -0.0371 - val_dice_coef: 0.0371\n",
      "Epoch 627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8027 - dice_coef: 0.8027 - val_loss: -0.9913 - val_dice_coef: 0.9913\n",
      "Epoch 628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8093 - dice_coef: 0.8093 - val_loss: -0.0275 - val_dice_coef: 0.0275\n",
      "Epoch 629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8198 - dice_coef: 0.8198 - val_loss: -0.6022 - val_dice_coef: 0.6022\n",
      "Epoch 630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8278 - dice_coef: 0.8278 - val_loss: -0.3513 - val_dice_coef: 0.3513\n",
      "Epoch 631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.2364 - val_dice_coef: 0.2364\n",
      "Epoch 632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.5728 - val_dice_coef: 0.5728\n",
      "Epoch 633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.6481 - val_dice_coef: 0.6481\n",
      "Epoch 634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.2212 - val_dice_coef: 0.2212\n",
      "Epoch 635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8379 - dice_coef: 0.8379 - val_loss: -0.5144 - val_dice_coef: 0.5144\n",
      "Epoch 636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.3816 - val_dice_coef: 0.3816\n",
      "Epoch 637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.3823 - val_dice_coef: 0.3823\n",
      "Epoch 638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8392 - dice_coef: 0.8392 - val_loss: -0.3142 - val_dice_coef: 0.3142\n",
      "Epoch 639/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.3412 - val_dice_coef: 0.3412\n",
      "Epoch 640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8413 - dice_coef: 0.8413 - val_loss: -0.7510 - val_dice_coef: 0.7510\n",
      "Epoch 641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8342 - dice_coef: 0.8342 - val_loss: -0.5192 - val_dice_coef: 0.5192\n",
      "Epoch 642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8389 - dice_coef: 0.8389 - val_loss: -0.0560 - val_dice_coef: 0.0560\n",
      "Epoch 643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8275 - dice_coef: 0.8275 - val_loss: -0.6707 - val_dice_coef: 0.6707\n",
      "Epoch 644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8334 - dice_coef: 0.8334 - val_loss: -0.7639 - val_dice_coef: 0.7639\n",
      "Epoch 645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8363 - dice_coef: 0.8363 - val_loss: -0.4404 - val_dice_coef: 0.4404\n",
      "Epoch 646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.2856 - val_dice_coef: 0.2856\n",
      "Epoch 647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.5237 - val_dice_coef: 0.5237\n",
      "Epoch 648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8352 - dice_coef: 0.8352 - val_loss: -0.7274 - val_dice_coef: 0.7274\n",
      "Epoch 649/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.1787 - val_dice_coef: 0.1787\n",
      "Epoch 650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8377 - dice_coef: 0.8377 - val_loss: -0.3011 - val_dice_coef: 0.3011\n",
      "Epoch 651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.6969 - val_dice_coef: 0.6969\n",
      "Epoch 652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8369 - dice_coef: 0.8369 - val_loss: -0.1611 - val_dice_coef: 0.1611\n",
      "Epoch 653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8373 - dice_coef: 0.8373 - val_loss: -0.4017 - val_dice_coef: 0.4017\n",
      "Epoch 654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.7956 - val_dice_coef: 0.7956\n",
      "Epoch 655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.2720 - val_dice_coef: 0.2720\n",
      "Epoch 656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8399 - dice_coef: 0.8399 - val_loss: -0.3397 - val_dice_coef: 0.3397\n",
      "Epoch 657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.8481 - val_dice_coef: 0.8481\n",
      "Epoch 658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.5583 - val_dice_coef: 0.5583\n",
      "Epoch 659/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.0544 - val_dice_coef: 0.0544\n",
      "Epoch 660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8261 - dice_coef: 0.8261 - val_loss: -0.6444 - val_dice_coef: 0.6444\n",
      "Epoch 661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8272 - dice_coef: 0.8272 - val_loss: -0.7144 - val_dice_coef: 0.7144\n",
      "Epoch 662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8157 - dice_coef: 0.8157 - val_loss: -0.0158 - val_dice_coef: 0.0158\n",
      "Epoch 663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7752 - dice_coef: 0.7752 - val_loss: -0.2079 - val_dice_coef: 0.2079\n",
      "Epoch 664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.6270 - val_dice_coef: 0.6270\n",
      "Epoch 665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8258 - dice_coef: 0.8258 - val_loss: -0.1171 - val_dice_coef: 0.1171\n",
      "Epoch 666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.8650 - val_dice_coef: 0.8650\n",
      "Epoch 667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8395 - dice_coef: 0.8395 - val_loss: -0.6320 - val_dice_coef: 0.6320\n",
      "Epoch 668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8424 - dice_coef: 0.8424 - val_loss: -0.5525 - val_dice_coef: 0.5525\n",
      "Epoch 669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8391 - dice_coef: 0.8391 - val_loss: -0.8774 - val_dice_coef: 0.8774\n",
      "Epoch 670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.5239 - val_dice_coef: 0.5239\n",
      "Epoch 671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.1818 - val_dice_coef: 0.1818\n",
      "Epoch 672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8286 - dice_coef: 0.8286 - val_loss: -0.2185 - val_dice_coef: 0.2185\n",
      "Epoch 673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8309 - dice_coef: 0.8309 - val_loss: -0.9362 - val_dice_coef: 0.9362\n",
      "Epoch 674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.2254 - val_dice_coef: 0.2254\n",
      "Epoch 675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8384 - dice_coef: 0.8384 - val_loss: -0.3132 - val_dice_coef: 0.3132\n",
      "Epoch 676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8433 - dice_coef: 0.8433 - val_loss: -0.8573 - val_dice_coef: 0.8573\n",
      "Epoch 677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.2573 - val_dice_coef: 0.2573\n",
      "Epoch 678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.4857 - val_dice_coef: 0.4857\n",
      "Epoch 679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8445 - dice_coef: 0.8445 - val_loss: -0.7931 - val_dice_coef: 0.7931\n",
      "Epoch 680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8336 - dice_coef: 0.8336 - val_loss: -0.1880 - val_dice_coef: 0.1880\n",
      "Epoch 681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8396 - dice_coef: 0.8396 - val_loss: -0.2356 - val_dice_coef: 0.2356\n",
      "Epoch 682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8431 - dice_coef: 0.8431 - val_loss: -0.7485 - val_dice_coef: 0.7485\n",
      "Epoch 683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8439 - dice_coef: 0.8439 - val_loss: -0.2251 - val_dice_coef: 0.2251\n",
      "Epoch 684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8401 - dice_coef: 0.8401 - val_loss: -0.4985 - val_dice_coef: 0.4985\n",
      "Epoch 685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.7831 - val_dice_coef: 0.7831\n",
      "Epoch 686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.0811 - val_dice_coef: 0.0811\n",
      "Epoch 687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8300 - dice_coef: 0.8300 - val_loss: -0.3282 - val_dice_coef: 0.3282\n",
      "Epoch 688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8425 - dice_coef: 0.8425 - val_loss: -0.8692 - val_dice_coef: 0.8692\n",
      "Epoch 689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8402 - dice_coef: 0.8402 - val_loss: -0.5329 - val_dice_coef: 0.5329\n",
      "Epoch 690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.3908 - val_dice_coef: 0.3908\n",
      "Epoch 691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8451 - dice_coef: 0.8451 - val_loss: -0.7364 - val_dice_coef: 0.7364\n",
      "Epoch 692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.6834 - val_dice_coef: 0.6834\n",
      "Epoch 693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.2906 - val_dice_coef: 0.2906\n",
      "Epoch 694/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8452 - dice_coef: 0.8452 - val_loss: -0.3159 - val_dice_coef: 0.3159\n",
      "Epoch 695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.5617 - val_dice_coef: 0.5617\n",
      "Epoch 696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.6209 - val_dice_coef: 0.6209\n",
      "Epoch 697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.3204 - val_dice_coef: 0.3204\n",
      "Epoch 698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8416 - dice_coef: 0.8416 - val_loss: -0.3793 - val_dice_coef: 0.3793\n",
      "Epoch 699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8408 - dice_coef: 0.8408 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "Epoch 700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.3962 - val_dice_coef: 0.3962\n",
      "Epoch 701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.6602 - val_dice_coef: 0.6602\n",
      "Epoch 702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8473 - dice_coef: 0.8473 - val_loss: -0.6013 - val_dice_coef: 0.6013\n",
      "Epoch 703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.6774 - val_dice_coef: 0.6774\n",
      "Epoch 704/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8363 - dice_coef: 0.8363 - val_loss: -0.5603 - val_dice_coef: 0.5603\n",
      "Epoch 705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8423 - dice_coef: 0.8423 - val_loss: -0.0642 - val_dice_coef: 0.0642\n",
      "Epoch 706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8324 - dice_coef: 0.8324 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.6630 - val_dice_coef: 0.6630\n",
      "Epoch 708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.2338 - val_dice_coef: 0.2338\n",
      "Epoch 709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.5562 - val_dice_coef: 0.5562\n",
      "Epoch 710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8441 - dice_coef: 0.8441 - val_loss: -0.6202 - val_dice_coef: 0.6202\n",
      "Epoch 711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.6704 - val_dice_coef: 0.6704\n",
      "Epoch 712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.6614 - val_dice_coef: 0.6614\n",
      "Epoch 713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.6289 - val_dice_coef: 0.6289\n",
      "Epoch 714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8457 - dice_coef: 0.8457 - val_loss: -0.1529 - val_dice_coef: 0.1529\n",
      "Epoch 715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8384 - dice_coef: 0.8384 - val_loss: -0.1108 - val_dice_coef: 0.1108\n",
      "Epoch 716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.9756 - val_dice_coef: 0.9756\n",
      "Epoch 717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8264 - dice_coef: 0.8264 - val_loss: -0.5430 - val_dice_coef: 0.5430\n",
      "Epoch 718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.1765 - val_dice_coef: 0.1765\n",
      "Epoch 719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.4790 - val_dice_coef: 0.4790\n",
      "Epoch 721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8463 - dice_coef: 0.8463 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8418 - dice_coef: 0.8418 - val_loss: -0.9695 - val_dice_coef: 0.9695\n",
      "Epoch 723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8085 - dice_coef: 0.8085 - val_loss: -0.4149 - val_dice_coef: 0.4149\n",
      "Epoch 724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0183 - val_dice_coef: 0.0183\n",
      "Epoch 725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8203 - dice_coef: 0.8203 - val_loss: -0.9363 - val_dice_coef: 0.9363\n",
      "Epoch 726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.1106 - val_dice_coef: 0.1106\n",
      "Epoch 727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.0991 - val_dice_coef: 0.0991\n",
      "Epoch 728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.9815 - val_dice_coef: 0.9815\n",
      "Epoch 729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.4321 - val_dice_coef: 0.4321\n",
      "Epoch 730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8383 - dice_coef: 0.8383 - val_loss: -0.1485 - val_dice_coef: 0.1485\n",
      "Epoch 731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8358 - dice_coef: 0.8358 - val_loss: -0.9855 - val_dice_coef: 0.9855\n",
      "Epoch 732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.1318 - val_dice_coef: 0.1318\n",
      "Epoch 733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8332 - dice_coef: 0.8332 - val_loss: -0.3812 - val_dice_coef: 0.3812\n",
      "Epoch 734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8412 - dice_coef: 0.8412 - val_loss: -0.8816 - val_dice_coef: 0.8816\n",
      "Epoch 735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8430 - dice_coef: 0.8430 - val_loss: -0.3899 - val_dice_coef: 0.3899\n",
      "Epoch 736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.3458 - val_dice_coef: 0.3458\n",
      "Epoch 737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.9369 - val_dice_coef: 0.9369\n",
      "Epoch 738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8434 - dice_coef: 0.8434 - val_loss: -0.3495 - val_dice_coef: 0.3495\n",
      "Epoch 739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8411 - dice_coef: 0.8411 - val_loss: -0.5169 - val_dice_coef: 0.5169\n",
      "Epoch 740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8492 - dice_coef: 0.8492 - val_loss: -0.8756 - val_dice_coef: 0.8756\n",
      "Epoch 741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.5438 - val_dice_coef: 0.5438\n",
      "Epoch 742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.4142 - val_dice_coef: 0.4142\n",
      "Epoch 743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.6685 - val_dice_coef: 0.6685\n",
      "Epoch 744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.8682 - val_dice_coef: 0.8682\n",
      "Epoch 745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8460 - dice_coef: 0.8460 - val_loss: -0.5560 - val_dice_coef: 0.5560\n",
      "Epoch 746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.2725 - val_dice_coef: 0.2725\n",
      "Epoch 747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8489 - dice_coef: 0.8489 - val_loss: -0.6455 - val_dice_coef: 0.6455\n",
      "Epoch 748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.6092 - val_dice_coef: 0.6092\n",
      "Epoch 749/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.2267 - val_dice_coef: 0.2267\n",
      "Epoch 750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8472 - dice_coef: 0.8472 - val_loss: -0.7079 - val_dice_coef: 0.7079\n",
      "Epoch 751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8482 - dice_coef: 0.8482 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8464 - dice_coef: 0.8464 - val_loss: -0.3359 - val_dice_coef: 0.3359\n",
      "Epoch 753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8483 - dice_coef: 0.8483 - val_loss: -0.4852 - val_dice_coef: 0.4852\n",
      "Epoch 754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.8795 - val_dice_coef: 0.8795\n",
      "Epoch 755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.6648 - val_dice_coef: 0.6648\n",
      "Epoch 756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8470 - dice_coef: 0.8470 - val_loss: -0.2681 - val_dice_coef: 0.2681\n",
      "Epoch 757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.6538 - val_dice_coef: 0.6538\n",
      "Epoch 758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.7737 - val_dice_coef: 0.7737\n",
      "Epoch 759/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8458 - dice_coef: 0.8458 - val_loss: -0.5625 - val_dice_coef: 0.5625\n",
      "Epoch 760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.7626 - val_dice_coef: 0.7626\n",
      "Epoch 761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8480 - dice_coef: 0.8480 - val_loss: -0.6463 - val_dice_coef: 0.6463\n",
      "Epoch 762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.2825 - val_dice_coef: 0.2825\n",
      "Epoch 763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.4971 - val_dice_coef: 0.4971\n",
      "Epoch 764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.6287 - val_dice_coef: 0.6287\n",
      "Epoch 765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.6401 - val_dice_coef: 0.6401\n",
      "Epoch 766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.6936 - val_dice_coef: 0.6936\n",
      "Epoch 767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.4167 - val_dice_coef: 0.4167\n",
      "Epoch 768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.4295 - val_dice_coef: 0.4295\n",
      "Epoch 769/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.7763 - val_dice_coef: 0.7763\n",
      "Epoch 770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8509 - dice_coef: 0.8509 - val_loss: -0.8231 - val_dice_coef: 0.8231\n",
      "Epoch 771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8507 - dice_coef: 0.8507 - val_loss: -0.7932 - val_dice_coef: 0.7932\n",
      "Epoch 772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.3768 - val_dice_coef: 0.3768\n",
      "Epoch 773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.4115 - val_dice_coef: 0.4115\n",
      "Epoch 774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.5884 - val_dice_coef: 0.5884\n",
      "Epoch 775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8531 - dice_coef: 0.8531 - val_loss: -0.6688 - val_dice_coef: 0.6688\n",
      "Epoch 776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.8369 - val_dice_coef: 0.8369\n",
      "Epoch 777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.6895 - val_dice_coef: 0.6895\n",
      "Epoch 778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8514 - dice_coef: 0.8514 - val_loss: -0.6263 - val_dice_coef: 0.6263\n",
      "Epoch 779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.4246 - val_dice_coef: 0.4246\n",
      "Epoch 780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.3193 - val_dice_coef: 0.3193\n",
      "Epoch 781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.6160 - val_dice_coef: 0.6160\n",
      "Epoch 782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9589 - val_dice_coef: 0.9589\n",
      "Epoch 783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.8186 - val_dice_coef: 0.8186\n",
      "Epoch 784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8436 - dice_coef: 0.8436 - val_loss: -0.1388 - val_dice_coef: 0.1388\n",
      "Epoch 785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8456 - dice_coef: 0.8456 - val_loss: -0.3074 - val_dice_coef: 0.3074\n",
      "Epoch 786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.9070 - val_dice_coef: 0.9070\n",
      "Epoch 787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8455 - dice_coef: 0.8455 - val_loss: -0.8317 - val_dice_coef: 0.8317\n",
      "Epoch 788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.5644 - val_dice_coef: 0.5644\n",
      "Epoch 789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8536 - dice_coef: 0.8536 - val_loss: -0.3972 - val_dice_coef: 0.3972\n",
      "Epoch 790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.4738 - val_dice_coef: 0.4738\n",
      "Epoch 791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8553 - dice_coef: 0.8553 - val_loss: -0.6124 - val_dice_coef: 0.6124\n",
      "Epoch 792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8535 - dice_coef: 0.8535 - val_loss: -0.9356 - val_dice_coef: 0.9356\n",
      "Epoch 793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8499 - dice_coef: 0.8499 - val_loss: -0.7161 - val_dice_coef: 0.7161\n",
      "Epoch 794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.1549 - val_dice_coef: 0.1549\n",
      "Epoch 795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8453 - dice_coef: 0.8453 - val_loss: -0.2801 - val_dice_coef: 0.2801\n",
      "Epoch 796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8504 - dice_coef: 0.8504 - val_loss: -0.5559 - val_dice_coef: 0.5559\n",
      "Epoch 797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8556 - dice_coef: 0.8556 - val_loss: -0.8554 - val_dice_coef: 0.8554\n",
      "Epoch 798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8528 - dice_coef: 0.8528 - val_loss: -0.3655 - val_dice_coef: 0.3655\n",
      "Epoch 799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.1151 - val_dice_coef: 0.1151\n",
      "Epoch 800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8386 - dice_coef: 0.8386 - val_loss: -0.2047 - val_dice_coef: 0.2047\n",
      "Epoch 801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8109 - dice_coef: 0.8109 - val_loss: -0.9355 - val_dice_coef: 0.9355\n",
      "Epoch 803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8212 - dice_coef: 0.8212 - val_loss: -0.0244 - val_dice_coef: 0.0244\n",
      "Epoch 804/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8173 - dice_coef: 0.8173 - val_loss: -0.3989 - val_dice_coef: 0.3989\n",
      "Epoch 805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8277 - dice_coef: 0.8277 - val_loss: -0.8731 - val_dice_coef: 0.8731\n",
      "Epoch 806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8146 - dice_coef: 0.8146 - val_loss: -0.0170 - val_dice_coef: 0.0170\n",
      "Epoch 807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8062 - dice_coef: 0.8062 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.1861 - val_dice_coef: 0.1861\n",
      "Epoch 809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8280 - dice_coef: 0.8280 - val_loss: -0.1426 - val_dice_coef: 0.1426\n",
      "Epoch 810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8269 - dice_coef: 0.8269 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.4603 - val_dice_coef: 0.4603\n",
      "Epoch 812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8461 - dice_coef: 0.8461 - val_loss: -0.5005 - val_dice_coef: 0.5005\n",
      "Epoch 813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8460 - dice_coef: 0.8460 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 814/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.6413 - val_dice_coef: 0.6413\n",
      "Epoch 815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8526 - dice_coef: 0.8526 - val_loss: -0.6075 - val_dice_coef: 0.6075\n",
      "Epoch 816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.8333 - val_dice_coef: 0.8333\n",
      "Epoch 817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.4402 - val_dice_coef: 0.4402\n",
      "Epoch 818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.4477 - val_dice_coef: 0.4477\n",
      "Epoch 819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8514 - dice_coef: 0.8514 - val_loss: -0.9301 - val_dice_coef: 0.9301\n",
      "Epoch 820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.3854 - val_dice_coef: 0.3854\n",
      "Epoch 821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8519 - dice_coef: 0.8519 - val_loss: -0.6451 - val_dice_coef: 0.6451\n",
      "Epoch 822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8548 - dice_coef: 0.8548 - val_loss: -0.8534 - val_dice_coef: 0.8534\n",
      "Epoch 823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.5227 - val_dice_coef: 0.5227\n",
      "Epoch 824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8531 - dice_coef: 0.8531 - val_loss: -0.7357 - val_dice_coef: 0.7357\n",
      "Epoch 825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.8460 - val_dice_coef: 0.8460\n",
      "Epoch 826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8563 - dice_coef: 0.8563 - val_loss: -0.7245 - val_dice_coef: 0.7245\n",
      "Epoch 827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.3914 - val_dice_coef: 0.3914\n",
      "Epoch 828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8482 - dice_coef: 0.8482 - val_loss: -0.7330 - val_dice_coef: 0.7330\n",
      "Epoch 830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.6213 - val_dice_coef: 0.6213\n",
      "Epoch 831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.7375 - val_dice_coef: 0.7375\n",
      "Epoch 832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8554 - dice_coef: 0.8554 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8388 - dice_coef: 0.8388 - val_loss: -0.6835 - val_dice_coef: 0.6835\n",
      "Epoch 834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.0724 - val_dice_coef: 0.0724\n",
      "Epoch 835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.7645 - val_dice_coef: 0.7645\n",
      "Epoch 836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.9822 - val_dice_coef: 0.9822\n",
      "Epoch 837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8433 - dice_coef: 0.8433 - val_loss: -0.3740 - val_dice_coef: 0.3740\n",
      "Epoch 838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.3880 - val_dice_coef: 0.3880\n",
      "Epoch 839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.9392 - val_dice_coef: 0.9392\n",
      "Epoch 840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.6092 - val_dice_coef: 0.6092\n",
      "Epoch 841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.2208 - val_dice_coef: 0.2208\n",
      "Epoch 842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.9423 - val_dice_coef: 0.9423\n",
      "Epoch 843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8536 - dice_coef: 0.8536 - val_loss: -0.2052 - val_dice_coef: 0.2052\n",
      "Epoch 845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.6049 - val_dice_coef: 0.6049\n",
      "Epoch 846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.8703 - val_dice_coef: 0.8703\n",
      "Epoch 847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8554 - dice_coef: 0.8554 - val_loss: -0.6792 - val_dice_coef: 0.6792\n",
      "Epoch 848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.5180 - val_dice_coef: 0.5180\n",
      "Epoch 849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.8877 - val_dice_coef: 0.8877\n",
      "Epoch 850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8568 - dice_coef: 0.8568 - val_loss: -0.8671 - val_dice_coef: 0.8671\n",
      "Epoch 851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8534 - dice_coef: 0.8534 - val_loss: -0.2253 - val_dice_coef: 0.2253\n",
      "Epoch 852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.4381 - val_dice_coef: 0.4381\n",
      "Epoch 853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.9643 - val_dice_coef: 0.9643\n",
      "Epoch 854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -0.6585 - val_dice_coef: 0.6585\n",
      "Epoch 855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8537 - dice_coef: 0.8537 - val_loss: -0.5929 - val_dice_coef: 0.5929\n",
      "Epoch 856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.4989 - val_dice_coef: 0.4989\n",
      "Epoch 857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.8995 - val_dice_coef: 0.8995\n",
      "Epoch 858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.9217 - val_dice_coef: 0.9217\n",
      "Epoch 859/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8558 - dice_coef: 0.8558 - val_loss: -0.2018 - val_dice_coef: 0.2018\n",
      "Epoch 860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.4001 - val_dice_coef: 0.4001\n",
      "Epoch 861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.7284 - val_dice_coef: 0.7284\n",
      "Epoch 863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.3112 - val_dice_coef: 0.3112\n",
      "Epoch 864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8516 - dice_coef: 0.8516 - val_loss: -0.1725 - val_dice_coef: 0.1725\n",
      "Epoch 865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.7859 - val_dice_coef: 0.7859\n",
      "Epoch 866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.7054 - val_dice_coef: 0.7054\n",
      "Epoch 867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.3892 - val_dice_coef: 0.3892\n",
      "Epoch 868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8555 - dice_coef: 0.8555 - val_loss: -0.7265 - val_dice_coef: 0.7265\n",
      "Epoch 869/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8555 - dice_coef: 0.8555 - val_loss: -0.9342 - val_dice_coef: 0.9342\n",
      "Epoch 870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.8625 - val_dice_coef: 0.8625\n",
      "Epoch 871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8576 - dice_coef: 0.8576 - val_loss: -0.6924 - val_dice_coef: 0.6924\n",
      "Epoch 872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8590 - dice_coef: 0.8590 - val_loss: -0.3277 - val_dice_coef: 0.3277\n",
      "Epoch 873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8561 - dice_coef: 0.8561 - val_loss: -0.9711 - val_dice_coef: 0.9711\n",
      "Epoch 874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.7968 - val_dice_coef: 0.7968\n",
      "Epoch 875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8313 - dice_coef: 0.8313 - val_loss: -0.0267 - val_dice_coef: 0.0267\n",
      "Epoch 876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8287 - dice_coef: 0.8287 - val_loss: -0.6550 - val_dice_coef: 0.6550\n",
      "Epoch 877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9616 - val_dice_coef: 0.9616\n",
      "Epoch 878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8542 - dice_coef: 0.8542 - val_loss: -0.4779 - val_dice_coef: 0.4779\n",
      "Epoch 879/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.5987 - val_dice_coef: 0.5987\n",
      "Epoch 880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8575 - dice_coef: 0.8575 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.7415 - val_dice_coef: 0.7415\n",
      "Epoch 882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8557 - dice_coef: 0.8557 - val_loss: -0.3103 - val_dice_coef: 0.3103\n",
      "Epoch 883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9463 - val_dice_coef: 0.9463\n",
      "Epoch 884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8585 - dice_coef: 0.8585 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8585 - dice_coef: 0.8585 - val_loss: -0.6874 - val_dice_coef: 0.6874\n",
      "Epoch 886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.0696 - val_dice_coef: 0.0696\n",
      "Epoch 887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8335 - dice_coef: 0.8335 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "Epoch 888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8458 - dice_coef: 0.8458 - val_loss: -0.9836 - val_dice_coef: 0.9836\n",
      "Epoch 889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.1278 - val_dice_coef: 0.1278\n",
      "Epoch 890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.1465 - val_dice_coef: 0.1465\n",
      "Epoch 891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8288 - dice_coef: 0.8288 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.9762 - val_dice_coef: 0.9762\n",
      "Epoch 893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8296 - dice_coef: 0.8296 - val_loss: -0.0449 - val_dice_coef: 0.0449\n",
      "Epoch 894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8268 - dice_coef: 0.8268 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7870 - dice_coef: 0.7870 - val_loss: -0.5563 - val_dice_coef: 0.5563\n",
      "Epoch 896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.0207 - val_dice_coef: 0.0207\n",
      "Epoch 897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7943 - dice_coef: 0.7943 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7990 - dice_coef: 0.7990 - val_loss: -0.0056 - val_dice_coef: 0.0056\n",
      "Epoch 899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7997 - dice_coef: 0.7997 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8140 - dice_coef: 0.8140 - val_loss: -0.0163 - val_dice_coef: 0.0163\n",
      "Epoch 901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8278 - dice_coef: 0.8278 - val_loss: -0.1731 - val_dice_coef: 0.1731\n",
      "Epoch 903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8410 - dice_coef: 0.8410 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.0969 - val_dice_coef: 0.0969\n",
      "Epoch 905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8331 - dice_coef: 0.8331 - val_loss: -0.9669 - val_dice_coef: 0.9669\n",
      "Epoch 906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8434 - dice_coef: 0.8434 - val_loss: -0.6003 - val_dice_coef: 0.6003\n",
      "Epoch 907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8463 - dice_coef: 0.8463 - val_loss: -0.8600 - val_dice_coef: 0.8600\n",
      "Epoch 908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.4440 - val_dice_coef: 0.4440\n",
      "Epoch 910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9277 - val_dice_coef: 0.9277\n",
      "Epoch 913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.9548 - val_dice_coef: 0.9548\n",
      "Epoch 914/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8631 - dice_coef: 0.8631 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9537 - val_dice_coef: 0.9537\n",
      "Epoch 916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9325 - val_dice_coef: 0.9325\n",
      "Epoch 917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.6866 - val_dice_coef: 0.6866\n",
      "Epoch 918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8566 - dice_coef: 0.8566 - val_loss: -0.8557 - val_dice_coef: 0.8557\n",
      "Epoch 919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.7017 - val_dice_coef: 0.7017\n",
      "Epoch 921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8570 - dice_coef: 0.8570 - val_loss: -0.9189 - val_dice_coef: 0.9189\n",
      "Epoch 922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.9010 - val_dice_coef: 0.9010\n",
      "Epoch 923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8594 - dice_coef: 0.8594 - val_loss: -0.9313 - val_dice_coef: 0.9313\n",
      "Epoch 924/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8615 - dice_coef: 0.8615 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.9542 - val_dice_coef: 0.9542\n",
      "Epoch 926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.9186 - val_dice_coef: 0.9186\n",
      "Epoch 927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.9228 - val_dice_coef: 0.9228\n",
      "Epoch 928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8612 - dice_coef: 0.8612 - val_loss: -0.8624 - val_dice_coef: 0.8624\n",
      "Epoch 929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8621 - dice_coef: 0.8621 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8621 - dice_coef: 0.8621 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.9413 - val_dice_coef: 0.9413\n",
      "Epoch 932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8624 - dice_coef: 0.8624 - val_loss: -0.6561 - val_dice_coef: 0.6561\n",
      "Epoch 933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8547 - dice_coef: 0.8547 - val_loss: -0.2725 - val_dice_coef: 0.2725\n",
      "Epoch 936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8480 - dice_coef: 0.8480 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -0.4746 - val_dice_coef: 0.4746\n",
      "Epoch 938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8517 - dice_coef: 0.8517 - val_loss: -0.5272 - val_dice_coef: 0.5272\n",
      "Epoch 939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.5573 - val_dice_coef: 0.5573\n",
      "Epoch 941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.8822 - val_dice_coef: 0.8822\n",
      "Epoch 942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.9764 - val_dice_coef: 0.9764\n",
      "Epoch 943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8608 - dice_coef: 0.8608 - val_loss: -0.6972 - val_dice_coef: 0.6972\n",
      "Epoch 944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.9316 - val_dice_coef: 0.9316\n",
      "Epoch 945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.5515 - val_dice_coef: 0.5515\n",
      "Epoch 947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8560 - dice_coef: 0.8560 - val_loss: -0.7683 - val_dice_coef: 0.7683\n",
      "Epoch 948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8602 - dice_coef: 0.8602 - val_loss: -0.9385 - val_dice_coef: 0.9385\n",
      "Epoch 949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.8939 - val_dice_coef: 0.8939\n",
      "Epoch 950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.8332 - val_dice_coef: 0.8332\n",
      "Epoch 951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8623 - dice_coef: 0.8623 - val_loss: -0.7924 - val_dice_coef: 0.7924\n",
      "Epoch 952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.8816 - val_dice_coef: 0.8816\n",
      "Epoch 954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.9252 - val_dice_coef: 0.9252\n",
      "Epoch 955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9265 - val_dice_coef: 0.9265\n",
      "Epoch 956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.8976 - val_dice_coef: 0.8976\n",
      "Epoch 957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8627 - dice_coef: 0.8627 - val_loss: -0.9492 - val_dice_coef: 0.9492\n",
      "Epoch 958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8616 - dice_coef: 0.8616 - val_loss: -0.9407 - val_dice_coef: 0.9407\n",
      "Epoch 959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.8555 - val_dice_coef: 0.8555\n",
      "Epoch 960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8579 - dice_coef: 0.8579 - val_loss: -0.8050 - val_dice_coef: 0.8050\n",
      "Epoch 961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8629 - dice_coef: 0.8629 - val_loss: -0.8673 - val_dice_coef: 0.8673\n",
      "Epoch 962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.8563 - val_dice_coef: 0.8563\n",
      "Epoch 963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.2059 - val_dice_coef: 0.2059\n",
      "Epoch 964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9696 - val_dice_coef: 0.9696\n",
      "Epoch 965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8543 - dice_coef: 0.8543 - val_loss: -0.9292 - val_dice_coef: 0.9292\n",
      "Epoch 966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8556 - dice_coef: 0.8556 - val_loss: -0.3905 - val_dice_coef: 0.3905\n",
      "Epoch 967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8597 - dice_coef: 0.8597 - val_loss: -0.6444 - val_dice_coef: 0.6444\n",
      "Epoch 968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8627 - dice_coef: 0.8627 - val_loss: -0.9868 - val_dice_coef: 0.9868\n",
      "Epoch 969/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -0.9687 - val_dice_coef: 0.9687\n",
      "Epoch 970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8599 - dice_coef: 0.8599 - val_loss: -0.7404 - val_dice_coef: 0.7404\n",
      "Epoch 971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.8665 - val_dice_coef: 0.8665\n",
      "Epoch 972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.1268 - val_dice_coef: 0.1268\n",
      "Epoch 974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.8072 - val_dice_coef: 0.8072\n",
      "Epoch 975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.9781 - val_dice_coef: 0.9781\n",
      "Epoch 976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8661 - dice_coef: 0.8661 - val_loss: -0.6156 - val_dice_coef: 0.6156\n",
      "Epoch 977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8617 - dice_coef: 0.8617 - val_loss: -0.9634 - val_dice_coef: 0.9634\n",
      "Epoch 978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8646 - dice_coef: 0.8646 - val_loss: -0.9197 - val_dice_coef: 0.9197\n",
      "Epoch 979/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.6328 - val_dice_coef: 0.6328\n",
      "Epoch 980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.8507 - val_dice_coef: 0.8507\n",
      "Epoch 981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8634 - dice_coef: 0.8634 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.7881 - val_dice_coef: 0.7881\n",
      "Epoch 983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8595 - dice_coef: 0.8595 - val_loss: -0.9413 - val_dice_coef: 0.9413\n",
      "Epoch 984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8638 - dice_coef: 0.8638 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8649 - dice_coef: 0.8649 - val_loss: -0.5486 - val_dice_coef: 0.5486\n",
      "Epoch 986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8647 - dice_coef: 0.8647 - val_loss: -0.9300 - val_dice_coef: 0.9300\n",
      "Epoch 988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 989/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.8006 - val_dice_coef: 0.8006\n",
      "Epoch 990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.7084 - val_dice_coef: 0.7084\n",
      "Epoch 991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8947 - val_dice_coef: 0.8947\n",
      "Epoch 992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9819 - val_dice_coef: 0.9819\n",
      "Epoch 993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.8766 - val_dice_coef: 0.8766\n",
      "Epoch 994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.5579 - val_dice_coef: 0.5579\n",
      "Epoch 995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8679 - dice_coef: 0.8679 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8581 - dice_coef: 0.8581 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.7333 - val_dice_coef: 0.7333\n",
      "Epoch 998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.4334 - val_dice_coef: 0.4334\n",
      "Epoch 999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8604 - dice_coef: 0.8604 - val_loss: -0.8550 - val_dice_coef: 0.8550\n",
      "Epoch 1000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.9571 - val_dice_coef: 0.9571\n",
      "Epoch 1001/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8622 - dice_coef: 0.8622 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 1002/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8472 - dice_coef: 0.8472 - val_loss: -0.0536 - val_dice_coef: 0.0536\n",
      "Epoch 1003/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8317 - dice_coef: 0.8317 - val_loss: -0.1666 - val_dice_coef: 0.1666\n",
      "Epoch 1004/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1005/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.1120 - val_dice_coef: 0.1120\n",
      "Epoch 1006/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8338 - dice_coef: 0.8338 - val_loss: -0.6016 - val_dice_coef: 0.6016\n",
      "Epoch 1007/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8502 - dice_coef: 0.8502 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1008/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.0098 - val_dice_coef: 0.0098\n",
      "Epoch 1009/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1010/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8097 - dice_coef: 0.8097 - val_loss: -0.6957 - val_dice_coef: 0.6957\n",
      "Epoch 1011/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8291 - dice_coef: 0.8291 - val_loss: -0.0575 - val_dice_coef: 0.0575\n",
      "Epoch 1012/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1013/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.3387 - val_dice_coef: 0.3387\n",
      "Epoch 1014/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8446 - dice_coef: 0.8446 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 1015/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8405 - dice_coef: 0.8405 - val_loss: -0.9880 - val_dice_coef: 0.9880\n",
      "Epoch 1016/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8426 - dice_coef: 0.8426 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 1017/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1018/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.4361 - val_dice_coef: 0.4361\n",
      "Epoch 1019/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8579 - dice_coef: 0.8579 - val_loss: -0.8517 - val_dice_coef: 0.8517\n",
      "Epoch 1020/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8610 - dice_coef: 0.8610 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 1021/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8625 - dice_coef: 0.8625 - val_loss: -0.6310 - val_dice_coef: 0.6310\n",
      "Epoch 1022/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8658 - dice_coef: 0.8658 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1023/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8412 - dice_coef: 0.8412 - val_loss: -0.5694 - val_dice_coef: 0.5694\n",
      "Epoch 1024/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.1939 - val_dice_coef: 0.1939\n",
      "Epoch 1025/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1026/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.5309 - val_dice_coef: 0.5309\n",
      "Epoch 1027/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8594 - dice_coef: 0.8594 - val_loss: -0.8949 - val_dice_coef: 0.8949\n",
      "Epoch 1028/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.9792 - val_dice_coef: 0.9792\n",
      "Epoch 1029/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8665 - dice_coef: 0.8665 - val_loss: -0.7203 - val_dice_coef: 0.7203\n",
      "Epoch 1030/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 1031/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8660 - dice_coef: 0.8660 - val_loss: -0.9150 - val_dice_coef: 0.9150\n",
      "Epoch 1032/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8670 - dice_coef: 0.8670 - val_loss: -0.7944 - val_dice_coef: 0.7944\n",
      "Epoch 1033/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.8140 - val_dice_coef: 0.8140\n",
      "Epoch 1034/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.9357 - val_dice_coef: 0.9357\n",
      "Epoch 1035/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.7574 - val_dice_coef: 0.7574\n",
      "Epoch 1036/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8654 - dice_coef: 0.8654 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 1037/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 1038/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8660 - dice_coef: 0.8660 - val_loss: -0.3575 - val_dice_coef: 0.3575\n",
      "Epoch 1039/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8628 - dice_coef: 0.8628 - val_loss: -0.9336 - val_dice_coef: 0.9336\n",
      "Epoch 1040/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 1041/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.8473 - val_dice_coef: 0.8473\n",
      "Epoch 1042/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.6599 - val_dice_coef: 0.6599\n",
      "Epoch 1043/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8600 - dice_coef: 0.8600 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1044/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8666 - dice_coef: 0.8666 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1045/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8676 - dice_coef: 0.8676 - val_loss: -0.6482 - val_dice_coef: 0.6482\n",
      "Epoch 1046/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.6694 - val_dice_coef: 0.6694\n",
      "Epoch 1047/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.9896 - val_dice_coef: 0.9896\n",
      "Epoch 1048/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9164 - val_dice_coef: 0.9164\n",
      "Epoch 1049/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8592 - dice_coef: 0.8592 - val_loss: -0.5549 - val_dice_coef: 0.5549\n",
      "Epoch 1050/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8654 - dice_coef: 0.8654 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 1051/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8705 - dice_coef: 0.8705 - val_loss: -0.9049 - val_dice_coef: 0.9049\n",
      "Epoch 1052/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8694 - dice_coef: 0.8694 - val_loss: -0.9109 - val_dice_coef: 0.9109\n",
      "Epoch 1053/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.8367 - val_dice_coef: 0.8367\n",
      "Epoch 1054/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8696 - dice_coef: 0.8696 - val_loss: -0.9657 - val_dice_coef: 0.9657\n",
      "Epoch 1055/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9415 - val_dice_coef: 0.9415\n",
      "Epoch 1056/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8690 - dice_coef: 0.8690 - val_loss: -0.7286 - val_dice_coef: 0.7286\n",
      "Epoch 1057/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8688 - dice_coef: 0.8688 - val_loss: -0.9478 - val_dice_coef: 0.9478\n",
      "Epoch 1058/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8705 - dice_coef: 0.8705 - val_loss: -0.9559 - val_dice_coef: 0.9559\n",
      "Epoch 1059/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.7451 - val_dice_coef: 0.7451\n",
      "Epoch 1060/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8699 - dice_coef: 0.8699 - val_loss: -0.8512 - val_dice_coef: 0.8512\n",
      "Epoch 1061/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1062/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.9079 - val_dice_coef: 0.9079\n",
      "Epoch 1063/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.7620 - val_dice_coef: 0.7620\n",
      "Epoch 1064/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.7545 - val_dice_coef: 0.7545\n",
      "Epoch 1065/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 1066/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8601 - dice_coef: 0.8601 - val_loss: -0.9141 - val_dice_coef: 0.9141\n",
      "Epoch 1067/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.4374 - val_dice_coef: 0.4374\n",
      "Epoch 1068/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8572 - dice_coef: 0.8572 - val_loss: -0.9088 - val_dice_coef: 0.9088\n",
      "Epoch 1069/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1070/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8502 - dice_coef: 0.8502 - val_loss: -0.0892 - val_dice_coef: 0.0892\n",
      "Epoch 1071/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.3519 - val_dice_coef: 0.3519\n",
      "Epoch 1072/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1073/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.1056 - val_dice_coef: 0.1056\n",
      "Epoch 1074/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.9048 - val_dice_coef: 0.9048\n",
      "Epoch 1075/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1076/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.0317 - val_dice_coef: 0.0317\n",
      "Epoch 1077/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8090 - dice_coef: 0.8090 - val_loss: -0.4089 - val_dice_coef: 0.4089\n",
      "Epoch 1078/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1079/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.1518 - val_dice_coef: 0.1518\n",
      "Epoch 1080/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8499 - dice_coef: 0.8499 - val_loss: -0.7791 - val_dice_coef: 0.7791\n",
      "Epoch 1081/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8526 - dice_coef: 0.8526 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1082/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.0804 - val_dice_coef: 0.0804\n",
      "Epoch 1083/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8449 - dice_coef: 0.8449 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 1084/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.8349 - val_dice_coef: 0.8349\n",
      "Epoch 1085/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.1126 - val_dice_coef: 0.1126\n",
      "Epoch 1086/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8385 - dice_coef: 0.8385 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1087/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8254 - dice_coef: 0.8254 - val_loss: -0.5600 - val_dice_coef: 0.5600\n",
      "Epoch 1088/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8609 - dice_coef: 0.8609 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 1089/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8603 - dice_coef: 0.8603 - val_loss: -0.9614 - val_dice_coef: 0.9614\n",
      "Epoch 1090/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8645 - dice_coef: 0.8645 - val_loss: -0.8877 - val_dice_coef: 0.8877\n",
      "Epoch 1091/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 1092/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8304 - val_dice_coef: 0.8304\n",
      "Epoch 1093/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9045 - val_dice_coef: 0.9045\n",
      "Epoch 1094/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1095/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8688 - dice_coef: 0.8688 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "Epoch 1096/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.8798 - val_dice_coef: 0.8798\n",
      "Epoch 1097/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1098/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.6924 - val_dice_coef: 0.6924\n",
      "Epoch 1099/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.9647 - val_dice_coef: 0.9647\n",
      "Epoch 1100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8693 - dice_coef: 0.8693 - val_loss: -0.9751 - val_dice_coef: 0.9751\n",
      "Epoch 1101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8683 - dice_coef: 0.8683 - val_loss: -0.8918 - val_dice_coef: 0.8918\n",
      "Epoch 1102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8741 - dice_coef: 0.8741 - val_loss: -0.9223 - val_dice_coef: 0.9223\n",
      "Epoch 1103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "Epoch 1104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.9560 - val_dice_coef: 0.9560\n",
      "Epoch 1105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8715 - dice_coef: 0.8715 - val_loss: -0.9793 - val_dice_coef: 0.9793\n",
      "Epoch 1106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.7256 - val_dice_coef: 0.7256\n",
      "Epoch 1107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.8245 - val_dice_coef: 0.8245\n",
      "Epoch 1108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8672 - dice_coef: 0.8672 - val_loss: -0.7725 - val_dice_coef: 0.7725\n",
      "Epoch 1110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9215 - val_dice_coef: 0.9215\n",
      "Epoch 1111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8685 - dice_coef: 0.8685 - val_loss: -0.8775 - val_dice_coef: 0.8775\n",
      "Epoch 1113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.9527 - val_dice_coef: 0.9527\n",
      "Epoch 1114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.4950 - val_dice_coef: 0.4950\n",
      "Epoch 1116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8658 - dice_coef: 0.8658 - val_loss: -0.9236 - val_dice_coef: 0.9236\n",
      "Epoch 1117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8686 - dice_coef: 0.8686 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8689 - dice_coef: 0.8689 - val_loss: -0.7843 - val_dice_coef: 0.7843\n",
      "Epoch 1119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.9836 - val_dice_coef: 0.9836\n",
      "Epoch 1120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8718 - dice_coef: 0.8718 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.9663 - val_dice_coef: 0.9663\n",
      "Epoch 1122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8737 - dice_coef: 0.8737 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 1123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.8007 - val_dice_coef: 0.8007\n",
      "Epoch 1124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.9861 - val_dice_coef: 0.9861\n",
      "Epoch 1125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8616 - dice_coef: 0.8616 - val_loss: -0.0640 - val_dice_coef: 0.0640\n",
      "Epoch 1127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.8262 - val_dice_coef: 0.8262\n",
      "Epoch 1128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.1988 - val_dice_coef: 0.1988\n",
      "Epoch 1130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8562 - dice_coef: 0.8562 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8604 - dice_coef: 0.8604 - val_loss: -0.7498 - val_dice_coef: 0.7498\n",
      "Epoch 1132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8689 - dice_coef: 0.8689 - val_loss: -0.3435 - val_dice_coef: 0.3435\n",
      "Epoch 1135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.9566 - val_dice_coef: 0.9566\n",
      "Epoch 1136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8607 - dice_coef: 0.8607 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.8013 - val_dice_coef: 0.8013\n",
      "Epoch 1138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.8925 - val_dice_coef: 0.8925\n",
      "Epoch 1139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8708 - dice_coef: 0.8708 - val_loss: -0.9755 - val_dice_coef: 0.9755\n",
      "Epoch 1140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9490 - val_dice_coef: 0.9490\n",
      "Epoch 1141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9386 - val_dice_coef: 0.9386\n",
      "Epoch 1142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.8723 - val_dice_coef: 0.8723\n",
      "Epoch 1143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 1144/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.9019 - val_dice_coef: 0.9019\n",
      "Epoch 1145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.8416 - val_dice_coef: 0.8416\n",
      "Epoch 1146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 1147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 1148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8733 - dice_coef: 0.8733 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9353 - val_dice_coef: 0.9353\n",
      "Epoch 1150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.8787 - val_dice_coef: 0.8787\n",
      "Epoch 1151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9200 - val_dice_coef: 0.9200\n",
      "Epoch 1152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8685 - dice_coef: 0.8685 - val_loss: -0.9765 - val_dice_coef: 0.9765\n",
      "Epoch 1153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8744 - dice_coef: 0.8744 - val_loss: -0.8773 - val_dice_coef: 0.8773\n",
      "Epoch 1154/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.9595 - val_dice_coef: 0.9595\n",
      "Epoch 1155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 1156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.5922 - val_dice_coef: 0.5922\n",
      "Epoch 1158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.7393 - val_dice_coef: 0.7393\n",
      "Epoch 1159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8656 - dice_coef: 0.8656 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 1160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 1161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.4817 - val_dice_coef: 0.4817\n",
      "Epoch 1162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 1163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 1164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8684 - dice_coef: 0.8684 - val_loss: -0.1108 - val_dice_coef: 0.1108\n",
      "Epoch 1165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8624 - dice_coef: 0.8624 - val_loss: -0.9803 - val_dice_coef: 0.9803\n",
      "Epoch 1167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.1844 - val_dice_coef: 0.1844\n",
      "Epoch 1168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 1169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.6831 - val_dice_coef: 0.6831\n",
      "Epoch 1170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -0.5705 - val_dice_coef: 0.5705\n",
      "Epoch 1171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.6655 - val_dice_coef: 0.6655\n",
      "Epoch 1173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.8917 - val_dice_coef: 0.8917\n",
      "Epoch 1174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8692 - dice_coef: 0.8692 - val_loss: -0.9620 - val_dice_coef: 0.9620\n",
      "Epoch 1175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 1176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9668 - val_dice_coef: 0.9668\n",
      "Epoch 1177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8760 - dice_coef: 0.8760 - val_loss: -0.4225 - val_dice_coef: 0.4225\n",
      "Epoch 1178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8568 - dice_coef: 0.8568 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8617 - dice_coef: 0.8617 - val_loss: -0.2472 - val_dice_coef: 0.2472\n",
      "Epoch 1181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.9606 - val_dice_coef: 0.9606\n",
      "Epoch 1182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 1183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.8566 - val_dice_coef: 0.8566\n",
      "Epoch 1184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.7026 - val_dice_coef: 0.7026\n",
      "Epoch 1185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "Epoch 1187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9058 - val_dice_coef: 0.9058\n",
      "Epoch 1188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.4322 - val_dice_coef: 0.4322\n",
      "Epoch 1190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.7995 - val_dice_coef: 0.7995\n",
      "Epoch 1191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.9844 - val_dice_coef: 0.9844\n",
      "Epoch 1192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9046 - val_dice_coef: 0.9046\n",
      "Epoch 1193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.5496 - val_dice_coef: 0.5496\n",
      "Epoch 1194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8648 - dice_coef: 0.8648 - val_loss: -0.9909 - val_dice_coef: 0.9909\n",
      "Epoch 1195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 1196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.0458 - val_dice_coef: 0.0458\n",
      "Epoch 1197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8235 - dice_coef: 0.8235 - val_loss: -0.0956 - val_dice_coef: 0.0956\n",
      "Epoch 1198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8426 - dice_coef: 0.8426 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1199/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.0376 - val_dice_coef: 0.0376\n",
      "Epoch 1200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9591 - val_dice_coef: 0.9591\n",
      "Epoch 1202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.3772 - val_dice_coef: 0.3772\n",
      "Epoch 1203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8635 - dice_coef: 0.8635 - val_loss: -0.8594 - val_dice_coef: 0.8594\n",
      "Epoch 1205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9872 - val_dice_coef: 0.9872\n",
      "Epoch 1206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 1207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.6851 - val_dice_coef: 0.6851\n",
      "Epoch 1208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9956 - val_dice_coef: 0.9956\n",
      "Epoch 1209/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.9248 - val_dice_coef: 0.9248\n",
      "Epoch 1210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -0.5337 - val_dice_coef: 0.5337\n",
      "Epoch 1211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.9769 - val_dice_coef: 0.9769\n",
      "Epoch 1212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8773 - dice_coef: 0.8773 - val_loss: -0.7920 - val_dice_coef: 0.7920\n",
      "Epoch 1213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9271 - val_dice_coef: 0.9271\n",
      "Epoch 1214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.9746 - val_dice_coef: 0.9746\n",
      "Epoch 1215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8755 - dice_coef: 0.8755 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "Epoch 1216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.8132 - val_dice_coef: 0.8132\n",
      "Epoch 1217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.9755 - val_dice_coef: 0.9755\n",
      "Epoch 1218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9377 - val_dice_coef: 0.9377\n",
      "Epoch 1219/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 1220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9523 - val_dice_coef: 0.9523\n",
      "Epoch 1221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.9513 - val_dice_coef: 0.9513\n",
      "Epoch 1222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9321 - val_dice_coef: 0.9321\n",
      "Epoch 1223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9393 - val_dice_coef: 0.9393\n",
      "Epoch 1224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8780 - dice_coef: 0.8780 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 1225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.9235 - val_dice_coef: 0.9235\n",
      "Epoch 1226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.9359 - val_dice_coef: 0.9359\n",
      "Epoch 1227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9820 - val_dice_coef: 0.9820\n",
      "Epoch 1228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8799 - dice_coef: 0.8799 - val_loss: -0.6893 - val_dice_coef: 0.6893\n",
      "Epoch 1229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 1231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9458 - val_dice_coef: 0.9458\n",
      "Epoch 1232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9079 - val_dice_coef: 0.9079\n",
      "Epoch 1233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8787 - dice_coef: 0.8787 - val_loss: -0.9396 - val_dice_coef: 0.9396\n",
      "Epoch 1234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9063 - val_dice_coef: 0.9063\n",
      "Epoch 1235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8770 - dice_coef: 0.8770 - val_loss: -0.5947 - val_dice_coef: 0.5947\n",
      "Epoch 1238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.9679 - val_dice_coef: 0.9679\n",
      "Epoch 1239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 1240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8702 - dice_coef: 0.8702 - val_loss: -0.2189 - val_dice_coef: 0.2189\n",
      "Epoch 1241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.9456 - val_dice_coef: 0.9456\n",
      "Epoch 1242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8687 - dice_coef: 0.8687 - val_loss: -0.4867 - val_dice_coef: 0.4867\n",
      "Epoch 1244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8629 - dice_coef: 0.8629 - val_loss: -0.2168 - val_dice_coef: 0.2168\n",
      "Epoch 1245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.6962 - val_dice_coef: 0.6962\n",
      "Epoch 1247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.1174 - val_dice_coef: 0.1174\n",
      "Epoch 1248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8549 - dice_coef: 0.8549 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.9383 - val_dice_coef: 0.9383\n",
      "Epoch 1250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8724 - dice_coef: 0.8724 - val_loss: -0.5627 - val_dice_coef: 0.5627\n",
      "Epoch 1251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 1253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8777 - dice_coef: 0.8777 - val_loss: -0.7830 - val_dice_coef: 0.7830\n",
      "Epoch 1254/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9698 - val_dice_coef: 0.9698\n",
      "Epoch 1255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8799 - dice_coef: 0.8799 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.8652 - val_dice_coef: 0.8652\n",
      "Epoch 1257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9314 - val_dice_coef: 0.9314\n",
      "Epoch 1258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8762 - dice_coef: 0.8762 - val_loss: -0.9479 - val_dice_coef: 0.9479\n",
      "Epoch 1261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.8223 - val_dice_coef: 0.8223\n",
      "Epoch 1262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.7438 - val_dice_coef: 0.7438\n",
      "Epoch 1264/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8679 - dice_coef: 0.8679 - val_loss: -0.2187 - val_dice_coef: 0.2187\n",
      "Epoch 1265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8427 - dice_coef: 0.8427 - val_loss: -0.5254 - val_dice_coef: 0.5254\n",
      "Epoch 1267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.0585 - val_dice_coef: 0.0585\n",
      "Epoch 1268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0653 - val_dice_coef: 0.0653\n",
      "Epoch 1270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.5930 - val_dice_coef: 0.5930\n",
      "Epoch 1271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.4535 - val_dice_coef: 0.4535\n",
      "Epoch 1273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8697 - dice_coef: 0.8697 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9800 - val_dice_coef: 0.9800\n",
      "Epoch 1275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.6696 - val_dice_coef: 0.6696\n",
      "Epoch 1276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8661 - dice_coef: 0.8661 - val_loss: -0.1610 - val_dice_coef: 0.1610\n",
      "Epoch 1279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8699 - dice_coef: 0.8699 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.7982 - val_dice_coef: 0.7982\n",
      "Epoch 1281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.9349 - val_dice_coef: 0.9349\n",
      "Epoch 1282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8737 - dice_coef: 0.8737 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.8544 - val_dice_coef: 0.8544\n",
      "Epoch 1284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9820 - val_dice_coef: 0.9820\n",
      "Epoch 1285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8794 - dice_coef: 0.8794 - val_loss: -0.7478 - val_dice_coef: 0.7478\n",
      "Epoch 1287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 1288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.7808 - val_dice_coef: 0.7808\n",
      "Epoch 1290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.9448 - val_dice_coef: 0.9448\n",
      "Epoch 1292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.7170 - val_dice_coef: 0.7170\n",
      "Epoch 1293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9073 - val_dice_coef: 0.9073\n",
      "Epoch 1295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.5361 - val_dice_coef: 0.5361\n",
      "Epoch 1296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8763 - dice_coef: 0.8763 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9063 - val_dice_coef: 0.9063\n",
      "Epoch 1298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8755 - dice_coef: 0.8755 - val_loss: -0.8915 - val_dice_coef: 0.8915\n",
      "Epoch 1299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -0.5298 - val_dice_coef: 0.5298\n",
      "Epoch 1301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8740 - dice_coef: 0.8740 - val_loss: -0.9875 - val_dice_coef: 0.9875\n",
      "Epoch 1302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 1303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.8967 - val_dice_coef: 0.8967\n",
      "Epoch 1304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9702 - val_dice_coef: 0.9702\n",
      "Epoch 1305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 1306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8818 - dice_coef: 0.8818 - val_loss: -0.7640 - val_dice_coef: 0.7640\n",
      "Epoch 1307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9842 - val_dice_coef: 0.9842\n",
      "Epoch 1309/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8804 - dice_coef: 0.8804 - val_loss: -0.8562 - val_dice_coef: 0.8562\n",
      "Epoch 1310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8779 - dice_coef: 0.8779 - val_loss: -0.8712 - val_dice_coef: 0.8712\n",
      "Epoch 1311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 1313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
      "Epoch 1314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.8932 - val_dice_coef: 0.8932\n",
      "Epoch 1316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.7943 - val_dice_coef: 0.7943\n",
      "Epoch 1317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9017 - val_dice_coef: 0.9017\n",
      "Epoch 1319/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8702 - dice_coef: 0.8702 - val_loss: -0.8048 - val_dice_coef: 0.8048\n",
      "Epoch 1320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 1321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.7515 - val_dice_coef: 0.7515\n",
      "Epoch 1322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.4710 - val_dice_coef: 0.4710\n",
      "Epoch 1323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8622 - dice_coef: 0.8622 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 1325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.0405 - val_dice_coef: 0.0405\n",
      "Epoch 1326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8495 - dice_coef: 0.8495 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8563 - dice_coef: 0.8563 - val_loss: -0.9283 - val_dice_coef: 0.9283\n",
      "Epoch 1328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8684 - dice_coef: 0.8684 - val_loss: -0.4080 - val_dice_coef: 0.4080\n",
      "Epoch 1329/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8703 - dice_coef: 0.8703 - val_loss: -0.7567 - val_dice_coef: 0.7567\n",
      "Epoch 1331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9764 - val_dice_coef: 0.9764\n",
      "Epoch 1332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 1333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.2174 - val_dice_coef: 0.2174\n",
      "Epoch 1334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8640 - dice_coef: 0.8640 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.7884 - val_dice_coef: 0.7884\n",
      "Epoch 1336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.8379 - val_dice_coef: 0.8379\n",
      "Epoch 1337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8759 - dice_coef: 0.8759 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 1339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.9426 - val_dice_coef: 0.9426\n",
      "Epoch 1340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8823 - dice_coef: 0.8823 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -0.5192 - val_dice_coef: 0.5192\n",
      "Epoch 1342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9811 - val_dice_coef: 0.9811\n",
      "Epoch 1343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.8578 - val_dice_coef: 0.8578\n",
      "Epoch 1345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 1346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9368 - val_dice_coef: 0.9368\n",
      "Epoch 1348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8851 - dice_coef: 0.8851 - val_loss: -0.9873 - val_dice_coef: 0.9873\n",
      "Epoch 1349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8815 - dice_coef: 0.8815 - val_loss: -0.8931 - val_dice_coef: 0.8931\n",
      "Epoch 1350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8831 - dice_coef: 0.8831 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 1351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 1353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.8807 - val_dice_coef: 0.8807\n",
      "Epoch 1354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 1355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9674 - val_dice_coef: 0.9674\n",
      "Epoch 1356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9875 - val_dice_coef: 0.9875\n",
      "Epoch 1357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8847 - dice_coef: 0.8847 - val_loss: -0.9623 - val_dice_coef: 0.9623\n",
      "Epoch 1358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9287 - val_dice_coef: 0.9287\n",
      "Epoch 1359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9515 - val_dice_coef: 0.9515\n",
      "Epoch 1360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8842 - dice_coef: 0.8842 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 1361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.9364 - val_dice_coef: 0.9364\n",
      "Epoch 1362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.8061 - val_dice_coef: 0.8061\n",
      "Epoch 1363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 1364/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.8924 - val_dice_coef: 0.8924\n",
      "Epoch 1366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.8853 - val_dice_coef: 0.8853\n",
      "Epoch 1367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.7476 - val_dice_coef: 0.7476\n",
      "Epoch 1370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 1371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8656 - dice_coef: 0.8656 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.2390 - val_dice_coef: 0.2390\n",
      "Epoch 1374/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8795 - dice_coef: 0.8795 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.6036 - val_dice_coef: 0.6036\n",
      "Epoch 1377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.8611 - val_dice_coef: 0.8611\n",
      "Epoch 1378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9521 - val_dice_coef: 0.9521\n",
      "Epoch 1380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9455 - val_dice_coef: 0.9455\n",
      "Epoch 1381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9195 - val_dice_coef: 0.9195\n",
      "Epoch 1383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.7753 - val_dice_coef: 0.7753\n",
      "Epoch 1384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.9845 - val_dice_coef: 0.9845\n",
      "Epoch 1386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.6840 - val_dice_coef: 0.6840\n",
      "Epoch 1387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.5232 - val_dice_coef: 0.5232\n",
      "Epoch 1390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 1391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 1393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8864 - dice_coef: 0.8864 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9704 - val_dice_coef: 0.9704\n",
      "Epoch 1395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8829 - dice_coef: 0.8829 - val_loss: -0.8821 - val_dice_coef: 0.8821\n",
      "Epoch 1396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8823 - dice_coef: 0.8823 - val_loss: -0.8286 - val_dice_coef: 0.8286\n",
      "Epoch 1398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.7954 - val_dice_coef: 0.7954\n",
      "Epoch 1399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.7331 - val_dice_coef: 0.7331\n",
      "Epoch 1401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.2798 - val_dice_coef: 0.2798\n",
      "Epoch 1402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.5671 - val_dice_coef: 0.5671\n",
      "Epoch 1404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.8881 - val_dice_coef: 0.8881\n",
      "Epoch 1405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8686 - dice_coef: 0.8686 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 1407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8757 - dice_coef: 0.8757 - val_loss: -0.8560 - val_dice_coef: 0.8560\n",
      "Epoch 1408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.5029 - val_dice_coef: 0.5029\n",
      "Epoch 1410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 1411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8750 - dice_coef: 0.8750 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.8011 - val_dice_coef: 0.8011\n",
      "Epoch 1413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8780 - dice_coef: 0.8780 - val_loss: -0.7275 - val_dice_coef: 0.7275\n",
      "Epoch 1414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.8300 - val_dice_coef: 0.8300\n",
      "Epoch 1416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9668 - val_dice_coef: 0.9668\n",
      "Epoch 1417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.7602 - val_dice_coef: 0.7602\n",
      "Epoch 1419/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 1420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8869 - dice_coef: 0.8869 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9878 - val_dice_coef: 0.9878\n",
      "Epoch 1422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8874 - dice_coef: 0.8874 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 1423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9813 - val_dice_coef: 0.9813\n",
      "Epoch 1425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8862 - dice_coef: 0.8862 - val_loss: -0.9892 - val_dice_coef: 0.9892\n",
      "Epoch 1426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.7790 - val_dice_coef: 0.7790\n",
      "Epoch 1428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1429/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.5066 - val_dice_coef: 0.5066\n",
      "Epoch 1431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 1432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 1433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.9503 - val_dice_coef: 0.9503\n",
      "Epoch 1434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9680 - val_dice_coef: 0.9680\n",
      "Epoch 1435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.9775 - val_dice_coef: 0.9775\n",
      "Epoch 1437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 1438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1439/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9406 - val_dice_coef: 0.9406\n",
      "Epoch 1440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9496 - val_dice_coef: 0.9496\n",
      "Epoch 1441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.7550 - val_dice_coef: 0.7550\n",
      "Epoch 1444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9906 - val_dice_coef: 0.9906\n",
      "Epoch 1445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8869 - dice_coef: 0.8869 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8820 - dice_coef: 0.8820 - val_loss: -0.9122 - val_dice_coef: 0.9122\n",
      "Epoch 1447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9654 - val_dice_coef: 0.9654\n",
      "Epoch 1448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 1450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "Epoch 1451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 1452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 1453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8880 - dice_coef: 0.8880 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 1454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8853 - dice_coef: 0.8853 - val_loss: -0.9077 - val_dice_coef: 0.9077\n",
      "Epoch 1455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8872 - dice_coef: 0.8872 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 1457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8854 - dice_coef: 0.8854 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 1458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.8697 - val_dice_coef: 0.8697\n",
      "Epoch 1459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 1462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9592 - val_dice_coef: 0.9592\n",
      "Epoch 1463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8878 - dice_coef: 0.8878 - val_loss: -0.9028 - val_dice_coef: 0.9028\n",
      "Epoch 1466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.9455 - val_dice_coef: 0.9455\n",
      "Epoch 1471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.9116 - val_dice_coef: 0.9116\n",
      "Epoch 1472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1474/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9324 - val_dice_coef: 0.9324\n",
      "Epoch 1475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9858 - val_dice_coef: 0.9858\n",
      "Epoch 1476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8901 - dice_coef: 0.8901 - val_loss: -0.9861 - val_dice_coef: 0.9860\n",
      "Epoch 1477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8898 - dice_coef: 0.8898 - val_loss: -0.9476 - val_dice_coef: 0.9476\n",
      "Epoch 1478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 1479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8847 - dice_coef: 0.8847 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 1480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -0.4743 - val_dice_coef: 0.4743\n",
      "Epoch 1481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8806 - dice_coef: 0.8806 - val_loss: -0.8402 - val_dice_coef: 0.8402\n",
      "Epoch 1482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8809 - dice_coef: 0.8809 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1484/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.2526 - val_dice_coef: 0.2526\n",
      "Epoch 1485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.9901 - val_dice_coef: 0.9901\n",
      "Epoch 1486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.8856 - val_dice_coef: 0.8856\n",
      "Epoch 1488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8830 - dice_coef: 0.8830 - val_loss: -0.0971 - val_dice_coef: 0.0971\n",
      "Epoch 1489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.3692 - val_dice_coef: 0.3692\n",
      "Epoch 1492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 1493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9403 - val_dice_coef: 0.9403\n",
      "Epoch 1495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8871 - dice_coef: 0.8871 - val_loss: -0.9277 - val_dice_coef: 0.9277\n",
      "Epoch 1497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.5883 - val_dice_coef: 0.5883\n",
      "Epoch 1498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8878 - dice_coef: 0.8878 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 1500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.4534 - val_dice_coef: 0.4534\n",
      "Epoch 1501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8789 - dice_coef: 0.8789 - val_loss: -0.9245 - val_dice_coef: 0.9245\n",
      "Epoch 1502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8800 - dice_coef: 0.8800 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9635 - val_dice_coef: 0.9635\n",
      "Epoch 1504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.6363 - val_dice_coef: 0.6363\n",
      "Epoch 1505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 1507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 1508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.6256 - val_dice_coef: 0.6256\n",
      "Epoch 1509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8813 - dice_coef: 0.8813 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9877 - val_dice_coef: 0.9877\n",
      "Epoch 1511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8885 - dice_coef: 0.8885 - val_loss: -0.7086 - val_dice_coef: 0.7086\n",
      "Epoch 1512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 1513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8889 - dice_coef: 0.8889 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8842 - dice_coef: 0.8842 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 1515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.8409 - val_dice_coef: 0.8409\n",
      "Epoch 1516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.8782 - val_dice_coef: 0.8782\n",
      "Epoch 1520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.9585 - val_dice_coef: 0.9585\n",
      "Epoch 1523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.5229 - val_dice_coef: 0.5229\n",
      "Epoch 1524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9806 - val_dice_coef: 0.9806\n",
      "Epoch 1526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8927 - dice_coef: 0.8927 - val_loss: -0.9602 - val_dice_coef: 0.9602\n",
      "Epoch 1529/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 1531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 1532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8910 - dice_coef: 0.8910 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 1535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9702 - val_dice_coef: 0.9702\n",
      "Epoch 1537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 1539/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 1541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9630 - val_dice_coef: 0.9630\n",
      "Epoch 1542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9517 - val_dice_coef: 0.9517\n",
      "Epoch 1543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8925 - dice_coef: 0.8925 - val_loss: -0.9853 - val_dice_coef: 0.9853\n",
      "Epoch 1548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8915 - dice_coef: 0.8915 - val_loss: -0.9361 - val_dice_coef: 0.9361\n",
      "Epoch 1549/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "Epoch 1550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8800 - dice_coef: 0.8800 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 1553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9578 - val_dice_coef: 0.9578\n",
      "Epoch 1554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 1555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8939 - dice_coef: 0.8939 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 1556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8935 - dice_coef: 0.8935 - val_loss: -0.9822 - val_dice_coef: 0.9822\n",
      "Epoch 1557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.8629 - val_dice_coef: 0.8629\n",
      "Epoch 1558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 1559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 1560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8905 - dice_coef: 0.8905 - val_loss: -0.9371 - val_dice_coef: 0.9371\n",
      "Epoch 1562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.3627 - val_dice_coef: 0.3627\n",
      "Epoch 1563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.8936 - val_dice_coef: 0.8936\n",
      "Epoch 1566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.5421 - val_dice_coef: 0.5421\n",
      "Epoch 1567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.8160 - val_dice_coef: 0.8160\n",
      "Epoch 1570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.8215 - val_dice_coef: 0.8215\n",
      "Epoch 1571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8777 - dice_coef: 0.8777 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 1573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.8056 - val_dice_coef: 0.8056\n",
      "Epoch 1574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8813 - dice_coef: 0.8813 - val_loss: -0.7738 - val_dice_coef: 0.7738\n",
      "Epoch 1575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8851 - dice_coef: 0.8851 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8876 - dice_coef: 0.8876 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 1578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.9532 - val_dice_coef: 0.9532\n",
      "Epoch 1579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8855 - dice_coef: 0.8855 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 1583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.8843 - val_dice_coef: 0.8843\n",
      "Epoch 1584/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8898 - dice_coef: 0.8898 - val_loss: -0.9842 - val_dice_coef: 0.9842\n",
      "Epoch 1585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9646 - val_dice_coef: 0.9646\n",
      "Epoch 1588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9435 - val_dice_coef: 0.9435\n",
      "Epoch 1589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9877 - val_dice_coef: 0.9877\n",
      "Epoch 1590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9839 - val_dice_coef: 0.9839\n",
      "Epoch 1591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9308 - val_dice_coef: 0.9308\n",
      "Epoch 1592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 1594/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 1596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 1599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8889 - dice_coef: 0.8889 - val_loss: -0.8511 - val_dice_coef: 0.8511\n",
      "Epoch 1600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.8326 - val_dice_coef: 0.8326\n",
      "Epoch 1601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 1604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.0651 - val_dice_coef: 0.0651\n",
      "Epoch 1605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 1606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8809 - dice_coef: 0.8809 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 1608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.8713 - val_dice_coef: 0.8713\n",
      "Epoch 1609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8924 - dice_coef: 0.8924 - val_loss: -0.9309 - val_dice_coef: 0.9309\n",
      "Epoch 1613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 1614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.8763 - val_dice_coef: 0.8763\n",
      "Epoch 1616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 1618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 1620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 1621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8843 - dice_coef: 0.8843 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.4770 - val_dice_coef: 0.4770\n",
      "Epoch 1631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.9613 - val_dice_coef: 0.9613\n",
      "Epoch 1632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9713 - val_dice_coef: 0.9713\n",
      "Epoch 1634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 1635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8920 - dice_coef: 0.8920 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 1639/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8924 - dice_coef: 0.8924 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 1646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9299 - val_dice_coef: 0.9299\n",
      "Epoch 1647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9878 - val_dice_coef: 0.9878\n",
      "Epoch 1649/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 1650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9784 - val_dice_coef: 0.9784\n",
      "Epoch 1651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 1652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 1655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9644 - val_dice_coef: 0.9644\n",
      "Epoch 1659/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 1660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9716 - val_dice_coef: 0.9716\n",
      "Epoch 1661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 1662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9715 - val_dice_coef: 0.9715\n",
      "Epoch 1665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.7468 - val_dice_coef: 0.7468\n",
      "Epoch 1666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.5739 - val_dice_coef: 0.5739\n",
      "Epoch 1667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8676 - dice_coef: 0.8676 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8680 - dice_coef: 0.8680 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8694 - dice_coef: 0.8694 - val_loss: -0.8318 - val_dice_coef: 0.8318\n",
      "Epoch 1670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.1576 - val_dice_coef: 0.1576\n",
      "Epoch 1671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8592 - dice_coef: 0.8592 - val_loss: -0.5521 - val_dice_coef: 0.5521\n",
      "Epoch 1672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.5260 - val_dice_coef: 0.5260\n",
      "Epoch 1674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.8793 - val_dice_coef: 0.8793\n",
      "Epoch 1677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9944 - val_dice_coef: 0.9944\n",
      "Epoch 1679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9348 - val_dice_coef: 0.9348\n",
      "Epoch 1680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 1681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8935 - dice_coef: 0.8935 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 1684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8958 - dice_coef: 0.8958 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 1685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9341 - val_dice_coef: 0.9341\n",
      "Epoch 1688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9782 - val_dice_coef: 0.9782\n",
      "Epoch 1690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 1691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9905 - val_dice_coef: 0.9905\n",
      "Epoch 1692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1694/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9083 - val_dice_coef: 0.9083\n",
      "Epoch 1699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8951 - dice_coef: 0.8951 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 1700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 1703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1704/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 1708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 1709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9008 - dice_coef: 0.9008 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9001 - dice_coef: 0.9001 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9852 - val_dice_coef: 0.9852\n",
      "Epoch 1715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9847 - val_dice_coef: 0.9847\n",
      "Epoch 1716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9677 - val_dice_coef: 0.9677\n",
      "Epoch 1721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.7673 - val_dice_coef: 0.7673\n",
      "Epoch 1722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.9616 - val_dice_coef: 0.9616\n",
      "Epoch 1723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9504 - val_dice_coef: 0.9504\n",
      "Epoch 1727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.8598 - val_dice_coef: 0.8598\n",
      "Epoch 1728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 1729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8903 - dice_coef: 0.8903 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9930 - val_dice_coef: 0.9930\n",
      "Epoch 1732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9200 - val_dice_coef: 0.9200\n",
      "Epoch 1733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8996 - dice_coef: 0.8996 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 1738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8996 - dice_coef: 0.8996 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8981 - dice_coef: 0.8981 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8969 - dice_coef: 0.8969 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 1745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 1746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8970 - dice_coef: 0.8970 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 1748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1749/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 1753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9865 - val_dice_coef: 0.9865\n",
      "Epoch 1754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9000 - dice_coef: 0.9000 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 1759/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8883 - dice_coef: 0.8883 - val_loss: -0.3491 - val_dice_coef: 0.3491\n",
      "Epoch 1760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8696 - dice_coef: 0.8696 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8764 - dice_coef: 0.8764 - val_loss: -0.9459 - val_dice_coef: 0.9459\n",
      "Epoch 1763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.3883 - val_dice_coef: 0.3883\n",
      "Epoch 1764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8882 - dice_coef: 0.8882 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9517 - val_dice_coef: 0.9517\n",
      "Epoch 1768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8930 - dice_coef: 0.8930 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1769/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 1771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9906 - val_dice_coef: 0.9906\n",
      "Epoch 1772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8914 - dice_coef: 0.8914 - val_loss: -0.9747 - val_dice_coef: 0.9747\n",
      "Epoch 1774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9855 - val_dice_coef: 0.9855\n",
      "Epoch 1775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9271 - val_dice_coef: 0.9271\n",
      "Epoch 1779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.7942 - val_dice_coef: 0.7942\n",
      "Epoch 1780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.7378 - val_dice_coef: 0.7378\n",
      "Epoch 1783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.8769 - val_dice_coef: 0.8769\n",
      "Epoch 1784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9462 - val_dice_coef: 0.9462\n",
      "Epoch 1788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.9004 - val_dice_coef: 0.9004\n",
      "Epoch 1789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.8421 - val_dice_coef: 0.8421\n",
      "Epoch 1792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 1796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 1800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1804/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9086 - val_dice_coef: 0.9086\n",
      "Epoch 1805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.8330 - val_dice_coef: 0.8330\n",
      "Epoch 1806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9029 - val_dice_coef: 0.9029\n",
      "Epoch 1809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8934 - dice_coef: 0.8934 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 1810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.8401 - val_dice_coef: 0.8401\n",
      "Epoch 1813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9761 - val_dice_coef: 0.9761\n",
      "Epoch 1814/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 1821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 1822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8930 - dice_coef: 0.8930 - val_loss: -0.6426 - val_dice_coef: 0.6426\n",
      "Epoch 1826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9610 - val_dice_coef: 0.9610\n",
      "Epoch 1827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8910 - dice_coef: 0.8910 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.7763 - val_dice_coef: 0.7763\n",
      "Epoch 1830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.7866 - val_dice_coef: 0.7866\n",
      "Epoch 1834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9697 - val_dice_coef: 0.9697\n",
      "Epoch 1839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.9662 - val_dice_coef: 0.9662\n",
      "Epoch 1842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9009 - dice_coef: 0.9009 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 1846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 1849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9014 - dice_coef: 0.9014 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 1859/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "Epoch 1860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9030 - dice_coef: 0.9030 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 1864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 1865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9025 - dice_coef: 0.9025 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8992 - dice_coef: 0.8992 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1869/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8931 - dice_coef: 0.8931 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 1871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.5848 - val_dice_coef: 0.5848\n",
      "Epoch 1872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.7944 - val_dice_coef: 0.7944\n",
      "Epoch 1876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9835 - val_dice_coef: 0.9835\n",
      "Epoch 1877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 1879/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9046 - dice_coef: 0.9046 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.8094 - val_dice_coef: 0.8094\n",
      "Epoch 1883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.7506 - val_dice_coef: 0.7506\n",
      "Epoch 1884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9655 - val_dice_coef: 0.9655\n",
      "Epoch 1887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.9596 - val_dice_coef: 0.9596\n",
      "Epoch 1888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9808 - val_dice_coef: 0.9808\n",
      "Epoch 1891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9312 - val_dice_coef: 0.9312\n",
      "Epoch 1892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9297 - val_dice_coef: 0.9297\n",
      "Epoch 1893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9009 - dice_coef: 0.9009 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 1895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 1896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 1897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 1898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.8928 - val_dice_coef: 0.8928\n",
      "Epoch 1900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.7940 - val_dice_coef: 0.7940\n",
      "Epoch 1901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.1956 - val_dice_coef: 0.1956\n",
      "Epoch 1904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8806 - dice_coef: 0.8806 - val_loss: -0.8431 - val_dice_coef: 0.8431\n",
      "Epoch 1905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8834 - dice_coef: 0.8834 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8751 - dice_coef: 0.8751 - val_loss: -0.4669 - val_dice_coef: 0.4669\n",
      "Epoch 1907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.0583 - val_dice_coef: 0.0583\n",
      "Epoch 1908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8623 - dice_coef: 0.8623 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8566 - dice_coef: 0.8566 - val_loss: -0.6860 - val_dice_coef: 0.6860\n",
      "Epoch 1910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8841 - dice_coef: 0.8841 - val_loss: -0.6182 - val_dice_coef: 0.6182\n",
      "Epoch 1911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8912 - dice_coef: 0.8912 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 1913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8914 - dice_coef: 0.8914 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1914/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8970 - dice_coef: 0.8970 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 1916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9619 - val_dice_coef: 0.9619\n",
      "Epoch 1919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 1922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 1923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1924/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8939 - dice_coef: 0.8939 - val_loss: -0.6276 - val_dice_coef: 0.6276\n",
      "Epoch 1926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.3067 - val_dice_coef: 0.3067\n",
      "Epoch 1929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.4411 - val_dice_coef: 0.4411\n",
      "Epoch 1932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8760 - dice_coef: 0.8760 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 1933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8610 - dice_coef: 0.8610 - val_loss: -0.4877 - val_dice_coef: 0.4877\n",
      "Epoch 1935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 1936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8883 - dice_coef: 0.8883 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9485 - val_dice_coef: 0.9485\n",
      "Epoch 1938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8948 - dice_coef: 0.8948 - val_loss: -0.9521 - val_dice_coef: 0.9521\n",
      "Epoch 1939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.9690 - val_dice_coef: 0.9690\n",
      "Epoch 1942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 1947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 1948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 1950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9722 - val_dice_coef: 0.9722\n",
      "Epoch 1951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9008 - dice_coef: 0.9008 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9876 - val_dice_coef: 0.9876\n",
      "Epoch 1954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 1955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9396 - val_dice_coef: 0.9396\n",
      "Epoch 1958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 1959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9052 - dice_coef: 0.9052 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 1961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9805 - val_dice_coef: 0.9805\n",
      "Epoch 1962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9029 - dice_coef: 0.9029 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 1967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 1968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1969/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9753 - val_dice_coef: 0.9753\n",
      "Epoch 1971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 1978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9037 - dice_coef: 0.9037 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1979/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 1980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.8670 - val_dice_coef: 0.8670\n",
      "Epoch 1981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.8830 - val_dice_coef: 0.8830\n",
      "Epoch 1982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.9545 - val_dice_coef: 0.9545\n",
      "Epoch 1986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 1987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 1989/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 1995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9783 - val_dice_coef: 0.9783\n",
      "Epoch 1996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8885 - dice_coef: 0.8885 - val_loss: -0.9682 - val_dice_coef: 0.9682\n",
      "Epoch 1998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.2416 - val_dice_coef: 0.2416\n",
      "Epoch 1999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 2000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9014 - dice_coef: 0.9014 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2001/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.7513 - val_dice_coef: 0.7513\n",
      "Epoch 2002/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.8799 - val_dice_coef: 0.8799\n",
      "Epoch 2003/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2004/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2005/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9047 - dice_coef: 0.9047 - val_loss: -0.9774 - val_dice_coef: 0.9774\n",
      "Epoch 2006/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9044 - dice_coef: 0.9044 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2007/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2008/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2009/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2010/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9712 - val_dice_coef: 0.9712\n",
      "Epoch 2011/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2012/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2013/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2014/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2015/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9602 - val_dice_coef: 0.9602\n",
      "Epoch 2016/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 2017/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2018/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2019/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2020/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 2021/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2022/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.9562 - val_dice_coef: 0.9562\n",
      "Epoch 2023/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9831 - val_dice_coef: 0.9831\n",
      "Epoch 2024/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9445 - val_dice_coef: 0.9445\n",
      "Epoch 2025/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9607 - val_dice_coef: 0.9607\n",
      "Epoch 2026/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2027/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9814 - val_dice_coef: 0.9814\n",
      "Epoch 2028/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9624 - val_dice_coef: 0.9624\n",
      "Epoch 2029/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2030/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2031/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2032/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8233 - val_dice_coef: 0.8233\n",
      "Epoch 2033/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.0927 - val_dice_coef: 0.0927\n",
      "Epoch 2034/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2035/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2036/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.3486 - val_dice_coef: 0.3486\n",
      "Epoch 2037/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 2038/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2039/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2040/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.8120 - val_dice_coef: 0.8120\n",
      "Epoch 2041/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2042/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2043/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2044/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 2045/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.7585 - val_dice_coef: 0.7585\n",
      "Epoch 2046/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9634 - val_dice_coef: 0.9634\n",
      "Epoch 2047/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2048/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2049/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9001 - dice_coef: 0.9001 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2050/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9299 - val_dice_coef: 0.9299\n",
      "Epoch 2051/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.7435 - val_dice_coef: 0.7435\n",
      "Epoch 2052/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 2053/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2054/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 2055/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "Epoch 2056/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8979 - dice_coef: 0.8979 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2057/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2058/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.0455 - val_dice_coef: 0.0455\n",
      "Epoch 2059/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 2060/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2061/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 2062/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.8678 - val_dice_coef: 0.8678\n",
      "Epoch 2063/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2064/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2065/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.6703 - val_dice_coef: 0.6703\n",
      "Epoch 2066/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2067/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2068/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.6828 - val_dice_coef: 0.6828\n",
      "Epoch 2069/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8999 - dice_coef: 0.8999 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2070/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2071/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.6301 - val_dice_coef: 0.6301\n",
      "Epoch 2072/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2073/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 2074/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.3043 - val_dice_coef: 0.3043\n",
      "Epoch 2075/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2076/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2077/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.7334 - val_dice_coef: 0.7334\n",
      "Epoch 2078/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 2079/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2080/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8992 - dice_coef: 0.8992 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2081/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.7743 - val_dice_coef: 0.7743\n",
      "Epoch 2082/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.9696 - val_dice_coef: 0.9696\n",
      "Epoch 2083/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9059 - dice_coef: 0.9059 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2084/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.8784 - val_dice_coef: 0.8784\n",
      "Epoch 2085/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.6214 - val_dice_coef: 0.6214\n",
      "Epoch 2086/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2087/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 2088/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.7279 - val_dice_coef: 0.7279\n",
      "Epoch 2089/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.8486 - val_dice_coef: 0.8486\n",
      "Epoch 2090/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2091/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2092/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.5195 - val_dice_coef: 0.5195\n",
      "Epoch 2093/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9506 - val_dice_coef: 0.9506\n",
      "Epoch 2094/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2095/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.6622 - val_dice_coef: 0.6622\n",
      "Epoch 2096/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9161 - val_dice_coef: 0.9161\n",
      "Epoch 2097/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9048 - dice_coef: 0.9048 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2098/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2099/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.4942 - val_dice_coef: 0.4942\n",
      "Epoch 2100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8958 - dice_coef: 0.8958 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.0474 - val_dice_coef: 0.0474\n",
      "Epoch 2103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8718 - dice_coef: 0.8718 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9472 - val_dice_coef: 0.9472\n",
      "Epoch 2105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.0916 - val_dice_coef: 0.0916\n",
      "Epoch 2106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8903 - dice_coef: 0.8903 - val_loss: -0.9310 - val_dice_coef: 0.9310\n",
      "Epoch 2108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9342 - val_dice_coef: 0.9342\n",
      "Epoch 2109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.2731 - val_dice_coef: 0.2731\n",
      "Epoch 2111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.8293 - val_dice_coef: 0.8293\n",
      "Epoch 2114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9751 - val_dice_coef: 0.9751\n",
      "Epoch 2115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "Epoch 2117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9895 - val_dice_coef: 0.9895\n",
      "Epoch 2118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9381 - val_dice_coef: 0.9381\n",
      "Epoch 2120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.9411 - val_dice_coef: 0.9411\n",
      "Epoch 2123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.6858 - val_dice_coef: 0.6858\n",
      "Epoch 2124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.7141 - val_dice_coef: 0.7141\n",
      "Epoch 2126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.8951 - val_dice_coef: 0.8951\n",
      "Epoch 2127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.8321 - val_dice_coef: 0.8321\n",
      "Epoch 2129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 2130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9442 - val_dice_coef: 0.9442\n",
      "Epoch 2132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 2134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9257 - val_dice_coef: 0.9257\n",
      "Epoch 2135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9563 - val_dice_coef: 0.9563\n",
      "Epoch 2138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9310 - val_dice_coef: 0.9310\n",
      "Epoch 2141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9590 - val_dice_coef: 0.9590\n",
      "Epoch 2142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2144/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9518 - val_dice_coef: 0.9518\n",
      "Epoch 2145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9400 - val_dice_coef: 0.9400\n",
      "Epoch 2146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 2150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 2151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9562 - val_dice_coef: 0.9562\n",
      "Epoch 2152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 2154/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 2155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9573 - val_dice_coef: 0.9573\n",
      "Epoch 2156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 2157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 2158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9833 - val_dice_coef: 0.9833\n",
      "Epoch 2160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.6026 - val_dice_coef: 0.6026\n",
      "Epoch 2161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.6253 - val_dice_coef: 0.6253\n",
      "Epoch 2162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 2163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9053 - dice_coef: 0.9053 - val_loss: -0.9454 - val_dice_coef: 0.9454\n",
      "Epoch 2166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.8475 - val_dice_coef: 0.8475\n",
      "Epoch 2167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.9166 - val_dice_coef: 0.9166\n",
      "Epoch 2170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.6904 - val_dice_coef: 0.6904\n",
      "Epoch 2171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9470 - val_dice_coef: 0.9470\n",
      "Epoch 2172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9489 - val_dice_coef: 0.9489\n",
      "Epoch 2174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 2175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9062 - dice_coef: 0.9062 - val_loss: -0.8374 - val_dice_coef: 0.8374\n",
      "Epoch 2178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.6803 - val_dice_coef: 0.6803\n",
      "Epoch 2179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.9183 - val_dice_coef: 0.9183\n",
      "Epoch 2180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9088 - dice_coef: 0.9088 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 2181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9816 - val_dice_coef: 0.9816\n",
      "Epoch 2182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 2183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9761 - val_dice_coef: 0.9761\n",
      "Epoch 2185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 2186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 2187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 2188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 2190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9784 - val_dice_coef: 0.9784\n",
      "Epoch 2191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 2192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9600 - val_dice_coef: 0.9600\n",
      "Epoch 2193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9814 - val_dice_coef: 0.9814\n",
      "Epoch 2194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.4542 - val_dice_coef: 0.4542\n",
      "Epoch 2197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.1773 - val_dice_coef: 0.1773\n",
      "Epoch 2198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 2199/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9010 - dice_coef: 0.9010 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 2201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.0938 - val_dice_coef: 0.0938\n",
      "Epoch 2202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8848 - dice_coef: 0.8848 - val_loss: -0.9051 - val_dice_coef: 0.9051\n",
      "Epoch 2204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8954 - dice_coef: 0.8954 - val_loss: -0.1643 - val_dice_coef: 0.1643\n",
      "Epoch 2205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 2207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9123 - val_dice_coef: 0.9123\n",
      "Epoch 2208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2209/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 2210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 2211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9094 - dice_coef: 0.9094 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 2213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.7664 - val_dice_coef: 0.7664\n",
      "Epoch 2214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.7833 - val_dice_coef: 0.7833\n",
      "Epoch 2217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9089 - dice_coef: 0.9089 - val_loss: -0.9804 - val_dice_coef: 0.9804\n",
      "Epoch 2218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2219/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9089 - dice_coef: 0.9089 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9301 - val_dice_coef: 0.9301\n",
      "Epoch 2221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.5832 - val_dice_coef: 0.5832\n",
      "Epoch 2222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9064 - dice_coef: 0.9064 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9178 - val_dice_coef: 0.9178\n",
      "Epoch 2225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.8188 - val_dice_coef: 0.8188\n",
      "Epoch 2226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9806 - val_dice_coef: 0.9806\n",
      "Epoch 2227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 2228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9689 - val_dice_coef: 0.9689\n",
      "Epoch 2229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 2232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 2234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9120 - val_dice_coef: 0.9120\n",
      "Epoch 2235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.8574 - val_dice_coef: 0.8574\n",
      "Epoch 2236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.6431 - val_dice_coef: 0.6431\n",
      "Epoch 2237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 2240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.9571 - val_dice_coef: 0.9571\n",
      "Epoch 2241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 2242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9239 - val_dice_coef: 0.9239\n",
      "Epoch 2243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 2244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9133 - dice_coef: 0.9133 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9028 - val_dice_coef: 0.9028\n",
      "Epoch 2246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.9756 - val_dice_coef: 0.9756\n",
      "Epoch 2247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 2249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9026 - val_dice_coef: 0.9026\n",
      "Epoch 2250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.6725 - val_dice_coef: 0.6725\n",
      "Epoch 2251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9062 - val_dice_coef: 0.9062\n",
      "Epoch 2252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 2254/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9481 - val_dice_coef: 0.9481\n",
      "Epoch 2255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 2258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9205 - val_dice_coef: 0.9205\n",
      "Epoch 2260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.8805 - val_dice_coef: 0.8805\n",
      "Epoch 2261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9302 - val_dice_coef: 0.9302\n",
      "Epoch 2263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9021 - val_dice_coef: 0.9021\n",
      "Epoch 2264/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9340 - val_dice_coef: 0.9340\n",
      "Epoch 2265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 2266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 2267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9082 - val_dice_coef: 0.9082\n",
      "Epoch 2268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.5658 - val_dice_coef: 0.5658\n",
      "Epoch 2269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.7773 - val_dice_coef: 0.7773\n",
      "Epoch 2272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9052 - dice_coef: 0.9052 - val_loss: -0.6216 - val_dice_coef: 0.6216\n",
      "Epoch 2273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.9831 - val_dice_coef: 0.9831\n",
      "Epoch 2274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.8679 - val_dice_coef: 0.8679\n",
      "Epoch 2276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.3709 - val_dice_coef: 0.3709\n",
      "Epoch 2277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.7028 - val_dice_coef: 0.7028\n",
      "Epoch 2278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 2280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.8944 - val_dice_coef: 0.8944\n",
      "Epoch 2281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.8804 - val_dice_coef: 0.8804\n",
      "Epoch 2286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.4114 - val_dice_coef: 0.4114\n",
      "Epoch 2287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9617 - val_dice_coef: 0.9617\n",
      "Epoch 2288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9088 - dice_coef: 0.9088 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.7745 - val_dice_coef: 0.7745\n",
      "Epoch 2291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9046 - dice_coef: 0.9046 - val_loss: -0.2139 - val_dice_coef: 0.2139\n",
      "Epoch 2292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 2293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.8347 - val_dice_coef: 0.8347\n",
      "Epoch 2295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9288 - val_dice_coef: 0.9288\n",
      "Epoch 2296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9366 - val_dice_coef: 0.9366\n",
      "Epoch 2297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9793 - val_dice_coef: 0.9793\n",
      "Epoch 2298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9966 - val_dice_coef: 0.9966\n",
      "Epoch 2300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9266 - val_dice_coef: 0.9266\n",
      "Epoch 2301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.5115 - val_dice_coef: 0.5115\n",
      "Epoch 2302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 2303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9819 - val_dice_coef: 0.9819\n",
      "Epoch 2305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.7982 - val_dice_coef: 0.7982\n",
      "Epoch 2306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9093 - dice_coef: 0.9093 - val_loss: -0.6480 - val_dice_coef: 0.6480\n",
      "Epoch 2307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2309/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.5058 - val_dice_coef: 0.5058\n",
      "Epoch 2310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.6644 - val_dice_coef: 0.6644\n",
      "Epoch 2311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.4163 - val_dice_coef: 0.4163\n",
      "Epoch 2314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.3054 - val_dice_coef: 0.3054\n",
      "Epoch 2315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.9825 - val_dice_coef: 0.9825\n",
      "Epoch 2317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.4694 - val_dice_coef: 0.4694\n",
      "Epoch 2318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.9431 - val_dice_coef: 0.9431\n",
      "Epoch 2319/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9846 - val_dice_coef: 0.9846\n",
      "Epoch 2321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 2322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9565 - val_dice_coef: 0.9565\n",
      "Epoch 2323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.2464 - val_dice_coef: 0.2464\n",
      "Epoch 2324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9622 - val_dice_coef: 0.9622\n",
      "Epoch 2325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9629 - val_dice_coef: 0.9629\n",
      "Epoch 2327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.2290 - val_dice_coef: 0.2290\n",
      "Epoch 2328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8977 - dice_coef: 0.8977 - val_loss: -0.9703 - val_dice_coef: 0.9703\n",
      "Epoch 2329/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9872 - val_dice_coef: 0.9872\n",
      "Epoch 2331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.4349 - val_dice_coef: 0.4349\n",
      "Epoch 2332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.8048 - val_dice_coef: 0.8048\n",
      "Epoch 2333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8969 - dice_coef: 0.8969 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 2335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.6067 - val_dice_coef: 0.6067\n",
      "Epoch 2336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9059 - dice_coef: 0.9059 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 2337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9061 - dice_coef: 0.9061 - val_loss: -0.9525 - val_dice_coef: 0.9525\n",
      "Epoch 2339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.4830 - val_dice_coef: 0.4830\n",
      "Epoch 2340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9852 - val_dice_coef: 0.9852\n",
      "Epoch 2341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9791 - val_dice_coef: 0.9791\n",
      "Epoch 2343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.8013 - val_dice_coef: 0.8013\n",
      "Epoch 2344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 2346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9789 - val_dice_coef: 0.9789\n",
      "Epoch 2347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.7830 - val_dice_coef: 0.7830\n",
      "Epoch 2348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9232 - val_dice_coef: 0.9232\n",
      "Epoch 2349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9580 - val_dice_coef: 0.9580\n",
      "Epoch 2350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9480 - val_dice_coef: 0.9480\n",
      "Epoch 2351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9031 - val_dice_coef: 0.9031\n",
      "Epoch 2352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 2353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9660 - val_dice_coef: 0.9660\n",
      "Epoch 2356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 2357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 2358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 2359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9811 - val_dice_coef: 0.9811\n",
      "Epoch 2360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9651 - val_dice_coef: 0.9651\n",
      "Epoch 2361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9843 - val_dice_coef: 0.9843\n",
      "Epoch 2362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9917 - val_dice_coef: 0.9917\n",
      "Epoch 2364/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9901 - val_dice_coef: 0.9901\n",
      "Epoch 2367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9768 - val_dice_coef: 0.9768\n",
      "Epoch 2370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.8090 - val_dice_coef: 0.8090\n",
      "Epoch 2371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.2923 - val_dice_coef: 0.2923\n",
      "Epoch 2372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2374/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.4193 - val_dice_coef: 0.4193\n",
      "Epoch 2375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8951 - dice_coef: 0.8951 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 2376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.5547 - val_dice_coef: 0.5547\n",
      "Epoch 2378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.0490 - val_dice_coef: 0.0490\n",
      "Epoch 2379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.0556 - val_dice_coef: 0.0556\n",
      "Epoch 2381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 2383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 2384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9010 - dice_coef: 0.9010 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9729 - val_dice_coef: 0.9729\n",
      "Epoch 2386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.6195 - val_dice_coef: 0.6195\n",
      "Epoch 2387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.9684 - val_dice_coef: 0.9684\n",
      "Epoch 2389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9320 - val_dice_coef: 0.9320\n",
      "Epoch 2390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.5473 - val_dice_coef: 0.5473\n",
      "Epoch 2393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9727 - val_dice_coef: 0.9727\n",
      "Epoch 2394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9716 - val_dice_coef: 0.9716\n",
      "Epoch 2396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 2398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9745 - val_dice_coef: 0.9745\n",
      "Epoch 2400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9131 - dice_coef: 0.9131 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 2405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 2406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 2407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 2408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9826 - val_dice_coef: 0.9826\n",
      "Epoch 2409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9905 - val_dice_coef: 0.9905\n",
      "Epoch 2412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9138 - dice_coef: 0.9138 - val_loss: -0.7774 - val_dice_coef: 0.7774\n",
      "Epoch 2413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9553 - val_dice_coef: 0.9553\n",
      "Epoch 2417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2419/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9930 - val_dice_coef: 0.9930\n",
      "Epoch 2420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 2421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.8831 - val_dice_coef: 0.8831\n",
      "Epoch 2422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 2423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.9650 - val_dice_coef: 0.9650\n",
      "Epoch 2426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.7634 - val_dice_coef: 0.7634\n",
      "Epoch 2427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9733 - val_dice_coef: 0.9733\n",
      "Epoch 2428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2429/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 2431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "Epoch 2432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.6367 - val_dice_coef: 0.6367\n",
      "Epoch 2433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9871 - val_dice_coef: 0.9871\n",
      "Epoch 2434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 2436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.7614 - val_dice_coef: 0.7614\n",
      "Epoch 2437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.6913 - val_dice_coef: 0.6913\n",
      "Epoch 2438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 2439/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.6776 - val_dice_coef: 0.6776\n",
      "Epoch 2443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.1864 - val_dice_coef: 0.1864\n",
      "Epoch 2444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9498 - val_dice_coef: 0.9498\n",
      "Epoch 2447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9039 - val_dice_coef: 0.9039\n",
      "Epoch 2448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.7625 - val_dice_coef: 0.7625\n",
      "Epoch 2449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.7575 - val_dice_coef: 0.7575\n",
      "Epoch 2450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 2453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9336 - val_dice_coef: 0.9336\n",
      "Epoch 2454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.5875 - val_dice_coef: 0.5875\n",
      "Epoch 2458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.3099 - val_dice_coef: 0.3099\n",
      "Epoch 2459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9698 - val_dice_coef: 0.9698\n",
      "Epoch 2460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9670 - val_dice_coef: 0.9670\n",
      "Epoch 2462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.3318 - val_dice_coef: 0.3318\n",
      "Epoch 2463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.4738 - val_dice_coef: 0.4738\n",
      "Epoch 2464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.6963 - val_dice_coef: 0.6963\n",
      "Epoch 2466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.2105 - val_dice_coef: 0.2105\n",
      "Epoch 2467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 2469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.6050 - val_dice_coef: 0.6050\n",
      "Epoch 2470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 2472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.8910 - val_dice_coef: 0.8910\n",
      "Epoch 2473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.6591 - val_dice_coef: 0.6591\n",
      "Epoch 2474/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.3696 - val_dice_coef: 0.3696\n",
      "Epoch 2477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.4352 - val_dice_coef: 0.4352\n",
      "Epoch 2478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9402 - val_dice_coef: 0.9402\n",
      "Epoch 2481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.3410 - val_dice_coef: 0.3410\n",
      "Epoch 2482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 2483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2484/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.1221 - val_dice_coef: 0.1221\n",
      "Epoch 2485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.8153 - val_dice_coef: 0.8153\n",
      "Epoch 2488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9361 - val_dice_coef: 0.9361\n",
      "Epoch 2491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 2494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.8146 - val_dice_coef: 0.8146\n",
      "Epoch 2495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9127 - val_dice_coef: 0.9127\n",
      "Epoch 2498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.3409 - val_dice_coef: 0.3409\n",
      "Epoch 2499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9138 - val_dice_coef: 0.9138\n",
      "Epoch 2501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.5536 - val_dice_coef: 0.5536\n",
      "Epoch 2502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.2602 - val_dice_coef: 0.2602\n",
      "Epoch 2505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9884 - val_dice_coef: 0.9884\n",
      "Epoch 2507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.2527 - val_dice_coef: 0.2527\n",
      "Epoch 2508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 2509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -0.7993 - val_dice_coef: 0.7993\n",
      "Epoch 2511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.5294 - val_dice_coef: 0.5294\n",
      "Epoch 2512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 2514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.8441 - val_dice_coef: 0.8441\n",
      "Epoch 2515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9006 - val_dice_coef: 0.9006\n",
      "Epoch 2516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9769 - val_dice_coef: 0.9769\n",
      "Epoch 2517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9760 - val_dice_coef: 0.9760\n",
      "Epoch 2518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9511 - val_dice_coef: 0.9511\n",
      "Epoch 2521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8498 - val_dice_coef: 0.8498\n",
      "Epoch 2522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 2523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9138 - dice_coef: 0.9138 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 2525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9139 - dice_coef: 0.9139 - val_loss: -0.9584 - val_dice_coef: 0.9584\n",
      "Epoch 2526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9207 - val_dice_coef: 0.9207\n",
      "Epoch 2527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9138 - val_dice_coef: 0.9138\n",
      "Epoch 2528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2529/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 2530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 2531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9574 - val_dice_coef: 0.9574\n",
      "Epoch 2532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9499 - val_dice_coef: 0.9499\n",
      "Epoch 2534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 2535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9387 - val_dice_coef: 0.9387\n",
      "Epoch 2538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.7852 - val_dice_coef: 0.7852\n",
      "Epoch 2539/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.8365 - val_dice_coef: 0.8365\n",
      "Epoch 2540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 2541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.6630 - val_dice_coef: 0.6630\n",
      "Epoch 2543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.2535 - val_dice_coef: 0.2535\n",
      "Epoch 2544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.3855 - val_dice_coef: 0.3855\n",
      "Epoch 2546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.0618 - val_dice_coef: 0.0618\n",
      "Epoch 2547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.0220 - val_dice_coef: 0.0220\n",
      "Epoch 2549/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8882 - dice_coef: 0.8882 - val_loss: -0.1945 - val_dice_coef: 0.1945\n",
      "Epoch 2552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.0718 - val_dice_coef: 0.0718\n",
      "Epoch 2554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.8228 - val_dice_coef: 0.8228\n",
      "Epoch 2556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9731 - val_dice_coef: 0.9731\n",
      "Epoch 2557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9399 - val_dice_coef: 0.9399\n",
      "Epoch 2559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 2562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.8389 - val_dice_coef: 0.8389\n",
      "Epoch 2563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9534 - val_dice_coef: 0.9534\n",
      "Epoch 2566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9137 - dice_coef: 0.9137 - val_loss: -0.9694 - val_dice_coef: 0.9694\n",
      "Epoch 2567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 2570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9725 - val_dice_coef: 0.9725\n",
      "Epoch 2571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9186 - dice_coef: 0.9186 - val_loss: -0.9791 - val_dice_coef: 0.9791\n",
      "Epoch 2574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 2578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9523 - val_dice_coef: 0.9523\n",
      "Epoch 2579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9673 - val_dice_coef: 0.9673\n",
      "Epoch 2580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 2581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2584/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9705 - val_dice_coef: 0.9705\n",
      "Epoch 2585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.7353 - val_dice_coef: 0.7353\n",
      "Epoch 2586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 2589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9493 - val_dice_coef: 0.9493\n",
      "Epoch 2591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9382 - val_dice_coef: 0.9382\n",
      "Epoch 2592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9844 - val_dice_coef: 0.9844\n",
      "Epoch 2593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2594/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9159 - dice_coef: 0.9159 - val_loss: -0.9854 - val_dice_coef: 0.9854\n",
      "Epoch 2595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9117 - val_dice_coef: 0.9117\n",
      "Epoch 2596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 2597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9594 - val_dice_coef: 0.9594\n",
      "Epoch 2601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.8438 - val_dice_coef: 0.8438\n",
      "Epoch 2602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9817 - val_dice_coef: 0.9817\n",
      "Epoch 2606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9159 - dice_coef: 0.9159 - val_loss: -0.7647 - val_dice_coef: 0.7647\n",
      "Epoch 2607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8983 - val_dice_coef: 0.8983\n",
      "Epoch 2608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9884 - val_dice_coef: 0.9884\n",
      "Epoch 2609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9188 - dice_coef: 0.9188 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9389 - val_dice_coef: 0.9389\n",
      "Epoch 2612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9502 - val_dice_coef: 0.9502\n",
      "Epoch 2613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9673 - val_dice_coef: 0.9673\n",
      "Epoch 2614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 2615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.9213 - val_dice_coef: 0.9213\n",
      "Epoch 2618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.8335 - val_dice_coef: 0.8335\n",
      "Epoch 2619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 2620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9193 - dice_coef: 0.9193 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 2622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 2623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9428 - val_dice_coef: 0.9428\n",
      "Epoch 2624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9559 - val_dice_coef: 0.9559\n",
      "Epoch 2625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9580 - val_dice_coef: 0.9580\n",
      "Epoch 2626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 2627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 2631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9049 - val_dice_coef: 0.9049\n",
      "Epoch 2632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8991 - val_dice_coef: 0.8991\n",
      "Epoch 2633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9495 - val_dice_coef: 0.9495\n",
      "Epoch 2634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 2635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.2885 - val_dice_coef: 0.2885\n",
      "Epoch 2638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.2576 - val_dice_coef: 0.2576\n",
      "Epoch 2639/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9048 - dice_coef: 0.9048 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9642 - val_dice_coef: 0.9642\n",
      "Epoch 2642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.8795 - val_dice_coef: 0.8795\n",
      "Epoch 2643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9816 - val_dice_coef: 0.9816\n",
      "Epoch 2644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.7112 - val_dice_coef: 0.7112\n",
      "Epoch 2647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.7026 - val_dice_coef: 0.7026\n",
      "Epoch 2648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.7975 - val_dice_coef: 0.7975\n",
      "Epoch 2649/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9131 - dice_coef: 0.9131 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 2652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9450 - val_dice_coef: 0.9450\n",
      "Epoch 2653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9080 - val_dice_coef: 0.9080\n",
      "Epoch 2654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9741 - val_dice_coef: 0.9741\n",
      "Epoch 2655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 2656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 2657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9289 - val_dice_coef: 0.9289\n",
      "Epoch 2658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 2659/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 2661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9839 - val_dice_coef: 0.9839\n",
      "Epoch 2662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.8275 - val_dice_coef: 0.8275\n",
      "Epoch 2664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.7169 - val_dice_coef: 0.7169\n",
      "Epoch 2665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9956 - val_dice_coef: 0.9956\n",
      "Epoch 2668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9465 - val_dice_coef: 0.9465\n",
      "Epoch 2670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.6517 - val_dice_coef: 0.6517\n",
      "Epoch 2671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.6271 - val_dice_coef: 0.6271\n",
      "Epoch 2672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 2675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9111 - dice_coef: 0.9111 - val_loss: -0.8553 - val_dice_coef: 0.8553\n",
      "Epoch 2676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.6418 - val_dice_coef: 0.6418\n",
      "Epoch 2677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9451 - val_dice_coef: 0.9451\n",
      "Epoch 2678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9378 - val_dice_coef: 0.9378\n",
      "Epoch 2679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9139 - dice_coef: 0.9139 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9474 - val_dice_coef: 0.9474\n",
      "Epoch 2684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9631 - val_dice_coef: 0.9631\n",
      "Epoch 2686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9537 - val_dice_coef: 0.9537\n",
      "Epoch 2687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 2688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9706 - val_dice_coef: 0.9706\n",
      "Epoch 2689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2694/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9513 - val_dice_coef: 0.9513\n",
      "Epoch 2695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.8110 - val_dice_coef: 0.8110\n",
      "Epoch 2696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9871 - val_dice_coef: 0.9871\n",
      "Epoch 2697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 2700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 2701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9530 - val_dice_coef: 0.9530\n",
      "Epoch 2704/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9678 - val_dice_coef: 0.9678\n",
      "Epoch 2705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9263 - val_dice_coef: 0.9263\n",
      "Epoch 2707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9615 - val_dice_coef: 0.9615\n",
      "Epoch 2708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9825 - val_dice_coef: 0.9825\n",
      "Epoch 2709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9718 - val_dice_coef: 0.9718\n",
      "Epoch 2710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9606 - val_dice_coef: 0.9606\n",
      "Epoch 2711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9210 - dice_coef: 0.9210 - val_loss: -0.9876 - val_dice_coef: 0.9876\n",
      "Epoch 2712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.9686 - val_dice_coef: 0.9686\n",
      "Epoch 2713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.9230 - val_dice_coef: 0.9230\n",
      "Epoch 2714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.6055 - val_dice_coef: 0.6055\n",
      "Epoch 2715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.7039 - val_dice_coef: 0.7039\n",
      "Epoch 2716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 2717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 2718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9753 - val_dice_coef: 0.9753\n",
      "Epoch 2719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9210 - dice_coef: 0.9210 - val_loss: -0.9767 - val_dice_coef: 0.9767\n",
      "Epoch 2720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 2721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9204 - dice_coef: 0.9204 - val_loss: -0.9916 - val_dice_coef: 0.9916\n",
      "Epoch 2722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9181 - dice_coef: 0.9181 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9895 - val_dice_coef: 0.9895\n",
      "Epoch 2725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 2726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9553 - val_dice_coef: 0.9553\n",
      "Epoch 2727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 2728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.5576 - val_dice_coef: 0.5576\n",
      "Epoch 2730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.0683 - val_dice_coef: 0.0683\n",
      "Epoch 2731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9944 - val_dice_coef: 0.9944\n",
      "Epoch 2733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.2141 - val_dice_coef: 0.2141\n",
      "Epoch 2734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.5150 - val_dice_coef: 0.5150\n",
      "Epoch 2735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.9897 - val_dice_coef: 0.9897\n",
      "Epoch 2737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.4916 - val_dice_coef: 0.4916\n",
      "Epoch 2738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 2739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9206 - dice_coef: 0.9206 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 2740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9186 - dice_coef: 0.9186 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 2741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9199 - dice_coef: 0.9199 - val_loss: -0.9775 - val_dice_coef: 0.9775\n",
      "Epoch 2742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 2744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9773 - val_dice_coef: 0.9773\n",
      "Epoch 2748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9449 - val_dice_coef: 0.9449\n",
      "Epoch 2749/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.6856 - val_dice_coef: 0.6856\n",
      "Epoch 2750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.1605 - val_dice_coef: 0.1605\n",
      "Epoch 2751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9913 - val_dice_coef: 0.9913\n",
      "Epoch 2753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.1673 - val_dice_coef: 0.1673\n",
      "Epoch 2754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 2755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.8341 - val_dice_coef: 0.8341\n",
      "Epoch 2757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.3254 - val_dice_coef: 0.3254\n",
      "Epoch 2758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 2759/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 2760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.6873 - val_dice_coef: 0.6873\n",
      "Epoch 2761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.2790 - val_dice_coef: 0.2790\n",
      "Epoch 2762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.8434 - val_dice_coef: 0.8434\n",
      "Epoch 2765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.6315 - val_dice_coef: 0.6315\n",
      "Epoch 2766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.8974 - val_dice_coef: 0.8974\n",
      "Epoch 2767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9656 - val_dice_coef: 0.9656\n",
      "Epoch 2769/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 2770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9206 - dice_coef: 0.9206 - val_loss: -0.8701 - val_dice_coef: 0.8701\n",
      "Epoch 2771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 2772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 2773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.8602 - val_dice_coef: 0.8602\n",
      "Epoch 2774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.9125 - val_dice_coef: 0.9125\n",
      "Epoch 2775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 2776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9193 - dice_coef: 0.9193 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 2777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9188 - dice_coef: 0.9188 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9551 - val_dice_coef: 0.9551\n",
      "Epoch 2780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 2781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.8195 - val_dice_coef: 0.8195\n",
      "Epoch 2782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.8337 - val_dice_coef: 0.8337\n",
      "Epoch 2783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9586 - val_dice_coef: 0.9586\n",
      "Epoch 2784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.8526 - val_dice_coef: 0.8526\n",
      "Epoch 2785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9293 - val_dice_coef: 0.9293\n",
      "Epoch 2786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 2787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9813 - val_dice_coef: 0.9813\n",
      "Epoch 2788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 2789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9026 - val_dice_coef: 0.9026\n",
      "Epoch 2790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.8888 - val_dice_coef: 0.8888\n",
      "Epoch 2791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.4764 - val_dice_coef: 0.4764\n",
      "Epoch 2792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.5740 - val_dice_coef: 0.5740\n",
      "Epoch 2795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9747 - val_dice_coef: 0.9747\n",
      "Epoch 2796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.3430 - val_dice_coef: 0.3430\n",
      "Epoch 2798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.5994 - val_dice_coef: 0.5994\n",
      "Epoch 2799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.6466 - val_dice_coef: 0.6466\n",
      "Epoch 2802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.8355 - val_dice_coef: 0.8355\n",
      "Epoch 2803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9594 - val_dice_coef: 0.9594\n",
      "Epoch 2804/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.7488 - val_dice_coef: 0.7488\n",
      "Epoch 2805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9708 - val_dice_coef: 0.9708\n",
      "Epoch 2806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.0411 - val_dice_coef: 0.0411\n",
      "Epoch 2809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.5443 - val_dice_coef: 0.5443\n",
      "Epoch 2810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.8374 - val_dice_coef: 0.8374\n",
      "Epoch 2812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9044 - val_dice_coef: 0.9044\n",
      "Epoch 2813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2814/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9197 - val_dice_coef: 0.9197\n",
      "Epoch 2815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.6469 - val_dice_coef: 0.6469\n",
      "Epoch 2816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.7670 - val_dice_coef: 0.7670\n",
      "Epoch 2819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9133 - dice_coef: 0.9133 - val_loss: -0.3303 - val_dice_coef: 0.3303\n",
      "Epoch 2820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8931 - dice_coef: 0.8931 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.0246 - val_dice_coef: 0.0246\n",
      "Epoch 2823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.3323 - val_dice_coef: 0.3323\n",
      "Epoch 2825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.0754 - val_dice_coef: 0.0754\n",
      "Epoch 2826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9044 - dice_coef: 0.9044 - val_loss: -0.2435 - val_dice_coef: 0.2435\n",
      "Epoch 2828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9496 - val_dice_coef: 0.9496\n",
      "Epoch 2831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9773 - val_dice_coef: 0.9773\n",
      "Epoch 2832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9168 - dice_coef: 0.9168 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.7813 - val_dice_coef: 0.7813\n",
      "Epoch 2834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9454 - val_dice_coef: 0.9454\n",
      "Epoch 2835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.8028 - val_dice_coef: 0.8028\n",
      "Epoch 2838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 2839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9359 - val_dice_coef: 0.9359\n",
      "Epoch 2841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9202 - val_dice_coef: 0.9202\n",
      "Epoch 2842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 2843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9515 - val_dice_coef: 0.9515\n",
      "Epoch 2846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 2847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9468 - val_dice_coef: 0.9468\n",
      "Epoch 2848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.7922 - val_dice_coef: 0.7922\n",
      "Epoch 2849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9071 - val_dice_coef: 0.9071\n",
      "Epoch 2850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9181 - dice_coef: 0.9181 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.6913 - val_dice_coef: 0.6913\n",
      "Epoch 2853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.2032 - val_dice_coef: 0.2032\n",
      "Epoch 2854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9037 - dice_coef: 0.9037 - val_loss: -0.8833 - val_dice_coef: 0.8833\n",
      "Epoch 2856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.1882 - val_dice_coef: 0.1882\n",
      "Epoch 2857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2859/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.8098 - val_dice_coef: 0.8098\n",
      "Epoch 2860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.4437 - val_dice_coef: 0.4437\n",
      "Epoch 2861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.7748 - val_dice_coef: 0.7748\n",
      "Epoch 2864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.7879 - val_dice_coef: 0.7879\n",
      "Epoch 2865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.2887 - val_dice_coef: 0.2887\n",
      "Epoch 2868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9497 - val_dice_coef: 0.9497\n",
      "Epoch 2869/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9258 - val_dice_coef: 0.9258\n",
      "Epoch 2871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.6020 - val_dice_coef: 0.6020\n",
      "Epoch 2872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 2873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 2874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9841 - val_dice_coef: 0.9841\n",
      "Epoch 2875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.7869 - val_dice_coef: 0.7869\n",
      "Epoch 2876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9667 - val_dice_coef: 0.9667\n",
      "Epoch 2877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 2878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9676 - val_dice_coef: 0.9676\n",
      "Epoch 2879/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 2880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9508 - val_dice_coef: 0.9508\n",
      "Epoch 2881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.9433 - val_dice_coef: 0.9433\n",
      "Epoch 2882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9675 - val_dice_coef: 0.9675\n",
      "Epoch 2883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9897 - val_dice_coef: 0.9897\n",
      "Epoch 2884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9507 - val_dice_coef: 0.9507\n",
      "Epoch 2885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9471 - val_dice_coef: 0.9471\n",
      "Epoch 2886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9889 - val_dice_coef: 0.9889\n",
      "Epoch 2887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9220 - dice_coef: 0.9220 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9233 - dice_coef: 0.9233 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 2889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9916 - val_dice_coef: 0.9916\n",
      "Epoch 2890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 2892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9199 - dice_coef: 0.9199 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9610 - val_dice_coef: 0.9610\n",
      "Epoch 2894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9166 - dice_coef: 0.9166 - val_loss: -0.5778 - val_dice_coef: 0.5778\n",
      "Epoch 2895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.7792 - val_dice_coef: 0.7792\n",
      "Epoch 2896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 2897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 2898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9207 - dice_coef: 0.9207 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 2900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9542 - val_dice_coef: 0.9542\n",
      "Epoch 2901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9624 - val_dice_coef: 0.9624\n",
      "Epoch 2902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9215 - dice_coef: 0.9215 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9230 - dice_coef: 0.9230 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.8969 - val_dice_coef: 0.8969\n",
      "Epoch 2909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.7985 - val_dice_coef: 0.7985\n",
      "Epoch 2910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9008 - val_dice_coef: 0.9008\n",
      "Epoch 2911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.8960 - val_dice_coef: 0.8960\n",
      "Epoch 2912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9213 - dice_coef: 0.9213 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2914/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.5299 - val_dice_coef: 0.5299\n",
      "Epoch 2917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.4511 - val_dice_coef: 0.4511\n",
      "Epoch 2918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9224 - dice_coef: 0.9224 - val_loss: -0.9183 - val_dice_coef: 0.9183\n",
      "Epoch 2923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9228 - dice_coef: 0.9228 - val_loss: -0.8274 - val_dice_coef: 0.8274\n",
      "Epoch 2924/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9805 - val_dice_coef: 0.9805\n",
      "Epoch 2925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9199 - val_dice_coef: 0.9199\n",
      "Epoch 2930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9224 - dice_coef: 0.9224 - val_loss: -0.9598 - val_dice_coef: 0.9598\n",
      "Epoch 2931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9249 - val_dice_coef: 0.9249\n",
      "Epoch 2932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9215 - dice_coef: 0.9215 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9232 - dice_coef: 0.9232 - val_loss: -0.9848 - val_dice_coef: 0.9848\n",
      "Epoch 2934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9229 - dice_coef: 0.9229 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 2935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9227 - dice_coef: 0.9227 - val_loss: -0.9853 - val_dice_coef: 0.9853\n",
      "Epoch 2936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9232 - dice_coef: 0.9232 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 2937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9238 - dice_coef: 0.9238 - val_loss: -0.9717 - val_dice_coef: 0.9717\n",
      "Epoch 2938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9040 - val_dice_coef: 0.9040\n",
      "Epoch 2939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 2940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9207 - dice_coef: 0.9207 - val_loss: -0.9860 - val_dice_coef: 0.9860\n",
      "Epoch 2941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9576 - val_dice_coef: 0.9576\n",
      "Epoch 2944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9229 - dice_coef: 0.9229 - val_loss: -0.8049 - val_dice_coef: 0.8049\n",
      "Epoch 2945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.4973 - val_dice_coef: 0.4973\n",
      "Epoch 2946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.5387 - val_dice_coef: 0.5387\n",
      "Epoch 2947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.6299 - val_dice_coef: 0.6299\n",
      "Epoch 2950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.5632 - val_dice_coef: 0.5632\n",
      "Epoch 2951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9418 - val_dice_coef: 0.9418\n",
      "Epoch 2952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.7234 - val_dice_coef: 0.7234\n",
      "Epoch 2954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.0527 - val_dice_coef: 0.0527\n",
      "Epoch 2955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.8292 - val_dice_coef: 0.8292\n",
      "Epoch 2958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.5083 - val_dice_coef: 0.5083\n",
      "Epoch 2959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.2455 - val_dice_coef: 0.2455\n",
      "Epoch 2962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.7099 - val_dice_coef: 0.7099\n",
      "Epoch 2963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 2965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.8014 - val_dice_coef: 0.8014\n",
      "Epoch 2966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.8227 - val_dice_coef: 0.8227\n",
      "Epoch 2967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9204 - dice_coef: 0.9204 - val_loss: -0.9774 - val_dice_coef: 0.9774\n",
      "Epoch 2968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 2969/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9790 - val_dice_coef: 0.9790\n",
      "Epoch 2970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9908 - val_dice_coef: 0.9908\n",
      "Epoch 2971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9236 - dice_coef: 0.9236 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9242 - dice_coef: 0.9242 - val_loss: -0.9597 - val_dice_coef: 0.9597\n",
      "Epoch 2974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9817 - val_dice_coef: 0.9817\n",
      "Epoch 2975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9244 - dice_coef: 0.9244 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 2977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9896 - val_dice_coef: 0.9896\n",
      "Epoch 2978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 2979/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.9339 - val_dice_coef: 0.9339\n",
      "Epoch 2980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9235 - dice_coef: 0.9235 - val_loss: -0.8915 - val_dice_coef: 0.8915\n",
      "Epoch 2981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.6100 - val_dice_coef: 0.6100\n",
      "Epoch 2982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.8801 - val_dice_coef: 0.8801\n",
      "Epoch 2983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 2984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9235 - dice_coef: 0.9235 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9561 - val_dice_coef: 0.9561\n",
      "Epoch 2986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.6162 - val_dice_coef: 0.6162\n",
      "Epoch 2987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.4257 - val_dice_coef: 0.4257\n",
      "Epoch 2988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.8258 - val_dice_coef: 0.8258\n",
      "Epoch 2989/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9841 - val_dice_coef: 0.9841\n",
      "Epoch 2990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9220 - dice_coef: 0.9220 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 2991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9827 - val_dice_coef: 0.9827\n",
      "Epoch 2993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.8863 - val_dice_coef: 0.8863\n",
      "Epoch 2994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.8742 - val_dice_coef: 0.8742\n",
      "Epoch 2995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9217 - dice_coef: 0.9217 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 2996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.8957 - val_dice_coef: 0.8957\n",
      "Epoch 2997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9598 - val_dice_coef: 0.9598\n",
      "Epoch 2998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9350 - val_dice_coef: 0.9350\n",
      "Epoch 2999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9240 - dice_coef: 0.9240 - val_loss: -0.9408 - val_dice_coef: 0.9408\n",
      "Epoch 3000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.8405 - val_dice_coef: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff126c17748>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "model = get_unet()\n",
    "print(model.summary())\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "model.fit(train_z, train_z_m, batch_size=32, epochs=3000, verbose=1, shuffle=True,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weights.h5',custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_train = model.predict(train_z[:int(train_z.shape[0]*0.9)], verbose=1)\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val = model.predict(train_z[int(train_z.shape[0]*0.9):], verbose=1)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Low image data range; displaying image with stretched contrast.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "ix = 70\n",
    "imshow(np.squeeze(train_z[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(train_z_m[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((IMG_H, IMG_W, 1))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "local_conv1 = Conv2D(64, (7, 7), activation='relu', padding='same')(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(64)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(1)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_18/Max:0' shape=(?, 1, 64, 64) dtype=float32>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_231/Relu:0' shape=(?, 64, 64, 64) dtype=float32>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('img3d_train', img_array)\n",
    "np.save('msk3d_train', msk_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 320, 232)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "tf-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
