{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from medpy.io import load\n",
    "import os\n",
    "import itk\n",
    "import skimage\n",
    "import SimpleITK as sitk\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input, Maximum, concatenate, Activation, Conv3D, MaxPooling3D, Conv2DTranspose\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "'''\n",
    "from keras import layers\n",
    "from keras.layers import Input, Conv2D, Maximum, MaxPooling2D, concatenate, Activation, Conv3D, MaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam'''\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../patients/'\n",
    "IMG_H = 64\n",
    "IMG_W = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CengJia',\n",
       " 'GangZu',\n",
       " 'JiaHuiQiong',\n",
       " 'KongDan',\n",
       " 'LanDingKun',\n",
       " 'LiangChengJun',\n",
       " 'LiuGuangQiong',\n",
       " 'LiuQuanXing',\n",
       " 'LiuYanMu',\n",
       " 'ShenXin',\n",
       " 'TanHongJun',\n",
       " 'XiaGang',\n",
       " 'XiaoChangLun',\n",
       " 'YangChuanFu',\n",
       " 'YangXia',\n",
       " 'YangYunFei',\n",
       " 'ZhangJianMing',\n",
       " 'ZhouDaoMing',\n",
       " 'ZhouLiangYong']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = next(os.walk(data_path))[1]\n",
    "train_ids.sort()\n",
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CengJiaT1SegRAIROIResampling.mha',\n",
       " 'bak_CengJiaT1SegRAIROIResampling.mha',\n",
       " 'CengJiaT1SegDistanceMap.mha',\n",
       " 'CengJiaT1RAIROIResamplingNormalize.mha']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_prof = next(os.walk(data_path + '/' + train_ids[0]))[2]\n",
    "ind_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CengJiaT1RAIROIResamplingNormalize.mha'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "#ind_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pylab import has clobbered these variables: ['imshow', 'concatenate', 'resize', 'imread', 'load']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "img = sitk.ReadImage(data_path + train_ids[0] + '/' + img_name)\n",
    "msk = sitk.ReadImage(data_path + train_ids[0] + '/' + msk_b)\n",
    "img_array = sitk.GetArrayFromImage(img)\n",
    "msk_array = sitk.GetArrayFromImage(msk)\n",
    "\n",
    "%pylab inline\n",
    "subplot(121)\n",
    "imgplot = plt.imshow(np.flip(np.flip(img_array[:,136,:]), 1))\n",
    "plt.show()\n",
    "subplot(122)\n",
    "plt.imshow(np.flip(np.flip(msk_array[:,136,:]), 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n"
     ]
    }
   ],
   "source": [
    "#Trying to break the data and then concate to a 1.2w*64*64 data set.\n",
    "\n",
    "train_z = np.ndarray((103 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y = np.ndarray((320 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x = np.ndarray((232 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_z = np.ndarray((103 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_y = np.ndarray((320 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_x = np.ndarray((232 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "for i in range(len(train_ids)):\n",
    "    ind_prof = next(os.walk(data_path + '/' + train_ids[i]))[2]\n",
    "    img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "    msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "    img = sitk.ReadImage(data_path + train_ids[i] + '/' + img_name)\n",
    "    msk = sitk.ReadImage(data_path + train_ids[i] + '/' + msk_b)\n",
    "    img_array = sitk.GetArrayFromImage(img)\n",
    "    msk_array = sitk.GetArrayFromImage(msk)\n",
    "    \n",
    "    #z = np.ndarray((103, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #y = np.ndarray((320, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #x = np.ndarray((232, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    for z in range(img_array.shape[0]):\n",
    "        train_z[z + i*103,:,:,0] = resize(img_array[z,:,:], (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
    "    for y in range(img_array.shape[1]):\n",
    "        train_y[y + i*320,:,:,0] = np.flip(np.flip(resize(img_array[:,y,:], (IMG_H, IMG_W),\n",
    "                                            mode='constant', preserve_range=True), 1))\n",
    "    for x in range(img_array.shape[2]):\n",
    "        train_x[x + i*232,:,:,0] = np.flip(np.flip(resize(img_array[:,:,x], (IMG_H, IMG_W),\n",
    "                                            mode='constant', preserve_range=True), 1))\n",
    "    \n",
    "    #z_msk = np.ndarray((103, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #y_msk = np.ndarray((320, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #x_msk = np.ndarray((232, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    for z in range(msk_array.shape[0]):\n",
    "        mask_z[z + i*103,:,:,0] = resize(msk_array[z,:,:], (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
    "    for y in range(msk_array.shape[1]):\n",
    "        mask_y[y + i*320,:,:,0] = np.flip(np.flip(resize(msk_array[:,y,:], (IMG_H, IMG_W),\n",
    "                                                mode='constant', preserve_range=True), 1))\n",
    "    for x in range(msk_array.shape[2]):\n",
    "        mask_x[x + i*232,:,:,0] = np.flip(np.flip(resize(msk_array[:,:,x], (IMG_H, IMG_W),\n",
    "                                                mode='constant', preserve_range=True), 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12445, 64, 64, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = np.concatenate((train_x, train_y, train_z), axis=0)\n",
    "tmp2 = np.concatenate((mask_x, mask_y, mask_z), axis=0)\n",
    "tmp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 103, 320, 232, 1) (19, 103, 320, 232, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Trying to directly obtrain data with shape of (# of patients)*original\n",
    "#size of the image.\n",
    "\n",
    "X_data = np.ndarray((len(train_ids), img_array.shape[0], img_array.shape[1], img_array.shape[2], 1), dtype=np.uint8)\n",
    "Y_mask = np.ndarray((len(train_ids), msk_array.shape[0], msk_array.shape[1], msk_array.shape[2], 1), dtype=np.uint8)\n",
    "for i in range(len(train_ids)):\n",
    "    ind_prof = next(os.walk(data_path + '/' + train_ids[i]))[2]\n",
    "    img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "    msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "    img = sitk.ReadImage(data_path + train_ids[i] + '/' + img_name)\n",
    "    msk = sitk.ReadImage(data_path + train_ids[i] + '/' + msk_b)\n",
    "    img_array = sitk.GetArrayFromImage(img)\n",
    "    msk_array = sitk.GetArrayFromImage(msk)\n",
    "    for z in range(img_array.shape[0]):\n",
    "        X_data[i,z,:,:,0] = img_array[z,:,:]\n",
    "    for y in range(img_array.shape[1]):\n",
    "        X_data[i,:,y,:,0] = img_array[:,y,:]\n",
    "    for x in range(img_array.shape[0]):\n",
    "        X_data[i,:,:,x,0] = img_array[:,:,x]\n",
    "        \n",
    "    for z in range(msk_array.shape[0]):\n",
    "        Y_mask[i,z,:,:,0] = msk_array[z,:,:]\n",
    "    for y in range(msk_array.shape[1]):\n",
    "        Y_mask[i,:,y,:,0] = msk_array[:,y,:]\n",
    "    for x in range(msk_array.shape[0]):\n",
    "        Y_mask[i,:,:,x,0] = msk_array[:,:,x]\n",
    "        \n",
    "\n",
    "subplot(121)\n",
    "imshow(X_data[18,51,:,:,0])\n",
    "subplot(122)\n",
    "imshow(Y_mask[18,51,:,:,0])\n",
    "print(X_data.shape, Y_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the input, due to err:\"expected input_3 to have\n",
    "#shape (65, 65, 65, 1) but got array with shape (103, 320, 232, 1)\"\n",
    "def preprocessing(arch_name):\n",
    "    X_global = []\n",
    "    X_local = []\n",
    "    Y = []\n",
    "    if arch_name == 'input':\n",
    "        s = 65\n",
    "        for i in range(1):\n",
    "            print(str(i+1)+'/19 data processed')\n",
    "            for z in range(X_data.shape[1]-s):\n",
    "                for y in range(X_data.shape[2]-s):\n",
    "                    for x in range(X_data.shape[3]-s):\n",
    "                        if X_data[i,z+16:z+49,y+16:y+49,x+16:x+49,0].any() != 0:\n",
    "                            X_global.append(X_data[i,z:z+s,y:y+s,x:x+s,0])\n",
    "                            X_local.append(X_data[i,z+16:z+49,y+16:y+49,\n",
    "                                                  x+16:x+49,0])\n",
    "                            Y.append(Y_mask[i,z:z+s,y:y+s,x:x+s,0])\n",
    "    \n",
    "    #X1 = np.asarray(X_global)\n",
    "    #X2 = np.asarray(X_local)\n",
    "    #Y = np.asarray(Y_out)\n",
    "    \n",
    "    return [X_global, X_local, Y]    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/19 data processed\n"
     ]
    }
   ],
   "source": [
    "f_data = preprocessing('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1618230"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_path3D(X_input, arch_type):\n",
    "    if arch_type == 'input':\n",
    "        #upper path\n",
    "        X = Conv3D(64, (7, 7, 7), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X1 = Conv3D(64, (7, 7, 7), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X1 = Maximum()([X,X1])\n",
    "        X1 = MaxPooling3D((4,4,4), strides=(1,1,1), padding='valid')(X1)\n",
    "        \n",
    "        X = Conv3D(64, (3,3,3), strides=(1,1,1), padding='valid')(X1)\n",
    "        X1 = Conv3D(64, (3,3,3), strides=(1,1,1), padding='valid')(X1)\n",
    "        X1 = Maximum()([X,X1])\n",
    "        X1 = MaxPooling3D((2,2,2), strides=(1,1,1), padding='valid')(X1)\n",
    "        \n",
    "        #lower path\n",
    "        X = Conv3D(160, (13, 13, 13), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X2 = Conv3D(160, (13, 13, 13), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X2 = Maximum()([X,X2])\n",
    "        \n",
    "        #concatenation\n",
    "        X = concatenate([X1,X2], axis=4)\n",
    "        X = Conv3D(5, (21, 21, 21), strides=(1,1,1), padding='valid')(X)\n",
    "        #X = Activation('softmax')(X)\n",
    "    \n",
    "        #model = Model(inputs=X_input, outputs=X)\n",
    "        return X\n",
    "def InputCascadeCNN(shape1, shape2):\n",
    "    #concatenate input and output of the 1st two path network\n",
    "    X1 = Input(shape1)\n",
    "    X = two_path3D(X1, 'input')\n",
    "    \n",
    "    X2 = Input(shape2)\n",
    "    X = concatenate([X, X2], axis=4)\n",
    "    X = two_path3D(X, 'input')\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=[X1,X2], outputs=X)\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 65, 65, 65, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 59, 59, 59, 6 22016       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 59, 59, 59, 6 22016       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_1 (Maximum)             (None, 59, 59, 59, 6 0           conv3d_1[0][0]                   \n",
      "                                                                 conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 56, 56, 56, 6 0           maximum_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 54, 54, 54, 6 110656      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 54, 54, 54, 6 110656      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_2 (Maximum)             (None, 54, 54, 54, 6 0           conv3d_3[0][0]                   \n",
      "                                                                 conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 53, 53, 53, 1 351680      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 53, 53, 53, 1 351680      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 53, 53, 53, 6 0           maximum_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_3 (Maximum)             (None, 53, 53, 53, 1 0           conv3d_5[0][0]                   \n",
      "                                                                 conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 53, 53, 53, 2 0           max_pooling3d_2[0][0]            \n",
      "                                                                 maximum_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 33, 33, 33, 5 10372325    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 33, 33, 33, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 33, 33, 33, 6 0           conv3d_7[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 27, 27, 27, 6 131776      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 27, 27, 27, 6 131776      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maximum_4 (Maximum)             (None, 27, 27, 27, 6 0           conv3d_8[0][0]                   \n",
      "                                                                 conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 24, 24, 24, 6 0           maximum_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_5 (Maximum)             (None, 22, 22, 22, 6 0           conv3d_10[0][0]                  \n",
      "                                                                 conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 21, 21, 21, 6 0           maximum_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_6 (Maximum)             (None, 21, 21, 21, 1 0           conv3d_12[0][0]                  \n",
      "                                                                 conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 21, 21, 21, 2 0           max_pooling3d_4[0][0]            \n",
      "                                                                 maximum_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 1, 1, 1, 5)   10372325    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 1, 5)   0           conv3d_14[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,416,778\n",
      "Trainable params: 26,416,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1 = InputCascadeCNN((65,65,65,1), (33,33,33,1))\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 103, 320, 232, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 71, 288, 200, 5), (None, 33, 33, 33, 1)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-506450411cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Creating and compiling model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputCascadeCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m103\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m232\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#m1 = get_unet()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-10da454d4a63>\u001b[0m in \u001b[0;36mInputCascadeCNN\u001b[0;34m(shape1, shape2)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_path3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    352\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 71, 288, 200, 5), (None, 33, 33, 33, 1)]"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "m1 = InputCascadeCNN((65,65,65,1), (33,33,33,1))\n",
    "#m1 = get_unet()\n",
    "print(m1.summary())\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "m1.fit([X_data,X_data], Y_mask, batch_size=8, epochs=50, verbose=1, shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Processed_Data/img_z', oz)\n",
    "np.save('../Processed_Data/img_y', oy)\n",
    "np.save('../Processed_Data/img_x', ox)\n",
    "np.save('../Processed_Data/msk_z', oz_msk)\n",
    "np.save('../Processed_Data/msk_y', oy_msk)\n",
    "np.save('../Processed_Data/msk_x', ox_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_z = np.ndarray((len(oz), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y = np.ndarray((len(oy), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x = np.ndarray((len(ox), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_z_m = np.ndarray((len(oz_msk), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y_m = np.ndarray((len(oy_msk), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x_m = np.ndarray((len(ox_msk), IMG_H, IMG_W, 1), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n"
     ]
    }
   ],
   "source": [
    "for n, img in enumerate(oz):\n",
    "    train_z[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oy):\n",
    "    train_y[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(ox):\n",
    "    train_x[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oz_msk):\n",
    "    train_z_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oy_msk):\n",
    "    train_y_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(ox_msk):\n",
    "    train_x_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 128, 128, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 1)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 32) 320         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 32)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 16, 16, 256)  524544      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 512)  0           conv2d_transpose_13[0][0]        \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 256)  0           conv2d_transpose_14[0][0]        \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 128)  0           conv2d_transpose_15[0][0]        \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 128, 128, 64) 0           conv2d_transpose_16[0][0]        \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 128, 128, 1)  33          conv2d_75[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,759,521\n",
      "Trainable params: 7,759,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Train on 92 samples, validate on 11 samples\n",
      "Epoch 1/3000\n",
      "92/92 [==============================] - 6s 61ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1107e-05 - val_dice_coef: 1.1107e-05\n",
      "Epoch 2/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1105e-05 - val_dice_coef: 1.1105e-05\n",
      "Epoch 3/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1103e-05 - val_dice_coef: 1.1103e-05\n",
      "Epoch 4/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1101e-05 - val_dice_coef: 1.1101e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1099e-05 - val_dice_coef: 1.1099e-05\n",
      "Epoch 6/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1098e-05 - val_dice_coef: 1.1098e-05\n",
      "Epoch 7/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1096e-05 - val_dice_coef: 1.1096e-05\n",
      "Epoch 8/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1094e-05 - val_dice_coef: 1.1094e-05\n",
      "Epoch 9/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1092e-05 - val_dice_coef: 1.1092e-05\n",
      "Epoch 10/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1091e-05 - val_dice_coef: 1.1091e-05\n",
      "Epoch 11/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1089e-05 - val_dice_coef: 1.1089e-05\n",
      "Epoch 12/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1088e-05 - val_dice_coef: 1.1088e-05\n",
      "Epoch 13/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1087e-05 - val_dice_coef: 1.1087e-05\n",
      "Epoch 14/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1085e-05 - val_dice_coef: 1.1085e-05\n",
      "Epoch 15/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1084e-05 - val_dice_coef: 1.1084e-05\n",
      "Epoch 16/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1082e-05 - val_dice_coef: 1.1082e-05\n",
      "Epoch 17/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1081e-05 - val_dice_coef: 1.1081e-05\n",
      "Epoch 18/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 19/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1079e-05 - val_dice_coef: 1.1079e-05\n",
      "Epoch 20/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 21/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 22/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1076e-05 - val_dice_coef: 1.1076e-05\n",
      "Epoch 23/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 24/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1074e-05 - val_dice_coef: 1.1074e-05\n",
      "Epoch 25/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 26/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 27/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 28/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 29/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 30/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 31/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 32/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 33/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 34/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 35/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 36/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 37/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 38/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 39/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 40/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 41/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 42/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 43/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 44/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 45/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 46/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1074e-05 - val_dice_coef: 1.1074e-05\n",
      "Epoch 47/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 48/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 49/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1076e-05 - val_dice_coef: 1.1076e-05\n",
      "Epoch 50/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 51/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 52/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1078e-05 - val_dice_coef: 1.1078e-05\n",
      "Epoch 53/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1078e-05 - val_dice_coef: 1.1078e-05\n",
      "Epoch 54/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1079e-05 - val_dice_coef: 1.1079e-05\n",
      "Epoch 55/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 56/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 57/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1081e-05 - val_dice_coef: 1.1081e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1082e-05 - val_dice_coef: 1.1082e-05\n",
      "Epoch 59/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1083e-05 - val_dice_coef: 1.1083e-05\n",
      "Epoch 60/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1083e-05 - val_dice_coef: 1.1083e-05\n",
      "Epoch 61/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1084e-05 - val_dice_coef: 1.1084e-05\n",
      "Epoch 62/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1085e-05 - val_dice_coef: 1.1085e-05\n",
      "Epoch 63/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1086e-05 - val_dice_coef: 1.1086e-05\n",
      "Epoch 64/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1087e-05 - val_dice_coef: 1.1087e-05\n",
      "Epoch 65/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1088e-05 - val_dice_coef: 1.1088e-05\n",
      "Epoch 66/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1089e-05 - val_dice_coef: 1.1089e-05\n",
      "Epoch 67/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1090e-05 - val_dice_coef: 1.1090e-05\n",
      "Epoch 68/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1091e-05 - val_dice_coef: 1.1091e-05\n",
      "Epoch 69/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1092e-05 - val_dice_coef: 1.1092e-05\n",
      "Epoch 70/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1093e-05 - val_dice_coef: 1.1093e-05\n",
      "Epoch 71/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1094e-05 - val_dice_coef: 1.1094e-05\n",
      "Epoch 72/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1096e-05 - val_dice_coef: 1.1096e-05\n",
      "Epoch 73/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1097e-05 - val_dice_coef: 1.1097e-05\n",
      "Epoch 74/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1098e-05 - val_dice_coef: 1.1098e-05\n",
      "Epoch 75/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1100e-05 - val_dice_coef: 1.1100e-05\n",
      "Epoch 76/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1101e-05 - val_dice_coef: 1.1101e-05\n",
      "Epoch 77/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1102e-05 - val_dice_coef: 1.1102e-05\n",
      "Epoch 78/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1104e-05 - val_dice_coef: 1.1104e-05\n",
      "Epoch 79/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1105e-05 - val_dice_coef: 1.1105e-05\n",
      "Epoch 80/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1106e-05 - val_dice_coef: 1.1106e-05\n",
      "Epoch 81/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1108e-05 - val_dice_coef: 1.1108e-05\n",
      "Epoch 82/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1109e-05 - val_dice_coef: 1.1109e-05\n",
      "Epoch 83/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1110e-05 - val_dice_coef: 1.1110e-05\n",
      "Epoch 84/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1112e-05 - val_dice_coef: 1.1112e-05\n",
      "Epoch 85/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1113e-05 - val_dice_coef: 1.1113e-05\n",
      "Epoch 86/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1115e-05 - val_dice_coef: 1.1115e-05\n",
      "Epoch 87/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1116e-05 - val_dice_coef: 1.1116e-05\n",
      "Epoch 88/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1117e-05 - val_dice_coef: 1.1117e-05\n",
      "Epoch 89/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1118e-05 - val_dice_coef: 1.1118e-05\n",
      "Epoch 90/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1120e-05 - val_dice_coef: 1.1120e-05\n",
      "Epoch 91/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1121e-05 - val_dice_coef: 1.1121e-05\n",
      "Epoch 92/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1123e-05 - val_dice_coef: 1.1123e-05\n",
      "Epoch 93/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1125e-05 - val_dice_coef: 1.1125e-05\n",
      "Epoch 94/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1126e-05 - val_dice_coef: 1.1126e-05\n",
      "Epoch 95/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1128e-05 - val_dice_coef: 1.1128e-05\n",
      "Epoch 96/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1130e-05 - val_dice_coef: 1.1130e-05\n",
      "Epoch 97/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0111 - dice_coef: 0.0111 - val_loss: -1.1133e-05 - val_dice_coef: 1.1133e-05\n",
      "Epoch 98/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0111 - dice_coef: 0.0111 - val_loss: -1.1135e-05 - val_dice_coef: 1.1135e-05\n",
      "Epoch 99/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0112 - dice_coef: 0.0112 - val_loss: -1.1138e-05 - val_dice_coef: 1.1138e-05\n",
      "Epoch 100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0112 - dice_coef: 0.0112 - val_loss: -1.1140e-05 - val_dice_coef: 1.1140e-05\n",
      "Epoch 101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0113 - dice_coef: 0.0113 - val_loss: -1.1144e-05 - val_dice_coef: 1.1144e-05\n",
      "Epoch 102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0114 - dice_coef: 0.0114 - val_loss: -1.1148e-05 - val_dice_coef: 1.1148e-05\n",
      "Epoch 103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0115 - dice_coef: 0.0115 - val_loss: -1.1151e-05 - val_dice_coef: 1.1151e-05\n",
      "Epoch 104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0115 - dice_coef: 0.0115 - val_loss: -1.1156e-05 - val_dice_coef: 1.1156e-05\n",
      "Epoch 105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0116 - dice_coef: 0.0116 - val_loss: -1.1162e-05 - val_dice_coef: 1.1162e-05\n",
      "Epoch 106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0117 - dice_coef: 0.0117 - val_loss: -1.1167e-05 - val_dice_coef: 1.1167e-05\n",
      "Epoch 107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0118 - dice_coef: 0.0118 - val_loss: -1.1175e-05 - val_dice_coef: 1.1175e-05\n",
      "Epoch 108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0119 - dice_coef: 0.0119 - val_loss: -1.1183e-05 - val_dice_coef: 1.1183e-05\n",
      "Epoch 109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0121 - dice_coef: 0.0121 - val_loss: -1.1193e-05 - val_dice_coef: 1.1193e-05\n",
      "Epoch 110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0122 - dice_coef: 0.0122 - val_loss: -1.1207e-05 - val_dice_coef: 1.1207e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0124 - dice_coef: 0.0124 - val_loss: -1.1224e-05 - val_dice_coef: 1.1224e-05\n",
      "Epoch 112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0125 - dice_coef: 0.0125 - val_loss: -1.1242e-05 - val_dice_coef: 1.1242e-05\n",
      "Epoch 113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0128 - dice_coef: 0.0128 - val_loss: -1.1271e-05 - val_dice_coef: 1.1271e-05\n",
      "Epoch 114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0130 - dice_coef: 0.0130 - val_loss: -1.1302e-05 - val_dice_coef: 1.1302e-05\n",
      "Epoch 115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0133 - dice_coef: 0.0133 - val_loss: -1.1336e-05 - val_dice_coef: 1.1336e-05\n",
      "Epoch 116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0136 - dice_coef: 0.0136 - val_loss: -1.1398e-05 - val_dice_coef: 1.1398e-05\n",
      "Epoch 117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0139 - dice_coef: 0.0139 - val_loss: -1.1497e-05 - val_dice_coef: 1.1497e-05\n",
      "Epoch 118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0143 - dice_coef: 0.0143 - val_loss: -1.1565e-05 - val_dice_coef: 1.1565e-05\n",
      "Epoch 119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0149 - dice_coef: 0.0149 - val_loss: -1.1802e-05 - val_dice_coef: 1.1802e-05\n",
      "Epoch 120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0155 - dice_coef: 0.0155 - val_loss: -1.1994e-05 - val_dice_coef: 1.1994e-05\n",
      "Epoch 121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0161 - dice_coef: 0.0161 - val_loss: -1.2419e-05 - val_dice_coef: 1.2419e-05\n",
      "Epoch 122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0172 - dice_coef: 0.0172 - val_loss: -1.2878e-05 - val_dice_coef: 1.2878e-05\n",
      "Epoch 123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0185 - dice_coef: 0.0185 - val_loss: -1.4198e-05 - val_dice_coef: 1.4198e-05\n",
      "Epoch 124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0202 - dice_coef: 0.0202 - val_loss: -1.5069e-05 - val_dice_coef: 1.5069e-05\n",
      "Epoch 125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0230 - dice_coef: 0.0230 - val_loss: -1.8830e-05 - val_dice_coef: 1.8830e-05\n",
      "Epoch 126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0277 - dice_coef: 0.0277 - val_loss: -2.5383e-05 - val_dice_coef: 2.5383e-05\n",
      "Epoch 127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0338 - dice_coef: 0.0338 - val_loss: -3.0613e-05 - val_dice_coef: 3.0613e-05\n",
      "Epoch 128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0440 - dice_coef: 0.0440 - val_loss: -3.7309e-05 - val_dice_coef: 3.7309e-05\n",
      "Epoch 129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0589 - dice_coef: 0.0589 - val_loss: -5.4508e-05 - val_dice_coef: 5.4508e-05\n",
      "Epoch 130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0796 - dice_coef: 0.0796 - val_loss: -8.9018e-05 - val_dice_coef: 8.9018e-05\n",
      "Epoch 131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0968 - dice_coef: 0.0968 - val_loss: -7.3245e-05 - val_dice_coef: 7.3245e-05\n",
      "Epoch 132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1158 - dice_coef: 0.1158 - val_loss: -1.5367e-04 - val_dice_coef: 1.5367e-04\n",
      "Epoch 133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1511 - dice_coef: 0.1511 - val_loss: -2.6846e-04 - val_dice_coef: 2.6846e-04\n",
      "Epoch 134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1832 - dice_coef: 0.1832 - val_loss: -3.1565e-04 - val_dice_coef: 3.1565e-04\n",
      "Epoch 135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1991 - dice_coef: 0.1991 - val_loss: -1.4018e-04 - val_dice_coef: 1.4018e-04\n",
      "Epoch 136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1806 - dice_coef: 0.1806 - val_loss: -4.9281e-04 - val_dice_coef: 4.9281e-04\n",
      "Epoch 137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2291 - dice_coef: 0.2291 - val_loss: -2.9947e-04 - val_dice_coef: 2.9947e-04\n",
      "Epoch 138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2629 - dice_coef: 0.2629 - val_loss: -2.4638e-04 - val_dice_coef: 2.4638e-04\n",
      "Epoch 139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2359 - dice_coef: 0.2359 - val_loss: -7.2372e-04 - val_dice_coef: 7.2372e-04\n",
      "Epoch 140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2803 - dice_coef: 0.2803 - val_loss: -2.6312e-04 - val_dice_coef: 2.6312e-04\n",
      "Epoch 141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2769 - dice_coef: 0.2769 - val_loss: -0.0012 - val_dice_coef: 0.0012\n",
      "Epoch 142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3336 - dice_coef: 0.3336 - val_loss: -4.0191e-04 - val_dice_coef: 4.0191e-04\n",
      "Epoch 143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3543 - dice_coef: 0.3543 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 144/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3593 - dice_coef: 0.3593 - val_loss: -3.4966e-04 - val_dice_coef: 3.4966e-04\n",
      "Epoch 145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3690 - dice_coef: 0.3690 - val_loss: -0.0038 - val_dice_coef: 0.0038\n",
      "Epoch 146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3731 - dice_coef: 0.3731 - val_loss: -5.3135e-04 - val_dice_coef: 5.3135e-04\n",
      "Epoch 147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3957 - dice_coef: 0.3957 - val_loss: -0.0028 - val_dice_coef: 0.0028\n",
      "Epoch 148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4610 - dice_coef: 0.4610 - val_loss: -0.0023 - val_dice_coef: 0.0023\n",
      "Epoch 149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4710 - dice_coef: 0.4710 - val_loss: -0.0014 - val_dice_coef: 0.0014\n",
      "Epoch 150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4698 - dice_coef: 0.4698 - val_loss: -0.0074 - val_dice_coef: 0.0074\n",
      "Epoch 151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4465 - dice_coef: 0.4465 - val_loss: -0.0016 - val_dice_coef: 0.0016\n",
      "Epoch 152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4922 - dice_coef: 0.4922 - val_loss: -0.0030 - val_dice_coef: 0.0030\n",
      "Epoch 153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5099 - dice_coef: 0.5099 - val_loss: -0.0074 - val_dice_coef: 0.0074\n",
      "Epoch 154/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5115 - dice_coef: 0.5115 - val_loss: -0.0033 - val_dice_coef: 0.0033\n",
      "Epoch 155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5275 - dice_coef: 0.5275 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5467 - dice_coef: 0.5467 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5057 - dice_coef: 0.5057 - val_loss: -0.0020 - val_dice_coef: 0.0020\n",
      "Epoch 158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5405 - dice_coef: 0.5405 - val_loss: -0.0041 - val_dice_coef: 0.0041\n",
      "Epoch 159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5680 - dice_coef: 0.5680 - val_loss: -0.0095 - val_dice_coef: 0.0095\n",
      "Epoch 160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5403 - dice_coef: 0.5403 - val_loss: -0.0082 - val_dice_coef: 0.0082\n",
      "Epoch 161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5418 - dice_coef: 0.5418 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5725 - dice_coef: 0.5725 - val_loss: -0.0022 - val_dice_coef: 0.0022\n",
      "Epoch 163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5570 - dice_coef: 0.5570 - val_loss: -0.0157 - val_dice_coef: 0.0157\n",
      "Epoch 164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5478 - dice_coef: 0.5478 - val_loss: -0.0057 - val_dice_coef: 0.0057\n",
      "Epoch 165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5625 - dice_coef: 0.5625 - val_loss: -0.0017 - val_dice_coef: 0.0017\n",
      "Epoch 166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5734 - dice_coef: 0.5734 - val_loss: -0.0263 - val_dice_coef: 0.0263\n",
      "Epoch 167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5060 - dice_coef: 0.5060 - val_loss: -0.0012 - val_dice_coef: 0.0012\n",
      "Epoch 168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5289 - dice_coef: 0.5289 - val_loss: -0.0095 - val_dice_coef: 0.0095\n",
      "Epoch 169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5431 - dice_coef: 0.5431 - val_loss: -0.0043 - val_dice_coef: 0.0043\n",
      "Epoch 170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5746 - dice_coef: 0.5746 - val_loss: -0.0021 - val_dice_coef: 0.0021\n",
      "Epoch 171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5672 - dice_coef: 0.5672 - val_loss: -0.0185 - val_dice_coef: 0.0185\n",
      "Epoch 172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5998 - dice_coef: 0.5998 - val_loss: -0.0021 - val_dice_coef: 0.0021\n",
      "Epoch 173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5934 - dice_coef: 0.5934 - val_loss: -0.0227 - val_dice_coef: 0.0227\n",
      "Epoch 174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5620 - dice_coef: 0.5620 - val_loss: -0.0024 - val_dice_coef: 0.0024\n",
      "Epoch 175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5871 - dice_coef: 0.5871 - val_loss: -0.0051 - val_dice_coef: 0.0051\n",
      "Epoch 176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6136 - dice_coef: 0.6136 - val_loss: -0.0080 - val_dice_coef: 0.0080\n",
      "Epoch 177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6234 - dice_coef: 0.6234 - val_loss: -0.0028 - val_dice_coef: 0.0028\n",
      "Epoch 178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6085 - dice_coef: 0.6085 - val_loss: -0.0268 - val_dice_coef: 0.0268\n",
      "Epoch 179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6012 - dice_coef: 0.6012 - val_loss: -0.0029 - val_dice_coef: 0.0029\n",
      "Epoch 180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6337 - dice_coef: 0.6337 - val_loss: -0.0189 - val_dice_coef: 0.0189\n",
      "Epoch 181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6154 - dice_coef: 0.6154 - val_loss: -0.0062 - val_dice_coef: 0.0062\n",
      "Epoch 182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6435 - dice_coef: 0.6435 - val_loss: -0.0052 - val_dice_coef: 0.0052\n",
      "Epoch 183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6477 - dice_coef: 0.6477 - val_loss: -0.0080 - val_dice_coef: 0.0080\n",
      "Epoch 184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6506 - dice_coef: 0.6506 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6532 - dice_coef: 0.6532 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6516 - dice_coef: 0.6516 - val_loss: -0.0236 - val_dice_coef: 0.0236\n",
      "Epoch 187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6464 - dice_coef: 0.6464 - val_loss: -0.0035 - val_dice_coef: 0.0035\n",
      "Epoch 188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6166 - dice_coef: 0.6166 - val_loss: -0.0066 - val_dice_coef: 0.0066\n",
      "Epoch 189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6000 - dice_coef: 0.6000 - val_loss: -0.0093 - val_dice_coef: 0.0093\n",
      "Epoch 190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6448 - dice_coef: 0.6448 - val_loss: -0.0034 - val_dice_coef: 0.0034\n",
      "Epoch 191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6118 - dice_coef: 0.6118 - val_loss: -0.0278 - val_dice_coef: 0.0278\n",
      "Epoch 192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6444 - dice_coef: 0.6444 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6396 - dice_coef: 0.6396 - val_loss: -0.0102 - val_dice_coef: 0.0102\n",
      "Epoch 194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6707 - dice_coef: 0.6707 - val_loss: -0.0072 - val_dice_coef: 0.0072\n",
      "Epoch 195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6327 - dice_coef: 0.6327 - val_loss: -0.0024 - val_dice_coef: 0.0024\n",
      "Epoch 196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6094 - dice_coef: 0.6094 - val_loss: -0.0249 - val_dice_coef: 0.0249\n",
      "Epoch 197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6616 - dice_coef: 0.6616 - val_loss: -0.0029 - val_dice_coef: 0.0029\n",
      "Epoch 198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6442 - dice_coef: 0.6442 - val_loss: -0.0407 - val_dice_coef: 0.0407\n",
      "Epoch 199/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6436 - dice_coef: 0.6436 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6376 - dice_coef: 0.6376 - val_loss: -0.0210 - val_dice_coef: 0.0210\n",
      "Epoch 201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6463 - dice_coef: 0.6463 - val_loss: -0.0057 - val_dice_coef: 0.0057\n",
      "Epoch 202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6588 - dice_coef: 0.6588 - val_loss: -0.0055 - val_dice_coef: 0.0055\n",
      "Epoch 203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6548 - dice_coef: 0.6548 - val_loss: -0.0221 - val_dice_coef: 0.0221\n",
      "Epoch 204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6466 - dice_coef: 0.6466 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6399 - dice_coef: 0.6399 - val_loss: -0.0501 - val_dice_coef: 0.0501\n",
      "Epoch 206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6406 - dice_coef: 0.6406 - val_loss: -0.0042 - val_dice_coef: 0.0042\n",
      "Epoch 207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6891 - dice_coef: 0.6891 - val_loss: -0.0334 - val_dice_coef: 0.0334\n",
      "Epoch 208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6813 - dice_coef: 0.6813 - val_loss: -0.0030 - val_dice_coef: 0.0030\n",
      "Epoch 209/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6654 - dice_coef: 0.6654 - val_loss: -0.0236 - val_dice_coef: 0.0236\n",
      "Epoch 210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6557 - dice_coef: 0.6557 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6867 - dice_coef: 0.6867 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6828 - dice_coef: 0.6828 - val_loss: -0.0213 - val_dice_coef: 0.0213\n",
      "Epoch 213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6963 - dice_coef: 0.6963 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6900 - dice_coef: 0.6900 - val_loss: -0.0160 - val_dice_coef: 0.0160\n",
      "Epoch 215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7085 - dice_coef: 0.7085 - val_loss: -0.0060 - val_dice_coef: 0.0060\n",
      "Epoch 216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7012 - dice_coef: 0.7012 - val_loss: -0.0172 - val_dice_coef: 0.0172\n",
      "Epoch 217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7031 - dice_coef: 0.7031 - val_loss: -0.0050 - val_dice_coef: 0.0050\n",
      "Epoch 218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7066 - dice_coef: 0.7066 - val_loss: -0.0333 - val_dice_coef: 0.0333\n",
      "Epoch 219/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7029 - dice_coef: 0.7029 - val_loss: -0.0038 - val_dice_coef: 0.0038\n",
      "Epoch 220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6974 - dice_coef: 0.6974 - val_loss: -0.0762 - val_dice_coef: 0.0762\n",
      "Epoch 221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6840 - dice_coef: 0.6840 - val_loss: -0.0042 - val_dice_coef: 0.0042\n",
      "Epoch 222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7095 - dice_coef: 0.7095 - val_loss: -0.0456 - val_dice_coef: 0.0456\n",
      "Epoch 223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6927 - dice_coef: 0.6927 - val_loss: -0.0048 - val_dice_coef: 0.0048\n",
      "Epoch 224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6993 - dice_coef: 0.6993 - val_loss: -0.0125 - val_dice_coef: 0.0125\n",
      "Epoch 225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7147 - dice_coef: 0.7147 - val_loss: -0.0098 - val_dice_coef: 0.0098\n",
      "Epoch 226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7212 - dice_coef: 0.7212 - val_loss: -0.0073 - val_dice_coef: 0.0073\n",
      "Epoch 227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7165 - dice_coef: 0.7165 - val_loss: -0.0154 - val_dice_coef: 0.0154\n",
      "Epoch 228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7287 - dice_coef: 0.7287 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7251 - dice_coef: 0.7251 - val_loss: -0.0087 - val_dice_coef: 0.0087\n",
      "Epoch 230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7258 - dice_coef: 0.7258 - val_loss: -0.0120 - val_dice_coef: 0.0120\n",
      "Epoch 231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7331 - dice_coef: 0.7331 - val_loss: -0.0119 - val_dice_coef: 0.0119\n",
      "Epoch 232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7328 - dice_coef: 0.7328 - val_loss: -0.0118 - val_dice_coef: 0.0118\n",
      "Epoch 233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7270 - dice_coef: 0.7270 - val_loss: -0.0081 - val_dice_coef: 0.0081\n",
      "Epoch 234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7355 - dice_coef: 0.7355 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7344 - dice_coef: 0.7344 - val_loss: -0.0076 - val_dice_coef: 0.0076\n",
      "Epoch 236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7305 - dice_coef: 0.7305 - val_loss: -0.0531 - val_dice_coef: 0.0531\n",
      "Epoch 237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7165 - dice_coef: 0.7165 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7345 - dice_coef: 0.7345 - val_loss: -0.0081 - val_dice_coef: 0.0081\n",
      "Epoch 239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7349 - dice_coef: 0.7349 - val_loss: -0.0205 - val_dice_coef: 0.0205\n",
      "Epoch 240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7402 - dice_coef: 0.7402 - val_loss: -0.0069 - val_dice_coef: 0.0069\n",
      "Epoch 241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7214 - dice_coef: 0.7214 - val_loss: -0.0201 - val_dice_coef: 0.0201\n",
      "Epoch 242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7329 - dice_coef: 0.7329 - val_loss: -0.0245 - val_dice_coef: 0.0245\n",
      "Epoch 243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7348 - dice_coef: 0.7348 - val_loss: -0.0086 - val_dice_coef: 0.0086\n",
      "Epoch 244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7320 - dice_coef: 0.7320 - val_loss: -0.0145 - val_dice_coef: 0.0145\n",
      "Epoch 245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7330 - dice_coef: 0.7330 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7447 - dice_coef: 0.7447 - val_loss: -0.0222 - val_dice_coef: 0.0222\n",
      "Epoch 247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7501 - dice_coef: 0.7501 - val_loss: -0.0142 - val_dice_coef: 0.0142\n",
      "Epoch 248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7491 - dice_coef: 0.7491 - val_loss: -0.0147 - val_dice_coef: 0.0147\n",
      "Epoch 249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7529 - dice_coef: 0.7529 - val_loss: -0.0142 - val_dice_coef: 0.0142\n",
      "Epoch 250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7491 - dice_coef: 0.7491 - val_loss: -0.0514 - val_dice_coef: 0.0514\n",
      "Epoch 251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7485 - dice_coef: 0.7485 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7539 - dice_coef: 0.7539 - val_loss: -0.0343 - val_dice_coef: 0.0343\n",
      "Epoch 253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7467 - dice_coef: 0.7467 - val_loss: -0.0375 - val_dice_coef: 0.0375\n",
      "Epoch 254/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7548 - dice_coef: 0.7548 - val_loss: -0.0094 - val_dice_coef: 0.0094\n",
      "Epoch 255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7531 - dice_coef: 0.7531 - val_loss: -0.0179 - val_dice_coef: 0.0179\n",
      "Epoch 256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7568 - dice_coef: 0.7568 - val_loss: -0.0368 - val_dice_coef: 0.0368\n",
      "Epoch 257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7534 - dice_coef: 0.7534 - val_loss: -0.0270 - val_dice_coef: 0.0270\n",
      "Epoch 258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7571 - dice_coef: 0.7571 - val_loss: -0.0097 - val_dice_coef: 0.0097\n",
      "Epoch 259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7560 - dice_coef: 0.7560 - val_loss: -0.0201 - val_dice_coef: 0.0201\n",
      "Epoch 260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7627 - dice_coef: 0.7627 - val_loss: -0.0293 - val_dice_coef: 0.0293\n",
      "Epoch 261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7637 - dice_coef: 0.7637 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7538 - dice_coef: 0.7538 - val_loss: -0.0205 - val_dice_coef: 0.0205\n",
      "Epoch 263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7650 - dice_coef: 0.7650 - val_loss: -0.0238 - val_dice_coef: 0.0238\n",
      "Epoch 264/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7660 - dice_coef: 0.7660 - val_loss: -0.0292 - val_dice_coef: 0.0292\n",
      "Epoch 265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.0419 - val_dice_coef: 0.0419\n",
      "Epoch 266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7528 - dice_coef: 0.7528 - val_loss: -0.0428 - val_dice_coef: 0.0428\n",
      "Epoch 267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7596 - dice_coef: 0.7596 - val_loss: -0.0121 - val_dice_coef: 0.0121\n",
      "Epoch 268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7546 - dice_coef: 0.7546 - val_loss: -0.0121 - val_dice_coef: 0.0121\n",
      "Epoch 269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7489 - dice_coef: 0.7489 - val_loss: -0.0822 - val_dice_coef: 0.0822\n",
      "Epoch 270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7523 - dice_coef: 0.7523 - val_loss: -0.0180 - val_dice_coef: 0.0180\n",
      "Epoch 271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7621 - dice_coef: 0.7621 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7515 - dice_coef: 0.7515 - val_loss: -0.0182 - val_dice_coef: 0.0182\n",
      "Epoch 273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7665 - dice_coef: 0.7665 - val_loss: -0.1468 - val_dice_coef: 0.1468\n",
      "Epoch 274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7493 - dice_coef: 0.7493 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7508 - dice_coef: 0.7508 - val_loss: -0.0054 - val_dice_coef: 0.0054\n",
      "Epoch 276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7320 - dice_coef: 0.7320 - val_loss: -0.0317 - val_dice_coef: 0.0317\n",
      "Epoch 277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7667 - dice_coef: 0.7667 - val_loss: -0.0886 - val_dice_coef: 0.0886\n",
      "Epoch 278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7651 - dice_coef: 0.7651 - val_loss: -0.0332 - val_dice_coef: 0.0332\n",
      "Epoch 279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7680 - dice_coef: 0.7680 - val_loss: -0.0117 - val_dice_coef: 0.0117\n",
      "Epoch 280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7641 - dice_coef: 0.7641 - val_loss: -0.0450 - val_dice_coef: 0.0450\n",
      "Epoch 281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7727 - dice_coef: 0.7727 - val_loss: -0.0529 - val_dice_coef: 0.0529\n",
      "Epoch 282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7684 - dice_coef: 0.7684 - val_loss: -0.0181 - val_dice_coef: 0.0181\n",
      "Epoch 283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7581 - dice_coef: 0.7581 - val_loss: -0.0128 - val_dice_coef: 0.0128\n",
      "Epoch 284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7690 - dice_coef: 0.7690 - val_loss: -0.1661 - val_dice_coef: 0.1661\n",
      "Epoch 285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7511 - dice_coef: 0.7511 - val_loss: -0.0575 - val_dice_coef: 0.0575\n",
      "Epoch 286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7490 - dice_coef: 0.7490 - val_loss: -0.0060 - val_dice_coef: 0.0060\n",
      "Epoch 287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7464 - dice_coef: 0.7464 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.1159 - val_dice_coef: 0.1159\n",
      "Epoch 289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7589 - dice_coef: 0.7589 - val_loss: -0.0304 - val_dice_coef: 0.0304\n",
      "Epoch 290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7723 - dice_coef: 0.7723 - val_loss: -0.0227 - val_dice_coef: 0.0227\n",
      "Epoch 291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.1234 - val_dice_coef: 0.1234\n",
      "Epoch 292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7605 - dice_coef: 0.7605 - val_loss: -0.0438 - val_dice_coef: 0.0438\n",
      "Epoch 293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7657 - dice_coef: 0.7657 - val_loss: -0.0111 - val_dice_coef: 0.0111\n",
      "Epoch 294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7631 - dice_coef: 0.7631 - val_loss: -0.0315 - val_dice_coef: 0.0315\n",
      "Epoch 295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7672 - dice_coef: 0.7672 - val_loss: -0.1202 - val_dice_coef: 0.1202\n",
      "Epoch 296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7644 - dice_coef: 0.7644 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7772 - dice_coef: 0.7772 - val_loss: -0.0368 - val_dice_coef: 0.0368\n",
      "Epoch 298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7811 - dice_coef: 0.7811 - val_loss: -0.0406 - val_dice_coef: 0.0406\n",
      "Epoch 299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7793 - dice_coef: 0.7793 - val_loss: -0.0366 - val_dice_coef: 0.0366\n",
      "Epoch 300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7765 - dice_coef: 0.7765 - val_loss: -0.0462 - val_dice_coef: 0.0462\n",
      "Epoch 301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7801 - dice_coef: 0.7801 - val_loss: -0.0380 - val_dice_coef: 0.0380\n",
      "Epoch 302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7843 - dice_coef: 0.7843 - val_loss: -0.0308 - val_dice_coef: 0.0308\n",
      "Epoch 303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.0704 - val_dice_coef: 0.0704\n",
      "Epoch 304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7836 - dice_coef: 0.7836 - val_loss: -0.0287 - val_dice_coef: 0.0287\n",
      "Epoch 305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7746 - dice_coef: 0.7746 - val_loss: -0.0166 - val_dice_coef: 0.0166\n",
      "Epoch 306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7803 - dice_coef: 0.7803 - val_loss: -0.0775 - val_dice_coef: 0.0775\n",
      "Epoch 307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7800 - dice_coef: 0.7800 - val_loss: -0.1300 - val_dice_coef: 0.1300\n",
      "Epoch 308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7711 - dice_coef: 0.7711 - val_loss: -0.0263 - val_dice_coef: 0.0263\n",
      "Epoch 309/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.0347 - val_dice_coef: 0.0347\n",
      "Epoch 310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7814 - dice_coef: 0.7814 - val_loss: -0.1873 - val_dice_coef: 0.1873\n",
      "Epoch 311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7737 - dice_coef: 0.7737 - val_loss: -0.0234 - val_dice_coef: 0.0234\n",
      "Epoch 312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7865 - dice_coef: 0.7865 - val_loss: -0.0305 - val_dice_coef: 0.0305\n",
      "Epoch 313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7862 - dice_coef: 0.7862 - val_loss: -0.1655 - val_dice_coef: 0.1655\n",
      "Epoch 314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7647 - dice_coef: 0.7647 - val_loss: -0.0500 - val_dice_coef: 0.0500\n",
      "Epoch 315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7715 - dice_coef: 0.7715 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7758 - dice_coef: 0.7758 - val_loss: -0.0337 - val_dice_coef: 0.0337\n",
      "Epoch 317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7726 - dice_coef: 0.7726 - val_loss: -0.3706 - val_dice_coef: 0.3706\n",
      "Epoch 318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7635 - dice_coef: 0.7635 - val_loss: -0.0253 - val_dice_coef: 0.0253\n",
      "Epoch 319/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7743 - dice_coef: 0.7743 - val_loss: -0.0220 - val_dice_coef: 0.0220\n",
      "Epoch 320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7790 - dice_coef: 0.7790 - val_loss: -0.3092 - val_dice_coef: 0.3092\n",
      "Epoch 321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7765 - dice_coef: 0.7765 - val_loss: -0.0460 - val_dice_coef: 0.0460\n",
      "Epoch 322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.0553 - val_dice_coef: 0.0553\n",
      "Epoch 323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7894 - dice_coef: 0.7894 - val_loss: -0.0739 - val_dice_coef: 0.0739\n",
      "Epoch 324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7897 - dice_coef: 0.7897 - val_loss: -0.0448 - val_dice_coef: 0.0448\n",
      "Epoch 325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7875 - dice_coef: 0.7875 - val_loss: -0.1956 - val_dice_coef: 0.1956\n",
      "Epoch 326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7813 - dice_coef: 0.7813 - val_loss: -0.0695 - val_dice_coef: 0.0695\n",
      "Epoch 327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7855 - dice_coef: 0.7855 - val_loss: -0.0172 - val_dice_coef: 0.0172\n",
      "Epoch 328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7796 - dice_coef: 0.7796 - val_loss: -0.1357 - val_dice_coef: 0.1357\n",
      "Epoch 329/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.0997 - val_dice_coef: 0.0997\n",
      "Epoch 330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7906 - dice_coef: 0.7906 - val_loss: -0.0891 - val_dice_coef: 0.0891\n",
      "Epoch 331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0921 - val_dice_coef: 0.0921\n",
      "Epoch 332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0405 - val_dice_coef: 0.0405\n",
      "Epoch 333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7855 - dice_coef: 0.7855 - val_loss: -0.0510 - val_dice_coef: 0.0510\n",
      "Epoch 334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7910 - dice_coef: 0.7910 - val_loss: -0.1837 - val_dice_coef: 0.1837\n",
      "Epoch 335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7908 - dice_coef: 0.7908 - val_loss: -0.0455 - val_dice_coef: 0.0455\n",
      "Epoch 336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7915 - dice_coef: 0.7915 - val_loss: -0.0512 - val_dice_coef: 0.0512\n",
      "Epoch 337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7943 - dice_coef: 0.7943 - val_loss: -0.0565 - val_dice_coef: 0.0565\n",
      "Epoch 338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7922 - dice_coef: 0.7922 - val_loss: -0.1822 - val_dice_coef: 0.1822\n",
      "Epoch 339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7888 - dice_coef: 0.7888 - val_loss: -0.1480 - val_dice_coef: 0.1480\n",
      "Epoch 340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0323 - val_dice_coef: 0.0323\n",
      "Epoch 341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7877 - dice_coef: 0.7877 - val_loss: -0.0631 - val_dice_coef: 0.0631\n",
      "Epoch 342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7904 - dice_coef: 0.7904 - val_loss: -0.2945 - val_dice_coef: 0.2945\n",
      "Epoch 343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7871 - dice_coef: 0.7871 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7925 - dice_coef: 0.7925 - val_loss: -0.0235 - val_dice_coef: 0.0235\n",
      "Epoch 345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.2343 - val_dice_coef: 0.2343\n",
      "Epoch 346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.3386 - val_dice_coef: 0.3386\n",
      "Epoch 347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7806 - dice_coef: 0.7806 - val_loss: -0.0261 - val_dice_coef: 0.0261\n",
      "Epoch 348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7710 - dice_coef: 0.7710 - val_loss: -0.0138 - val_dice_coef: 0.0138\n",
      "Epoch 349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7821 - dice_coef: 0.7821 - val_loss: -0.1816 - val_dice_coef: 0.1816\n",
      "Epoch 350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7889 - dice_coef: 0.7889 - val_loss: -0.1050 - val_dice_coef: 0.1050\n",
      "Epoch 351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.0298 - val_dice_coef: 0.0298\n",
      "Epoch 352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0611 - val_dice_coef: 0.0611\n",
      "Epoch 353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7945 - dice_coef: 0.7945 - val_loss: -0.2319 - val_dice_coef: 0.2319\n",
      "Epoch 354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7917 - dice_coef: 0.7917 - val_loss: -0.0280 - val_dice_coef: 0.0280\n",
      "Epoch 355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7923 - dice_coef: 0.7923 - val_loss: -0.0318 - val_dice_coef: 0.0318\n",
      "Epoch 356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7939 - dice_coef: 0.7939 - val_loss: -0.3564 - val_dice_coef: 0.3564\n",
      "Epoch 357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7757 - dice_coef: 0.7757 - val_loss: -0.2784 - val_dice_coef: 0.2784\n",
      "Epoch 358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.0262 - val_dice_coef: 0.0262\n",
      "Epoch 359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.0401 - val_dice_coef: 0.0401\n",
      "Epoch 360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7981 - dice_coef: 0.7981 - val_loss: -0.1451 - val_dice_coef: 0.1451\n",
      "Epoch 361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7965 - dice_coef: 0.7965 - val_loss: -0.1857 - val_dice_coef: 0.1857\n",
      "Epoch 362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7975 - dice_coef: 0.7975 - val_loss: -0.1279 - val_dice_coef: 0.1279\n",
      "Epoch 363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7960 - dice_coef: 0.7960 - val_loss: -0.0669 - val_dice_coef: 0.0669\n",
      "Epoch 364/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7950 - dice_coef: 0.7950 - val_loss: -0.0174 - val_dice_coef: 0.0174\n",
      "Epoch 365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7857 - dice_coef: 0.7857 - val_loss: -0.2840 - val_dice_coef: 0.2840\n",
      "Epoch 366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7901 - dice_coef: 0.7901 - val_loss: -0.1057 - val_dice_coef: 0.1057\n",
      "Epoch 367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7978 - dice_coef: 0.7978 - val_loss: -0.0326 - val_dice_coef: 0.0326\n",
      "Epoch 368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8003 - dice_coef: 0.8003 - val_loss: -0.2679 - val_dice_coef: 0.2679\n",
      "Epoch 369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7977 - dice_coef: 0.7977 - val_loss: -0.0832 - val_dice_coef: 0.0832\n",
      "Epoch 370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7953 - dice_coef: 0.7953 - val_loss: -0.0212 - val_dice_coef: 0.0212\n",
      "Epoch 371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7756 - dice_coef: 0.7756 - val_loss: -0.0832 - val_dice_coef: 0.0832\n",
      "Epoch 372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7952 - dice_coef: 0.7952 - val_loss: -0.2984 - val_dice_coef: 0.2984\n",
      "Epoch 373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7982 - dice_coef: 0.7982 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 374/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7899 - dice_coef: 0.7899 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7938 - dice_coef: 0.7938 - val_loss: -0.4212 - val_dice_coef: 0.4212\n",
      "Epoch 376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7856 - dice_coef: 0.7856 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0200 - val_dice_coef: 0.0200\n",
      "Epoch 378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.1871 - val_dice_coef: 0.1871\n",
      "Epoch 379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8004 - dice_coef: 0.8004 - val_loss: -0.0478 - val_dice_coef: 0.0478\n",
      "Epoch 380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7945 - dice_coef: 0.7945 - val_loss: -0.1252 - val_dice_coef: 0.1252\n",
      "Epoch 381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8001 - dice_coef: 0.8001 - val_loss: -0.0781 - val_dice_coef: 0.0781\n",
      "Epoch 382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8039 - dice_coef: 0.8039 - val_loss: -0.0673 - val_dice_coef: 0.0673\n",
      "Epoch 383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8036 - dice_coef: 0.8036 - val_loss: -0.2480 - val_dice_coef: 0.2480\n",
      "Epoch 384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8073 - dice_coef: 0.8073 - val_loss: -0.1304 - val_dice_coef: 0.1304\n",
      "Epoch 385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.0706 - val_dice_coef: 0.0706\n",
      "Epoch 386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8046 - dice_coef: 0.8046 - val_loss: -0.1223 - val_dice_coef: 0.1223\n",
      "Epoch 387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7970 - dice_coef: 0.7970 - val_loss: -0.0542 - val_dice_coef: 0.0542\n",
      "Epoch 388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.0396 - val_dice_coef: 0.0396\n",
      "Epoch 389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.0432 - val_dice_coef: 0.0432\n",
      "Epoch 390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8010 - dice_coef: 0.8010 - val_loss: -0.0633 - val_dice_coef: 0.0633\n",
      "Epoch 391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7970 - dice_coef: 0.7970 - val_loss: -0.2965 - val_dice_coef: 0.2965\n",
      "Epoch 392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8006 - dice_coef: 0.8006 - val_loss: -0.0632 - val_dice_coef: 0.0632\n",
      "Epoch 393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.0993 - val_dice_coef: 0.0993\n",
      "Epoch 394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8019 - dice_coef: 0.8019 - val_loss: -0.1495 - val_dice_coef: 0.1495\n",
      "Epoch 395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8043 - dice_coef: 0.8043 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.1207 - val_dice_coef: 0.1207\n",
      "Epoch 397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8080 - dice_coef: 0.8080 - val_loss: -0.2400 - val_dice_coef: 0.2400\n",
      "Epoch 398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.0589 - val_dice_coef: 0.0589\n",
      "Epoch 399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7983 - dice_coef: 0.7983 - val_loss: -0.0306 - val_dice_coef: 0.0306\n",
      "Epoch 400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7974 - dice_coef: 0.7974 - val_loss: -0.2292 - val_dice_coef: 0.2292\n",
      "Epoch 401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7948 - dice_coef: 0.7948 - val_loss: -0.1820 - val_dice_coef: 0.1820\n",
      "Epoch 402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.0473 - val_dice_coef: 0.0473\n",
      "Epoch 403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7961 - dice_coef: 0.7961 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8052 - dice_coef: 0.8052 - val_loss: -0.1058 - val_dice_coef: 0.1058\n",
      "Epoch 405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.1093 - val_dice_coef: 0.1093\n",
      "Epoch 407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8056 - dice_coef: 0.8056 - val_loss: -0.1696 - val_dice_coef: 0.1696\n",
      "Epoch 408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7967 - dice_coef: 0.7967 - val_loss: -0.2107 - val_dice_coef: 0.2107\n",
      "Epoch 409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.2258 - val_dice_coef: 0.2258\n",
      "Epoch 410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.0673 - val_dice_coef: 0.0673\n",
      "Epoch 411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8081 - dice_coef: 0.8081 - val_loss: -0.0421 - val_dice_coef: 0.0421\n",
      "Epoch 412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7927 - dice_coef: 0.7927 - val_loss: -0.0356 - val_dice_coef: 0.0356\n",
      "Epoch 413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7405 - dice_coef: 0.7405 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7844 - dice_coef: 0.7844 - val_loss: -0.6107 - val_dice_coef: 0.6107\n",
      "Epoch 415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7791 - dice_coef: 0.7791 - val_loss: -0.0159 - val_dice_coef: 0.0159\n",
      "Epoch 416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0370 - val_dice_coef: 0.0370\n",
      "Epoch 417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8034 - dice_coef: 0.8034 - val_loss: -0.2351 - val_dice_coef: 0.2351\n",
      "Epoch 418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8086 - dice_coef: 0.8086 - val_loss: -0.1190 - val_dice_coef: 0.1190\n",
      "Epoch 419/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.0477 - val_dice_coef: 0.0477\n",
      "Epoch 420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8046 - dice_coef: 0.8046 - val_loss: -0.2101 - val_dice_coef: 0.2101\n",
      "Epoch 421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8109 - dice_coef: 0.8109 - val_loss: -0.2076 - val_dice_coef: 0.2076\n",
      "Epoch 422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8069 - dice_coef: 0.8069 - val_loss: -0.0993 - val_dice_coef: 0.0993\n",
      "Epoch 423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.0434 - val_dice_coef: 0.0434\n",
      "Epoch 424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8075 - dice_coef: 0.8075 - val_loss: -0.1762 - val_dice_coef: 0.1762\n",
      "Epoch 425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8059 - dice_coef: 0.8059 - val_loss: -0.1748 - val_dice_coef: 0.1748\n",
      "Epoch 426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.0394 - val_dice_coef: 0.0394\n",
      "Epoch 427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8040 - dice_coef: 0.8040 - val_loss: -0.1564 - val_dice_coef: 0.1564\n",
      "Epoch 428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8008 - dice_coef: 0.8008 - val_loss: -0.4271 - val_dice_coef: 0.4271\n",
      "Epoch 429/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7984 - dice_coef: 0.7984 - val_loss: -0.1725 - val_dice_coef: 0.1725\n",
      "Epoch 430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8074 - dice_coef: 0.8074 - val_loss: -0.0370 - val_dice_coef: 0.0370\n",
      "Epoch 431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8131 - dice_coef: 0.8131 - val_loss: -0.1404 - val_dice_coef: 0.1404\n",
      "Epoch 433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8154 - dice_coef: 0.8154 - val_loss: -0.0652 - val_dice_coef: 0.0652\n",
      "Epoch 434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8114 - dice_coef: 0.8114 - val_loss: -0.2139 - val_dice_coef: 0.2139\n",
      "Epoch 435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8117 - dice_coef: 0.8117 - val_loss: -0.1163 - val_dice_coef: 0.1163\n",
      "Epoch 436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8121 - dice_coef: 0.8121 - val_loss: -0.0403 - val_dice_coef: 0.0403\n",
      "Epoch 437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8067 - dice_coef: 0.8067 - val_loss: -0.1288 - val_dice_coef: 0.1288\n",
      "Epoch 438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8150 - dice_coef: 0.8150 - val_loss: -0.1334 - val_dice_coef: 0.1334\n",
      "Epoch 439/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8177 - dice_coef: 0.8177 - val_loss: -0.1014 - val_dice_coef: 0.1014\n",
      "Epoch 440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8152 - dice_coef: 0.8152 - val_loss: -0.2299 - val_dice_coef: 0.2299\n",
      "Epoch 441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.1904 - val_dice_coef: 0.1904\n",
      "Epoch 442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8164 - dice_coef: 0.8164 - val_loss: -0.0625 - val_dice_coef: 0.0625\n",
      "Epoch 443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.1399 - val_dice_coef: 0.1399\n",
      "Epoch 444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8148 - dice_coef: 0.8148 - val_loss: -0.1434 - val_dice_coef: 0.1434\n",
      "Epoch 445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.3043 - val_dice_coef: 0.3043\n",
      "Epoch 446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8101 - dice_coef: 0.8101 - val_loss: -0.0396 - val_dice_coef: 0.0396\n",
      "Epoch 447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8028 - dice_coef: 0.8028 - val_loss: -0.0283 - val_dice_coef: 0.0283\n",
      "Epoch 448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8115 - dice_coef: 0.8115 - val_loss: -0.0963 - val_dice_coef: 0.0963\n",
      "Epoch 449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8078 - dice_coef: 0.8078 - val_loss: -0.4016 - val_dice_coef: 0.4016\n",
      "Epoch 450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.0483 - val_dice_coef: 0.0483\n",
      "Epoch 451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.0221 - val_dice_coef: 0.0221\n",
      "Epoch 452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.1492 - val_dice_coef: 0.1492\n",
      "Epoch 453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8146 - dice_coef: 0.8146 - val_loss: -0.5575 - val_dice_coef: 0.5575\n",
      "Epoch 454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8078 - dice_coef: 0.8078 - val_loss: -0.1795 - val_dice_coef: 0.1795\n",
      "Epoch 455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7962 - dice_coef: 0.7962 - val_loss: -0.0179 - val_dice_coef: 0.0179\n",
      "Epoch 456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.0442 - val_dice_coef: 0.0442\n",
      "Epoch 457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8024 - dice_coef: 0.8024 - val_loss: -0.6116 - val_dice_coef: 0.6116\n",
      "Epoch 458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8017 - dice_coef: 0.8017 - val_loss: -0.3085 - val_dice_coef: 0.3085\n",
      "Epoch 459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8160 - dice_coef: 0.8160 - val_loss: -0.0279 - val_dice_coef: 0.0279\n",
      "Epoch 460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8097 - dice_coef: 0.8097 - val_loss: -0.0992 - val_dice_coef: 0.0992\n",
      "Epoch 461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8141 - dice_coef: 0.8141 - val_loss: -0.5515 - val_dice_coef: 0.5515\n",
      "Epoch 462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8051 - dice_coef: 0.8051 - val_loss: -0.3915 - val_dice_coef: 0.3915\n",
      "Epoch 463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8133 - dice_coef: 0.8133 - val_loss: -0.0291 - val_dice_coef: 0.0291\n",
      "Epoch 464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.1182 - val_dice_coef: 0.1182\n",
      "Epoch 465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8176 - dice_coef: 0.8176 - val_loss: -0.2284 - val_dice_coef: 0.2284\n",
      "Epoch 466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8167 - dice_coef: 0.8167 - val_loss: -0.0484 - val_dice_coef: 0.0484\n",
      "Epoch 467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8147 - dice_coef: 0.8147 - val_loss: -0.1196 - val_dice_coef: 0.1196\n",
      "Epoch 468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.5032 - val_dice_coef: 0.5032\n",
      "Epoch 469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8130 - dice_coef: 0.8130 - val_loss: -0.0393 - val_dice_coef: 0.0393\n",
      "Epoch 470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.0320 - val_dice_coef: 0.0320\n",
      "Epoch 471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8117 - dice_coef: 0.8117 - val_loss: -0.5914 - val_dice_coef: 0.5914\n",
      "Epoch 472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.6983 - val_dice_coef: 0.6983\n",
      "Epoch 473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7959 - dice_coef: 0.7959 - val_loss: -0.0990 - val_dice_coef: 0.0990\n",
      "Epoch 474/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8124 - dice_coef: 0.8124 - val_loss: -0.0336 - val_dice_coef: 0.0336\n",
      "Epoch 475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8132 - dice_coef: 0.8132 - val_loss: -0.4476 - val_dice_coef: 0.4476\n",
      "Epoch 476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.1058 - val_dice_coef: 0.1058\n",
      "Epoch 477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.1145 - val_dice_coef: 0.1145\n",
      "Epoch 478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.2891 - val_dice_coef: 0.2891\n",
      "Epoch 479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8193 - dice_coef: 0.8193 - val_loss: -0.1217 - val_dice_coef: 0.1217\n",
      "Epoch 480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8199 - dice_coef: 0.8199 - val_loss: -0.2064 - val_dice_coef: 0.2064\n",
      "Epoch 481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8178 - dice_coef: 0.8178 - val_loss: -0.2016 - val_dice_coef: 0.2016\n",
      "Epoch 482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8206 - dice_coef: 0.8206 - val_loss: -0.2538 - val_dice_coef: 0.2538\n",
      "Epoch 483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8219 - dice_coef: 0.8219 - val_loss: -0.2956 - val_dice_coef: 0.2956\n",
      "Epoch 484/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8207 - dice_coef: 0.8207 - val_loss: -0.1771 - val_dice_coef: 0.1771\n",
      "Epoch 485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.2624 - val_dice_coef: 0.2624\n",
      "Epoch 486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8105 - dice_coef: 0.8105 - val_loss: -0.4911 - val_dice_coef: 0.4911\n",
      "Epoch 487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8167 - dice_coef: 0.8167 - val_loss: -0.0686 - val_dice_coef: 0.0686\n",
      "Epoch 488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8197 - dice_coef: 0.8197 - val_loss: -0.0760 - val_dice_coef: 0.0760\n",
      "Epoch 489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8223 - dice_coef: 0.8223 - val_loss: -0.0500 - val_dice_coef: 0.0500\n",
      "Epoch 490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.0601 - val_dice_coef: 0.0601\n",
      "Epoch 491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8160 - dice_coef: 0.8160 - val_loss: -0.4535 - val_dice_coef: 0.4535\n",
      "Epoch 492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.2184 - val_dice_coef: 0.2184\n",
      "Epoch 493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0320 - val_dice_coef: 0.0320\n",
      "Epoch 494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7959 - dice_coef: 0.7959 - val_loss: -0.0186 - val_dice_coef: 0.0186\n",
      "Epoch 495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8054 - dice_coef: 0.8054 - val_loss: -0.3697 - val_dice_coef: 0.3697\n",
      "Epoch 496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7997 - dice_coef: 0.7997 - val_loss: -0.7929 - val_dice_coef: 0.7929\n",
      "Epoch 497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.0672 - val_dice_coef: 0.0672\n",
      "Epoch 498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.0293 - val_dice_coef: 0.0293\n",
      "Epoch 499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.9266 - val_dice_coef: 0.9266\n",
      "Epoch 500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7841 - dice_coef: 0.7841 - val_loss: -0.1199 - val_dice_coef: 0.1199\n",
      "Epoch 501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8165 - dice_coef: 0.8165 - val_loss: -0.0417 - val_dice_coef: 0.0417\n",
      "Epoch 502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.4505 - val_dice_coef: 0.4505\n",
      "Epoch 503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8198 - dice_coef: 0.8198 - val_loss: -0.2722 - val_dice_coef: 0.2722\n",
      "Epoch 504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8236 - dice_coef: 0.8236 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8252 - dice_coef: 0.8252 - val_loss: -0.2344 - val_dice_coef: 0.2344\n",
      "Epoch 506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8219 - dice_coef: 0.8219 - val_loss: -0.3935 - val_dice_coef: 0.3935\n",
      "Epoch 507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8250 - dice_coef: 0.8250 - val_loss: -0.0641 - val_dice_coef: 0.0641\n",
      "Epoch 508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.4545 - val_dice_coef: 0.4545\n",
      "Epoch 509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8205 - dice_coef: 0.8205 - val_loss: -0.3286 - val_dice_coef: 0.3286\n",
      "Epoch 510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8140 - dice_coef: 0.8140 - val_loss: -0.1836 - val_dice_coef: 0.1836\n",
      "Epoch 511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8239 - dice_coef: 0.8239 - val_loss: -0.2571 - val_dice_coef: 0.2571\n",
      "Epoch 512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8244 - dice_coef: 0.8244 - val_loss: -0.1180 - val_dice_coef: 0.1180\n",
      "Epoch 513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.2087 - val_dice_coef: 0.2087\n",
      "Epoch 514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8267 - dice_coef: 0.8267 - val_loss: -0.1494 - val_dice_coef: 0.1494\n",
      "Epoch 515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8282 - dice_coef: 0.8282 - val_loss: -0.1149 - val_dice_coef: 0.1149\n",
      "Epoch 516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8282 - dice_coef: 0.8282 - val_loss: -0.4932 - val_dice_coef: 0.4932\n",
      "Epoch 517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8136 - dice_coef: 0.8136 - val_loss: -0.5778 - val_dice_coef: 0.5778\n",
      "Epoch 518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8171 - dice_coef: 0.8171 - val_loss: -0.1004 - val_dice_coef: 0.1004\n",
      "Epoch 519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8237 - dice_coef: 0.8237 - val_loss: -0.1345 - val_dice_coef: 0.1345\n",
      "Epoch 520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.1655 - val_dice_coef: 0.1655\n",
      "Epoch 521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8269 - dice_coef: 0.8269 - val_loss: -0.7545 - val_dice_coef: 0.7545\n",
      "Epoch 522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8210 - dice_coef: 0.8210 - val_loss: -0.3689 - val_dice_coef: 0.3689\n",
      "Epoch 523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.2003 - val_dice_coef: 0.2003\n",
      "Epoch 524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.0712 - val_dice_coef: 0.0712\n",
      "Epoch 525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8176 - dice_coef: 0.8176 - val_loss: -0.0582 - val_dice_coef: 0.0582\n",
      "Epoch 526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8188 - dice_coef: 0.8188 - val_loss: -0.0770 - val_dice_coef: 0.0770\n",
      "Epoch 527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8180 - dice_coef: 0.8180 - val_loss: -0.2046 - val_dice_coef: 0.2046\n",
      "Epoch 528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8192 - dice_coef: 0.8192 - val_loss: -0.9066 - val_dice_coef: 0.9066\n",
      "Epoch 529/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7969 - dice_coef: 0.7969 - val_loss: -0.0630 - val_dice_coef: 0.0630\n",
      "Epoch 530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.0144 - val_dice_coef: 0.0144\n",
      "Epoch 531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.6773 - val_dice_coef: 0.6773\n",
      "Epoch 532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.4786 - val_dice_coef: 0.4786\n",
      "Epoch 533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8136 - dice_coef: 0.8136 - val_loss: -0.0916 - val_dice_coef: 0.0916\n",
      "Epoch 534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8265 - dice_coef: 0.8265 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.2900 - val_dice_coef: 0.2900\n",
      "Epoch 536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8082 - dice_coef: 0.8082 - val_loss: -0.0148 - val_dice_coef: 0.0148\n",
      "Epoch 537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.0460 - val_dice_coef: 0.0460\n",
      "Epoch 538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8138 - dice_coef: 0.8138 - val_loss: -0.7499 - val_dice_coef: 0.7499\n",
      "Epoch 539/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8153 - dice_coef: 0.8153 - val_loss: -0.0671 - val_dice_coef: 0.0671\n",
      "Epoch 540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8169 - dice_coef: 0.8169 - val_loss: -0.0314 - val_dice_coef: 0.0314\n",
      "Epoch 541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8112 - dice_coef: 0.8112 - val_loss: -0.7243 - val_dice_coef: 0.7243\n",
      "Epoch 542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8226 - dice_coef: 0.8226 - val_loss: -0.0891 - val_dice_coef: 0.0891\n",
      "Epoch 543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8200 - dice_coef: 0.8200 - val_loss: -0.0178 - val_dice_coef: 0.0178\n",
      "Epoch 544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.6045 - val_dice_coef: 0.6045\n",
      "Epoch 545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8159 - dice_coef: 0.8159 - val_loss: -0.5087 - val_dice_coef: 0.5087\n",
      "Epoch 546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8215 - dice_coef: 0.8215 - val_loss: -0.1051 - val_dice_coef: 0.1051\n",
      "Epoch 547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8251 - dice_coef: 0.8251 - val_loss: -0.3124 - val_dice_coef: 0.3124\n",
      "Epoch 548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8321 - dice_coef: 0.8321 - val_loss: -0.2700 - val_dice_coef: 0.2700\n",
      "Epoch 549/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8308 - dice_coef: 0.8308 - val_loss: -0.3569 - val_dice_coef: 0.3569\n",
      "Epoch 550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8291 - dice_coef: 0.8291 - val_loss: -0.2589 - val_dice_coef: 0.2589\n",
      "Epoch 551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8312 - dice_coef: 0.8312 - val_loss: -0.4501 - val_dice_coef: 0.4501\n",
      "Epoch 552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8288 - dice_coef: 0.8288 - val_loss: -0.2028 - val_dice_coef: 0.2028\n",
      "Epoch 553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8296 - dice_coef: 0.8296 - val_loss: -0.0799 - val_dice_coef: 0.0799\n",
      "Epoch 554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8302 - dice_coef: 0.8302 - val_loss: -0.5327 - val_dice_coef: 0.5327\n",
      "Epoch 555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8187 - dice_coef: 0.8187 - val_loss: -0.6675 - val_dice_coef: 0.6675\n",
      "Epoch 556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.1430 - val_dice_coef: 0.1430\n",
      "Epoch 557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.2106 - val_dice_coef: 0.2106\n",
      "Epoch 558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.2974 - val_dice_coef: 0.2974\n",
      "Epoch 559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8298 - dice_coef: 0.8298 - val_loss: -0.4039 - val_dice_coef: 0.4039\n",
      "Epoch 560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8331 - dice_coef: 0.8331 - val_loss: -0.6531 - val_dice_coef: 0.6531\n",
      "Epoch 561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.2544 - val_dice_coef: 0.2544\n",
      "Epoch 562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.0751 - val_dice_coef: 0.0751\n",
      "Epoch 563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.2586 - val_dice_coef: 0.2586\n",
      "Epoch 564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.5444 - val_dice_coef: 0.5444\n",
      "Epoch 565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.1186 - val_dice_coef: 0.1186\n",
      "Epoch 566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8259 - dice_coef: 0.8259 - val_loss: -0.1178 - val_dice_coef: 0.1178\n",
      "Epoch 567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.9145 - val_dice_coef: 0.9145\n",
      "Epoch 568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7752 - dice_coef: 0.7752 - val_loss: -0.6345 - val_dice_coef: 0.6345\n",
      "Epoch 569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7562 - dice_coef: 0.7562 - val_loss: -0.0040 - val_dice_coef: 0.0040\n",
      "Epoch 570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6895 - dice_coef: 0.6895 - val_loss: -0.1639 - val_dice_coef: 0.1639\n",
      "Epoch 571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7304 - dice_coef: 0.7304 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7258 - dice_coef: 0.7258 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7116 - dice_coef: 0.7116 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7699 - dice_coef: 0.7699 - val_loss: -0.0039 - val_dice_coef: 0.0039\n",
      "Epoch 575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7622 - dice_coef: 0.7622 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7658 - dice_coef: 0.7658 - val_loss: -0.0136 - val_dice_coef: 0.0136\n",
      "Epoch 577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7974 - dice_coef: 0.7974 - val_loss: -0.9098 - val_dice_coef: 0.9098\n",
      "Epoch 578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8113 - dice_coef: 0.8113 - val_loss: -0.0898 - val_dice_coef: 0.0898\n",
      "Epoch 579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.2365 - val_dice_coef: 0.2365\n",
      "Epoch 580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8177 - dice_coef: 0.8177 - val_loss: -0.6985 - val_dice_coef: 0.6985\n",
      "Epoch 581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8187 - dice_coef: 0.8187 - val_loss: -0.0752 - val_dice_coef: 0.0752\n",
      "Epoch 582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8180 - dice_coef: 0.8180 - val_loss: -0.7295 - val_dice_coef: 0.7295\n",
      "Epoch 583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.3519 - val_dice_coef: 0.3519\n",
      "Epoch 584/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.1809 - val_dice_coef: 0.1809\n",
      "Epoch 585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8238 - dice_coef: 0.8238 - val_loss: -0.6086 - val_dice_coef: 0.6086\n",
      "Epoch 586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8228 - dice_coef: 0.8228 - val_loss: -0.0682 - val_dice_coef: 0.0682\n",
      "Epoch 587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.3823 - val_dice_coef: 0.3823\n",
      "Epoch 588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8308 - dice_coef: 0.8308 - val_loss: -0.4799 - val_dice_coef: 0.4799\n",
      "Epoch 589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.1169 - val_dice_coef: 0.1169\n",
      "Epoch 590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8199 - dice_coef: 0.8199 - val_loss: -0.3753 - val_dice_coef: 0.3753\n",
      "Epoch 591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.4125 - val_dice_coef: 0.4125\n",
      "Epoch 592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8271 - dice_coef: 0.8271 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.6504 - val_dice_coef: 0.6504\n",
      "Epoch 594/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.3559 - val_dice_coef: 0.3559\n",
      "Epoch 595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8261 - dice_coef: 0.8261 - val_loss: -0.1354 - val_dice_coef: 0.1354\n",
      "Epoch 596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8276 - dice_coef: 0.8276 - val_loss: -0.6209 - val_dice_coef: 0.6209\n",
      "Epoch 597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8263 - dice_coef: 0.8263 - val_loss: -0.6462 - val_dice_coef: 0.6462\n",
      "Epoch 598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.2361 - val_dice_coef: 0.2361\n",
      "Epoch 599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.4628 - val_dice_coef: 0.4628\n",
      "Epoch 600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8351 - dice_coef: 0.8351 - val_loss: -0.3246 - val_dice_coef: 0.3246\n",
      "Epoch 601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.2202 - val_dice_coef: 0.2202\n",
      "Epoch 602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8328 - dice_coef: 0.8328 - val_loss: -0.2158 - val_dice_coef: 0.2158\n",
      "Epoch 603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.3146 - val_dice_coef: 0.3146\n",
      "Epoch 604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.6112 - val_dice_coef: 0.6112\n",
      "Epoch 605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8333 - dice_coef: 0.8333 - val_loss: -0.2770 - val_dice_coef: 0.2770\n",
      "Epoch 606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8330 - dice_coef: 0.8330 - val_loss: -0.1664 - val_dice_coef: 0.1664\n",
      "Epoch 607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.4966 - val_dice_coef: 0.4966\n",
      "Epoch 608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.2649 - val_dice_coef: 0.2649\n",
      "Epoch 609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8364 - dice_coef: 0.8364 - val_loss: -0.5426 - val_dice_coef: 0.5426\n",
      "Epoch 610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.2237 - val_dice_coef: 0.2237\n",
      "Epoch 611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8365 - dice_coef: 0.8365 - val_loss: -0.3087 - val_dice_coef: 0.3087\n",
      "Epoch 612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8360 - dice_coef: 0.8360 - val_loss: -0.6877 - val_dice_coef: 0.6877\n",
      "Epoch 613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8360 - dice_coef: 0.8360 - val_loss: -0.2832 - val_dice_coef: 0.2832\n",
      "Epoch 614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8373 - dice_coef: 0.8373 - val_loss: -0.2565 - val_dice_coef: 0.2565\n",
      "Epoch 615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8374 - dice_coef: 0.8374 - val_loss: -0.4029 - val_dice_coef: 0.4029\n",
      "Epoch 616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8396 - dice_coef: 0.8396 - val_loss: -0.4864 - val_dice_coef: 0.4864\n",
      "Epoch 617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8393 - dice_coef: 0.8393 - val_loss: -0.3034 - val_dice_coef: 0.3034\n",
      "Epoch 618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.2535 - val_dice_coef: 0.2535\n",
      "Epoch 619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.2476 - val_dice_coef: 0.2476\n",
      "Epoch 620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.6186 - val_dice_coef: 0.6186\n",
      "Epoch 621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.4832 - val_dice_coef: 0.4832\n",
      "Epoch 622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8194 - dice_coef: 0.8194 - val_loss: -0.0482 - val_dice_coef: 0.0482\n",
      "Epoch 623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8163 - dice_coef: 0.8163 - val_loss: -0.0297 - val_dice_coef: 0.0297\n",
      "Epoch 624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8084 - dice_coef: 0.8084 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7976 - dice_coef: 0.7976 - val_loss: -0.0325 - val_dice_coef: 0.0325\n",
      "Epoch 626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8020 - dice_coef: 0.8020 - val_loss: -0.0371 - val_dice_coef: 0.0371\n",
      "Epoch 627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8027 - dice_coef: 0.8027 - val_loss: -0.9913 - val_dice_coef: 0.9913\n",
      "Epoch 628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8093 - dice_coef: 0.8093 - val_loss: -0.0275 - val_dice_coef: 0.0275\n",
      "Epoch 629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8198 - dice_coef: 0.8198 - val_loss: -0.6022 - val_dice_coef: 0.6022\n",
      "Epoch 630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8278 - dice_coef: 0.8278 - val_loss: -0.3513 - val_dice_coef: 0.3513\n",
      "Epoch 631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.2364 - val_dice_coef: 0.2364\n",
      "Epoch 632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.5728 - val_dice_coef: 0.5728\n",
      "Epoch 633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.6481 - val_dice_coef: 0.6481\n",
      "Epoch 634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.2212 - val_dice_coef: 0.2212\n",
      "Epoch 635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8379 - dice_coef: 0.8379 - val_loss: -0.5144 - val_dice_coef: 0.5144\n",
      "Epoch 636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.3816 - val_dice_coef: 0.3816\n",
      "Epoch 637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.3823 - val_dice_coef: 0.3823\n",
      "Epoch 638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8392 - dice_coef: 0.8392 - val_loss: -0.3142 - val_dice_coef: 0.3142\n",
      "Epoch 639/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.3412 - val_dice_coef: 0.3412\n",
      "Epoch 640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8413 - dice_coef: 0.8413 - val_loss: -0.7510 - val_dice_coef: 0.7510\n",
      "Epoch 641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8342 - dice_coef: 0.8342 - val_loss: -0.5192 - val_dice_coef: 0.5192\n",
      "Epoch 642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8389 - dice_coef: 0.8389 - val_loss: -0.0560 - val_dice_coef: 0.0560\n",
      "Epoch 643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8275 - dice_coef: 0.8275 - val_loss: -0.6707 - val_dice_coef: 0.6707\n",
      "Epoch 644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8334 - dice_coef: 0.8334 - val_loss: -0.7639 - val_dice_coef: 0.7639\n",
      "Epoch 645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8363 - dice_coef: 0.8363 - val_loss: -0.4404 - val_dice_coef: 0.4404\n",
      "Epoch 646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.2856 - val_dice_coef: 0.2856\n",
      "Epoch 647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.5237 - val_dice_coef: 0.5237\n",
      "Epoch 648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8352 - dice_coef: 0.8352 - val_loss: -0.7274 - val_dice_coef: 0.7274\n",
      "Epoch 649/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.1787 - val_dice_coef: 0.1787\n",
      "Epoch 650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8377 - dice_coef: 0.8377 - val_loss: -0.3011 - val_dice_coef: 0.3011\n",
      "Epoch 651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.6969 - val_dice_coef: 0.6969\n",
      "Epoch 652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8369 - dice_coef: 0.8369 - val_loss: -0.1611 - val_dice_coef: 0.1611\n",
      "Epoch 653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8373 - dice_coef: 0.8373 - val_loss: -0.4017 - val_dice_coef: 0.4017\n",
      "Epoch 654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.7956 - val_dice_coef: 0.7956\n",
      "Epoch 655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.2720 - val_dice_coef: 0.2720\n",
      "Epoch 656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8399 - dice_coef: 0.8399 - val_loss: -0.3397 - val_dice_coef: 0.3397\n",
      "Epoch 657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.8481 - val_dice_coef: 0.8481\n",
      "Epoch 658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.5583 - val_dice_coef: 0.5583\n",
      "Epoch 659/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.0544 - val_dice_coef: 0.0544\n",
      "Epoch 660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8261 - dice_coef: 0.8261 - val_loss: -0.6444 - val_dice_coef: 0.6444\n",
      "Epoch 661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8272 - dice_coef: 0.8272 - val_loss: -0.7144 - val_dice_coef: 0.7144\n",
      "Epoch 662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8157 - dice_coef: 0.8157 - val_loss: -0.0158 - val_dice_coef: 0.0158\n",
      "Epoch 663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7752 - dice_coef: 0.7752 - val_loss: -0.2079 - val_dice_coef: 0.2079\n",
      "Epoch 664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.6270 - val_dice_coef: 0.6270\n",
      "Epoch 665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8258 - dice_coef: 0.8258 - val_loss: -0.1171 - val_dice_coef: 0.1171\n",
      "Epoch 666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.8650 - val_dice_coef: 0.8650\n",
      "Epoch 667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8395 - dice_coef: 0.8395 - val_loss: -0.6320 - val_dice_coef: 0.6320\n",
      "Epoch 668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8424 - dice_coef: 0.8424 - val_loss: -0.5525 - val_dice_coef: 0.5525\n",
      "Epoch 669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8391 - dice_coef: 0.8391 - val_loss: -0.8774 - val_dice_coef: 0.8774\n",
      "Epoch 670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.5239 - val_dice_coef: 0.5239\n",
      "Epoch 671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.1818 - val_dice_coef: 0.1818\n",
      "Epoch 672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8286 - dice_coef: 0.8286 - val_loss: -0.2185 - val_dice_coef: 0.2185\n",
      "Epoch 673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8309 - dice_coef: 0.8309 - val_loss: -0.9362 - val_dice_coef: 0.9362\n",
      "Epoch 674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.2254 - val_dice_coef: 0.2254\n",
      "Epoch 675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8384 - dice_coef: 0.8384 - val_loss: -0.3132 - val_dice_coef: 0.3132\n",
      "Epoch 676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8433 - dice_coef: 0.8433 - val_loss: -0.8573 - val_dice_coef: 0.8573\n",
      "Epoch 677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.2573 - val_dice_coef: 0.2573\n",
      "Epoch 678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.4857 - val_dice_coef: 0.4857\n",
      "Epoch 679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8445 - dice_coef: 0.8445 - val_loss: -0.7931 - val_dice_coef: 0.7931\n",
      "Epoch 680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8336 - dice_coef: 0.8336 - val_loss: -0.1880 - val_dice_coef: 0.1880\n",
      "Epoch 681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8396 - dice_coef: 0.8396 - val_loss: -0.2356 - val_dice_coef: 0.2356\n",
      "Epoch 682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8431 - dice_coef: 0.8431 - val_loss: -0.7485 - val_dice_coef: 0.7485\n",
      "Epoch 683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8439 - dice_coef: 0.8439 - val_loss: -0.2251 - val_dice_coef: 0.2251\n",
      "Epoch 684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8401 - dice_coef: 0.8401 - val_loss: -0.4985 - val_dice_coef: 0.4985\n",
      "Epoch 685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.7831 - val_dice_coef: 0.7831\n",
      "Epoch 686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.0811 - val_dice_coef: 0.0811\n",
      "Epoch 687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8300 - dice_coef: 0.8300 - val_loss: -0.3282 - val_dice_coef: 0.3282\n",
      "Epoch 688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8425 - dice_coef: 0.8425 - val_loss: -0.8692 - val_dice_coef: 0.8692\n",
      "Epoch 689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8402 - dice_coef: 0.8402 - val_loss: -0.5329 - val_dice_coef: 0.5329\n",
      "Epoch 690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.3908 - val_dice_coef: 0.3908\n",
      "Epoch 691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8451 - dice_coef: 0.8451 - val_loss: -0.7364 - val_dice_coef: 0.7364\n",
      "Epoch 692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.6834 - val_dice_coef: 0.6834\n",
      "Epoch 693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.2906 - val_dice_coef: 0.2906\n",
      "Epoch 694/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8452 - dice_coef: 0.8452 - val_loss: -0.3159 - val_dice_coef: 0.3159\n",
      "Epoch 695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.5617 - val_dice_coef: 0.5617\n",
      "Epoch 696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.6209 - val_dice_coef: 0.6209\n",
      "Epoch 697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.3204 - val_dice_coef: 0.3204\n",
      "Epoch 698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8416 - dice_coef: 0.8416 - val_loss: -0.3793 - val_dice_coef: 0.3793\n",
      "Epoch 699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8408 - dice_coef: 0.8408 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "Epoch 700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.3962 - val_dice_coef: 0.3962\n",
      "Epoch 701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.6602 - val_dice_coef: 0.6602\n",
      "Epoch 702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8473 - dice_coef: 0.8473 - val_loss: -0.6013 - val_dice_coef: 0.6013\n",
      "Epoch 703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.6774 - val_dice_coef: 0.6774\n",
      "Epoch 704/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8363 - dice_coef: 0.8363 - val_loss: -0.5603 - val_dice_coef: 0.5603\n",
      "Epoch 705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8423 - dice_coef: 0.8423 - val_loss: -0.0642 - val_dice_coef: 0.0642\n",
      "Epoch 706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8324 - dice_coef: 0.8324 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.6630 - val_dice_coef: 0.6630\n",
      "Epoch 708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.2338 - val_dice_coef: 0.2338\n",
      "Epoch 709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.5562 - val_dice_coef: 0.5562\n",
      "Epoch 710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8441 - dice_coef: 0.8441 - val_loss: -0.6202 - val_dice_coef: 0.6202\n",
      "Epoch 711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.6704 - val_dice_coef: 0.6704\n",
      "Epoch 712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.6614 - val_dice_coef: 0.6614\n",
      "Epoch 713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.6289 - val_dice_coef: 0.6289\n",
      "Epoch 714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8457 - dice_coef: 0.8457 - val_loss: -0.1529 - val_dice_coef: 0.1529\n",
      "Epoch 715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8384 - dice_coef: 0.8384 - val_loss: -0.1108 - val_dice_coef: 0.1108\n",
      "Epoch 716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.9756 - val_dice_coef: 0.9756\n",
      "Epoch 717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8264 - dice_coef: 0.8264 - val_loss: -0.5430 - val_dice_coef: 0.5430\n",
      "Epoch 718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.1765 - val_dice_coef: 0.1765\n",
      "Epoch 719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.4790 - val_dice_coef: 0.4790\n",
      "Epoch 721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8463 - dice_coef: 0.8463 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8418 - dice_coef: 0.8418 - val_loss: -0.9695 - val_dice_coef: 0.9695\n",
      "Epoch 723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8085 - dice_coef: 0.8085 - val_loss: -0.4149 - val_dice_coef: 0.4149\n",
      "Epoch 724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0183 - val_dice_coef: 0.0183\n",
      "Epoch 725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8203 - dice_coef: 0.8203 - val_loss: -0.9363 - val_dice_coef: 0.9363\n",
      "Epoch 726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.1106 - val_dice_coef: 0.1106\n",
      "Epoch 727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.0991 - val_dice_coef: 0.0991\n",
      "Epoch 728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.9815 - val_dice_coef: 0.9815\n",
      "Epoch 729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.4321 - val_dice_coef: 0.4321\n",
      "Epoch 730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8383 - dice_coef: 0.8383 - val_loss: -0.1485 - val_dice_coef: 0.1485\n",
      "Epoch 731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8358 - dice_coef: 0.8358 - val_loss: -0.9855 - val_dice_coef: 0.9855\n",
      "Epoch 732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.1318 - val_dice_coef: 0.1318\n",
      "Epoch 733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8332 - dice_coef: 0.8332 - val_loss: -0.3812 - val_dice_coef: 0.3812\n",
      "Epoch 734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8412 - dice_coef: 0.8412 - val_loss: -0.8816 - val_dice_coef: 0.8816\n",
      "Epoch 735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8430 - dice_coef: 0.8430 - val_loss: -0.3899 - val_dice_coef: 0.3899\n",
      "Epoch 736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.3458 - val_dice_coef: 0.3458\n",
      "Epoch 737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.9369 - val_dice_coef: 0.9369\n",
      "Epoch 738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8434 - dice_coef: 0.8434 - val_loss: -0.3495 - val_dice_coef: 0.3495\n",
      "Epoch 739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8411 - dice_coef: 0.8411 - val_loss: -0.5169 - val_dice_coef: 0.5169\n",
      "Epoch 740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8492 - dice_coef: 0.8492 - val_loss: -0.8756 - val_dice_coef: 0.8756\n",
      "Epoch 741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.5438 - val_dice_coef: 0.5438\n",
      "Epoch 742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.4142 - val_dice_coef: 0.4142\n",
      "Epoch 743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.6685 - val_dice_coef: 0.6685\n",
      "Epoch 744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.8682 - val_dice_coef: 0.8682\n",
      "Epoch 745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8460 - dice_coef: 0.8460 - val_loss: -0.5560 - val_dice_coef: 0.5560\n",
      "Epoch 746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.2725 - val_dice_coef: 0.2725\n",
      "Epoch 747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8489 - dice_coef: 0.8489 - val_loss: -0.6455 - val_dice_coef: 0.6455\n",
      "Epoch 748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.6092 - val_dice_coef: 0.6092\n",
      "Epoch 749/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.2267 - val_dice_coef: 0.2267\n",
      "Epoch 750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8472 - dice_coef: 0.8472 - val_loss: -0.7079 - val_dice_coef: 0.7079\n",
      "Epoch 751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8482 - dice_coef: 0.8482 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8464 - dice_coef: 0.8464 - val_loss: -0.3359 - val_dice_coef: 0.3359\n",
      "Epoch 753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8483 - dice_coef: 0.8483 - val_loss: -0.4852 - val_dice_coef: 0.4852\n",
      "Epoch 754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.8795 - val_dice_coef: 0.8795\n",
      "Epoch 755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.6648 - val_dice_coef: 0.6648\n",
      "Epoch 756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8470 - dice_coef: 0.8470 - val_loss: -0.2681 - val_dice_coef: 0.2681\n",
      "Epoch 757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.6538 - val_dice_coef: 0.6538\n",
      "Epoch 758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.7737 - val_dice_coef: 0.7737\n",
      "Epoch 759/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8458 - dice_coef: 0.8458 - val_loss: -0.5625 - val_dice_coef: 0.5625\n",
      "Epoch 760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.7626 - val_dice_coef: 0.7626\n",
      "Epoch 761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8480 - dice_coef: 0.8480 - val_loss: -0.6463 - val_dice_coef: 0.6463\n",
      "Epoch 762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.2825 - val_dice_coef: 0.2825\n",
      "Epoch 763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.4971 - val_dice_coef: 0.4971\n",
      "Epoch 764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.6287 - val_dice_coef: 0.6287\n",
      "Epoch 765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.6401 - val_dice_coef: 0.6401\n",
      "Epoch 766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.6936 - val_dice_coef: 0.6936\n",
      "Epoch 767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.4167 - val_dice_coef: 0.4167\n",
      "Epoch 768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.4295 - val_dice_coef: 0.4295\n",
      "Epoch 769/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.7763 - val_dice_coef: 0.7763\n",
      "Epoch 770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8509 - dice_coef: 0.8509 - val_loss: -0.8231 - val_dice_coef: 0.8231\n",
      "Epoch 771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8507 - dice_coef: 0.8507 - val_loss: -0.7932 - val_dice_coef: 0.7932\n",
      "Epoch 772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.3768 - val_dice_coef: 0.3768\n",
      "Epoch 773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.4115 - val_dice_coef: 0.4115\n",
      "Epoch 774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.5884 - val_dice_coef: 0.5884\n",
      "Epoch 775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8531 - dice_coef: 0.8531 - val_loss: -0.6688 - val_dice_coef: 0.6688\n",
      "Epoch 776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.8369 - val_dice_coef: 0.8369\n",
      "Epoch 777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.6895 - val_dice_coef: 0.6895\n",
      "Epoch 778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8514 - dice_coef: 0.8514 - val_loss: -0.6263 - val_dice_coef: 0.6263\n",
      "Epoch 779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.4246 - val_dice_coef: 0.4246\n",
      "Epoch 780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.3193 - val_dice_coef: 0.3193\n",
      "Epoch 781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.6160 - val_dice_coef: 0.6160\n",
      "Epoch 782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9589 - val_dice_coef: 0.9589\n",
      "Epoch 783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.8186 - val_dice_coef: 0.8186\n",
      "Epoch 784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8436 - dice_coef: 0.8436 - val_loss: -0.1388 - val_dice_coef: 0.1388\n",
      "Epoch 785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8456 - dice_coef: 0.8456 - val_loss: -0.3074 - val_dice_coef: 0.3074\n",
      "Epoch 786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.9070 - val_dice_coef: 0.9070\n",
      "Epoch 787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8455 - dice_coef: 0.8455 - val_loss: -0.8317 - val_dice_coef: 0.8317\n",
      "Epoch 788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.5644 - val_dice_coef: 0.5644\n",
      "Epoch 789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8536 - dice_coef: 0.8536 - val_loss: -0.3972 - val_dice_coef: 0.3972\n",
      "Epoch 790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.4738 - val_dice_coef: 0.4738\n",
      "Epoch 791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8553 - dice_coef: 0.8553 - val_loss: -0.6124 - val_dice_coef: 0.6124\n",
      "Epoch 792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8535 - dice_coef: 0.8535 - val_loss: -0.9356 - val_dice_coef: 0.9356\n",
      "Epoch 793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8499 - dice_coef: 0.8499 - val_loss: -0.7161 - val_dice_coef: 0.7161\n",
      "Epoch 794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.1549 - val_dice_coef: 0.1549\n",
      "Epoch 795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8453 - dice_coef: 0.8453 - val_loss: -0.2801 - val_dice_coef: 0.2801\n",
      "Epoch 796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8504 - dice_coef: 0.8504 - val_loss: -0.5559 - val_dice_coef: 0.5559\n",
      "Epoch 797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8556 - dice_coef: 0.8556 - val_loss: -0.8554 - val_dice_coef: 0.8554\n",
      "Epoch 798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8528 - dice_coef: 0.8528 - val_loss: -0.3655 - val_dice_coef: 0.3655\n",
      "Epoch 799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.1151 - val_dice_coef: 0.1151\n",
      "Epoch 800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8386 - dice_coef: 0.8386 - val_loss: -0.2047 - val_dice_coef: 0.2047\n",
      "Epoch 801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8109 - dice_coef: 0.8109 - val_loss: -0.9355 - val_dice_coef: 0.9355\n",
      "Epoch 803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8212 - dice_coef: 0.8212 - val_loss: -0.0244 - val_dice_coef: 0.0244\n",
      "Epoch 804/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8173 - dice_coef: 0.8173 - val_loss: -0.3989 - val_dice_coef: 0.3989\n",
      "Epoch 805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8277 - dice_coef: 0.8277 - val_loss: -0.8731 - val_dice_coef: 0.8731\n",
      "Epoch 806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8146 - dice_coef: 0.8146 - val_loss: -0.0170 - val_dice_coef: 0.0170\n",
      "Epoch 807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8062 - dice_coef: 0.8062 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.1861 - val_dice_coef: 0.1861\n",
      "Epoch 809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8280 - dice_coef: 0.8280 - val_loss: -0.1426 - val_dice_coef: 0.1426\n",
      "Epoch 810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8269 - dice_coef: 0.8269 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.4603 - val_dice_coef: 0.4603\n",
      "Epoch 812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8461 - dice_coef: 0.8461 - val_loss: -0.5005 - val_dice_coef: 0.5005\n",
      "Epoch 813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8460 - dice_coef: 0.8460 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 814/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.6413 - val_dice_coef: 0.6413\n",
      "Epoch 815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8526 - dice_coef: 0.8526 - val_loss: -0.6075 - val_dice_coef: 0.6075\n",
      "Epoch 816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.8333 - val_dice_coef: 0.8333\n",
      "Epoch 817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.4402 - val_dice_coef: 0.4402\n",
      "Epoch 818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.4477 - val_dice_coef: 0.4477\n",
      "Epoch 819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8514 - dice_coef: 0.8514 - val_loss: -0.9301 - val_dice_coef: 0.9301\n",
      "Epoch 820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.3854 - val_dice_coef: 0.3854\n",
      "Epoch 821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8519 - dice_coef: 0.8519 - val_loss: -0.6451 - val_dice_coef: 0.6451\n",
      "Epoch 822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8548 - dice_coef: 0.8548 - val_loss: -0.8534 - val_dice_coef: 0.8534\n",
      "Epoch 823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.5227 - val_dice_coef: 0.5227\n",
      "Epoch 824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8531 - dice_coef: 0.8531 - val_loss: -0.7357 - val_dice_coef: 0.7357\n",
      "Epoch 825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.8460 - val_dice_coef: 0.8460\n",
      "Epoch 826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8563 - dice_coef: 0.8563 - val_loss: -0.7245 - val_dice_coef: 0.7245\n",
      "Epoch 827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.3914 - val_dice_coef: 0.3914\n",
      "Epoch 828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8482 - dice_coef: 0.8482 - val_loss: -0.7330 - val_dice_coef: 0.7330\n",
      "Epoch 830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.6213 - val_dice_coef: 0.6213\n",
      "Epoch 831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.7375 - val_dice_coef: 0.7375\n",
      "Epoch 832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8554 - dice_coef: 0.8554 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8388 - dice_coef: 0.8388 - val_loss: -0.6835 - val_dice_coef: 0.6835\n",
      "Epoch 834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.0724 - val_dice_coef: 0.0724\n",
      "Epoch 835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.7645 - val_dice_coef: 0.7645\n",
      "Epoch 836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.9822 - val_dice_coef: 0.9822\n",
      "Epoch 837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8433 - dice_coef: 0.8433 - val_loss: -0.3740 - val_dice_coef: 0.3740\n",
      "Epoch 838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.3880 - val_dice_coef: 0.3880\n",
      "Epoch 839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.9392 - val_dice_coef: 0.9392\n",
      "Epoch 840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.6092 - val_dice_coef: 0.6092\n",
      "Epoch 841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.2208 - val_dice_coef: 0.2208\n",
      "Epoch 842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.9423 - val_dice_coef: 0.9423\n",
      "Epoch 843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8536 - dice_coef: 0.8536 - val_loss: -0.2052 - val_dice_coef: 0.2052\n",
      "Epoch 845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.6049 - val_dice_coef: 0.6049\n",
      "Epoch 846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.8703 - val_dice_coef: 0.8703\n",
      "Epoch 847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8554 - dice_coef: 0.8554 - val_loss: -0.6792 - val_dice_coef: 0.6792\n",
      "Epoch 848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.5180 - val_dice_coef: 0.5180\n",
      "Epoch 849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.8877 - val_dice_coef: 0.8877\n",
      "Epoch 850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8568 - dice_coef: 0.8568 - val_loss: -0.8671 - val_dice_coef: 0.8671\n",
      "Epoch 851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8534 - dice_coef: 0.8534 - val_loss: -0.2253 - val_dice_coef: 0.2253\n",
      "Epoch 852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.4381 - val_dice_coef: 0.4381\n",
      "Epoch 853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.9643 - val_dice_coef: 0.9643\n",
      "Epoch 854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -0.6585 - val_dice_coef: 0.6585\n",
      "Epoch 855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8537 - dice_coef: 0.8537 - val_loss: -0.5929 - val_dice_coef: 0.5929\n",
      "Epoch 856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.4989 - val_dice_coef: 0.4989\n",
      "Epoch 857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.8995 - val_dice_coef: 0.8995\n",
      "Epoch 858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.9217 - val_dice_coef: 0.9217\n",
      "Epoch 859/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8558 - dice_coef: 0.8558 - val_loss: -0.2018 - val_dice_coef: 0.2018\n",
      "Epoch 860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.4001 - val_dice_coef: 0.4001\n",
      "Epoch 861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.7284 - val_dice_coef: 0.7284\n",
      "Epoch 863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.3112 - val_dice_coef: 0.3112\n",
      "Epoch 864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8516 - dice_coef: 0.8516 - val_loss: -0.1725 - val_dice_coef: 0.1725\n",
      "Epoch 865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.7859 - val_dice_coef: 0.7859\n",
      "Epoch 866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.7054 - val_dice_coef: 0.7054\n",
      "Epoch 867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.3892 - val_dice_coef: 0.3892\n",
      "Epoch 868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8555 - dice_coef: 0.8555 - val_loss: -0.7265 - val_dice_coef: 0.7265\n",
      "Epoch 869/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8555 - dice_coef: 0.8555 - val_loss: -0.9342 - val_dice_coef: 0.9342\n",
      "Epoch 870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.8625 - val_dice_coef: 0.8625\n",
      "Epoch 871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8576 - dice_coef: 0.8576 - val_loss: -0.6924 - val_dice_coef: 0.6924\n",
      "Epoch 872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8590 - dice_coef: 0.8590 - val_loss: -0.3277 - val_dice_coef: 0.3277\n",
      "Epoch 873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8561 - dice_coef: 0.8561 - val_loss: -0.9711 - val_dice_coef: 0.9711\n",
      "Epoch 874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.7968 - val_dice_coef: 0.7968\n",
      "Epoch 875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8313 - dice_coef: 0.8313 - val_loss: -0.0267 - val_dice_coef: 0.0267\n",
      "Epoch 876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8287 - dice_coef: 0.8287 - val_loss: -0.6550 - val_dice_coef: 0.6550\n",
      "Epoch 877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9616 - val_dice_coef: 0.9616\n",
      "Epoch 878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8542 - dice_coef: 0.8542 - val_loss: -0.4779 - val_dice_coef: 0.4779\n",
      "Epoch 879/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.5987 - val_dice_coef: 0.5987\n",
      "Epoch 880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8575 - dice_coef: 0.8575 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.7415 - val_dice_coef: 0.7415\n",
      "Epoch 882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8557 - dice_coef: 0.8557 - val_loss: -0.3103 - val_dice_coef: 0.3103\n",
      "Epoch 883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9463 - val_dice_coef: 0.9463\n",
      "Epoch 884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8585 - dice_coef: 0.8585 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8585 - dice_coef: 0.8585 - val_loss: -0.6874 - val_dice_coef: 0.6874\n",
      "Epoch 886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.0696 - val_dice_coef: 0.0696\n",
      "Epoch 887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8335 - dice_coef: 0.8335 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "Epoch 888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8458 - dice_coef: 0.8458 - val_loss: -0.9836 - val_dice_coef: 0.9836\n",
      "Epoch 889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.1278 - val_dice_coef: 0.1278\n",
      "Epoch 890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.1465 - val_dice_coef: 0.1465\n",
      "Epoch 891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8288 - dice_coef: 0.8288 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.9762 - val_dice_coef: 0.9762\n",
      "Epoch 893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8296 - dice_coef: 0.8296 - val_loss: -0.0449 - val_dice_coef: 0.0449\n",
      "Epoch 894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8268 - dice_coef: 0.8268 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7870 - dice_coef: 0.7870 - val_loss: -0.5563 - val_dice_coef: 0.5563\n",
      "Epoch 896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.0207 - val_dice_coef: 0.0207\n",
      "Epoch 897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7943 - dice_coef: 0.7943 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7990 - dice_coef: 0.7990 - val_loss: -0.0056 - val_dice_coef: 0.0056\n",
      "Epoch 899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7997 - dice_coef: 0.7997 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8140 - dice_coef: 0.8140 - val_loss: -0.0163 - val_dice_coef: 0.0163\n",
      "Epoch 901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8278 - dice_coef: 0.8278 - val_loss: -0.1731 - val_dice_coef: 0.1731\n",
      "Epoch 903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8410 - dice_coef: 0.8410 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.0969 - val_dice_coef: 0.0969\n",
      "Epoch 905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8331 - dice_coef: 0.8331 - val_loss: -0.9669 - val_dice_coef: 0.9669\n",
      "Epoch 906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8434 - dice_coef: 0.8434 - val_loss: -0.6003 - val_dice_coef: 0.6003\n",
      "Epoch 907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8463 - dice_coef: 0.8463 - val_loss: -0.8600 - val_dice_coef: 0.8600\n",
      "Epoch 908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.4440 - val_dice_coef: 0.4440\n",
      "Epoch 910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9277 - val_dice_coef: 0.9277\n",
      "Epoch 913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.9548 - val_dice_coef: 0.9548\n",
      "Epoch 914/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8631 - dice_coef: 0.8631 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9537 - val_dice_coef: 0.9537\n",
      "Epoch 916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9325 - val_dice_coef: 0.9325\n",
      "Epoch 917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.6866 - val_dice_coef: 0.6866\n",
      "Epoch 918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8566 - dice_coef: 0.8566 - val_loss: -0.8557 - val_dice_coef: 0.8557\n",
      "Epoch 919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.7017 - val_dice_coef: 0.7017\n",
      "Epoch 921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8570 - dice_coef: 0.8570 - val_loss: -0.9189 - val_dice_coef: 0.9189\n",
      "Epoch 922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.9010 - val_dice_coef: 0.9010\n",
      "Epoch 923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8594 - dice_coef: 0.8594 - val_loss: -0.9313 - val_dice_coef: 0.9313\n",
      "Epoch 924/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8615 - dice_coef: 0.8615 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.9542 - val_dice_coef: 0.9542\n",
      "Epoch 926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.9186 - val_dice_coef: 0.9186\n",
      "Epoch 927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.9228 - val_dice_coef: 0.9228\n",
      "Epoch 928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8612 - dice_coef: 0.8612 - val_loss: -0.8624 - val_dice_coef: 0.8624\n",
      "Epoch 929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8621 - dice_coef: 0.8621 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8621 - dice_coef: 0.8621 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.9413 - val_dice_coef: 0.9413\n",
      "Epoch 932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8624 - dice_coef: 0.8624 - val_loss: -0.6561 - val_dice_coef: 0.6561\n",
      "Epoch 933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8547 - dice_coef: 0.8547 - val_loss: -0.2725 - val_dice_coef: 0.2725\n",
      "Epoch 936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8480 - dice_coef: 0.8480 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -0.4746 - val_dice_coef: 0.4746\n",
      "Epoch 938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8517 - dice_coef: 0.8517 - val_loss: -0.5272 - val_dice_coef: 0.5272\n",
      "Epoch 939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.5573 - val_dice_coef: 0.5573\n",
      "Epoch 941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.8822 - val_dice_coef: 0.8822\n",
      "Epoch 942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.9764 - val_dice_coef: 0.9764\n",
      "Epoch 943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8608 - dice_coef: 0.8608 - val_loss: -0.6972 - val_dice_coef: 0.6972\n",
      "Epoch 944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.9316 - val_dice_coef: 0.9316\n",
      "Epoch 945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.5515 - val_dice_coef: 0.5515\n",
      "Epoch 947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8560 - dice_coef: 0.8560 - val_loss: -0.7683 - val_dice_coef: 0.7683\n",
      "Epoch 948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8602 - dice_coef: 0.8602 - val_loss: -0.9385 - val_dice_coef: 0.9385\n",
      "Epoch 949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.8939 - val_dice_coef: 0.8939\n",
      "Epoch 950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.8332 - val_dice_coef: 0.8332\n",
      "Epoch 951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8623 - dice_coef: 0.8623 - val_loss: -0.7924 - val_dice_coef: 0.7924\n",
      "Epoch 952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.8816 - val_dice_coef: 0.8816\n",
      "Epoch 954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.9252 - val_dice_coef: 0.9252\n",
      "Epoch 955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9265 - val_dice_coef: 0.9265\n",
      "Epoch 956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.8976 - val_dice_coef: 0.8976\n",
      "Epoch 957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8627 - dice_coef: 0.8627 - val_loss: -0.9492 - val_dice_coef: 0.9492\n",
      "Epoch 958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8616 - dice_coef: 0.8616 - val_loss: -0.9407 - val_dice_coef: 0.9407\n",
      "Epoch 959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.8555 - val_dice_coef: 0.8555\n",
      "Epoch 960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8579 - dice_coef: 0.8579 - val_loss: -0.8050 - val_dice_coef: 0.8050\n",
      "Epoch 961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8629 - dice_coef: 0.8629 - val_loss: -0.8673 - val_dice_coef: 0.8673\n",
      "Epoch 962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.8563 - val_dice_coef: 0.8563\n",
      "Epoch 963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.2059 - val_dice_coef: 0.2059\n",
      "Epoch 964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9696 - val_dice_coef: 0.9696\n",
      "Epoch 965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8543 - dice_coef: 0.8543 - val_loss: -0.9292 - val_dice_coef: 0.9292\n",
      "Epoch 966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8556 - dice_coef: 0.8556 - val_loss: -0.3905 - val_dice_coef: 0.3905\n",
      "Epoch 967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8597 - dice_coef: 0.8597 - val_loss: -0.6444 - val_dice_coef: 0.6444\n",
      "Epoch 968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8627 - dice_coef: 0.8627 - val_loss: -0.9868 - val_dice_coef: 0.9868\n",
      "Epoch 969/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -0.9687 - val_dice_coef: 0.9687\n",
      "Epoch 970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8599 - dice_coef: 0.8599 - val_loss: -0.7404 - val_dice_coef: 0.7404\n",
      "Epoch 971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.8665 - val_dice_coef: 0.8665\n",
      "Epoch 972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.1268 - val_dice_coef: 0.1268\n",
      "Epoch 974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.8072 - val_dice_coef: 0.8072\n",
      "Epoch 975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.9781 - val_dice_coef: 0.9781\n",
      "Epoch 976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8661 - dice_coef: 0.8661 - val_loss: -0.6156 - val_dice_coef: 0.6156\n",
      "Epoch 977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8617 - dice_coef: 0.8617 - val_loss: -0.9634 - val_dice_coef: 0.9634\n",
      "Epoch 978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8646 - dice_coef: 0.8646 - val_loss: -0.9197 - val_dice_coef: 0.9197\n",
      "Epoch 979/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.6328 - val_dice_coef: 0.6328\n",
      "Epoch 980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.8507 - val_dice_coef: 0.8507\n",
      "Epoch 981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8634 - dice_coef: 0.8634 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.7881 - val_dice_coef: 0.7881\n",
      "Epoch 983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8595 - dice_coef: 0.8595 - val_loss: -0.9413 - val_dice_coef: 0.9413\n",
      "Epoch 984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8638 - dice_coef: 0.8638 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8649 - dice_coef: 0.8649 - val_loss: -0.5486 - val_dice_coef: 0.5486\n",
      "Epoch 986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8647 - dice_coef: 0.8647 - val_loss: -0.9300 - val_dice_coef: 0.9300\n",
      "Epoch 988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 989/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.8006 - val_dice_coef: 0.8006\n",
      "Epoch 990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.7084 - val_dice_coef: 0.7084\n",
      "Epoch 991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8947 - val_dice_coef: 0.8947\n",
      "Epoch 992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9819 - val_dice_coef: 0.9819\n",
      "Epoch 993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.8766 - val_dice_coef: 0.8766\n",
      "Epoch 994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.5579 - val_dice_coef: 0.5579\n",
      "Epoch 995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8679 - dice_coef: 0.8679 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8581 - dice_coef: 0.8581 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.7333 - val_dice_coef: 0.7333\n",
      "Epoch 998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.4334 - val_dice_coef: 0.4334\n",
      "Epoch 999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8604 - dice_coef: 0.8604 - val_loss: -0.8550 - val_dice_coef: 0.8550\n",
      "Epoch 1000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.9571 - val_dice_coef: 0.9571\n",
      "Epoch 1001/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8622 - dice_coef: 0.8622 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 1002/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8472 - dice_coef: 0.8472 - val_loss: -0.0536 - val_dice_coef: 0.0536\n",
      "Epoch 1003/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8317 - dice_coef: 0.8317 - val_loss: -0.1666 - val_dice_coef: 0.1666\n",
      "Epoch 1004/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1005/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.1120 - val_dice_coef: 0.1120\n",
      "Epoch 1006/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8338 - dice_coef: 0.8338 - val_loss: -0.6016 - val_dice_coef: 0.6016\n",
      "Epoch 1007/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8502 - dice_coef: 0.8502 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1008/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.0098 - val_dice_coef: 0.0098\n",
      "Epoch 1009/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1010/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8097 - dice_coef: 0.8097 - val_loss: -0.6957 - val_dice_coef: 0.6957\n",
      "Epoch 1011/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8291 - dice_coef: 0.8291 - val_loss: -0.0575 - val_dice_coef: 0.0575\n",
      "Epoch 1012/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1013/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.3387 - val_dice_coef: 0.3387\n",
      "Epoch 1014/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8446 - dice_coef: 0.8446 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 1015/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8405 - dice_coef: 0.8405 - val_loss: -0.9880 - val_dice_coef: 0.9880\n",
      "Epoch 1016/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8426 - dice_coef: 0.8426 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 1017/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1018/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.4361 - val_dice_coef: 0.4361\n",
      "Epoch 1019/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8579 - dice_coef: 0.8579 - val_loss: -0.8517 - val_dice_coef: 0.8517\n",
      "Epoch 1020/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8610 - dice_coef: 0.8610 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 1021/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8625 - dice_coef: 0.8625 - val_loss: -0.6310 - val_dice_coef: 0.6310\n",
      "Epoch 1022/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8658 - dice_coef: 0.8658 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1023/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8412 - dice_coef: 0.8412 - val_loss: -0.5694 - val_dice_coef: 0.5694\n",
      "Epoch 1024/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.1939 - val_dice_coef: 0.1939\n",
      "Epoch 1025/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1026/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.5309 - val_dice_coef: 0.5309\n",
      "Epoch 1027/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8594 - dice_coef: 0.8594 - val_loss: -0.8949 - val_dice_coef: 0.8949\n",
      "Epoch 1028/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.9792 - val_dice_coef: 0.9792\n",
      "Epoch 1029/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8665 - dice_coef: 0.8665 - val_loss: -0.7203 - val_dice_coef: 0.7203\n",
      "Epoch 1030/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 1031/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8660 - dice_coef: 0.8660 - val_loss: -0.9150 - val_dice_coef: 0.9150\n",
      "Epoch 1032/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8670 - dice_coef: 0.8670 - val_loss: -0.7944 - val_dice_coef: 0.7944\n",
      "Epoch 1033/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.8140 - val_dice_coef: 0.8140\n",
      "Epoch 1034/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.9357 - val_dice_coef: 0.9357\n",
      "Epoch 1035/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.7574 - val_dice_coef: 0.7574\n",
      "Epoch 1036/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8654 - dice_coef: 0.8654 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 1037/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 1038/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8660 - dice_coef: 0.8660 - val_loss: -0.3575 - val_dice_coef: 0.3575\n",
      "Epoch 1039/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8628 - dice_coef: 0.8628 - val_loss: -0.9336 - val_dice_coef: 0.9336\n",
      "Epoch 1040/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 1041/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.8473 - val_dice_coef: 0.8473\n",
      "Epoch 1042/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.6599 - val_dice_coef: 0.6599\n",
      "Epoch 1043/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8600 - dice_coef: 0.8600 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1044/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8666 - dice_coef: 0.8666 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1045/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8676 - dice_coef: 0.8676 - val_loss: -0.6482 - val_dice_coef: 0.6482\n",
      "Epoch 1046/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.6694 - val_dice_coef: 0.6694\n",
      "Epoch 1047/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.9896 - val_dice_coef: 0.9896\n",
      "Epoch 1048/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9164 - val_dice_coef: 0.9164\n",
      "Epoch 1049/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8592 - dice_coef: 0.8592 - val_loss: -0.5549 - val_dice_coef: 0.5549\n",
      "Epoch 1050/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8654 - dice_coef: 0.8654 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 1051/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8705 - dice_coef: 0.8705 - val_loss: -0.9049 - val_dice_coef: 0.9049\n",
      "Epoch 1052/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8694 - dice_coef: 0.8694 - val_loss: -0.9109 - val_dice_coef: 0.9109\n",
      "Epoch 1053/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.8367 - val_dice_coef: 0.8367\n",
      "Epoch 1054/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8696 - dice_coef: 0.8696 - val_loss: -0.9657 - val_dice_coef: 0.9657\n",
      "Epoch 1055/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9415 - val_dice_coef: 0.9415\n",
      "Epoch 1056/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8690 - dice_coef: 0.8690 - val_loss: -0.7286 - val_dice_coef: 0.7286\n",
      "Epoch 1057/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8688 - dice_coef: 0.8688 - val_loss: -0.9478 - val_dice_coef: 0.9478\n",
      "Epoch 1058/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8705 - dice_coef: 0.8705 - val_loss: -0.9559 - val_dice_coef: 0.9559\n",
      "Epoch 1059/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.7451 - val_dice_coef: 0.7451\n",
      "Epoch 1060/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8699 - dice_coef: 0.8699 - val_loss: -0.8512 - val_dice_coef: 0.8512\n",
      "Epoch 1061/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1062/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.9079 - val_dice_coef: 0.9079\n",
      "Epoch 1063/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.7620 - val_dice_coef: 0.7620\n",
      "Epoch 1064/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.7545 - val_dice_coef: 0.7545\n",
      "Epoch 1065/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 1066/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8601 - dice_coef: 0.8601 - val_loss: -0.9141 - val_dice_coef: 0.9141\n",
      "Epoch 1067/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.4374 - val_dice_coef: 0.4374\n",
      "Epoch 1068/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8572 - dice_coef: 0.8572 - val_loss: -0.9088 - val_dice_coef: 0.9088\n",
      "Epoch 1069/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1070/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8502 - dice_coef: 0.8502 - val_loss: -0.0892 - val_dice_coef: 0.0892\n",
      "Epoch 1071/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.3519 - val_dice_coef: 0.3519\n",
      "Epoch 1072/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1073/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.1056 - val_dice_coef: 0.1056\n",
      "Epoch 1074/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.9048 - val_dice_coef: 0.9048\n",
      "Epoch 1075/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1076/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.0317 - val_dice_coef: 0.0317\n",
      "Epoch 1077/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8090 - dice_coef: 0.8090 - val_loss: -0.4089 - val_dice_coef: 0.4089\n",
      "Epoch 1078/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1079/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.1518 - val_dice_coef: 0.1518\n",
      "Epoch 1080/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8499 - dice_coef: 0.8499 - val_loss: -0.7791 - val_dice_coef: 0.7791\n",
      "Epoch 1081/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8526 - dice_coef: 0.8526 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1082/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.0804 - val_dice_coef: 0.0804\n",
      "Epoch 1083/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8449 - dice_coef: 0.8449 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 1084/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.8349 - val_dice_coef: 0.8349\n",
      "Epoch 1085/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.1126 - val_dice_coef: 0.1126\n",
      "Epoch 1086/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8385 - dice_coef: 0.8385 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1087/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8254 - dice_coef: 0.8254 - val_loss: -0.5600 - val_dice_coef: 0.5600\n",
      "Epoch 1088/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8609 - dice_coef: 0.8609 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 1089/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8603 - dice_coef: 0.8603 - val_loss: -0.9614 - val_dice_coef: 0.9614\n",
      "Epoch 1090/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8645 - dice_coef: 0.8645 - val_loss: -0.8877 - val_dice_coef: 0.8877\n",
      "Epoch 1091/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 1092/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8304 - val_dice_coef: 0.8304\n",
      "Epoch 1093/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9045 - val_dice_coef: 0.9045\n",
      "Epoch 1094/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1095/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8688 - dice_coef: 0.8688 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "Epoch 1096/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.8798 - val_dice_coef: 0.8798\n",
      "Epoch 1097/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1098/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.6924 - val_dice_coef: 0.6924\n",
      "Epoch 1099/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.9647 - val_dice_coef: 0.9647\n",
      "Epoch 1100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8693 - dice_coef: 0.8693 - val_loss: -0.9751 - val_dice_coef: 0.9751\n",
      "Epoch 1101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8683 - dice_coef: 0.8683 - val_loss: -0.8918 - val_dice_coef: 0.8918\n",
      "Epoch 1102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8741 - dice_coef: 0.8741 - val_loss: -0.9223 - val_dice_coef: 0.9223\n",
      "Epoch 1103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "Epoch 1104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.9560 - val_dice_coef: 0.9560\n",
      "Epoch 1105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8715 - dice_coef: 0.8715 - val_loss: -0.9793 - val_dice_coef: 0.9793\n",
      "Epoch 1106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.7256 - val_dice_coef: 0.7256\n",
      "Epoch 1107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.8245 - val_dice_coef: 0.8245\n",
      "Epoch 1108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8672 - dice_coef: 0.8672 - val_loss: -0.7725 - val_dice_coef: 0.7725\n",
      "Epoch 1110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9215 - val_dice_coef: 0.9215\n",
      "Epoch 1111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8685 - dice_coef: 0.8685 - val_loss: -0.8775 - val_dice_coef: 0.8775\n",
      "Epoch 1113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.9527 - val_dice_coef: 0.9527\n",
      "Epoch 1114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.4950 - val_dice_coef: 0.4950\n",
      "Epoch 1116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8658 - dice_coef: 0.8658 - val_loss: -0.9236 - val_dice_coef: 0.9236\n",
      "Epoch 1117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8686 - dice_coef: 0.8686 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8689 - dice_coef: 0.8689 - val_loss: -0.7843 - val_dice_coef: 0.7843\n",
      "Epoch 1119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.9836 - val_dice_coef: 0.9836\n",
      "Epoch 1120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8718 - dice_coef: 0.8718 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.9663 - val_dice_coef: 0.9663\n",
      "Epoch 1122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8737 - dice_coef: 0.8737 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 1123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.8007 - val_dice_coef: 0.8007\n",
      "Epoch 1124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.9861 - val_dice_coef: 0.9861\n",
      "Epoch 1125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8616 - dice_coef: 0.8616 - val_loss: -0.0640 - val_dice_coef: 0.0640\n",
      "Epoch 1127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.8262 - val_dice_coef: 0.8262\n",
      "Epoch 1128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.1988 - val_dice_coef: 0.1988\n",
      "Epoch 1130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8562 - dice_coef: 0.8562 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8604 - dice_coef: 0.8604 - val_loss: -0.7498 - val_dice_coef: 0.7498\n",
      "Epoch 1132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8689 - dice_coef: 0.8689 - val_loss: -0.3435 - val_dice_coef: 0.3435\n",
      "Epoch 1135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.9566 - val_dice_coef: 0.9566\n",
      "Epoch 1136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8607 - dice_coef: 0.8607 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.8013 - val_dice_coef: 0.8013\n",
      "Epoch 1138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.8925 - val_dice_coef: 0.8925\n",
      "Epoch 1139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8708 - dice_coef: 0.8708 - val_loss: -0.9755 - val_dice_coef: 0.9755\n",
      "Epoch 1140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9490 - val_dice_coef: 0.9490\n",
      "Epoch 1141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9386 - val_dice_coef: 0.9386\n",
      "Epoch 1142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.8723 - val_dice_coef: 0.8723\n",
      "Epoch 1143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 1144/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.9019 - val_dice_coef: 0.9019\n",
      "Epoch 1145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.8416 - val_dice_coef: 0.8416\n",
      "Epoch 1146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 1147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 1148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8733 - dice_coef: 0.8733 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9353 - val_dice_coef: 0.9353\n",
      "Epoch 1150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.8787 - val_dice_coef: 0.8787\n",
      "Epoch 1151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9200 - val_dice_coef: 0.9200\n",
      "Epoch 1152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8685 - dice_coef: 0.8685 - val_loss: -0.9765 - val_dice_coef: 0.9765\n",
      "Epoch 1153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8744 - dice_coef: 0.8744 - val_loss: -0.8773 - val_dice_coef: 0.8773\n",
      "Epoch 1154/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.9595 - val_dice_coef: 0.9595\n",
      "Epoch 1155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 1156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.5922 - val_dice_coef: 0.5922\n",
      "Epoch 1158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.7393 - val_dice_coef: 0.7393\n",
      "Epoch 1159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8656 - dice_coef: 0.8656 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 1160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 1161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.4817 - val_dice_coef: 0.4817\n",
      "Epoch 1162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 1163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 1164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8684 - dice_coef: 0.8684 - val_loss: -0.1108 - val_dice_coef: 0.1108\n",
      "Epoch 1165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8624 - dice_coef: 0.8624 - val_loss: -0.9803 - val_dice_coef: 0.9803\n",
      "Epoch 1167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.1844 - val_dice_coef: 0.1844\n",
      "Epoch 1168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 1169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.6831 - val_dice_coef: 0.6831\n",
      "Epoch 1170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -0.5705 - val_dice_coef: 0.5705\n",
      "Epoch 1171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.6655 - val_dice_coef: 0.6655\n",
      "Epoch 1173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.8917 - val_dice_coef: 0.8917\n",
      "Epoch 1174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8692 - dice_coef: 0.8692 - val_loss: -0.9620 - val_dice_coef: 0.9620\n",
      "Epoch 1175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 1176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9668 - val_dice_coef: 0.9668\n",
      "Epoch 1177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8760 - dice_coef: 0.8760 - val_loss: -0.4225 - val_dice_coef: 0.4225\n",
      "Epoch 1178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8568 - dice_coef: 0.8568 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8617 - dice_coef: 0.8617 - val_loss: -0.2472 - val_dice_coef: 0.2472\n",
      "Epoch 1181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.9606 - val_dice_coef: 0.9606\n",
      "Epoch 1182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 1183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.8566 - val_dice_coef: 0.8566\n",
      "Epoch 1184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.7026 - val_dice_coef: 0.7026\n",
      "Epoch 1185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "Epoch 1187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9058 - val_dice_coef: 0.9058\n",
      "Epoch 1188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.4322 - val_dice_coef: 0.4322\n",
      "Epoch 1190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.7995 - val_dice_coef: 0.7995\n",
      "Epoch 1191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.9844 - val_dice_coef: 0.9844\n",
      "Epoch 1192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9046 - val_dice_coef: 0.9046\n",
      "Epoch 1193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.5496 - val_dice_coef: 0.5496\n",
      "Epoch 1194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8648 - dice_coef: 0.8648 - val_loss: -0.9909 - val_dice_coef: 0.9909\n",
      "Epoch 1195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 1196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.0458 - val_dice_coef: 0.0458\n",
      "Epoch 1197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8235 - dice_coef: 0.8235 - val_loss: -0.0956 - val_dice_coef: 0.0956\n",
      "Epoch 1198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8426 - dice_coef: 0.8426 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1199/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.0376 - val_dice_coef: 0.0376\n",
      "Epoch 1200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9591 - val_dice_coef: 0.9591\n",
      "Epoch 1202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.3772 - val_dice_coef: 0.3772\n",
      "Epoch 1203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8635 - dice_coef: 0.8635 - val_loss: -0.8594 - val_dice_coef: 0.8594\n",
      "Epoch 1205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9872 - val_dice_coef: 0.9872\n",
      "Epoch 1206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 1207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.6851 - val_dice_coef: 0.6851\n",
      "Epoch 1208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9956 - val_dice_coef: 0.9956\n",
      "Epoch 1209/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.9248 - val_dice_coef: 0.9248\n",
      "Epoch 1210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -0.5337 - val_dice_coef: 0.5337\n",
      "Epoch 1211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.9769 - val_dice_coef: 0.9769\n",
      "Epoch 1212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8773 - dice_coef: 0.8773 - val_loss: -0.7920 - val_dice_coef: 0.7920\n",
      "Epoch 1213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9271 - val_dice_coef: 0.9271\n",
      "Epoch 1214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.9746 - val_dice_coef: 0.9746\n",
      "Epoch 1215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8755 - dice_coef: 0.8755 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "Epoch 1216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.8132 - val_dice_coef: 0.8132\n",
      "Epoch 1217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.9755 - val_dice_coef: 0.9755\n",
      "Epoch 1218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9377 - val_dice_coef: 0.9377\n",
      "Epoch 1219/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 1220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9523 - val_dice_coef: 0.9523\n",
      "Epoch 1221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.9513 - val_dice_coef: 0.9513\n",
      "Epoch 1222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9321 - val_dice_coef: 0.9321\n",
      "Epoch 1223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9393 - val_dice_coef: 0.9393\n",
      "Epoch 1224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8780 - dice_coef: 0.8780 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 1225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.9235 - val_dice_coef: 0.9235\n",
      "Epoch 1226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.9359 - val_dice_coef: 0.9359\n",
      "Epoch 1227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9820 - val_dice_coef: 0.9820\n",
      "Epoch 1228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8799 - dice_coef: 0.8799 - val_loss: -0.6893 - val_dice_coef: 0.6893\n",
      "Epoch 1229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 1231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9458 - val_dice_coef: 0.9458\n",
      "Epoch 1232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9079 - val_dice_coef: 0.9079\n",
      "Epoch 1233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8787 - dice_coef: 0.8787 - val_loss: -0.9396 - val_dice_coef: 0.9396\n",
      "Epoch 1234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9063 - val_dice_coef: 0.9063\n",
      "Epoch 1235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8770 - dice_coef: 0.8770 - val_loss: -0.5947 - val_dice_coef: 0.5947\n",
      "Epoch 1238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.9679 - val_dice_coef: 0.9679\n",
      "Epoch 1239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 1240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8702 - dice_coef: 0.8702 - val_loss: -0.2189 - val_dice_coef: 0.2189\n",
      "Epoch 1241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.9456 - val_dice_coef: 0.9456\n",
      "Epoch 1242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8687 - dice_coef: 0.8687 - val_loss: -0.4867 - val_dice_coef: 0.4867\n",
      "Epoch 1244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8629 - dice_coef: 0.8629 - val_loss: -0.2168 - val_dice_coef: 0.2168\n",
      "Epoch 1245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.6962 - val_dice_coef: 0.6962\n",
      "Epoch 1247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.1174 - val_dice_coef: 0.1174\n",
      "Epoch 1248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8549 - dice_coef: 0.8549 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.9383 - val_dice_coef: 0.9383\n",
      "Epoch 1250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8724 - dice_coef: 0.8724 - val_loss: -0.5627 - val_dice_coef: 0.5627\n",
      "Epoch 1251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 1253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8777 - dice_coef: 0.8777 - val_loss: -0.7830 - val_dice_coef: 0.7830\n",
      "Epoch 1254/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9698 - val_dice_coef: 0.9698\n",
      "Epoch 1255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8799 - dice_coef: 0.8799 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.8652 - val_dice_coef: 0.8652\n",
      "Epoch 1257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9314 - val_dice_coef: 0.9314\n",
      "Epoch 1258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8762 - dice_coef: 0.8762 - val_loss: -0.9479 - val_dice_coef: 0.9479\n",
      "Epoch 1261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.8223 - val_dice_coef: 0.8223\n",
      "Epoch 1262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.7438 - val_dice_coef: 0.7438\n",
      "Epoch 1264/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8679 - dice_coef: 0.8679 - val_loss: -0.2187 - val_dice_coef: 0.2187\n",
      "Epoch 1265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8427 - dice_coef: 0.8427 - val_loss: -0.5254 - val_dice_coef: 0.5254\n",
      "Epoch 1267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.0585 - val_dice_coef: 0.0585\n",
      "Epoch 1268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0653 - val_dice_coef: 0.0653\n",
      "Epoch 1270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.5930 - val_dice_coef: 0.5930\n",
      "Epoch 1271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.4535 - val_dice_coef: 0.4535\n",
      "Epoch 1273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8697 - dice_coef: 0.8697 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9800 - val_dice_coef: 0.9800\n",
      "Epoch 1275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.6696 - val_dice_coef: 0.6696\n",
      "Epoch 1276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8661 - dice_coef: 0.8661 - val_loss: -0.1610 - val_dice_coef: 0.1610\n",
      "Epoch 1279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8699 - dice_coef: 0.8699 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.7982 - val_dice_coef: 0.7982\n",
      "Epoch 1281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.9349 - val_dice_coef: 0.9349\n",
      "Epoch 1282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8737 - dice_coef: 0.8737 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.8544 - val_dice_coef: 0.8544\n",
      "Epoch 1284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9820 - val_dice_coef: 0.9820\n",
      "Epoch 1285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8794 - dice_coef: 0.8794 - val_loss: -0.7478 - val_dice_coef: 0.7478\n",
      "Epoch 1287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 1288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.7808 - val_dice_coef: 0.7808\n",
      "Epoch 1290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.9448 - val_dice_coef: 0.9448\n",
      "Epoch 1292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.7170 - val_dice_coef: 0.7170\n",
      "Epoch 1293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9073 - val_dice_coef: 0.9073\n",
      "Epoch 1295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.5361 - val_dice_coef: 0.5361\n",
      "Epoch 1296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8763 - dice_coef: 0.8763 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9063 - val_dice_coef: 0.9063\n",
      "Epoch 1298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8755 - dice_coef: 0.8755 - val_loss: -0.8915 - val_dice_coef: 0.8915\n",
      "Epoch 1299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -0.5298 - val_dice_coef: 0.5298\n",
      "Epoch 1301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8740 - dice_coef: 0.8740 - val_loss: -0.9875 - val_dice_coef: 0.9875\n",
      "Epoch 1302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 1303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.8967 - val_dice_coef: 0.8967\n",
      "Epoch 1304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9702 - val_dice_coef: 0.9702\n",
      "Epoch 1305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 1306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8818 - dice_coef: 0.8818 - val_loss: -0.7640 - val_dice_coef: 0.7640\n",
      "Epoch 1307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9842 - val_dice_coef: 0.9842\n",
      "Epoch 1309/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8804 - dice_coef: 0.8804 - val_loss: -0.8562 - val_dice_coef: 0.8562\n",
      "Epoch 1310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8779 - dice_coef: 0.8779 - val_loss: -0.8712 - val_dice_coef: 0.8712\n",
      "Epoch 1311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 1313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
      "Epoch 1314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.8932 - val_dice_coef: 0.8932\n",
      "Epoch 1316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.7943 - val_dice_coef: 0.7943\n",
      "Epoch 1317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9017 - val_dice_coef: 0.9017\n",
      "Epoch 1319/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8702 - dice_coef: 0.8702 - val_loss: -0.8048 - val_dice_coef: 0.8048\n",
      "Epoch 1320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 1321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.7515 - val_dice_coef: 0.7515\n",
      "Epoch 1322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.4710 - val_dice_coef: 0.4710\n",
      "Epoch 1323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8622 - dice_coef: 0.8622 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 1325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.0405 - val_dice_coef: 0.0405\n",
      "Epoch 1326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8495 - dice_coef: 0.8495 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8563 - dice_coef: 0.8563 - val_loss: -0.9283 - val_dice_coef: 0.9283\n",
      "Epoch 1328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8684 - dice_coef: 0.8684 - val_loss: -0.4080 - val_dice_coef: 0.4080\n",
      "Epoch 1329/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8703 - dice_coef: 0.8703 - val_loss: -0.7567 - val_dice_coef: 0.7567\n",
      "Epoch 1331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9764 - val_dice_coef: 0.9764\n",
      "Epoch 1332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 1333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.2174 - val_dice_coef: 0.2174\n",
      "Epoch 1334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8640 - dice_coef: 0.8640 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.7884 - val_dice_coef: 0.7884\n",
      "Epoch 1336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.8379 - val_dice_coef: 0.8379\n",
      "Epoch 1337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8759 - dice_coef: 0.8759 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 1339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.9426 - val_dice_coef: 0.9426\n",
      "Epoch 1340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8823 - dice_coef: 0.8823 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -0.5192 - val_dice_coef: 0.5192\n",
      "Epoch 1342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9811 - val_dice_coef: 0.9811\n",
      "Epoch 1343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.8578 - val_dice_coef: 0.8578\n",
      "Epoch 1345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 1346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9368 - val_dice_coef: 0.9368\n",
      "Epoch 1348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8851 - dice_coef: 0.8851 - val_loss: -0.9873 - val_dice_coef: 0.9873\n",
      "Epoch 1349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8815 - dice_coef: 0.8815 - val_loss: -0.8931 - val_dice_coef: 0.8931\n",
      "Epoch 1350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8831 - dice_coef: 0.8831 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 1351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 1353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.8807 - val_dice_coef: 0.8807\n",
      "Epoch 1354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 1355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9674 - val_dice_coef: 0.9674\n",
      "Epoch 1356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9875 - val_dice_coef: 0.9875\n",
      "Epoch 1357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8847 - dice_coef: 0.8847 - val_loss: -0.9623 - val_dice_coef: 0.9623\n",
      "Epoch 1358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9287 - val_dice_coef: 0.9287\n",
      "Epoch 1359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9515 - val_dice_coef: 0.9515\n",
      "Epoch 1360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8842 - dice_coef: 0.8842 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 1361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.9364 - val_dice_coef: 0.9364\n",
      "Epoch 1362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.8061 - val_dice_coef: 0.8061\n",
      "Epoch 1363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 1364/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.8924 - val_dice_coef: 0.8924\n",
      "Epoch 1366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.8853 - val_dice_coef: 0.8853\n",
      "Epoch 1367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.7476 - val_dice_coef: 0.7476\n",
      "Epoch 1370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 1371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8656 - dice_coef: 0.8656 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.2390 - val_dice_coef: 0.2390\n",
      "Epoch 1374/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8795 - dice_coef: 0.8795 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.6036 - val_dice_coef: 0.6036\n",
      "Epoch 1377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.8611 - val_dice_coef: 0.8611\n",
      "Epoch 1378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9521 - val_dice_coef: 0.9521\n",
      "Epoch 1380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9455 - val_dice_coef: 0.9455\n",
      "Epoch 1381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9195 - val_dice_coef: 0.9195\n",
      "Epoch 1383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.7753 - val_dice_coef: 0.7753\n",
      "Epoch 1384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.9845 - val_dice_coef: 0.9845\n",
      "Epoch 1386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.6840 - val_dice_coef: 0.6840\n",
      "Epoch 1387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.5232 - val_dice_coef: 0.5232\n",
      "Epoch 1390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 1391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 1393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8864 - dice_coef: 0.8864 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9704 - val_dice_coef: 0.9704\n",
      "Epoch 1395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8829 - dice_coef: 0.8829 - val_loss: -0.8821 - val_dice_coef: 0.8821\n",
      "Epoch 1396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8823 - dice_coef: 0.8823 - val_loss: -0.8286 - val_dice_coef: 0.8286\n",
      "Epoch 1398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.7954 - val_dice_coef: 0.7954\n",
      "Epoch 1399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.7331 - val_dice_coef: 0.7331\n",
      "Epoch 1401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.2798 - val_dice_coef: 0.2798\n",
      "Epoch 1402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.5671 - val_dice_coef: 0.5671\n",
      "Epoch 1404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.8881 - val_dice_coef: 0.8881\n",
      "Epoch 1405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8686 - dice_coef: 0.8686 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 1407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8757 - dice_coef: 0.8757 - val_loss: -0.8560 - val_dice_coef: 0.8560\n",
      "Epoch 1408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.5029 - val_dice_coef: 0.5029\n",
      "Epoch 1410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 1411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8750 - dice_coef: 0.8750 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.8011 - val_dice_coef: 0.8011\n",
      "Epoch 1413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8780 - dice_coef: 0.8780 - val_loss: -0.7275 - val_dice_coef: 0.7275\n",
      "Epoch 1414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.8300 - val_dice_coef: 0.8300\n",
      "Epoch 1416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9668 - val_dice_coef: 0.9668\n",
      "Epoch 1417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.7602 - val_dice_coef: 0.7602\n",
      "Epoch 1419/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 1420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8869 - dice_coef: 0.8869 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9878 - val_dice_coef: 0.9878\n",
      "Epoch 1422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8874 - dice_coef: 0.8874 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 1423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9813 - val_dice_coef: 0.9813\n",
      "Epoch 1425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8862 - dice_coef: 0.8862 - val_loss: -0.9892 - val_dice_coef: 0.9892\n",
      "Epoch 1426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.7790 - val_dice_coef: 0.7790\n",
      "Epoch 1428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1429/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.5066 - val_dice_coef: 0.5066\n",
      "Epoch 1431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 1432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 1433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.9503 - val_dice_coef: 0.9503\n",
      "Epoch 1434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9680 - val_dice_coef: 0.9680\n",
      "Epoch 1435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.9775 - val_dice_coef: 0.9775\n",
      "Epoch 1437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 1438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1439/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9406 - val_dice_coef: 0.9406\n",
      "Epoch 1440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9496 - val_dice_coef: 0.9496\n",
      "Epoch 1441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.7550 - val_dice_coef: 0.7550\n",
      "Epoch 1444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9906 - val_dice_coef: 0.9906\n",
      "Epoch 1445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8869 - dice_coef: 0.8869 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8820 - dice_coef: 0.8820 - val_loss: -0.9122 - val_dice_coef: 0.9122\n",
      "Epoch 1447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9654 - val_dice_coef: 0.9654\n",
      "Epoch 1448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 1450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "Epoch 1451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 1452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 1453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8880 - dice_coef: 0.8880 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 1454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8853 - dice_coef: 0.8853 - val_loss: -0.9077 - val_dice_coef: 0.9077\n",
      "Epoch 1455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8872 - dice_coef: 0.8872 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 1457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8854 - dice_coef: 0.8854 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 1458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.8697 - val_dice_coef: 0.8697\n",
      "Epoch 1459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 1462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9592 - val_dice_coef: 0.9592\n",
      "Epoch 1463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8878 - dice_coef: 0.8878 - val_loss: -0.9028 - val_dice_coef: 0.9028\n",
      "Epoch 1466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.9455 - val_dice_coef: 0.9455\n",
      "Epoch 1471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.9116 - val_dice_coef: 0.9116\n",
      "Epoch 1472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1474/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9324 - val_dice_coef: 0.9324\n",
      "Epoch 1475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9858 - val_dice_coef: 0.9858\n",
      "Epoch 1476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8901 - dice_coef: 0.8901 - val_loss: -0.9861 - val_dice_coef: 0.9860\n",
      "Epoch 1477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8898 - dice_coef: 0.8898 - val_loss: -0.9476 - val_dice_coef: 0.9476\n",
      "Epoch 1478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 1479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8847 - dice_coef: 0.8847 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 1480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -0.4743 - val_dice_coef: 0.4743\n",
      "Epoch 1481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8806 - dice_coef: 0.8806 - val_loss: -0.8402 - val_dice_coef: 0.8402\n",
      "Epoch 1482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8809 - dice_coef: 0.8809 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1484/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.2526 - val_dice_coef: 0.2526\n",
      "Epoch 1485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.9901 - val_dice_coef: 0.9901\n",
      "Epoch 1486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.8856 - val_dice_coef: 0.8856\n",
      "Epoch 1488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8830 - dice_coef: 0.8830 - val_loss: -0.0971 - val_dice_coef: 0.0971\n",
      "Epoch 1489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.3692 - val_dice_coef: 0.3692\n",
      "Epoch 1492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 1493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9403 - val_dice_coef: 0.9403\n",
      "Epoch 1495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8871 - dice_coef: 0.8871 - val_loss: -0.9277 - val_dice_coef: 0.9277\n",
      "Epoch 1497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.5883 - val_dice_coef: 0.5883\n",
      "Epoch 1498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8878 - dice_coef: 0.8878 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 1500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.4534 - val_dice_coef: 0.4534\n",
      "Epoch 1501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8789 - dice_coef: 0.8789 - val_loss: -0.9245 - val_dice_coef: 0.9245\n",
      "Epoch 1502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8800 - dice_coef: 0.8800 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9635 - val_dice_coef: 0.9635\n",
      "Epoch 1504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.6363 - val_dice_coef: 0.6363\n",
      "Epoch 1505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 1507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 1508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.6256 - val_dice_coef: 0.6256\n",
      "Epoch 1509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8813 - dice_coef: 0.8813 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9877 - val_dice_coef: 0.9877\n",
      "Epoch 1511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8885 - dice_coef: 0.8885 - val_loss: -0.7086 - val_dice_coef: 0.7086\n",
      "Epoch 1512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 1513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8889 - dice_coef: 0.8889 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8842 - dice_coef: 0.8842 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 1515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.8409 - val_dice_coef: 0.8409\n",
      "Epoch 1516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.8782 - val_dice_coef: 0.8782\n",
      "Epoch 1520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.9585 - val_dice_coef: 0.9585\n",
      "Epoch 1523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.5229 - val_dice_coef: 0.5229\n",
      "Epoch 1524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9806 - val_dice_coef: 0.9806\n",
      "Epoch 1526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8927 - dice_coef: 0.8927 - val_loss: -0.9602 - val_dice_coef: 0.9602\n",
      "Epoch 1529/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 1531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 1532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8910 - dice_coef: 0.8910 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 1535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9702 - val_dice_coef: 0.9702\n",
      "Epoch 1537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 1539/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 1541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9630 - val_dice_coef: 0.9630\n",
      "Epoch 1542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9517 - val_dice_coef: 0.9517\n",
      "Epoch 1543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8925 - dice_coef: 0.8925 - val_loss: -0.9853 - val_dice_coef: 0.9853\n",
      "Epoch 1548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8915 - dice_coef: 0.8915 - val_loss: -0.9361 - val_dice_coef: 0.9361\n",
      "Epoch 1549/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "Epoch 1550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8800 - dice_coef: 0.8800 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 1553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9578 - val_dice_coef: 0.9578\n",
      "Epoch 1554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 1555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8939 - dice_coef: 0.8939 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 1556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8935 - dice_coef: 0.8935 - val_loss: -0.9822 - val_dice_coef: 0.9822\n",
      "Epoch 1557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.8629 - val_dice_coef: 0.8629\n",
      "Epoch 1558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 1559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 1560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8905 - dice_coef: 0.8905 - val_loss: -0.9371 - val_dice_coef: 0.9371\n",
      "Epoch 1562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.3627 - val_dice_coef: 0.3627\n",
      "Epoch 1563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.8936 - val_dice_coef: 0.8936\n",
      "Epoch 1566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.5421 - val_dice_coef: 0.5421\n",
      "Epoch 1567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.8160 - val_dice_coef: 0.8160\n",
      "Epoch 1570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.8215 - val_dice_coef: 0.8215\n",
      "Epoch 1571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8777 - dice_coef: 0.8777 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 1573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.8056 - val_dice_coef: 0.8056\n",
      "Epoch 1574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8813 - dice_coef: 0.8813 - val_loss: -0.7738 - val_dice_coef: 0.7738\n",
      "Epoch 1575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8851 - dice_coef: 0.8851 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8876 - dice_coef: 0.8876 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 1578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.9532 - val_dice_coef: 0.9532\n",
      "Epoch 1579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8855 - dice_coef: 0.8855 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 1583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.8843 - val_dice_coef: 0.8843\n",
      "Epoch 1584/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8898 - dice_coef: 0.8898 - val_loss: -0.9842 - val_dice_coef: 0.9842\n",
      "Epoch 1585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9646 - val_dice_coef: 0.9646\n",
      "Epoch 1588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9435 - val_dice_coef: 0.9435\n",
      "Epoch 1589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9877 - val_dice_coef: 0.9877\n",
      "Epoch 1590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9839 - val_dice_coef: 0.9839\n",
      "Epoch 1591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9308 - val_dice_coef: 0.9308\n",
      "Epoch 1592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 1594/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 1596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 1599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8889 - dice_coef: 0.8889 - val_loss: -0.8511 - val_dice_coef: 0.8511\n",
      "Epoch 1600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.8326 - val_dice_coef: 0.8326\n",
      "Epoch 1601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 1604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.0651 - val_dice_coef: 0.0651\n",
      "Epoch 1605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 1606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8809 - dice_coef: 0.8809 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 1608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.8713 - val_dice_coef: 0.8713\n",
      "Epoch 1609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8924 - dice_coef: 0.8924 - val_loss: -0.9309 - val_dice_coef: 0.9309\n",
      "Epoch 1613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 1614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.8763 - val_dice_coef: 0.8763\n",
      "Epoch 1616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 1618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 1620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 1621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8843 - dice_coef: 0.8843 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.4770 - val_dice_coef: 0.4770\n",
      "Epoch 1631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.9613 - val_dice_coef: 0.9613\n",
      "Epoch 1632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9713 - val_dice_coef: 0.9713\n",
      "Epoch 1634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 1635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8920 - dice_coef: 0.8920 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 1639/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8924 - dice_coef: 0.8924 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 1646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9299 - val_dice_coef: 0.9299\n",
      "Epoch 1647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9878 - val_dice_coef: 0.9878\n",
      "Epoch 1649/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 1650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9784 - val_dice_coef: 0.9784\n",
      "Epoch 1651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 1652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 1655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9644 - val_dice_coef: 0.9644\n",
      "Epoch 1659/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 1660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9716 - val_dice_coef: 0.9716\n",
      "Epoch 1661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 1662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9715 - val_dice_coef: 0.9715\n",
      "Epoch 1665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.7468 - val_dice_coef: 0.7468\n",
      "Epoch 1666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.5739 - val_dice_coef: 0.5739\n",
      "Epoch 1667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8676 - dice_coef: 0.8676 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8680 - dice_coef: 0.8680 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8694 - dice_coef: 0.8694 - val_loss: -0.8318 - val_dice_coef: 0.8318\n",
      "Epoch 1670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.1576 - val_dice_coef: 0.1576\n",
      "Epoch 1671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8592 - dice_coef: 0.8592 - val_loss: -0.5521 - val_dice_coef: 0.5521\n",
      "Epoch 1672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.5260 - val_dice_coef: 0.5260\n",
      "Epoch 1674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.8793 - val_dice_coef: 0.8793\n",
      "Epoch 1677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9944 - val_dice_coef: 0.9944\n",
      "Epoch 1679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9348 - val_dice_coef: 0.9348\n",
      "Epoch 1680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 1681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8935 - dice_coef: 0.8935 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 1684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8958 - dice_coef: 0.8958 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 1685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9341 - val_dice_coef: 0.9341\n",
      "Epoch 1688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9782 - val_dice_coef: 0.9782\n",
      "Epoch 1690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 1691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9905 - val_dice_coef: 0.9905\n",
      "Epoch 1692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1694/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9083 - val_dice_coef: 0.9083\n",
      "Epoch 1699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8951 - dice_coef: 0.8951 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 1700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 1703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1704/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 1708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 1709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9008 - dice_coef: 0.9008 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9001 - dice_coef: 0.9001 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9852 - val_dice_coef: 0.9852\n",
      "Epoch 1715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9847 - val_dice_coef: 0.9847\n",
      "Epoch 1716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9677 - val_dice_coef: 0.9677\n",
      "Epoch 1721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.7673 - val_dice_coef: 0.7673\n",
      "Epoch 1722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.9616 - val_dice_coef: 0.9616\n",
      "Epoch 1723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9504 - val_dice_coef: 0.9504\n",
      "Epoch 1727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.8598 - val_dice_coef: 0.8598\n",
      "Epoch 1728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 1729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8903 - dice_coef: 0.8903 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9930 - val_dice_coef: 0.9930\n",
      "Epoch 1732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9200 - val_dice_coef: 0.9200\n",
      "Epoch 1733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8996 - dice_coef: 0.8996 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 1738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8996 - dice_coef: 0.8996 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8981 - dice_coef: 0.8981 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8969 - dice_coef: 0.8969 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 1745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 1746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8970 - dice_coef: 0.8970 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 1748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1749/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 1753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9865 - val_dice_coef: 0.9865\n",
      "Epoch 1754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9000 - dice_coef: 0.9000 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 1759/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8883 - dice_coef: 0.8883 - val_loss: -0.3491 - val_dice_coef: 0.3491\n",
      "Epoch 1760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8696 - dice_coef: 0.8696 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8764 - dice_coef: 0.8764 - val_loss: -0.9459 - val_dice_coef: 0.9459\n",
      "Epoch 1763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.3883 - val_dice_coef: 0.3883\n",
      "Epoch 1764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8882 - dice_coef: 0.8882 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9517 - val_dice_coef: 0.9517\n",
      "Epoch 1768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8930 - dice_coef: 0.8930 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1769/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 1771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9906 - val_dice_coef: 0.9906\n",
      "Epoch 1772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8914 - dice_coef: 0.8914 - val_loss: -0.9747 - val_dice_coef: 0.9747\n",
      "Epoch 1774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9855 - val_dice_coef: 0.9855\n",
      "Epoch 1775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9271 - val_dice_coef: 0.9271\n",
      "Epoch 1779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.7942 - val_dice_coef: 0.7942\n",
      "Epoch 1780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.7378 - val_dice_coef: 0.7378\n",
      "Epoch 1783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.8769 - val_dice_coef: 0.8769\n",
      "Epoch 1784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9462 - val_dice_coef: 0.9462\n",
      "Epoch 1788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.9004 - val_dice_coef: 0.9004\n",
      "Epoch 1789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.8421 - val_dice_coef: 0.8421\n",
      "Epoch 1792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 1796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 1800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1804/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9086 - val_dice_coef: 0.9086\n",
      "Epoch 1805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.8330 - val_dice_coef: 0.8330\n",
      "Epoch 1806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9029 - val_dice_coef: 0.9029\n",
      "Epoch 1809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8934 - dice_coef: 0.8934 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 1810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.8401 - val_dice_coef: 0.8401\n",
      "Epoch 1813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9761 - val_dice_coef: 0.9761\n",
      "Epoch 1814/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 1821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 1822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8930 - dice_coef: 0.8930 - val_loss: -0.6426 - val_dice_coef: 0.6426\n",
      "Epoch 1826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9610 - val_dice_coef: 0.9610\n",
      "Epoch 1827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8910 - dice_coef: 0.8910 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.7763 - val_dice_coef: 0.7763\n",
      "Epoch 1830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.7866 - val_dice_coef: 0.7866\n",
      "Epoch 1834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9697 - val_dice_coef: 0.9697\n",
      "Epoch 1839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.9662 - val_dice_coef: 0.9662\n",
      "Epoch 1842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9009 - dice_coef: 0.9009 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 1846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 1849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9014 - dice_coef: 0.9014 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 1859/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "Epoch 1860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9030 - dice_coef: 0.9030 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 1864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 1865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9025 - dice_coef: 0.9025 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8992 - dice_coef: 0.8992 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1869/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8931 - dice_coef: 0.8931 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 1871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.5848 - val_dice_coef: 0.5848\n",
      "Epoch 1872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.7944 - val_dice_coef: 0.7944\n",
      "Epoch 1876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9835 - val_dice_coef: 0.9835\n",
      "Epoch 1877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 1879/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9046 - dice_coef: 0.9046 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.8094 - val_dice_coef: 0.8094\n",
      "Epoch 1883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.7506 - val_dice_coef: 0.7506\n",
      "Epoch 1884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9655 - val_dice_coef: 0.9655\n",
      "Epoch 1887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.9596 - val_dice_coef: 0.9596\n",
      "Epoch 1888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9808 - val_dice_coef: 0.9808\n",
      "Epoch 1891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9312 - val_dice_coef: 0.9312\n",
      "Epoch 1892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9297 - val_dice_coef: 0.9297\n",
      "Epoch 1893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9009 - dice_coef: 0.9009 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 1895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 1896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 1897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 1898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.8928 - val_dice_coef: 0.8928\n",
      "Epoch 1900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.7940 - val_dice_coef: 0.7940\n",
      "Epoch 1901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.1956 - val_dice_coef: 0.1956\n",
      "Epoch 1904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8806 - dice_coef: 0.8806 - val_loss: -0.8431 - val_dice_coef: 0.8431\n",
      "Epoch 1905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8834 - dice_coef: 0.8834 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8751 - dice_coef: 0.8751 - val_loss: -0.4669 - val_dice_coef: 0.4669\n",
      "Epoch 1907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.0583 - val_dice_coef: 0.0583\n",
      "Epoch 1908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8623 - dice_coef: 0.8623 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8566 - dice_coef: 0.8566 - val_loss: -0.6860 - val_dice_coef: 0.6860\n",
      "Epoch 1910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8841 - dice_coef: 0.8841 - val_loss: -0.6182 - val_dice_coef: 0.6182\n",
      "Epoch 1911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8912 - dice_coef: 0.8912 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 1913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8914 - dice_coef: 0.8914 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1914/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8970 - dice_coef: 0.8970 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 1916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9619 - val_dice_coef: 0.9619\n",
      "Epoch 1919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 1922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 1923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1924/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8939 - dice_coef: 0.8939 - val_loss: -0.6276 - val_dice_coef: 0.6276\n",
      "Epoch 1926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.3067 - val_dice_coef: 0.3067\n",
      "Epoch 1929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.4411 - val_dice_coef: 0.4411\n",
      "Epoch 1932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8760 - dice_coef: 0.8760 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 1933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8610 - dice_coef: 0.8610 - val_loss: -0.4877 - val_dice_coef: 0.4877\n",
      "Epoch 1935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 1936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8883 - dice_coef: 0.8883 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9485 - val_dice_coef: 0.9485\n",
      "Epoch 1938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8948 - dice_coef: 0.8948 - val_loss: -0.9521 - val_dice_coef: 0.9521\n",
      "Epoch 1939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.9690 - val_dice_coef: 0.9690\n",
      "Epoch 1942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 1947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 1948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 1950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9722 - val_dice_coef: 0.9722\n",
      "Epoch 1951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9008 - dice_coef: 0.9008 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9876 - val_dice_coef: 0.9876\n",
      "Epoch 1954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 1955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9396 - val_dice_coef: 0.9396\n",
      "Epoch 1958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 1959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9052 - dice_coef: 0.9052 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 1961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9805 - val_dice_coef: 0.9805\n",
      "Epoch 1962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9029 - dice_coef: 0.9029 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 1967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 1968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1969/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9753 - val_dice_coef: 0.9753\n",
      "Epoch 1971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 1978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9037 - dice_coef: 0.9037 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1979/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 1980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.8670 - val_dice_coef: 0.8670\n",
      "Epoch 1981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.8830 - val_dice_coef: 0.8830\n",
      "Epoch 1982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.9545 - val_dice_coef: 0.9545\n",
      "Epoch 1986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 1987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 1989/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 1995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9783 - val_dice_coef: 0.9783\n",
      "Epoch 1996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8885 - dice_coef: 0.8885 - val_loss: -0.9682 - val_dice_coef: 0.9682\n",
      "Epoch 1998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.2416 - val_dice_coef: 0.2416\n",
      "Epoch 1999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 2000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9014 - dice_coef: 0.9014 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2001/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.7513 - val_dice_coef: 0.7513\n",
      "Epoch 2002/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.8799 - val_dice_coef: 0.8799\n",
      "Epoch 2003/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2004/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2005/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9047 - dice_coef: 0.9047 - val_loss: -0.9774 - val_dice_coef: 0.9774\n",
      "Epoch 2006/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9044 - dice_coef: 0.9044 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2007/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2008/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2009/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2010/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9712 - val_dice_coef: 0.9712\n",
      "Epoch 2011/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2012/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2013/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2014/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2015/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9602 - val_dice_coef: 0.9602\n",
      "Epoch 2016/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 2017/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2018/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2019/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2020/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 2021/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2022/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.9562 - val_dice_coef: 0.9562\n",
      "Epoch 2023/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9831 - val_dice_coef: 0.9831\n",
      "Epoch 2024/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9445 - val_dice_coef: 0.9445\n",
      "Epoch 2025/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9607 - val_dice_coef: 0.9607\n",
      "Epoch 2026/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2027/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9814 - val_dice_coef: 0.9814\n",
      "Epoch 2028/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9624 - val_dice_coef: 0.9624\n",
      "Epoch 2029/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2030/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2031/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2032/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8233 - val_dice_coef: 0.8233\n",
      "Epoch 2033/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.0927 - val_dice_coef: 0.0927\n",
      "Epoch 2034/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2035/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2036/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.3486 - val_dice_coef: 0.3486\n",
      "Epoch 2037/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 2038/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2039/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2040/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.8120 - val_dice_coef: 0.8120\n",
      "Epoch 2041/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2042/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2043/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2044/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 2045/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.7585 - val_dice_coef: 0.7585\n",
      "Epoch 2046/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9634 - val_dice_coef: 0.9634\n",
      "Epoch 2047/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2048/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2049/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9001 - dice_coef: 0.9001 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2050/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9299 - val_dice_coef: 0.9299\n",
      "Epoch 2051/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.7435 - val_dice_coef: 0.7435\n",
      "Epoch 2052/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 2053/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2054/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 2055/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "Epoch 2056/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8979 - dice_coef: 0.8979 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2057/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2058/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.0455 - val_dice_coef: 0.0455\n",
      "Epoch 2059/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 2060/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2061/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 2062/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.8678 - val_dice_coef: 0.8678\n",
      "Epoch 2063/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2064/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2065/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.6703 - val_dice_coef: 0.6703\n",
      "Epoch 2066/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2067/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2068/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.6828 - val_dice_coef: 0.6828\n",
      "Epoch 2069/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8999 - dice_coef: 0.8999 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2070/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2071/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.6301 - val_dice_coef: 0.6301\n",
      "Epoch 2072/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2073/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 2074/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.3043 - val_dice_coef: 0.3043\n",
      "Epoch 2075/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2076/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2077/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.7334 - val_dice_coef: 0.7334\n",
      "Epoch 2078/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 2079/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2080/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8992 - dice_coef: 0.8992 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2081/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.7743 - val_dice_coef: 0.7743\n",
      "Epoch 2082/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.9696 - val_dice_coef: 0.9696\n",
      "Epoch 2083/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9059 - dice_coef: 0.9059 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2084/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.8784 - val_dice_coef: 0.8784\n",
      "Epoch 2085/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.6214 - val_dice_coef: 0.6214\n",
      "Epoch 2086/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2087/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 2088/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.7279 - val_dice_coef: 0.7279\n",
      "Epoch 2089/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.8486 - val_dice_coef: 0.8486\n",
      "Epoch 2090/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2091/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2092/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.5195 - val_dice_coef: 0.5195\n",
      "Epoch 2093/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9506 - val_dice_coef: 0.9506\n",
      "Epoch 2094/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2095/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.6622 - val_dice_coef: 0.6622\n",
      "Epoch 2096/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9161 - val_dice_coef: 0.9161\n",
      "Epoch 2097/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9048 - dice_coef: 0.9048 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2098/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2099/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.4942 - val_dice_coef: 0.4942\n",
      "Epoch 2100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8958 - dice_coef: 0.8958 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.0474 - val_dice_coef: 0.0474\n",
      "Epoch 2103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8718 - dice_coef: 0.8718 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9472 - val_dice_coef: 0.9472\n",
      "Epoch 2105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.0916 - val_dice_coef: 0.0916\n",
      "Epoch 2106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8903 - dice_coef: 0.8903 - val_loss: -0.9310 - val_dice_coef: 0.9310\n",
      "Epoch 2108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9342 - val_dice_coef: 0.9342\n",
      "Epoch 2109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.2731 - val_dice_coef: 0.2731\n",
      "Epoch 2111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.8293 - val_dice_coef: 0.8293\n",
      "Epoch 2114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9751 - val_dice_coef: 0.9751\n",
      "Epoch 2115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "Epoch 2117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9895 - val_dice_coef: 0.9895\n",
      "Epoch 2118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9381 - val_dice_coef: 0.9381\n",
      "Epoch 2120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.9411 - val_dice_coef: 0.9411\n",
      "Epoch 2123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.6858 - val_dice_coef: 0.6858\n",
      "Epoch 2124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.7141 - val_dice_coef: 0.7141\n",
      "Epoch 2126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.8951 - val_dice_coef: 0.8951\n",
      "Epoch 2127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.8321 - val_dice_coef: 0.8321\n",
      "Epoch 2129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 2130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9442 - val_dice_coef: 0.9442\n",
      "Epoch 2132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 2134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9257 - val_dice_coef: 0.9257\n",
      "Epoch 2135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9563 - val_dice_coef: 0.9563\n",
      "Epoch 2138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9310 - val_dice_coef: 0.9310\n",
      "Epoch 2141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9590 - val_dice_coef: 0.9590\n",
      "Epoch 2142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2144/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9518 - val_dice_coef: 0.9518\n",
      "Epoch 2145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9400 - val_dice_coef: 0.9400\n",
      "Epoch 2146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 2150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 2151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9562 - val_dice_coef: 0.9562\n",
      "Epoch 2152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 2154/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 2155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9573 - val_dice_coef: 0.9573\n",
      "Epoch 2156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 2157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 2158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9833 - val_dice_coef: 0.9833\n",
      "Epoch 2160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.6026 - val_dice_coef: 0.6026\n",
      "Epoch 2161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.6253 - val_dice_coef: 0.6253\n",
      "Epoch 2162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 2163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9053 - dice_coef: 0.9053 - val_loss: -0.9454 - val_dice_coef: 0.9454\n",
      "Epoch 2166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.8475 - val_dice_coef: 0.8475\n",
      "Epoch 2167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.9166 - val_dice_coef: 0.9166\n",
      "Epoch 2170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.6904 - val_dice_coef: 0.6904\n",
      "Epoch 2171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9470 - val_dice_coef: 0.9470\n",
      "Epoch 2172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9489 - val_dice_coef: 0.9489\n",
      "Epoch 2174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 2175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9062 - dice_coef: 0.9062 - val_loss: -0.8374 - val_dice_coef: 0.8374\n",
      "Epoch 2178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.6803 - val_dice_coef: 0.6803\n",
      "Epoch 2179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.9183 - val_dice_coef: 0.9183\n",
      "Epoch 2180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9088 - dice_coef: 0.9088 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 2181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9816 - val_dice_coef: 0.9816\n",
      "Epoch 2182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 2183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9761 - val_dice_coef: 0.9761\n",
      "Epoch 2185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 2186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 2187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 2188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 2190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9784 - val_dice_coef: 0.9784\n",
      "Epoch 2191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 2192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9600 - val_dice_coef: 0.9600\n",
      "Epoch 2193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9814 - val_dice_coef: 0.9814\n",
      "Epoch 2194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.4542 - val_dice_coef: 0.4542\n",
      "Epoch 2197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.1773 - val_dice_coef: 0.1773\n",
      "Epoch 2198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 2199/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9010 - dice_coef: 0.9010 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 2201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.0938 - val_dice_coef: 0.0938\n",
      "Epoch 2202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8848 - dice_coef: 0.8848 - val_loss: -0.9051 - val_dice_coef: 0.9051\n",
      "Epoch 2204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8954 - dice_coef: 0.8954 - val_loss: -0.1643 - val_dice_coef: 0.1643\n",
      "Epoch 2205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 2207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9123 - val_dice_coef: 0.9123\n",
      "Epoch 2208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2209/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 2210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 2211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9094 - dice_coef: 0.9094 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 2213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.7664 - val_dice_coef: 0.7664\n",
      "Epoch 2214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.7833 - val_dice_coef: 0.7833\n",
      "Epoch 2217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9089 - dice_coef: 0.9089 - val_loss: -0.9804 - val_dice_coef: 0.9804\n",
      "Epoch 2218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2219/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9089 - dice_coef: 0.9089 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9301 - val_dice_coef: 0.9301\n",
      "Epoch 2221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.5832 - val_dice_coef: 0.5832\n",
      "Epoch 2222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9064 - dice_coef: 0.9064 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9178 - val_dice_coef: 0.9178\n",
      "Epoch 2225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.8188 - val_dice_coef: 0.8188\n",
      "Epoch 2226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9806 - val_dice_coef: 0.9806\n",
      "Epoch 2227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 2228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9689 - val_dice_coef: 0.9689\n",
      "Epoch 2229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 2232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 2234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9120 - val_dice_coef: 0.9120\n",
      "Epoch 2235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.8574 - val_dice_coef: 0.8574\n",
      "Epoch 2236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.6431 - val_dice_coef: 0.6431\n",
      "Epoch 2237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 2240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.9571 - val_dice_coef: 0.9571\n",
      "Epoch 2241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 2242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9239 - val_dice_coef: 0.9239\n",
      "Epoch 2243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 2244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9133 - dice_coef: 0.9133 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9028 - val_dice_coef: 0.9028\n",
      "Epoch 2246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.9756 - val_dice_coef: 0.9756\n",
      "Epoch 2247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 2249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9026 - val_dice_coef: 0.9026\n",
      "Epoch 2250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.6725 - val_dice_coef: 0.6725\n",
      "Epoch 2251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9062 - val_dice_coef: 0.9062\n",
      "Epoch 2252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 2254/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9481 - val_dice_coef: 0.9481\n",
      "Epoch 2255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 2258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9205 - val_dice_coef: 0.9205\n",
      "Epoch 2260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.8805 - val_dice_coef: 0.8805\n",
      "Epoch 2261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9302 - val_dice_coef: 0.9302\n",
      "Epoch 2263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9021 - val_dice_coef: 0.9021\n",
      "Epoch 2264/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9340 - val_dice_coef: 0.9340\n",
      "Epoch 2265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 2266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 2267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9082 - val_dice_coef: 0.9082\n",
      "Epoch 2268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.5658 - val_dice_coef: 0.5658\n",
      "Epoch 2269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.7773 - val_dice_coef: 0.7773\n",
      "Epoch 2272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9052 - dice_coef: 0.9052 - val_loss: -0.6216 - val_dice_coef: 0.6216\n",
      "Epoch 2273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.9831 - val_dice_coef: 0.9831\n",
      "Epoch 2274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.8679 - val_dice_coef: 0.8679\n",
      "Epoch 2276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.3709 - val_dice_coef: 0.3709\n",
      "Epoch 2277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.7028 - val_dice_coef: 0.7028\n",
      "Epoch 2278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 2280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.8944 - val_dice_coef: 0.8944\n",
      "Epoch 2281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.8804 - val_dice_coef: 0.8804\n",
      "Epoch 2286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.4114 - val_dice_coef: 0.4114\n",
      "Epoch 2287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9617 - val_dice_coef: 0.9617\n",
      "Epoch 2288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9088 - dice_coef: 0.9088 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.7745 - val_dice_coef: 0.7745\n",
      "Epoch 2291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9046 - dice_coef: 0.9046 - val_loss: -0.2139 - val_dice_coef: 0.2139\n",
      "Epoch 2292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 2293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.8347 - val_dice_coef: 0.8347\n",
      "Epoch 2295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9288 - val_dice_coef: 0.9288\n",
      "Epoch 2296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9366 - val_dice_coef: 0.9366\n",
      "Epoch 2297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9793 - val_dice_coef: 0.9793\n",
      "Epoch 2298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9966 - val_dice_coef: 0.9966\n",
      "Epoch 2300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9266 - val_dice_coef: 0.9266\n",
      "Epoch 2301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.5115 - val_dice_coef: 0.5115\n",
      "Epoch 2302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 2303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9819 - val_dice_coef: 0.9819\n",
      "Epoch 2305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.7982 - val_dice_coef: 0.7982\n",
      "Epoch 2306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9093 - dice_coef: 0.9093 - val_loss: -0.6480 - val_dice_coef: 0.6480\n",
      "Epoch 2307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2309/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.5058 - val_dice_coef: 0.5058\n",
      "Epoch 2310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.6644 - val_dice_coef: 0.6644\n",
      "Epoch 2311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.4163 - val_dice_coef: 0.4163\n",
      "Epoch 2314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.3054 - val_dice_coef: 0.3054\n",
      "Epoch 2315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.9825 - val_dice_coef: 0.9825\n",
      "Epoch 2317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.4694 - val_dice_coef: 0.4694\n",
      "Epoch 2318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.9431 - val_dice_coef: 0.9431\n",
      "Epoch 2319/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9846 - val_dice_coef: 0.9846\n",
      "Epoch 2321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 2322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9565 - val_dice_coef: 0.9565\n",
      "Epoch 2323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.2464 - val_dice_coef: 0.2464\n",
      "Epoch 2324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9622 - val_dice_coef: 0.9622\n",
      "Epoch 2325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9629 - val_dice_coef: 0.9629\n",
      "Epoch 2327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.2290 - val_dice_coef: 0.2290\n",
      "Epoch 2328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8977 - dice_coef: 0.8977 - val_loss: -0.9703 - val_dice_coef: 0.9703\n",
      "Epoch 2329/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9872 - val_dice_coef: 0.9872\n",
      "Epoch 2331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.4349 - val_dice_coef: 0.4349\n",
      "Epoch 2332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.8048 - val_dice_coef: 0.8048\n",
      "Epoch 2333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8969 - dice_coef: 0.8969 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 2335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.6067 - val_dice_coef: 0.6067\n",
      "Epoch 2336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9059 - dice_coef: 0.9059 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 2337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9061 - dice_coef: 0.9061 - val_loss: -0.9525 - val_dice_coef: 0.9525\n",
      "Epoch 2339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.4830 - val_dice_coef: 0.4830\n",
      "Epoch 2340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9852 - val_dice_coef: 0.9852\n",
      "Epoch 2341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9791 - val_dice_coef: 0.9791\n",
      "Epoch 2343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.8013 - val_dice_coef: 0.8013\n",
      "Epoch 2344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 2346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9789 - val_dice_coef: 0.9789\n",
      "Epoch 2347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.7830 - val_dice_coef: 0.7830\n",
      "Epoch 2348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9232 - val_dice_coef: 0.9232\n",
      "Epoch 2349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9580 - val_dice_coef: 0.9580\n",
      "Epoch 2350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9480 - val_dice_coef: 0.9480\n",
      "Epoch 2351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9031 - val_dice_coef: 0.9031\n",
      "Epoch 2352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 2353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9660 - val_dice_coef: 0.9660\n",
      "Epoch 2356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 2357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 2358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 2359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9811 - val_dice_coef: 0.9811\n",
      "Epoch 2360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9651 - val_dice_coef: 0.9651\n",
      "Epoch 2361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9843 - val_dice_coef: 0.9843\n",
      "Epoch 2362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9917 - val_dice_coef: 0.9917\n",
      "Epoch 2364/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9901 - val_dice_coef: 0.9901\n",
      "Epoch 2367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9768 - val_dice_coef: 0.9768\n",
      "Epoch 2370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.8090 - val_dice_coef: 0.8090\n",
      "Epoch 2371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.2923 - val_dice_coef: 0.2923\n",
      "Epoch 2372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2374/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.4193 - val_dice_coef: 0.4193\n",
      "Epoch 2375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8951 - dice_coef: 0.8951 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 2376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.5547 - val_dice_coef: 0.5547\n",
      "Epoch 2378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.0490 - val_dice_coef: 0.0490\n",
      "Epoch 2379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.0556 - val_dice_coef: 0.0556\n",
      "Epoch 2381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 2383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 2384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9010 - dice_coef: 0.9010 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9729 - val_dice_coef: 0.9729\n",
      "Epoch 2386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.6195 - val_dice_coef: 0.6195\n",
      "Epoch 2387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.9684 - val_dice_coef: 0.9684\n",
      "Epoch 2389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9320 - val_dice_coef: 0.9320\n",
      "Epoch 2390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.5473 - val_dice_coef: 0.5473\n",
      "Epoch 2393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9727 - val_dice_coef: 0.9727\n",
      "Epoch 2394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9716 - val_dice_coef: 0.9716\n",
      "Epoch 2396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 2398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9745 - val_dice_coef: 0.9745\n",
      "Epoch 2400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9131 - dice_coef: 0.9131 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 2405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 2406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 2407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 2408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9826 - val_dice_coef: 0.9826\n",
      "Epoch 2409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9905 - val_dice_coef: 0.9905\n",
      "Epoch 2412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9138 - dice_coef: 0.9138 - val_loss: -0.7774 - val_dice_coef: 0.7774\n",
      "Epoch 2413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9553 - val_dice_coef: 0.9553\n",
      "Epoch 2417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2419/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9930 - val_dice_coef: 0.9930\n",
      "Epoch 2420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 2421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.8831 - val_dice_coef: 0.8831\n",
      "Epoch 2422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 2423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.9650 - val_dice_coef: 0.9650\n",
      "Epoch 2426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.7634 - val_dice_coef: 0.7634\n",
      "Epoch 2427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9733 - val_dice_coef: 0.9733\n",
      "Epoch 2428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2429/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 2431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "Epoch 2432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.6367 - val_dice_coef: 0.6367\n",
      "Epoch 2433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9871 - val_dice_coef: 0.9871\n",
      "Epoch 2434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 2436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.7614 - val_dice_coef: 0.7614\n",
      "Epoch 2437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.6913 - val_dice_coef: 0.6913\n",
      "Epoch 2438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 2439/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.6776 - val_dice_coef: 0.6776\n",
      "Epoch 2443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.1864 - val_dice_coef: 0.1864\n",
      "Epoch 2444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9498 - val_dice_coef: 0.9498\n",
      "Epoch 2447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9039 - val_dice_coef: 0.9039\n",
      "Epoch 2448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.7625 - val_dice_coef: 0.7625\n",
      "Epoch 2449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.7575 - val_dice_coef: 0.7575\n",
      "Epoch 2450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 2453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9336 - val_dice_coef: 0.9336\n",
      "Epoch 2454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.5875 - val_dice_coef: 0.5875\n",
      "Epoch 2458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.3099 - val_dice_coef: 0.3099\n",
      "Epoch 2459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9698 - val_dice_coef: 0.9698\n",
      "Epoch 2460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9670 - val_dice_coef: 0.9670\n",
      "Epoch 2462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.3318 - val_dice_coef: 0.3318\n",
      "Epoch 2463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.4738 - val_dice_coef: 0.4738\n",
      "Epoch 2464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.6963 - val_dice_coef: 0.6963\n",
      "Epoch 2466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.2105 - val_dice_coef: 0.2105\n",
      "Epoch 2467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 2469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.6050 - val_dice_coef: 0.6050\n",
      "Epoch 2470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 2472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.8910 - val_dice_coef: 0.8910\n",
      "Epoch 2473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.6591 - val_dice_coef: 0.6591\n",
      "Epoch 2474/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.3696 - val_dice_coef: 0.3696\n",
      "Epoch 2477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.4352 - val_dice_coef: 0.4352\n",
      "Epoch 2478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9402 - val_dice_coef: 0.9402\n",
      "Epoch 2481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.3410 - val_dice_coef: 0.3410\n",
      "Epoch 2482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 2483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2484/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.1221 - val_dice_coef: 0.1221\n",
      "Epoch 2485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.8153 - val_dice_coef: 0.8153\n",
      "Epoch 2488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9361 - val_dice_coef: 0.9361\n",
      "Epoch 2491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 2494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.8146 - val_dice_coef: 0.8146\n",
      "Epoch 2495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9127 - val_dice_coef: 0.9127\n",
      "Epoch 2498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.3409 - val_dice_coef: 0.3409\n",
      "Epoch 2499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9138 - val_dice_coef: 0.9138\n",
      "Epoch 2501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.5536 - val_dice_coef: 0.5536\n",
      "Epoch 2502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.2602 - val_dice_coef: 0.2602\n",
      "Epoch 2505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9884 - val_dice_coef: 0.9884\n",
      "Epoch 2507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.2527 - val_dice_coef: 0.2527\n",
      "Epoch 2508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 2509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -0.7993 - val_dice_coef: 0.7993\n",
      "Epoch 2511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.5294 - val_dice_coef: 0.5294\n",
      "Epoch 2512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 2514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.8441 - val_dice_coef: 0.8441\n",
      "Epoch 2515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9006 - val_dice_coef: 0.9006\n",
      "Epoch 2516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9769 - val_dice_coef: 0.9769\n",
      "Epoch 2517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9760 - val_dice_coef: 0.9760\n",
      "Epoch 2518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9511 - val_dice_coef: 0.9511\n",
      "Epoch 2521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8498 - val_dice_coef: 0.8498\n",
      "Epoch 2522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 2523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9138 - dice_coef: 0.9138 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 2525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9139 - dice_coef: 0.9139 - val_loss: -0.9584 - val_dice_coef: 0.9584\n",
      "Epoch 2526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9207 - val_dice_coef: 0.9207\n",
      "Epoch 2527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9138 - val_dice_coef: 0.9138\n",
      "Epoch 2528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2529/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 2530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 2531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9574 - val_dice_coef: 0.9574\n",
      "Epoch 2532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9499 - val_dice_coef: 0.9499\n",
      "Epoch 2534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 2535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9387 - val_dice_coef: 0.9387\n",
      "Epoch 2538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.7852 - val_dice_coef: 0.7852\n",
      "Epoch 2539/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.8365 - val_dice_coef: 0.8365\n",
      "Epoch 2540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 2541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.6630 - val_dice_coef: 0.6630\n",
      "Epoch 2543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.2535 - val_dice_coef: 0.2535\n",
      "Epoch 2544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.3855 - val_dice_coef: 0.3855\n",
      "Epoch 2546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.0618 - val_dice_coef: 0.0618\n",
      "Epoch 2547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.0220 - val_dice_coef: 0.0220\n",
      "Epoch 2549/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8882 - dice_coef: 0.8882 - val_loss: -0.1945 - val_dice_coef: 0.1945\n",
      "Epoch 2552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.0718 - val_dice_coef: 0.0718\n",
      "Epoch 2554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.8228 - val_dice_coef: 0.8228\n",
      "Epoch 2556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9731 - val_dice_coef: 0.9731\n",
      "Epoch 2557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9399 - val_dice_coef: 0.9399\n",
      "Epoch 2559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 2562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.8389 - val_dice_coef: 0.8389\n",
      "Epoch 2563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9534 - val_dice_coef: 0.9534\n",
      "Epoch 2566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9137 - dice_coef: 0.9137 - val_loss: -0.9694 - val_dice_coef: 0.9694\n",
      "Epoch 2567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 2570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9725 - val_dice_coef: 0.9725\n",
      "Epoch 2571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9186 - dice_coef: 0.9186 - val_loss: -0.9791 - val_dice_coef: 0.9791\n",
      "Epoch 2574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 2578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9523 - val_dice_coef: 0.9523\n",
      "Epoch 2579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9673 - val_dice_coef: 0.9673\n",
      "Epoch 2580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 2581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2584/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9705 - val_dice_coef: 0.9705\n",
      "Epoch 2585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.7353 - val_dice_coef: 0.7353\n",
      "Epoch 2586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 2589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9493 - val_dice_coef: 0.9493\n",
      "Epoch 2591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9382 - val_dice_coef: 0.9382\n",
      "Epoch 2592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9844 - val_dice_coef: 0.9844\n",
      "Epoch 2593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2594/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9159 - dice_coef: 0.9159 - val_loss: -0.9854 - val_dice_coef: 0.9854\n",
      "Epoch 2595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9117 - val_dice_coef: 0.9117\n",
      "Epoch 2596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 2597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9594 - val_dice_coef: 0.9594\n",
      "Epoch 2601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.8438 - val_dice_coef: 0.8438\n",
      "Epoch 2602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9817 - val_dice_coef: 0.9817\n",
      "Epoch 2606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9159 - dice_coef: 0.9159 - val_loss: -0.7647 - val_dice_coef: 0.7647\n",
      "Epoch 2607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8983 - val_dice_coef: 0.8983\n",
      "Epoch 2608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9884 - val_dice_coef: 0.9884\n",
      "Epoch 2609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9188 - dice_coef: 0.9188 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9389 - val_dice_coef: 0.9389\n",
      "Epoch 2612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9502 - val_dice_coef: 0.9502\n",
      "Epoch 2613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9673 - val_dice_coef: 0.9673\n",
      "Epoch 2614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 2615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.9213 - val_dice_coef: 0.9213\n",
      "Epoch 2618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.8335 - val_dice_coef: 0.8335\n",
      "Epoch 2619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 2620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9193 - dice_coef: 0.9193 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 2622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 2623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9428 - val_dice_coef: 0.9428\n",
      "Epoch 2624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9559 - val_dice_coef: 0.9559\n",
      "Epoch 2625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9580 - val_dice_coef: 0.9580\n",
      "Epoch 2626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 2627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 2631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9049 - val_dice_coef: 0.9049\n",
      "Epoch 2632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8991 - val_dice_coef: 0.8991\n",
      "Epoch 2633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9495 - val_dice_coef: 0.9495\n",
      "Epoch 2634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 2635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.2885 - val_dice_coef: 0.2885\n",
      "Epoch 2638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.2576 - val_dice_coef: 0.2576\n",
      "Epoch 2639/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9048 - dice_coef: 0.9048 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9642 - val_dice_coef: 0.9642\n",
      "Epoch 2642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.8795 - val_dice_coef: 0.8795\n",
      "Epoch 2643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9816 - val_dice_coef: 0.9816\n",
      "Epoch 2644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.7112 - val_dice_coef: 0.7112\n",
      "Epoch 2647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.7026 - val_dice_coef: 0.7026\n",
      "Epoch 2648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.7975 - val_dice_coef: 0.7975\n",
      "Epoch 2649/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9131 - dice_coef: 0.9131 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 2652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9450 - val_dice_coef: 0.9450\n",
      "Epoch 2653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9080 - val_dice_coef: 0.9080\n",
      "Epoch 2654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9741 - val_dice_coef: 0.9741\n",
      "Epoch 2655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 2656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 2657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9289 - val_dice_coef: 0.9289\n",
      "Epoch 2658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 2659/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 2661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9839 - val_dice_coef: 0.9839\n",
      "Epoch 2662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.8275 - val_dice_coef: 0.8275\n",
      "Epoch 2664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.7169 - val_dice_coef: 0.7169\n",
      "Epoch 2665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9956 - val_dice_coef: 0.9956\n",
      "Epoch 2668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9465 - val_dice_coef: 0.9465\n",
      "Epoch 2670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.6517 - val_dice_coef: 0.6517\n",
      "Epoch 2671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.6271 - val_dice_coef: 0.6271\n",
      "Epoch 2672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 2675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9111 - dice_coef: 0.9111 - val_loss: -0.8553 - val_dice_coef: 0.8553\n",
      "Epoch 2676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.6418 - val_dice_coef: 0.6418\n",
      "Epoch 2677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9451 - val_dice_coef: 0.9451\n",
      "Epoch 2678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9378 - val_dice_coef: 0.9378\n",
      "Epoch 2679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9139 - dice_coef: 0.9139 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9474 - val_dice_coef: 0.9474\n",
      "Epoch 2684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9631 - val_dice_coef: 0.9631\n",
      "Epoch 2686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9537 - val_dice_coef: 0.9537\n",
      "Epoch 2687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 2688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9706 - val_dice_coef: 0.9706\n",
      "Epoch 2689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2694/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9513 - val_dice_coef: 0.9513\n",
      "Epoch 2695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.8110 - val_dice_coef: 0.8110\n",
      "Epoch 2696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9871 - val_dice_coef: 0.9871\n",
      "Epoch 2697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 2700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 2701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9530 - val_dice_coef: 0.9530\n",
      "Epoch 2704/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9678 - val_dice_coef: 0.9678\n",
      "Epoch 2705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9263 - val_dice_coef: 0.9263\n",
      "Epoch 2707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9615 - val_dice_coef: 0.9615\n",
      "Epoch 2708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9825 - val_dice_coef: 0.9825\n",
      "Epoch 2709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9718 - val_dice_coef: 0.9718\n",
      "Epoch 2710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9606 - val_dice_coef: 0.9606\n",
      "Epoch 2711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9210 - dice_coef: 0.9210 - val_loss: -0.9876 - val_dice_coef: 0.9876\n",
      "Epoch 2712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.9686 - val_dice_coef: 0.9686\n",
      "Epoch 2713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.9230 - val_dice_coef: 0.9230\n",
      "Epoch 2714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.6055 - val_dice_coef: 0.6055\n",
      "Epoch 2715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.7039 - val_dice_coef: 0.7039\n",
      "Epoch 2716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 2717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 2718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9753 - val_dice_coef: 0.9753\n",
      "Epoch 2719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9210 - dice_coef: 0.9210 - val_loss: -0.9767 - val_dice_coef: 0.9767\n",
      "Epoch 2720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 2721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9204 - dice_coef: 0.9204 - val_loss: -0.9916 - val_dice_coef: 0.9916\n",
      "Epoch 2722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9181 - dice_coef: 0.9181 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9895 - val_dice_coef: 0.9895\n",
      "Epoch 2725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 2726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9553 - val_dice_coef: 0.9553\n",
      "Epoch 2727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 2728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.5576 - val_dice_coef: 0.5576\n",
      "Epoch 2730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.0683 - val_dice_coef: 0.0683\n",
      "Epoch 2731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9944 - val_dice_coef: 0.9944\n",
      "Epoch 2733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.2141 - val_dice_coef: 0.2141\n",
      "Epoch 2734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.5150 - val_dice_coef: 0.5150\n",
      "Epoch 2735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.9897 - val_dice_coef: 0.9897\n",
      "Epoch 2737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.4916 - val_dice_coef: 0.4916\n",
      "Epoch 2738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 2739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9206 - dice_coef: 0.9206 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 2740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9186 - dice_coef: 0.9186 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 2741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9199 - dice_coef: 0.9199 - val_loss: -0.9775 - val_dice_coef: 0.9775\n",
      "Epoch 2742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 2744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9773 - val_dice_coef: 0.9773\n",
      "Epoch 2748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9449 - val_dice_coef: 0.9449\n",
      "Epoch 2749/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.6856 - val_dice_coef: 0.6856\n",
      "Epoch 2750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.1605 - val_dice_coef: 0.1605\n",
      "Epoch 2751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9913 - val_dice_coef: 0.9913\n",
      "Epoch 2753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.1673 - val_dice_coef: 0.1673\n",
      "Epoch 2754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 2755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.8341 - val_dice_coef: 0.8341\n",
      "Epoch 2757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.3254 - val_dice_coef: 0.3254\n",
      "Epoch 2758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 2759/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 2760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.6873 - val_dice_coef: 0.6873\n",
      "Epoch 2761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.2790 - val_dice_coef: 0.2790\n",
      "Epoch 2762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.8434 - val_dice_coef: 0.8434\n",
      "Epoch 2765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.6315 - val_dice_coef: 0.6315\n",
      "Epoch 2766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.8974 - val_dice_coef: 0.8974\n",
      "Epoch 2767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9656 - val_dice_coef: 0.9656\n",
      "Epoch 2769/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 2770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9206 - dice_coef: 0.9206 - val_loss: -0.8701 - val_dice_coef: 0.8701\n",
      "Epoch 2771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 2772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 2773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.8602 - val_dice_coef: 0.8602\n",
      "Epoch 2774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.9125 - val_dice_coef: 0.9125\n",
      "Epoch 2775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 2776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9193 - dice_coef: 0.9193 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 2777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9188 - dice_coef: 0.9188 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9551 - val_dice_coef: 0.9551\n",
      "Epoch 2780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 2781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.8195 - val_dice_coef: 0.8195\n",
      "Epoch 2782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.8337 - val_dice_coef: 0.8337\n",
      "Epoch 2783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9586 - val_dice_coef: 0.9586\n",
      "Epoch 2784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.8526 - val_dice_coef: 0.8526\n",
      "Epoch 2785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9293 - val_dice_coef: 0.9293\n",
      "Epoch 2786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 2787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9813 - val_dice_coef: 0.9813\n",
      "Epoch 2788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 2789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9026 - val_dice_coef: 0.9026\n",
      "Epoch 2790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.8888 - val_dice_coef: 0.8888\n",
      "Epoch 2791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.4764 - val_dice_coef: 0.4764\n",
      "Epoch 2792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.5740 - val_dice_coef: 0.5740\n",
      "Epoch 2795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9747 - val_dice_coef: 0.9747\n",
      "Epoch 2796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.3430 - val_dice_coef: 0.3430\n",
      "Epoch 2798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.5994 - val_dice_coef: 0.5994\n",
      "Epoch 2799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.6466 - val_dice_coef: 0.6466\n",
      "Epoch 2802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.8355 - val_dice_coef: 0.8355\n",
      "Epoch 2803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9594 - val_dice_coef: 0.9594\n",
      "Epoch 2804/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.7488 - val_dice_coef: 0.7488\n",
      "Epoch 2805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9708 - val_dice_coef: 0.9708\n",
      "Epoch 2806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.0411 - val_dice_coef: 0.0411\n",
      "Epoch 2809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.5443 - val_dice_coef: 0.5443\n",
      "Epoch 2810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.8374 - val_dice_coef: 0.8374\n",
      "Epoch 2812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9044 - val_dice_coef: 0.9044\n",
      "Epoch 2813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2814/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9197 - val_dice_coef: 0.9197\n",
      "Epoch 2815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.6469 - val_dice_coef: 0.6469\n",
      "Epoch 2816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.7670 - val_dice_coef: 0.7670\n",
      "Epoch 2819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9133 - dice_coef: 0.9133 - val_loss: -0.3303 - val_dice_coef: 0.3303\n",
      "Epoch 2820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8931 - dice_coef: 0.8931 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.0246 - val_dice_coef: 0.0246\n",
      "Epoch 2823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.3323 - val_dice_coef: 0.3323\n",
      "Epoch 2825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.0754 - val_dice_coef: 0.0754\n",
      "Epoch 2826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9044 - dice_coef: 0.9044 - val_loss: -0.2435 - val_dice_coef: 0.2435\n",
      "Epoch 2828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9496 - val_dice_coef: 0.9496\n",
      "Epoch 2831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9773 - val_dice_coef: 0.9773\n",
      "Epoch 2832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9168 - dice_coef: 0.9168 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.7813 - val_dice_coef: 0.7813\n",
      "Epoch 2834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9454 - val_dice_coef: 0.9454\n",
      "Epoch 2835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.8028 - val_dice_coef: 0.8028\n",
      "Epoch 2838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 2839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9359 - val_dice_coef: 0.9359\n",
      "Epoch 2841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9202 - val_dice_coef: 0.9202\n",
      "Epoch 2842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 2843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9515 - val_dice_coef: 0.9515\n",
      "Epoch 2846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 2847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9468 - val_dice_coef: 0.9468\n",
      "Epoch 2848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.7922 - val_dice_coef: 0.7922\n",
      "Epoch 2849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9071 - val_dice_coef: 0.9071\n",
      "Epoch 2850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9181 - dice_coef: 0.9181 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.6913 - val_dice_coef: 0.6913\n",
      "Epoch 2853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.2032 - val_dice_coef: 0.2032\n",
      "Epoch 2854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9037 - dice_coef: 0.9037 - val_loss: -0.8833 - val_dice_coef: 0.8833\n",
      "Epoch 2856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.1882 - val_dice_coef: 0.1882\n",
      "Epoch 2857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2859/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.8098 - val_dice_coef: 0.8098\n",
      "Epoch 2860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.4437 - val_dice_coef: 0.4437\n",
      "Epoch 2861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.7748 - val_dice_coef: 0.7748\n",
      "Epoch 2864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.7879 - val_dice_coef: 0.7879\n",
      "Epoch 2865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.2887 - val_dice_coef: 0.2887\n",
      "Epoch 2868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9497 - val_dice_coef: 0.9497\n",
      "Epoch 2869/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9258 - val_dice_coef: 0.9258\n",
      "Epoch 2871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.6020 - val_dice_coef: 0.6020\n",
      "Epoch 2872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 2873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 2874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9841 - val_dice_coef: 0.9841\n",
      "Epoch 2875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.7869 - val_dice_coef: 0.7869\n",
      "Epoch 2876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9667 - val_dice_coef: 0.9667\n",
      "Epoch 2877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 2878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9676 - val_dice_coef: 0.9676\n",
      "Epoch 2879/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 2880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9508 - val_dice_coef: 0.9508\n",
      "Epoch 2881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.9433 - val_dice_coef: 0.9433\n",
      "Epoch 2882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9675 - val_dice_coef: 0.9675\n",
      "Epoch 2883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9897 - val_dice_coef: 0.9897\n",
      "Epoch 2884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9507 - val_dice_coef: 0.9507\n",
      "Epoch 2885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9471 - val_dice_coef: 0.9471\n",
      "Epoch 2886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9889 - val_dice_coef: 0.9889\n",
      "Epoch 2887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9220 - dice_coef: 0.9220 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9233 - dice_coef: 0.9233 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 2889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9916 - val_dice_coef: 0.9916\n",
      "Epoch 2890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 2892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9199 - dice_coef: 0.9199 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9610 - val_dice_coef: 0.9610\n",
      "Epoch 2894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9166 - dice_coef: 0.9166 - val_loss: -0.5778 - val_dice_coef: 0.5778\n",
      "Epoch 2895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.7792 - val_dice_coef: 0.7792\n",
      "Epoch 2896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 2897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 2898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9207 - dice_coef: 0.9207 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 2900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9542 - val_dice_coef: 0.9542\n",
      "Epoch 2901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9624 - val_dice_coef: 0.9624\n",
      "Epoch 2902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9215 - dice_coef: 0.9215 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9230 - dice_coef: 0.9230 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.8969 - val_dice_coef: 0.8969\n",
      "Epoch 2909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.7985 - val_dice_coef: 0.7985\n",
      "Epoch 2910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9008 - val_dice_coef: 0.9008\n",
      "Epoch 2911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.8960 - val_dice_coef: 0.8960\n",
      "Epoch 2912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9213 - dice_coef: 0.9213 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2914/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.5299 - val_dice_coef: 0.5299\n",
      "Epoch 2917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.4511 - val_dice_coef: 0.4511\n",
      "Epoch 2918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9224 - dice_coef: 0.9224 - val_loss: -0.9183 - val_dice_coef: 0.9183\n",
      "Epoch 2923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9228 - dice_coef: 0.9228 - val_loss: -0.8274 - val_dice_coef: 0.8274\n",
      "Epoch 2924/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9805 - val_dice_coef: 0.9805\n",
      "Epoch 2925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9199 - val_dice_coef: 0.9199\n",
      "Epoch 2930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9224 - dice_coef: 0.9224 - val_loss: -0.9598 - val_dice_coef: 0.9598\n",
      "Epoch 2931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9249 - val_dice_coef: 0.9249\n",
      "Epoch 2932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9215 - dice_coef: 0.9215 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9232 - dice_coef: 0.9232 - val_loss: -0.9848 - val_dice_coef: 0.9848\n",
      "Epoch 2934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9229 - dice_coef: 0.9229 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 2935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9227 - dice_coef: 0.9227 - val_loss: -0.9853 - val_dice_coef: 0.9853\n",
      "Epoch 2936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9232 - dice_coef: 0.9232 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 2937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9238 - dice_coef: 0.9238 - val_loss: -0.9717 - val_dice_coef: 0.9717\n",
      "Epoch 2938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9040 - val_dice_coef: 0.9040\n",
      "Epoch 2939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 2940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9207 - dice_coef: 0.9207 - val_loss: -0.9860 - val_dice_coef: 0.9860\n",
      "Epoch 2941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9576 - val_dice_coef: 0.9576\n",
      "Epoch 2944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9229 - dice_coef: 0.9229 - val_loss: -0.8049 - val_dice_coef: 0.8049\n",
      "Epoch 2945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.4973 - val_dice_coef: 0.4973\n",
      "Epoch 2946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.5387 - val_dice_coef: 0.5387\n",
      "Epoch 2947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.6299 - val_dice_coef: 0.6299\n",
      "Epoch 2950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.5632 - val_dice_coef: 0.5632\n",
      "Epoch 2951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9418 - val_dice_coef: 0.9418\n",
      "Epoch 2952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.7234 - val_dice_coef: 0.7234\n",
      "Epoch 2954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.0527 - val_dice_coef: 0.0527\n",
      "Epoch 2955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.8292 - val_dice_coef: 0.8292\n",
      "Epoch 2958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.5083 - val_dice_coef: 0.5083\n",
      "Epoch 2959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.2455 - val_dice_coef: 0.2455\n",
      "Epoch 2962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.7099 - val_dice_coef: 0.7099\n",
      "Epoch 2963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 2965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.8014 - val_dice_coef: 0.8014\n",
      "Epoch 2966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.8227 - val_dice_coef: 0.8227\n",
      "Epoch 2967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9204 - dice_coef: 0.9204 - val_loss: -0.9774 - val_dice_coef: 0.9774\n",
      "Epoch 2968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 2969/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9790 - val_dice_coef: 0.9790\n",
      "Epoch 2970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9908 - val_dice_coef: 0.9908\n",
      "Epoch 2971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9236 - dice_coef: 0.9236 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9242 - dice_coef: 0.9242 - val_loss: -0.9597 - val_dice_coef: 0.9597\n",
      "Epoch 2974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9817 - val_dice_coef: 0.9817\n",
      "Epoch 2975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9244 - dice_coef: 0.9244 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 2977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9896 - val_dice_coef: 0.9896\n",
      "Epoch 2978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 2979/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.9339 - val_dice_coef: 0.9339\n",
      "Epoch 2980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9235 - dice_coef: 0.9235 - val_loss: -0.8915 - val_dice_coef: 0.8915\n",
      "Epoch 2981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.6100 - val_dice_coef: 0.6100\n",
      "Epoch 2982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.8801 - val_dice_coef: 0.8801\n",
      "Epoch 2983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 2984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9235 - dice_coef: 0.9235 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9561 - val_dice_coef: 0.9561\n",
      "Epoch 2986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.6162 - val_dice_coef: 0.6162\n",
      "Epoch 2987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.4257 - val_dice_coef: 0.4257\n",
      "Epoch 2988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.8258 - val_dice_coef: 0.8258\n",
      "Epoch 2989/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9841 - val_dice_coef: 0.9841\n",
      "Epoch 2990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9220 - dice_coef: 0.9220 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 2991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9827 - val_dice_coef: 0.9827\n",
      "Epoch 2993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.8863 - val_dice_coef: 0.8863\n",
      "Epoch 2994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.8742 - val_dice_coef: 0.8742\n",
      "Epoch 2995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9217 - dice_coef: 0.9217 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 2996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.8957 - val_dice_coef: 0.8957\n",
      "Epoch 2997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9598 - val_dice_coef: 0.9598\n",
      "Epoch 2998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9350 - val_dice_coef: 0.9350\n",
      "Epoch 2999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9240 - dice_coef: 0.9240 - val_loss: -0.9408 - val_dice_coef: 0.9408\n",
      "Epoch 3000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.8405 - val_dice_coef: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff126c17748>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "model = get_unet()\n",
    "print(model.summary())\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "model.fit(train_z, train_z_m, batch_size=32, epochs=3000, verbose=1, shuffle=True,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weights.h5',custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_train = model.predict(train_z[:int(train_z.shape[0]*0.9)], verbose=1)\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val = model.predict(train_z[int(train_z.shape[0]*0.9):], verbose=1)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Low image data range; displaying image with stretched contrast.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "ix = 70\n",
    "imshow(np.squeeze(train_z[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(train_z_m[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((IMG_H, IMG_W, 1))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "local_conv1 = Conv2D(64, (7, 7), activation='relu', padding='same')(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(64)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(1)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_18/Max:0' shape=(?, 1, 64, 64) dtype=float32>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_231/Relu:0' shape=(?, 64, 64, 64) dtype=float32>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('img3d_train', img_array)\n",
    "np.save('msk3d_train', msk_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 320, 232)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
