{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medpy.io import load\n",
    "import os\n",
    "import itk\n",
    "import skimage\n",
    "import SimpleITK as sitk\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input, Maximum, concatenate, Activation, Conv3D, MaxPooling3D, Conv2DTranspose\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "'''\n",
    "from keras import layers\n",
    "from keras.layers import Input, Conv2D, Maximum, MaxPooling2D, concatenate, Activation, Conv3D, MaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam'''\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../patients/'\n",
    "IMG_H = 64\n",
    "IMG_W = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CengJia',\n",
       " 'GangZu',\n",
       " 'JiaHuiQiong',\n",
       " 'KongDan',\n",
       " 'LanDingKun',\n",
       " 'LiangChengJun',\n",
       " 'LiuGuangQiong',\n",
       " 'LiuQuanXing',\n",
       " 'LiuYanMu',\n",
       " 'ShenXin',\n",
       " 'TanHongJun',\n",
       " 'XiaGang',\n",
       " 'XiaoChangLun',\n",
       " 'YangChuanFu',\n",
       " 'YangXia',\n",
       " 'YangYunFei',\n",
       " 'ZhangJianMing',\n",
       " 'ZhouDaoMing',\n",
       " 'ZhouLiangYong']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = next(os.walk(data_path))[1]\n",
    "train_ids.sort()\n",
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CengJiaT1SegRAIROIResampling.mha',\n",
       " 'bak_CengJiaT1SegRAIROIResampling.mha',\n",
       " 'CengJiaT1SegDistanceMap.mha',\n",
       " 'CengJiaT1RAIROIResamplingNormalize.mha']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_prof = next(os.walk(data_path + '/' + train_ids[0]))[2]\n",
    "ind_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CengJiaT1RAIROIResamplingNormalize.mha'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "#ind_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pylab import has clobbered these variables: ['imshow', 'resize', 'concatenate', 'imread', 'load']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "img = sitk.ReadImage(data_path + train_ids[0] + '/' + img_name)\n",
    "msk = sitk.ReadImage(data_path + train_ids[0] + '/' + msk_b)\n",
    "img_array = sitk.GetArrayFromImage(img)\n",
    "msk_array = sitk.GetArrayFromImage(msk)\n",
    "\n",
    "%pylab inline\n",
    "subplot(121)\n",
    "imgplot = plt.imshow(np.flip(np.flip(img_array[:,136,:]), 1))\n",
    "plt.show()\n",
    "subplot(122)\n",
    "plt.imshow(np.flip(np.flip(msk_array[:,136,:]), 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n"
     ]
    }
   ],
   "source": [
    "#Trying to break the data and then concate to a 1.2w*64*64 data set.\n",
    "\n",
    "train_z = np.ndarray((103 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y = np.ndarray((320 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x = np.ndarray((232 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_z = np.ndarray((103 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_y = np.ndarray((320 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "mask_x = np.ndarray((232 * len(train_ids), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "for i in range(len(train_ids)):\n",
    "    ind_prof = next(os.walk(data_path + '/' + train_ids[i]))[2]\n",
    "    img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "    msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "    img = sitk.ReadImage(data_path + train_ids[i] + '/' + img_name)\n",
    "    msk = sitk.ReadImage(data_path + train_ids[i] + '/' + msk_b)\n",
    "    img_array = sitk.GetArrayFromImage(img)\n",
    "    msk_array = sitk.GetArrayFromImage(msk)\n",
    "    \n",
    "    #z = np.ndarray((103, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #y = np.ndarray((320, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #x = np.ndarray((232, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    for z in range(img_array.shape[0]):\n",
    "        train_z[z + i*103,:,:,0] = resize(img_array[z,:,:], (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
    "    for y in range(img_array.shape[1]):\n",
    "        train_y[y + i*320,:,:,0] = np.flip(np.flip(resize(img_array[:,y,:], (IMG_H, IMG_W),\n",
    "                                            mode='constant', preserve_range=True), 1))\n",
    "    for x in range(img_array.shape[2]):\n",
    "        train_x[x + i*232,:,:,0] = np.flip(np.flip(resize(img_array[:,:,x], (IMG_H, IMG_W),\n",
    "                                            mode='constant', preserve_range=True), 1))\n",
    "    \n",
    "    #z_msk = np.ndarray((103, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #y_msk = np.ndarray((320, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    #x_msk = np.ndarray((232, IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "    for z in range(msk_array.shape[0]):\n",
    "        mask_z[z + i*103,:,:,0] = resize(msk_array[z,:,:], (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
    "    for y in range(msk_array.shape[1]):\n",
    "        mask_y[y + i*320,:,:,0] = np.flip(np.flip(resize(msk_array[:,y,:], (IMG_H, IMG_W),\n",
    "                                                mode='constant', preserve_range=True), 1))\n",
    "    for x in range(msk_array.shape[2]):\n",
    "        mask_x[x + i*232,:,:,0] = np.flip(np.flip(resize(msk_array[:,:,x], (IMG_H, IMG_W),\n",
    "                                                mode='constant', preserve_range=True), 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12445, 64, 64, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = np.concatenate((train_x, train_y, train_z), axis=0)\n",
    "tmp2 = np.concatenate((mask_x, mask_y, mask_z), axis=0)\n",
    "tmp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 103, 320, 232, 1) (19, 103, 320, 232, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Low image data range; displaying image with stretched contrast.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Trying to directly obtrain data with shape of (# of patients)*original\n",
    "#size of the image.\n",
    "\n",
    "X_data = np.ndarray((len(train_ids), img_array.shape[0], img_array.shape[1], img_array.shape[2], 1), dtype=np.uint8)\n",
    "Y_mask = np.ndarray((len(train_ids), msk_array.shape[0], msk_array.shape[1], msk_array.shape[2], 1), dtype=np.uint8)\n",
    "for i in range(len(train_ids)):\n",
    "    ind_prof = next(os.walk(data_path + '/' + train_ids[i]))[2]\n",
    "    img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "    msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "    img = sitk.ReadImage(data_path + train_ids[i] + '/' + img_name)\n",
    "    msk = sitk.ReadImage(data_path + train_ids[i] + '/' + msk_b)\n",
    "    img_array = sitk.GetArrayFromImage(img)\n",
    "    msk_array = sitk.GetArrayFromImage(msk)\n",
    "    for z in range(img_array.shape[0]):\n",
    "        X_data[i,z,:,:,0] = img_array[z,:,:]\n",
    "    for y in range(img_array.shape[1]):\n",
    "        X_data[i,:,y,:,0] = img_array[:,y,:]\n",
    "    for x in range(img_array.shape[0]):\n",
    "        X_data[i,:,:,x,0] = img_array[:,:,x]\n",
    "        \n",
    "    for z in range(msk_array.shape[0]):\n",
    "        Y_mask[i,z,:,:,0] = msk_array[z,:,:]\n",
    "    for y in range(msk_array.shape[1]):\n",
    "        Y_mask[i,:,y,:,0] = msk_array[:,y,:]\n",
    "    for x in range(msk_array.shape[0]):\n",
    "        Y_mask[i,:,:,x,0] = msk_array[:,:,x]\n",
    "        \n",
    "\n",
    "subplot(121)\n",
    "imshow(X_data[18,51,:,:,0])\n",
    "subplot(122)\n",
    "imshow(Y_mask[18,51,:,:,0])\n",
    "print(X_data.shape, Y_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the input, due to err:\"expected input_3 to have\n",
    "#shape (65, 65, 65, 1) but got array with shape (103, 320, 232, 1)\"\n",
    "def preprocessing(arch_name):\n",
    "    #X_global = []\n",
    "    #X_local = []\n",
    "    #Y = []\n",
    "    \n",
    "    if arch_name == 'input':\n",
    "        s = 65\n",
    "        X2 = np.ndarray((s, s, s, 1), dtype=np.uint8)\n",
    "        X1 = np.ndarray((33, 33, 33, 1), dtype=np.uint8)\n",
    "        Y = np.ndarray((s, s, s, 1), dtype=np.uint8)\n",
    "        for i in range(1):\n",
    "            print(str(i+1)+'/19 data processed')\n",
    "            for z in range(0, X_data.shape[1]-s, 5):\n",
    "                for y in range(0, X_data.shape[2]-s, 25):\n",
    "                    for x in range(0, X_data.shape[3]-s, 20):\n",
    "                        if X_data[i,z+16:z+49,y+16:y+49,x+16:x+49,0].any() != 0:\n",
    "                            print(X2[:,:,:,0].shape)\n",
    "                            print(X_data[i,z:z+s,y:y+s,x:x+s,0].shape)\n",
    "                            break\n",
    "                            X2[:,:,:,0] = np.concatenate((X2[:,:,:,0], X_data[i,z:z+s,y:y+s,x:x+s,0]))\n",
    "                            X1[:,:,:,0] = np.concatenate((X1[:,:,:,0], X_data[i,z+16:z+49,y+16:y+49,x+16:x+49,0]))\n",
    "                            Y[:,:,:,0] = np.concatenate((Y[:,:,:,0], Y_mask[i,z:z+s,y:y+s,x:x+s,0]))\n",
    "    \n",
    "    #X1 = np.asarray(X_global)\n",
    "    #X2 = np.asarray(X_local)\n",
    "    #Y_out = np.asarray(Y)\n",
    "    \n",
    "    return [X1, X2, Y]    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/19 data processed\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n",
      "(65, 65, 65)\n"
     ]
    }
   ],
   "source": [
    "f_data = preprocessing('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15048, 33, 33, 33, 1) (15048, 65, 65, 65, 1) (15048, 65, 65, 65, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f_data[0].shape, f_data[1].shape, f_data[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_path3D(X_input, arch_type):\n",
    "    if arch_type == 'input':\n",
    "        #upper path\n",
    "        X = Conv3D(64, (7, 7, 7), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X1 = Conv3D(64, (7, 7, 7), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X1 = Maximum()([X,X1])\n",
    "        X1 = MaxPooling3D((4,4,4), strides=(1,1,1), padding='valid')(X1)\n",
    "        \n",
    "        X = Conv3D(64, (3,3,3), strides=(1,1,1), padding='valid')(X1)\n",
    "        X1 = Conv3D(64, (3,3,3), strides=(1,1,1), padding='valid')(X1)\n",
    "        X1 = Maximum()([X,X1])\n",
    "        X1 = MaxPooling3D((2,2,2), strides=(1,1,1), padding='valid')(X1)\n",
    "        \n",
    "        #lower path\n",
    "        X = Conv3D(160, (13, 13, 13), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X2 = Conv3D(160, (13, 13, 13), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X2 = Maximum()([X,X2])\n",
    "        \n",
    "        #concatenation\n",
    "        X = concatenate([X1,X2], axis=4)\n",
    "        X = Conv3D(5, (21, 21, 21), strides=(1,1,1), padding='valid')(X)\n",
    "        #X = Activation('softmax')(X)\n",
    "    \n",
    "        #model = Model(inputs=X_input, outputs=X)\n",
    "        return X\n",
    "def InputCascadeCNN(shape1, shape2):\n",
    "    #concatenate input and output of the 1st two path network\n",
    "    X1 = Input(shape1)\n",
    "    X = two_path3D(X1, 'input')\n",
    "    \n",
    "    X2 = Input(shape2)\n",
    "    X = concatenate([X, X2], axis=4)\n",
    "    X = two_path3D(X, 'input')\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=[X1,X2], outputs=X)\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 65, 65, 65, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 59, 59, 59, 6 22016       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 59, 59, 59, 6 22016       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_4 (Maximum)             (None, 59, 59, 59, 6 0           conv3d_7[0][0]                   \n",
      "                                                                 conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 56, 56, 56, 6 0           maximum_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 54, 54, 54, 6 110656      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 54, 54, 54, 6 110656      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_5 (Maximum)             (None, 54, 54, 54, 6 0           conv3d_9[0][0]                   \n",
      "                                                                 conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 53, 53, 53, 1 351680      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 53, 53, 53, 1 351680      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 53, 53, 53, 6 0           maximum_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_6 (Maximum)             (None, 53, 53, 53, 1 0           conv3d_11[0][0]                  \n",
      "                                                                 conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 53, 53, 53, 2 0           max_pooling3d_4[0][0]            \n",
      "                                                                 maximum_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 33, 33, 33, 5 10372325    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 33, 33, 33, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 33, 33, 33, 6 0           conv3d_13[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 27, 27, 27, 6 131776      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 27, 27, 27, 6 131776      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maximum_7 (Maximum)             (None, 27, 27, 27, 6 0           conv3d_14[0][0]                  \n",
      "                                                                 conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 24, 24, 24, 6 0           maximum_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_8 (Maximum)             (None, 22, 22, 22, 6 0           conv3d_16[0][0]                  \n",
      "                                                                 conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3D)  (None, 21, 21, 21, 6 0           maximum_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "maximum_9 (Maximum)             (None, 21, 21, 21, 1 0           conv3d_18[0][0]                  \n",
      "                                                                 conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 21, 21, 21, 2 0           max_pooling3d_6[0][0]            \n",
      "                                                                 maximum_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 1, 1, 1, 5)   10372325    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 1, 5)   0           conv3d_20[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,416,778\n",
      "Trainable params: 26,416,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1 = InputCascadeCNN((65,65,65,1), (33,33,33,1))\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0,0:64,0:64,0:64,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 65, 65, 65, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 59, 59, 59, 6 22016       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 59, 59, 59, 6 22016       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_10 (Maximum)            (None, 59, 59, 59, 6 0           conv3d_21[0][0]                  \n",
      "                                                                 conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3D)  (None, 56, 56, 56, 6 0           maximum_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 54, 54, 54, 6 110656      max_pooling3d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 54, 54, 54, 6 110656      max_pooling3d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_11 (Maximum)            (None, 54, 54, 54, 6 0           conv3d_23[0][0]                  \n",
      "                                                                 conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 53, 53, 53, 1 351680      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)              (None, 53, 53, 53, 1 351680      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3D)  (None, 53, 53, 53, 6 0           maximum_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maximum_12 (Maximum)            (None, 53, 53, 53, 1 0           conv3d_25[0][0]                  \n",
      "                                                                 conv3d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 53, 53, 53, 2 0           max_pooling3d_8[0][0]            \n",
      "                                                                 maximum_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 33, 33, 33, 5 10372325    concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 33, 33, 33, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 33, 33, 33, 6 0           conv3d_27[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)              (None, 27, 27, 27, 6 131776      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)              (None, 27, 27, 27, 6 131776      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maximum_13 (Maximum)            (None, 27, 27, 27, 6 0           conv3d_28[0][0]                  \n",
      "                                                                 conv3d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3D)  (None, 24, 24, 24, 6 0           maximum_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_30 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_31 (Conv3D)              (None, 22, 22, 22, 6 110656      max_pooling3d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "maximum_14 (Maximum)            (None, 22, 22, 22, 6 0           conv3d_30[0][0]                  \n",
      "                                                                 conv3d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_32 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_33 (Conv3D)              (None, 21, 21, 21, 1 2109280     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling3D) (None, 21, 21, 21, 6 0           maximum_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maximum_15 (Maximum)            (None, 21, 21, 21, 1 0           conv3d_32[0][0]                  \n",
      "                                                                 conv3d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 21, 21, 21, 2 0           max_pooling3d_10[0][0]           \n",
      "                                                                 maximum_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_34 (Conv3D)              (None, 1, 1, 1, 5)   10372325    concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 1, 1, 5)   0           conv3d_34[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,416,778\n",
      "Trainable params: 26,416,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_4 to have 5 dimensions, but got array with shape (29640, 33, 33, 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c3de9d579bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m m1.fit([f_data[1],f_data[0]], f_data[2], batch_size=8, epochs=50, verbose=1, shuffle=True,\n\u001b[1;32m     13\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         callbacks=[model_checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_4 to have 5 dimensions, but got array with shape (29640, 33, 33, 33)"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "m1 = InputCascadeCNN((65,65,65,1), (33,33,33,1))\n",
    "#m1 = get_unet()\n",
    "print(m1.summary())\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "m1.fit([f_data[1],f_data[0]], f_data[2], batch_size=8, epochs=50, verbose=1, shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Processed_Data/img_z', oz)\n",
    "np.save('../Processed_Data/img_y', oy)\n",
    "np.save('../Processed_Data/img_x', ox)\n",
    "np.save('../Processed_Data/msk_z', oz_msk)\n",
    "np.save('../Processed_Data/msk_y', oy_msk)\n",
    "np.save('../Processed_Data/msk_x', ox_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_z = np.ndarray((len(oz), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y = np.ndarray((len(oy), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x = np.ndarray((len(ox), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_z_m = np.ndarray((len(oz_msk), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y_m = np.ndarray((len(oy_msk), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x_m = np.ndarray((len(ox_msk), IMG_H, IMG_W, 1), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n"
     ]
    }
   ],
   "source": [
    "for n, img in enumerate(oz):\n",
    "    train_z[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oy):\n",
    "    train_y[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(ox):\n",
    "    train_x[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oz_msk):\n",
    "    train_z_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oy_msk):\n",
    "    train_y_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(ox_msk):\n",
    "    train_x_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 128, 128, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 1)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 32) 320         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 32)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 16, 16, 256)  524544      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 512)  0           conv2d_transpose_13[0][0]        \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 256)  0           conv2d_transpose_14[0][0]        \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 128)  0           conv2d_transpose_15[0][0]        \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 128, 128, 64) 0           conv2d_transpose_16[0][0]        \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 128, 128, 1)  33          conv2d_75[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,759,521\n",
      "Trainable params: 7,759,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Train on 92 samples, validate on 11 samples\n",
      "Epoch 1/3000\n",
      "92/92 [==============================] - 6s 61ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1107e-05 - val_dice_coef: 1.1107e-05\n",
      "Epoch 2/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1105e-05 - val_dice_coef: 1.1105e-05\n",
      "Epoch 3/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1103e-05 - val_dice_coef: 1.1103e-05\n",
      "Epoch 4/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1101e-05 - val_dice_coef: 1.1101e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1099e-05 - val_dice_coef: 1.1099e-05\n",
      "Epoch 6/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1098e-05 - val_dice_coef: 1.1098e-05\n",
      "Epoch 7/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1096e-05 - val_dice_coef: 1.1096e-05\n",
      "Epoch 8/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1094e-05 - val_dice_coef: 1.1094e-05\n",
      "Epoch 9/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1092e-05 - val_dice_coef: 1.1092e-05\n",
      "Epoch 10/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1091e-05 - val_dice_coef: 1.1091e-05\n",
      "Epoch 11/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1089e-05 - val_dice_coef: 1.1089e-05\n",
      "Epoch 12/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1088e-05 - val_dice_coef: 1.1088e-05\n",
      "Epoch 13/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1087e-05 - val_dice_coef: 1.1087e-05\n",
      "Epoch 14/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1085e-05 - val_dice_coef: 1.1085e-05\n",
      "Epoch 15/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1084e-05 - val_dice_coef: 1.1084e-05\n",
      "Epoch 16/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1082e-05 - val_dice_coef: 1.1082e-05\n",
      "Epoch 17/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1081e-05 - val_dice_coef: 1.1081e-05\n",
      "Epoch 18/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 19/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1079e-05 - val_dice_coef: 1.1079e-05\n",
      "Epoch 20/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 21/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 22/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1076e-05 - val_dice_coef: 1.1076e-05\n",
      "Epoch 23/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 24/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1074e-05 - val_dice_coef: 1.1074e-05\n",
      "Epoch 25/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 26/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 27/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 28/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 29/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 30/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 31/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 32/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 33/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 34/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 35/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 36/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 37/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 38/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 39/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 40/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 41/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 42/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 43/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 44/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 45/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 46/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1074e-05 - val_dice_coef: 1.1074e-05\n",
      "Epoch 47/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 48/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 49/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1076e-05 - val_dice_coef: 1.1076e-05\n",
      "Epoch 50/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 51/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 52/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1078e-05 - val_dice_coef: 1.1078e-05\n",
      "Epoch 53/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1078e-05 - val_dice_coef: 1.1078e-05\n",
      "Epoch 54/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1079e-05 - val_dice_coef: 1.1079e-05\n",
      "Epoch 55/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 56/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 57/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1081e-05 - val_dice_coef: 1.1081e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1082e-05 - val_dice_coef: 1.1082e-05\n",
      "Epoch 59/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1083e-05 - val_dice_coef: 1.1083e-05\n",
      "Epoch 60/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1083e-05 - val_dice_coef: 1.1083e-05\n",
      "Epoch 61/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1084e-05 - val_dice_coef: 1.1084e-05\n",
      "Epoch 62/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1085e-05 - val_dice_coef: 1.1085e-05\n",
      "Epoch 63/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1086e-05 - val_dice_coef: 1.1086e-05\n",
      "Epoch 64/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1087e-05 - val_dice_coef: 1.1087e-05\n",
      "Epoch 65/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1088e-05 - val_dice_coef: 1.1088e-05\n",
      "Epoch 66/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1089e-05 - val_dice_coef: 1.1089e-05\n",
      "Epoch 67/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1090e-05 - val_dice_coef: 1.1090e-05\n",
      "Epoch 68/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1091e-05 - val_dice_coef: 1.1091e-05\n",
      "Epoch 69/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1092e-05 - val_dice_coef: 1.1092e-05\n",
      "Epoch 70/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1093e-05 - val_dice_coef: 1.1093e-05\n",
      "Epoch 71/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1094e-05 - val_dice_coef: 1.1094e-05\n",
      "Epoch 72/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1096e-05 - val_dice_coef: 1.1096e-05\n",
      "Epoch 73/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1097e-05 - val_dice_coef: 1.1097e-05\n",
      "Epoch 74/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1098e-05 - val_dice_coef: 1.1098e-05\n",
      "Epoch 75/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1100e-05 - val_dice_coef: 1.1100e-05\n",
      "Epoch 76/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1101e-05 - val_dice_coef: 1.1101e-05\n",
      "Epoch 77/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1102e-05 - val_dice_coef: 1.1102e-05\n",
      "Epoch 78/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1104e-05 - val_dice_coef: 1.1104e-05\n",
      "Epoch 79/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1105e-05 - val_dice_coef: 1.1105e-05\n",
      "Epoch 80/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1106e-05 - val_dice_coef: 1.1106e-05\n",
      "Epoch 81/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1108e-05 - val_dice_coef: 1.1108e-05\n",
      "Epoch 82/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1109e-05 - val_dice_coef: 1.1109e-05\n",
      "Epoch 83/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1110e-05 - val_dice_coef: 1.1110e-05\n",
      "Epoch 84/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1112e-05 - val_dice_coef: 1.1112e-05\n",
      "Epoch 85/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1113e-05 - val_dice_coef: 1.1113e-05\n",
      "Epoch 86/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1115e-05 - val_dice_coef: 1.1115e-05\n",
      "Epoch 87/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1116e-05 - val_dice_coef: 1.1116e-05\n",
      "Epoch 88/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1117e-05 - val_dice_coef: 1.1117e-05\n",
      "Epoch 89/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1118e-05 - val_dice_coef: 1.1118e-05\n",
      "Epoch 90/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1120e-05 - val_dice_coef: 1.1120e-05\n",
      "Epoch 91/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1121e-05 - val_dice_coef: 1.1121e-05\n",
      "Epoch 92/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1123e-05 - val_dice_coef: 1.1123e-05\n",
      "Epoch 93/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1125e-05 - val_dice_coef: 1.1125e-05\n",
      "Epoch 94/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1126e-05 - val_dice_coef: 1.1126e-05\n",
      "Epoch 95/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1128e-05 - val_dice_coef: 1.1128e-05\n",
      "Epoch 96/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1130e-05 - val_dice_coef: 1.1130e-05\n",
      "Epoch 97/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0111 - dice_coef: 0.0111 - val_loss: -1.1133e-05 - val_dice_coef: 1.1133e-05\n",
      "Epoch 98/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0111 - dice_coef: 0.0111 - val_loss: -1.1135e-05 - val_dice_coef: 1.1135e-05\n",
      "Epoch 99/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0112 - dice_coef: 0.0112 - val_loss: -1.1138e-05 - val_dice_coef: 1.1138e-05\n",
      "Epoch 100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0112 - dice_coef: 0.0112 - val_loss: -1.1140e-05 - val_dice_coef: 1.1140e-05\n",
      "Epoch 101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0113 - dice_coef: 0.0113 - val_loss: -1.1144e-05 - val_dice_coef: 1.1144e-05\n",
      "Epoch 102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0114 - dice_coef: 0.0114 - val_loss: -1.1148e-05 - val_dice_coef: 1.1148e-05\n",
      "Epoch 103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0115 - dice_coef: 0.0115 - val_loss: -1.1151e-05 - val_dice_coef: 1.1151e-05\n",
      "Epoch 104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0115 - dice_coef: 0.0115 - val_loss: -1.1156e-05 - val_dice_coef: 1.1156e-05\n",
      "Epoch 105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0116 - dice_coef: 0.0116 - val_loss: -1.1162e-05 - val_dice_coef: 1.1162e-05\n",
      "Epoch 106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0117 - dice_coef: 0.0117 - val_loss: -1.1167e-05 - val_dice_coef: 1.1167e-05\n",
      "Epoch 107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0118 - dice_coef: 0.0118 - val_loss: -1.1175e-05 - val_dice_coef: 1.1175e-05\n",
      "Epoch 108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0119 - dice_coef: 0.0119 - val_loss: -1.1183e-05 - val_dice_coef: 1.1183e-05\n",
      "Epoch 109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0121 - dice_coef: 0.0121 - val_loss: -1.1193e-05 - val_dice_coef: 1.1193e-05\n",
      "Epoch 110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0122 - dice_coef: 0.0122 - val_loss: -1.1207e-05 - val_dice_coef: 1.1207e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0124 - dice_coef: 0.0124 - val_loss: -1.1224e-05 - val_dice_coef: 1.1224e-05\n",
      "Epoch 112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0125 - dice_coef: 0.0125 - val_loss: -1.1242e-05 - val_dice_coef: 1.1242e-05\n",
      "Epoch 113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0128 - dice_coef: 0.0128 - val_loss: -1.1271e-05 - val_dice_coef: 1.1271e-05\n",
      "Epoch 114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0130 - dice_coef: 0.0130 - val_loss: -1.1302e-05 - val_dice_coef: 1.1302e-05\n",
      "Epoch 115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0133 - dice_coef: 0.0133 - val_loss: -1.1336e-05 - val_dice_coef: 1.1336e-05\n",
      "Epoch 116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0136 - dice_coef: 0.0136 - val_loss: -1.1398e-05 - val_dice_coef: 1.1398e-05\n",
      "Epoch 117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0139 - dice_coef: 0.0139 - val_loss: -1.1497e-05 - val_dice_coef: 1.1497e-05\n",
      "Epoch 118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0143 - dice_coef: 0.0143 - val_loss: -1.1565e-05 - val_dice_coef: 1.1565e-05\n",
      "Epoch 119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0149 - dice_coef: 0.0149 - val_loss: -1.1802e-05 - val_dice_coef: 1.1802e-05\n",
      "Epoch 120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0155 - dice_coef: 0.0155 - val_loss: -1.1994e-05 - val_dice_coef: 1.1994e-05\n",
      "Epoch 121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0161 - dice_coef: 0.0161 - val_loss: -1.2419e-05 - val_dice_coef: 1.2419e-05\n",
      "Epoch 122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0172 - dice_coef: 0.0172 - val_loss: -1.2878e-05 - val_dice_coef: 1.2878e-05\n",
      "Epoch 123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0185 - dice_coef: 0.0185 - val_loss: -1.4198e-05 - val_dice_coef: 1.4198e-05\n",
      "Epoch 124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0202 - dice_coef: 0.0202 - val_loss: -1.5069e-05 - val_dice_coef: 1.5069e-05\n",
      "Epoch 125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0230 - dice_coef: 0.0230 - val_loss: -1.8830e-05 - val_dice_coef: 1.8830e-05\n",
      "Epoch 126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0277 - dice_coef: 0.0277 - val_loss: -2.5383e-05 - val_dice_coef: 2.5383e-05\n",
      "Epoch 127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0338 - dice_coef: 0.0338 - val_loss: -3.0613e-05 - val_dice_coef: 3.0613e-05\n",
      "Epoch 128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0440 - dice_coef: 0.0440 - val_loss: -3.7309e-05 - val_dice_coef: 3.7309e-05\n",
      "Epoch 129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0589 - dice_coef: 0.0589 - val_loss: -5.4508e-05 - val_dice_coef: 5.4508e-05\n",
      "Epoch 130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0796 - dice_coef: 0.0796 - val_loss: -8.9018e-05 - val_dice_coef: 8.9018e-05\n",
      "Epoch 131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0968 - dice_coef: 0.0968 - val_loss: -7.3245e-05 - val_dice_coef: 7.3245e-05\n",
      "Epoch 132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1158 - dice_coef: 0.1158 - val_loss: -1.5367e-04 - val_dice_coef: 1.5367e-04\n",
      "Epoch 133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1511 - dice_coef: 0.1511 - val_loss: -2.6846e-04 - val_dice_coef: 2.6846e-04\n",
      "Epoch 134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1832 - dice_coef: 0.1832 - val_loss: -3.1565e-04 - val_dice_coef: 3.1565e-04\n",
      "Epoch 135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1991 - dice_coef: 0.1991 - val_loss: -1.4018e-04 - val_dice_coef: 1.4018e-04\n",
      "Epoch 136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1806 - dice_coef: 0.1806 - val_loss: -4.9281e-04 - val_dice_coef: 4.9281e-04\n",
      "Epoch 137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2291 - dice_coef: 0.2291 - val_loss: -2.9947e-04 - val_dice_coef: 2.9947e-04\n",
      "Epoch 138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2629 - dice_coef: 0.2629 - val_loss: -2.4638e-04 - val_dice_coef: 2.4638e-04\n",
      "Epoch 139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2359 - dice_coef: 0.2359 - val_loss: -7.2372e-04 - val_dice_coef: 7.2372e-04\n",
      "Epoch 140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2803 - dice_coef: 0.2803 - val_loss: -2.6312e-04 - val_dice_coef: 2.6312e-04\n",
      "Epoch 141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2769 - dice_coef: 0.2769 - val_loss: -0.0012 - val_dice_coef: 0.0012\n",
      "Epoch 142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3336 - dice_coef: 0.3336 - val_loss: -4.0191e-04 - val_dice_coef: 4.0191e-04\n",
      "Epoch 143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3543 - dice_coef: 0.3543 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 144/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3593 - dice_coef: 0.3593 - val_loss: -3.4966e-04 - val_dice_coef: 3.4966e-04\n",
      "Epoch 145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3690 - dice_coef: 0.3690 - val_loss: -0.0038 - val_dice_coef: 0.0038\n",
      "Epoch 146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3731 - dice_coef: 0.3731 - val_loss: -5.3135e-04 - val_dice_coef: 5.3135e-04\n",
      "Epoch 147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3957 - dice_coef: 0.3957 - val_loss: -0.0028 - val_dice_coef: 0.0028\n",
      "Epoch 148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4610 - dice_coef: 0.4610 - val_loss: -0.0023 - val_dice_coef: 0.0023\n",
      "Epoch 149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4710 - dice_coef: 0.4710 - val_loss: -0.0014 - val_dice_coef: 0.0014\n",
      "Epoch 150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4698 - dice_coef: 0.4698 - val_loss: -0.0074 - val_dice_coef: 0.0074\n",
      "Epoch 151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4465 - dice_coef: 0.4465 - val_loss: -0.0016 - val_dice_coef: 0.0016\n",
      "Epoch 152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4922 - dice_coef: 0.4922 - val_loss: -0.0030 - val_dice_coef: 0.0030\n",
      "Epoch 153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5099 - dice_coef: 0.5099 - val_loss: -0.0074 - val_dice_coef: 0.0074\n",
      "Epoch 154/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5115 - dice_coef: 0.5115 - val_loss: -0.0033 - val_dice_coef: 0.0033\n",
      "Epoch 155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5275 - dice_coef: 0.5275 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5467 - dice_coef: 0.5467 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5057 - dice_coef: 0.5057 - val_loss: -0.0020 - val_dice_coef: 0.0020\n",
      "Epoch 158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5405 - dice_coef: 0.5405 - val_loss: -0.0041 - val_dice_coef: 0.0041\n",
      "Epoch 159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5680 - dice_coef: 0.5680 - val_loss: -0.0095 - val_dice_coef: 0.0095\n",
      "Epoch 160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5403 - dice_coef: 0.5403 - val_loss: -0.0082 - val_dice_coef: 0.0082\n",
      "Epoch 161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5418 - dice_coef: 0.5418 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5725 - dice_coef: 0.5725 - val_loss: -0.0022 - val_dice_coef: 0.0022\n",
      "Epoch 163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5570 - dice_coef: 0.5570 - val_loss: -0.0157 - val_dice_coef: 0.0157\n",
      "Epoch 164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5478 - dice_coef: 0.5478 - val_loss: -0.0057 - val_dice_coef: 0.0057\n",
      "Epoch 165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5625 - dice_coef: 0.5625 - val_loss: -0.0017 - val_dice_coef: 0.0017\n",
      "Epoch 166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5734 - dice_coef: 0.5734 - val_loss: -0.0263 - val_dice_coef: 0.0263\n",
      "Epoch 167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5060 - dice_coef: 0.5060 - val_loss: -0.0012 - val_dice_coef: 0.0012\n",
      "Epoch 168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5289 - dice_coef: 0.5289 - val_loss: -0.0095 - val_dice_coef: 0.0095\n",
      "Epoch 169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5431 - dice_coef: 0.5431 - val_loss: -0.0043 - val_dice_coef: 0.0043\n",
      "Epoch 170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5746 - dice_coef: 0.5746 - val_loss: -0.0021 - val_dice_coef: 0.0021\n",
      "Epoch 171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5672 - dice_coef: 0.5672 - val_loss: -0.0185 - val_dice_coef: 0.0185\n",
      "Epoch 172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5998 - dice_coef: 0.5998 - val_loss: -0.0021 - val_dice_coef: 0.0021\n",
      "Epoch 173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5934 - dice_coef: 0.5934 - val_loss: -0.0227 - val_dice_coef: 0.0227\n",
      "Epoch 174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5620 - dice_coef: 0.5620 - val_loss: -0.0024 - val_dice_coef: 0.0024\n",
      "Epoch 175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5871 - dice_coef: 0.5871 - val_loss: -0.0051 - val_dice_coef: 0.0051\n",
      "Epoch 176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6136 - dice_coef: 0.6136 - val_loss: -0.0080 - val_dice_coef: 0.0080\n",
      "Epoch 177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6234 - dice_coef: 0.6234 - val_loss: -0.0028 - val_dice_coef: 0.0028\n",
      "Epoch 178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6085 - dice_coef: 0.6085 - val_loss: -0.0268 - val_dice_coef: 0.0268\n",
      "Epoch 179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6012 - dice_coef: 0.6012 - val_loss: -0.0029 - val_dice_coef: 0.0029\n",
      "Epoch 180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6337 - dice_coef: 0.6337 - val_loss: -0.0189 - val_dice_coef: 0.0189\n",
      "Epoch 181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6154 - dice_coef: 0.6154 - val_loss: -0.0062 - val_dice_coef: 0.0062\n",
      "Epoch 182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6435 - dice_coef: 0.6435 - val_loss: -0.0052 - val_dice_coef: 0.0052\n",
      "Epoch 183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6477 - dice_coef: 0.6477 - val_loss: -0.0080 - val_dice_coef: 0.0080\n",
      "Epoch 184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6506 - dice_coef: 0.6506 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6532 - dice_coef: 0.6532 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6516 - dice_coef: 0.6516 - val_loss: -0.0236 - val_dice_coef: 0.0236\n",
      "Epoch 187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6464 - dice_coef: 0.6464 - val_loss: -0.0035 - val_dice_coef: 0.0035\n",
      "Epoch 188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6166 - dice_coef: 0.6166 - val_loss: -0.0066 - val_dice_coef: 0.0066\n",
      "Epoch 189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6000 - dice_coef: 0.6000 - val_loss: -0.0093 - val_dice_coef: 0.0093\n",
      "Epoch 190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6448 - dice_coef: 0.6448 - val_loss: -0.0034 - val_dice_coef: 0.0034\n",
      "Epoch 191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6118 - dice_coef: 0.6118 - val_loss: -0.0278 - val_dice_coef: 0.0278\n",
      "Epoch 192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6444 - dice_coef: 0.6444 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6396 - dice_coef: 0.6396 - val_loss: -0.0102 - val_dice_coef: 0.0102\n",
      "Epoch 194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6707 - dice_coef: 0.6707 - val_loss: -0.0072 - val_dice_coef: 0.0072\n",
      "Epoch 195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6327 - dice_coef: 0.6327 - val_loss: -0.0024 - val_dice_coef: 0.0024\n",
      "Epoch 196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6094 - dice_coef: 0.6094 - val_loss: -0.0249 - val_dice_coef: 0.0249\n",
      "Epoch 197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6616 - dice_coef: 0.6616 - val_loss: -0.0029 - val_dice_coef: 0.0029\n",
      "Epoch 198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6442 - dice_coef: 0.6442 - val_loss: -0.0407 - val_dice_coef: 0.0407\n",
      "Epoch 199/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6436 - dice_coef: 0.6436 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6376 - dice_coef: 0.6376 - val_loss: -0.0210 - val_dice_coef: 0.0210\n",
      "Epoch 201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6463 - dice_coef: 0.6463 - val_loss: -0.0057 - val_dice_coef: 0.0057\n",
      "Epoch 202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6588 - dice_coef: 0.6588 - val_loss: -0.0055 - val_dice_coef: 0.0055\n",
      "Epoch 203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6548 - dice_coef: 0.6548 - val_loss: -0.0221 - val_dice_coef: 0.0221\n",
      "Epoch 204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6466 - dice_coef: 0.6466 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6399 - dice_coef: 0.6399 - val_loss: -0.0501 - val_dice_coef: 0.0501\n",
      "Epoch 206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6406 - dice_coef: 0.6406 - val_loss: -0.0042 - val_dice_coef: 0.0042\n",
      "Epoch 207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6891 - dice_coef: 0.6891 - val_loss: -0.0334 - val_dice_coef: 0.0334\n",
      "Epoch 208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6813 - dice_coef: 0.6813 - val_loss: -0.0030 - val_dice_coef: 0.0030\n",
      "Epoch 209/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6654 - dice_coef: 0.6654 - val_loss: -0.0236 - val_dice_coef: 0.0236\n",
      "Epoch 210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6557 - dice_coef: 0.6557 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6867 - dice_coef: 0.6867 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6828 - dice_coef: 0.6828 - val_loss: -0.0213 - val_dice_coef: 0.0213\n",
      "Epoch 213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6963 - dice_coef: 0.6963 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6900 - dice_coef: 0.6900 - val_loss: -0.0160 - val_dice_coef: 0.0160\n",
      "Epoch 215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7085 - dice_coef: 0.7085 - val_loss: -0.0060 - val_dice_coef: 0.0060\n",
      "Epoch 216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7012 - dice_coef: 0.7012 - val_loss: -0.0172 - val_dice_coef: 0.0172\n",
      "Epoch 217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7031 - dice_coef: 0.7031 - val_loss: -0.0050 - val_dice_coef: 0.0050\n",
      "Epoch 218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7066 - dice_coef: 0.7066 - val_loss: -0.0333 - val_dice_coef: 0.0333\n",
      "Epoch 219/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7029 - dice_coef: 0.7029 - val_loss: -0.0038 - val_dice_coef: 0.0038\n",
      "Epoch 220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6974 - dice_coef: 0.6974 - val_loss: -0.0762 - val_dice_coef: 0.0762\n",
      "Epoch 221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6840 - dice_coef: 0.6840 - val_loss: -0.0042 - val_dice_coef: 0.0042\n",
      "Epoch 222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7095 - dice_coef: 0.7095 - val_loss: -0.0456 - val_dice_coef: 0.0456\n",
      "Epoch 223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6927 - dice_coef: 0.6927 - val_loss: -0.0048 - val_dice_coef: 0.0048\n",
      "Epoch 224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6993 - dice_coef: 0.6993 - val_loss: -0.0125 - val_dice_coef: 0.0125\n",
      "Epoch 225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7147 - dice_coef: 0.7147 - val_loss: -0.0098 - val_dice_coef: 0.0098\n",
      "Epoch 226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7212 - dice_coef: 0.7212 - val_loss: -0.0073 - val_dice_coef: 0.0073\n",
      "Epoch 227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7165 - dice_coef: 0.7165 - val_loss: -0.0154 - val_dice_coef: 0.0154\n",
      "Epoch 228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7287 - dice_coef: 0.7287 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7251 - dice_coef: 0.7251 - val_loss: -0.0087 - val_dice_coef: 0.0087\n",
      "Epoch 230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7258 - dice_coef: 0.7258 - val_loss: -0.0120 - val_dice_coef: 0.0120\n",
      "Epoch 231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7331 - dice_coef: 0.7331 - val_loss: -0.0119 - val_dice_coef: 0.0119\n",
      "Epoch 232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7328 - dice_coef: 0.7328 - val_loss: -0.0118 - val_dice_coef: 0.0118\n",
      "Epoch 233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7270 - dice_coef: 0.7270 - val_loss: -0.0081 - val_dice_coef: 0.0081\n",
      "Epoch 234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7355 - dice_coef: 0.7355 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7344 - dice_coef: 0.7344 - val_loss: -0.0076 - val_dice_coef: 0.0076\n",
      "Epoch 236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7305 - dice_coef: 0.7305 - val_loss: -0.0531 - val_dice_coef: 0.0531\n",
      "Epoch 237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7165 - dice_coef: 0.7165 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7345 - dice_coef: 0.7345 - val_loss: -0.0081 - val_dice_coef: 0.0081\n",
      "Epoch 239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7349 - dice_coef: 0.7349 - val_loss: -0.0205 - val_dice_coef: 0.0205\n",
      "Epoch 240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7402 - dice_coef: 0.7402 - val_loss: -0.0069 - val_dice_coef: 0.0069\n",
      "Epoch 241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7214 - dice_coef: 0.7214 - val_loss: -0.0201 - val_dice_coef: 0.0201\n",
      "Epoch 242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7329 - dice_coef: 0.7329 - val_loss: -0.0245 - val_dice_coef: 0.0245\n",
      "Epoch 243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7348 - dice_coef: 0.7348 - val_loss: -0.0086 - val_dice_coef: 0.0086\n",
      "Epoch 244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7320 - dice_coef: 0.7320 - val_loss: -0.0145 - val_dice_coef: 0.0145\n",
      "Epoch 245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7330 - dice_coef: 0.7330 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7447 - dice_coef: 0.7447 - val_loss: -0.0222 - val_dice_coef: 0.0222\n",
      "Epoch 247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7501 - dice_coef: 0.7501 - val_loss: -0.0142 - val_dice_coef: 0.0142\n",
      "Epoch 248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7491 - dice_coef: 0.7491 - val_loss: -0.0147 - val_dice_coef: 0.0147\n",
      "Epoch 249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7529 - dice_coef: 0.7529 - val_loss: -0.0142 - val_dice_coef: 0.0142\n",
      "Epoch 250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7491 - dice_coef: 0.7491 - val_loss: -0.0514 - val_dice_coef: 0.0514\n",
      "Epoch 251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7485 - dice_coef: 0.7485 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7539 - dice_coef: 0.7539 - val_loss: -0.0343 - val_dice_coef: 0.0343\n",
      "Epoch 253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7467 - dice_coef: 0.7467 - val_loss: -0.0375 - val_dice_coef: 0.0375\n",
      "Epoch 254/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7548 - dice_coef: 0.7548 - val_loss: -0.0094 - val_dice_coef: 0.0094\n",
      "Epoch 255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7531 - dice_coef: 0.7531 - val_loss: -0.0179 - val_dice_coef: 0.0179\n",
      "Epoch 256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7568 - dice_coef: 0.7568 - val_loss: -0.0368 - val_dice_coef: 0.0368\n",
      "Epoch 257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7534 - dice_coef: 0.7534 - val_loss: -0.0270 - val_dice_coef: 0.0270\n",
      "Epoch 258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7571 - dice_coef: 0.7571 - val_loss: -0.0097 - val_dice_coef: 0.0097\n",
      "Epoch 259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7560 - dice_coef: 0.7560 - val_loss: -0.0201 - val_dice_coef: 0.0201\n",
      "Epoch 260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7627 - dice_coef: 0.7627 - val_loss: -0.0293 - val_dice_coef: 0.0293\n",
      "Epoch 261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7637 - dice_coef: 0.7637 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7538 - dice_coef: 0.7538 - val_loss: -0.0205 - val_dice_coef: 0.0205\n",
      "Epoch 263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7650 - dice_coef: 0.7650 - val_loss: -0.0238 - val_dice_coef: 0.0238\n",
      "Epoch 264/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7660 - dice_coef: 0.7660 - val_loss: -0.0292 - val_dice_coef: 0.0292\n",
      "Epoch 265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.0419 - val_dice_coef: 0.0419\n",
      "Epoch 266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7528 - dice_coef: 0.7528 - val_loss: -0.0428 - val_dice_coef: 0.0428\n",
      "Epoch 267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7596 - dice_coef: 0.7596 - val_loss: -0.0121 - val_dice_coef: 0.0121\n",
      "Epoch 268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7546 - dice_coef: 0.7546 - val_loss: -0.0121 - val_dice_coef: 0.0121\n",
      "Epoch 269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7489 - dice_coef: 0.7489 - val_loss: -0.0822 - val_dice_coef: 0.0822\n",
      "Epoch 270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7523 - dice_coef: 0.7523 - val_loss: -0.0180 - val_dice_coef: 0.0180\n",
      "Epoch 271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7621 - dice_coef: 0.7621 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7515 - dice_coef: 0.7515 - val_loss: -0.0182 - val_dice_coef: 0.0182\n",
      "Epoch 273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7665 - dice_coef: 0.7665 - val_loss: -0.1468 - val_dice_coef: 0.1468\n",
      "Epoch 274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7493 - dice_coef: 0.7493 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7508 - dice_coef: 0.7508 - val_loss: -0.0054 - val_dice_coef: 0.0054\n",
      "Epoch 276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7320 - dice_coef: 0.7320 - val_loss: -0.0317 - val_dice_coef: 0.0317\n",
      "Epoch 277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7667 - dice_coef: 0.7667 - val_loss: -0.0886 - val_dice_coef: 0.0886\n",
      "Epoch 278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7651 - dice_coef: 0.7651 - val_loss: -0.0332 - val_dice_coef: 0.0332\n",
      "Epoch 279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7680 - dice_coef: 0.7680 - val_loss: -0.0117 - val_dice_coef: 0.0117\n",
      "Epoch 280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7641 - dice_coef: 0.7641 - val_loss: -0.0450 - val_dice_coef: 0.0450\n",
      "Epoch 281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7727 - dice_coef: 0.7727 - val_loss: -0.0529 - val_dice_coef: 0.0529\n",
      "Epoch 282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7684 - dice_coef: 0.7684 - val_loss: -0.0181 - val_dice_coef: 0.0181\n",
      "Epoch 283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7581 - dice_coef: 0.7581 - val_loss: -0.0128 - val_dice_coef: 0.0128\n",
      "Epoch 284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7690 - dice_coef: 0.7690 - val_loss: -0.1661 - val_dice_coef: 0.1661\n",
      "Epoch 285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7511 - dice_coef: 0.7511 - val_loss: -0.0575 - val_dice_coef: 0.0575\n",
      "Epoch 286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7490 - dice_coef: 0.7490 - val_loss: -0.0060 - val_dice_coef: 0.0060\n",
      "Epoch 287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7464 - dice_coef: 0.7464 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.1159 - val_dice_coef: 0.1159\n",
      "Epoch 289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7589 - dice_coef: 0.7589 - val_loss: -0.0304 - val_dice_coef: 0.0304\n",
      "Epoch 290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7723 - dice_coef: 0.7723 - val_loss: -0.0227 - val_dice_coef: 0.0227\n",
      "Epoch 291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.1234 - val_dice_coef: 0.1234\n",
      "Epoch 292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7605 - dice_coef: 0.7605 - val_loss: -0.0438 - val_dice_coef: 0.0438\n",
      "Epoch 293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7657 - dice_coef: 0.7657 - val_loss: -0.0111 - val_dice_coef: 0.0111\n",
      "Epoch 294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7631 - dice_coef: 0.7631 - val_loss: -0.0315 - val_dice_coef: 0.0315\n",
      "Epoch 295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7672 - dice_coef: 0.7672 - val_loss: -0.1202 - val_dice_coef: 0.1202\n",
      "Epoch 296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7644 - dice_coef: 0.7644 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7772 - dice_coef: 0.7772 - val_loss: -0.0368 - val_dice_coef: 0.0368\n",
      "Epoch 298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7811 - dice_coef: 0.7811 - val_loss: -0.0406 - val_dice_coef: 0.0406\n",
      "Epoch 299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7793 - dice_coef: 0.7793 - val_loss: -0.0366 - val_dice_coef: 0.0366\n",
      "Epoch 300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7765 - dice_coef: 0.7765 - val_loss: -0.0462 - val_dice_coef: 0.0462\n",
      "Epoch 301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7801 - dice_coef: 0.7801 - val_loss: -0.0380 - val_dice_coef: 0.0380\n",
      "Epoch 302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7843 - dice_coef: 0.7843 - val_loss: -0.0308 - val_dice_coef: 0.0308\n",
      "Epoch 303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.0704 - val_dice_coef: 0.0704\n",
      "Epoch 304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7836 - dice_coef: 0.7836 - val_loss: -0.0287 - val_dice_coef: 0.0287\n",
      "Epoch 305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7746 - dice_coef: 0.7746 - val_loss: -0.0166 - val_dice_coef: 0.0166\n",
      "Epoch 306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7803 - dice_coef: 0.7803 - val_loss: -0.0775 - val_dice_coef: 0.0775\n",
      "Epoch 307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7800 - dice_coef: 0.7800 - val_loss: -0.1300 - val_dice_coef: 0.1300\n",
      "Epoch 308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7711 - dice_coef: 0.7711 - val_loss: -0.0263 - val_dice_coef: 0.0263\n",
      "Epoch 309/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.0347 - val_dice_coef: 0.0347\n",
      "Epoch 310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7814 - dice_coef: 0.7814 - val_loss: -0.1873 - val_dice_coef: 0.1873\n",
      "Epoch 311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7737 - dice_coef: 0.7737 - val_loss: -0.0234 - val_dice_coef: 0.0234\n",
      "Epoch 312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7865 - dice_coef: 0.7865 - val_loss: -0.0305 - val_dice_coef: 0.0305\n",
      "Epoch 313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7862 - dice_coef: 0.7862 - val_loss: -0.1655 - val_dice_coef: 0.1655\n",
      "Epoch 314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7647 - dice_coef: 0.7647 - val_loss: -0.0500 - val_dice_coef: 0.0500\n",
      "Epoch 315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7715 - dice_coef: 0.7715 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7758 - dice_coef: 0.7758 - val_loss: -0.0337 - val_dice_coef: 0.0337\n",
      "Epoch 317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7726 - dice_coef: 0.7726 - val_loss: -0.3706 - val_dice_coef: 0.3706\n",
      "Epoch 318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7635 - dice_coef: 0.7635 - val_loss: -0.0253 - val_dice_coef: 0.0253\n",
      "Epoch 319/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7743 - dice_coef: 0.7743 - val_loss: -0.0220 - val_dice_coef: 0.0220\n",
      "Epoch 320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7790 - dice_coef: 0.7790 - val_loss: -0.3092 - val_dice_coef: 0.3092\n",
      "Epoch 321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7765 - dice_coef: 0.7765 - val_loss: -0.0460 - val_dice_coef: 0.0460\n",
      "Epoch 322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.0553 - val_dice_coef: 0.0553\n",
      "Epoch 323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7894 - dice_coef: 0.7894 - val_loss: -0.0739 - val_dice_coef: 0.0739\n",
      "Epoch 324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7897 - dice_coef: 0.7897 - val_loss: -0.0448 - val_dice_coef: 0.0448\n",
      "Epoch 325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7875 - dice_coef: 0.7875 - val_loss: -0.1956 - val_dice_coef: 0.1956\n",
      "Epoch 326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7813 - dice_coef: 0.7813 - val_loss: -0.0695 - val_dice_coef: 0.0695\n",
      "Epoch 327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7855 - dice_coef: 0.7855 - val_loss: -0.0172 - val_dice_coef: 0.0172\n",
      "Epoch 328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7796 - dice_coef: 0.7796 - val_loss: -0.1357 - val_dice_coef: 0.1357\n",
      "Epoch 329/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.0997 - val_dice_coef: 0.0997\n",
      "Epoch 330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7906 - dice_coef: 0.7906 - val_loss: -0.0891 - val_dice_coef: 0.0891\n",
      "Epoch 331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0921 - val_dice_coef: 0.0921\n",
      "Epoch 332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0405 - val_dice_coef: 0.0405\n",
      "Epoch 333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7855 - dice_coef: 0.7855 - val_loss: -0.0510 - val_dice_coef: 0.0510\n",
      "Epoch 334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7910 - dice_coef: 0.7910 - val_loss: -0.1837 - val_dice_coef: 0.1837\n",
      "Epoch 335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7908 - dice_coef: 0.7908 - val_loss: -0.0455 - val_dice_coef: 0.0455\n",
      "Epoch 336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7915 - dice_coef: 0.7915 - val_loss: -0.0512 - val_dice_coef: 0.0512\n",
      "Epoch 337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7943 - dice_coef: 0.7943 - val_loss: -0.0565 - val_dice_coef: 0.0565\n",
      "Epoch 338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7922 - dice_coef: 0.7922 - val_loss: -0.1822 - val_dice_coef: 0.1822\n",
      "Epoch 339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7888 - dice_coef: 0.7888 - val_loss: -0.1480 - val_dice_coef: 0.1480\n",
      "Epoch 340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0323 - val_dice_coef: 0.0323\n",
      "Epoch 341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7877 - dice_coef: 0.7877 - val_loss: -0.0631 - val_dice_coef: 0.0631\n",
      "Epoch 342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7904 - dice_coef: 0.7904 - val_loss: -0.2945 - val_dice_coef: 0.2945\n",
      "Epoch 343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7871 - dice_coef: 0.7871 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7925 - dice_coef: 0.7925 - val_loss: -0.0235 - val_dice_coef: 0.0235\n",
      "Epoch 345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.2343 - val_dice_coef: 0.2343\n",
      "Epoch 346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.3386 - val_dice_coef: 0.3386\n",
      "Epoch 347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7806 - dice_coef: 0.7806 - val_loss: -0.0261 - val_dice_coef: 0.0261\n",
      "Epoch 348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7710 - dice_coef: 0.7710 - val_loss: -0.0138 - val_dice_coef: 0.0138\n",
      "Epoch 349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7821 - dice_coef: 0.7821 - val_loss: -0.1816 - val_dice_coef: 0.1816\n",
      "Epoch 350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7889 - dice_coef: 0.7889 - val_loss: -0.1050 - val_dice_coef: 0.1050\n",
      "Epoch 351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.0298 - val_dice_coef: 0.0298\n",
      "Epoch 352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0611 - val_dice_coef: 0.0611\n",
      "Epoch 353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7945 - dice_coef: 0.7945 - val_loss: -0.2319 - val_dice_coef: 0.2319\n",
      "Epoch 354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7917 - dice_coef: 0.7917 - val_loss: -0.0280 - val_dice_coef: 0.0280\n",
      "Epoch 355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7923 - dice_coef: 0.7923 - val_loss: -0.0318 - val_dice_coef: 0.0318\n",
      "Epoch 356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7939 - dice_coef: 0.7939 - val_loss: -0.3564 - val_dice_coef: 0.3564\n",
      "Epoch 357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7757 - dice_coef: 0.7757 - val_loss: -0.2784 - val_dice_coef: 0.2784\n",
      "Epoch 358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.0262 - val_dice_coef: 0.0262\n",
      "Epoch 359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.0401 - val_dice_coef: 0.0401\n",
      "Epoch 360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7981 - dice_coef: 0.7981 - val_loss: -0.1451 - val_dice_coef: 0.1451\n",
      "Epoch 361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7965 - dice_coef: 0.7965 - val_loss: -0.1857 - val_dice_coef: 0.1857\n",
      "Epoch 362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7975 - dice_coef: 0.7975 - val_loss: -0.1279 - val_dice_coef: 0.1279\n",
      "Epoch 363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7960 - dice_coef: 0.7960 - val_loss: -0.0669 - val_dice_coef: 0.0669\n",
      "Epoch 364/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7950 - dice_coef: 0.7950 - val_loss: -0.0174 - val_dice_coef: 0.0174\n",
      "Epoch 365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7857 - dice_coef: 0.7857 - val_loss: -0.2840 - val_dice_coef: 0.2840\n",
      "Epoch 366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7901 - dice_coef: 0.7901 - val_loss: -0.1057 - val_dice_coef: 0.1057\n",
      "Epoch 367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7978 - dice_coef: 0.7978 - val_loss: -0.0326 - val_dice_coef: 0.0326\n",
      "Epoch 368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8003 - dice_coef: 0.8003 - val_loss: -0.2679 - val_dice_coef: 0.2679\n",
      "Epoch 369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7977 - dice_coef: 0.7977 - val_loss: -0.0832 - val_dice_coef: 0.0832\n",
      "Epoch 370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7953 - dice_coef: 0.7953 - val_loss: -0.0212 - val_dice_coef: 0.0212\n",
      "Epoch 371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7756 - dice_coef: 0.7756 - val_loss: -0.0832 - val_dice_coef: 0.0832\n",
      "Epoch 372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7952 - dice_coef: 0.7952 - val_loss: -0.2984 - val_dice_coef: 0.2984\n",
      "Epoch 373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7982 - dice_coef: 0.7982 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 374/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7899 - dice_coef: 0.7899 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7938 - dice_coef: 0.7938 - val_loss: -0.4212 - val_dice_coef: 0.4212\n",
      "Epoch 376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7856 - dice_coef: 0.7856 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0200 - val_dice_coef: 0.0200\n",
      "Epoch 378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.1871 - val_dice_coef: 0.1871\n",
      "Epoch 379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8004 - dice_coef: 0.8004 - val_loss: -0.0478 - val_dice_coef: 0.0478\n",
      "Epoch 380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7945 - dice_coef: 0.7945 - val_loss: -0.1252 - val_dice_coef: 0.1252\n",
      "Epoch 381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8001 - dice_coef: 0.8001 - val_loss: -0.0781 - val_dice_coef: 0.0781\n",
      "Epoch 382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8039 - dice_coef: 0.8039 - val_loss: -0.0673 - val_dice_coef: 0.0673\n",
      "Epoch 383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8036 - dice_coef: 0.8036 - val_loss: -0.2480 - val_dice_coef: 0.2480\n",
      "Epoch 384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8073 - dice_coef: 0.8073 - val_loss: -0.1304 - val_dice_coef: 0.1304\n",
      "Epoch 385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.0706 - val_dice_coef: 0.0706\n",
      "Epoch 386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8046 - dice_coef: 0.8046 - val_loss: -0.1223 - val_dice_coef: 0.1223\n",
      "Epoch 387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7970 - dice_coef: 0.7970 - val_loss: -0.0542 - val_dice_coef: 0.0542\n",
      "Epoch 388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.0396 - val_dice_coef: 0.0396\n",
      "Epoch 389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.0432 - val_dice_coef: 0.0432\n",
      "Epoch 390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8010 - dice_coef: 0.8010 - val_loss: -0.0633 - val_dice_coef: 0.0633\n",
      "Epoch 391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7970 - dice_coef: 0.7970 - val_loss: -0.2965 - val_dice_coef: 0.2965\n",
      "Epoch 392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8006 - dice_coef: 0.8006 - val_loss: -0.0632 - val_dice_coef: 0.0632\n",
      "Epoch 393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.0993 - val_dice_coef: 0.0993\n",
      "Epoch 394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8019 - dice_coef: 0.8019 - val_loss: -0.1495 - val_dice_coef: 0.1495\n",
      "Epoch 395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8043 - dice_coef: 0.8043 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.1207 - val_dice_coef: 0.1207\n",
      "Epoch 397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8080 - dice_coef: 0.8080 - val_loss: -0.2400 - val_dice_coef: 0.2400\n",
      "Epoch 398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.0589 - val_dice_coef: 0.0589\n",
      "Epoch 399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7983 - dice_coef: 0.7983 - val_loss: -0.0306 - val_dice_coef: 0.0306\n",
      "Epoch 400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7974 - dice_coef: 0.7974 - val_loss: -0.2292 - val_dice_coef: 0.2292\n",
      "Epoch 401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7948 - dice_coef: 0.7948 - val_loss: -0.1820 - val_dice_coef: 0.1820\n",
      "Epoch 402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.0473 - val_dice_coef: 0.0473\n",
      "Epoch 403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7961 - dice_coef: 0.7961 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8052 - dice_coef: 0.8052 - val_loss: -0.1058 - val_dice_coef: 0.1058\n",
      "Epoch 405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.1093 - val_dice_coef: 0.1093\n",
      "Epoch 407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8056 - dice_coef: 0.8056 - val_loss: -0.1696 - val_dice_coef: 0.1696\n",
      "Epoch 408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7967 - dice_coef: 0.7967 - val_loss: -0.2107 - val_dice_coef: 0.2107\n",
      "Epoch 409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.2258 - val_dice_coef: 0.2258\n",
      "Epoch 410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.0673 - val_dice_coef: 0.0673\n",
      "Epoch 411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8081 - dice_coef: 0.8081 - val_loss: -0.0421 - val_dice_coef: 0.0421\n",
      "Epoch 412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7927 - dice_coef: 0.7927 - val_loss: -0.0356 - val_dice_coef: 0.0356\n",
      "Epoch 413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7405 - dice_coef: 0.7405 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7844 - dice_coef: 0.7844 - val_loss: -0.6107 - val_dice_coef: 0.6107\n",
      "Epoch 415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7791 - dice_coef: 0.7791 - val_loss: -0.0159 - val_dice_coef: 0.0159\n",
      "Epoch 416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0370 - val_dice_coef: 0.0370\n",
      "Epoch 417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8034 - dice_coef: 0.8034 - val_loss: -0.2351 - val_dice_coef: 0.2351\n",
      "Epoch 418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8086 - dice_coef: 0.8086 - val_loss: -0.1190 - val_dice_coef: 0.1190\n",
      "Epoch 419/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.0477 - val_dice_coef: 0.0477\n",
      "Epoch 420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8046 - dice_coef: 0.8046 - val_loss: -0.2101 - val_dice_coef: 0.2101\n",
      "Epoch 421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8109 - dice_coef: 0.8109 - val_loss: -0.2076 - val_dice_coef: 0.2076\n",
      "Epoch 422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8069 - dice_coef: 0.8069 - val_loss: -0.0993 - val_dice_coef: 0.0993\n",
      "Epoch 423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.0434 - val_dice_coef: 0.0434\n",
      "Epoch 424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8075 - dice_coef: 0.8075 - val_loss: -0.1762 - val_dice_coef: 0.1762\n",
      "Epoch 425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8059 - dice_coef: 0.8059 - val_loss: -0.1748 - val_dice_coef: 0.1748\n",
      "Epoch 426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.0394 - val_dice_coef: 0.0394\n",
      "Epoch 427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8040 - dice_coef: 0.8040 - val_loss: -0.1564 - val_dice_coef: 0.1564\n",
      "Epoch 428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8008 - dice_coef: 0.8008 - val_loss: -0.4271 - val_dice_coef: 0.4271\n",
      "Epoch 429/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7984 - dice_coef: 0.7984 - val_loss: -0.1725 - val_dice_coef: 0.1725\n",
      "Epoch 430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8074 - dice_coef: 0.8074 - val_loss: -0.0370 - val_dice_coef: 0.0370\n",
      "Epoch 431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8131 - dice_coef: 0.8131 - val_loss: -0.1404 - val_dice_coef: 0.1404\n",
      "Epoch 433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8154 - dice_coef: 0.8154 - val_loss: -0.0652 - val_dice_coef: 0.0652\n",
      "Epoch 434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8114 - dice_coef: 0.8114 - val_loss: -0.2139 - val_dice_coef: 0.2139\n",
      "Epoch 435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8117 - dice_coef: 0.8117 - val_loss: -0.1163 - val_dice_coef: 0.1163\n",
      "Epoch 436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8121 - dice_coef: 0.8121 - val_loss: -0.0403 - val_dice_coef: 0.0403\n",
      "Epoch 437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8067 - dice_coef: 0.8067 - val_loss: -0.1288 - val_dice_coef: 0.1288\n",
      "Epoch 438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8150 - dice_coef: 0.8150 - val_loss: -0.1334 - val_dice_coef: 0.1334\n",
      "Epoch 439/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8177 - dice_coef: 0.8177 - val_loss: -0.1014 - val_dice_coef: 0.1014\n",
      "Epoch 440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8152 - dice_coef: 0.8152 - val_loss: -0.2299 - val_dice_coef: 0.2299\n",
      "Epoch 441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.1904 - val_dice_coef: 0.1904\n",
      "Epoch 442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8164 - dice_coef: 0.8164 - val_loss: -0.0625 - val_dice_coef: 0.0625\n",
      "Epoch 443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.1399 - val_dice_coef: 0.1399\n",
      "Epoch 444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8148 - dice_coef: 0.8148 - val_loss: -0.1434 - val_dice_coef: 0.1434\n",
      "Epoch 445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.3043 - val_dice_coef: 0.3043\n",
      "Epoch 446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8101 - dice_coef: 0.8101 - val_loss: -0.0396 - val_dice_coef: 0.0396\n",
      "Epoch 447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8028 - dice_coef: 0.8028 - val_loss: -0.0283 - val_dice_coef: 0.0283\n",
      "Epoch 448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8115 - dice_coef: 0.8115 - val_loss: -0.0963 - val_dice_coef: 0.0963\n",
      "Epoch 449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8078 - dice_coef: 0.8078 - val_loss: -0.4016 - val_dice_coef: 0.4016\n",
      "Epoch 450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.0483 - val_dice_coef: 0.0483\n",
      "Epoch 451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.0221 - val_dice_coef: 0.0221\n",
      "Epoch 452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.1492 - val_dice_coef: 0.1492\n",
      "Epoch 453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8146 - dice_coef: 0.8146 - val_loss: -0.5575 - val_dice_coef: 0.5575\n",
      "Epoch 454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8078 - dice_coef: 0.8078 - val_loss: -0.1795 - val_dice_coef: 0.1795\n",
      "Epoch 455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7962 - dice_coef: 0.7962 - val_loss: -0.0179 - val_dice_coef: 0.0179\n",
      "Epoch 456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.0442 - val_dice_coef: 0.0442\n",
      "Epoch 457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8024 - dice_coef: 0.8024 - val_loss: -0.6116 - val_dice_coef: 0.6116\n",
      "Epoch 458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8017 - dice_coef: 0.8017 - val_loss: -0.3085 - val_dice_coef: 0.3085\n",
      "Epoch 459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8160 - dice_coef: 0.8160 - val_loss: -0.0279 - val_dice_coef: 0.0279\n",
      "Epoch 460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8097 - dice_coef: 0.8097 - val_loss: -0.0992 - val_dice_coef: 0.0992\n",
      "Epoch 461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8141 - dice_coef: 0.8141 - val_loss: -0.5515 - val_dice_coef: 0.5515\n",
      "Epoch 462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8051 - dice_coef: 0.8051 - val_loss: -0.3915 - val_dice_coef: 0.3915\n",
      "Epoch 463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8133 - dice_coef: 0.8133 - val_loss: -0.0291 - val_dice_coef: 0.0291\n",
      "Epoch 464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.1182 - val_dice_coef: 0.1182\n",
      "Epoch 465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8176 - dice_coef: 0.8176 - val_loss: -0.2284 - val_dice_coef: 0.2284\n",
      "Epoch 466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8167 - dice_coef: 0.8167 - val_loss: -0.0484 - val_dice_coef: 0.0484\n",
      "Epoch 467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8147 - dice_coef: 0.8147 - val_loss: -0.1196 - val_dice_coef: 0.1196\n",
      "Epoch 468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.5032 - val_dice_coef: 0.5032\n",
      "Epoch 469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8130 - dice_coef: 0.8130 - val_loss: -0.0393 - val_dice_coef: 0.0393\n",
      "Epoch 470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.0320 - val_dice_coef: 0.0320\n",
      "Epoch 471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8117 - dice_coef: 0.8117 - val_loss: -0.5914 - val_dice_coef: 0.5914\n",
      "Epoch 472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.6983 - val_dice_coef: 0.6983\n",
      "Epoch 473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7959 - dice_coef: 0.7959 - val_loss: -0.0990 - val_dice_coef: 0.0990\n",
      "Epoch 474/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8124 - dice_coef: 0.8124 - val_loss: -0.0336 - val_dice_coef: 0.0336\n",
      "Epoch 475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8132 - dice_coef: 0.8132 - val_loss: -0.4476 - val_dice_coef: 0.4476\n",
      "Epoch 476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.1058 - val_dice_coef: 0.1058\n",
      "Epoch 477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.1145 - val_dice_coef: 0.1145\n",
      "Epoch 478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.2891 - val_dice_coef: 0.2891\n",
      "Epoch 479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8193 - dice_coef: 0.8193 - val_loss: -0.1217 - val_dice_coef: 0.1217\n",
      "Epoch 480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8199 - dice_coef: 0.8199 - val_loss: -0.2064 - val_dice_coef: 0.2064\n",
      "Epoch 481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8178 - dice_coef: 0.8178 - val_loss: -0.2016 - val_dice_coef: 0.2016\n",
      "Epoch 482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8206 - dice_coef: 0.8206 - val_loss: -0.2538 - val_dice_coef: 0.2538\n",
      "Epoch 483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8219 - dice_coef: 0.8219 - val_loss: -0.2956 - val_dice_coef: 0.2956\n",
      "Epoch 484/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8207 - dice_coef: 0.8207 - val_loss: -0.1771 - val_dice_coef: 0.1771\n",
      "Epoch 485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.2624 - val_dice_coef: 0.2624\n",
      "Epoch 486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8105 - dice_coef: 0.8105 - val_loss: -0.4911 - val_dice_coef: 0.4911\n",
      "Epoch 487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8167 - dice_coef: 0.8167 - val_loss: -0.0686 - val_dice_coef: 0.0686\n",
      "Epoch 488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8197 - dice_coef: 0.8197 - val_loss: -0.0760 - val_dice_coef: 0.0760\n",
      "Epoch 489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8223 - dice_coef: 0.8223 - val_loss: -0.0500 - val_dice_coef: 0.0500\n",
      "Epoch 490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.0601 - val_dice_coef: 0.0601\n",
      "Epoch 491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8160 - dice_coef: 0.8160 - val_loss: -0.4535 - val_dice_coef: 0.4535\n",
      "Epoch 492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.2184 - val_dice_coef: 0.2184\n",
      "Epoch 493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0320 - val_dice_coef: 0.0320\n",
      "Epoch 494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7959 - dice_coef: 0.7959 - val_loss: -0.0186 - val_dice_coef: 0.0186\n",
      "Epoch 495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8054 - dice_coef: 0.8054 - val_loss: -0.3697 - val_dice_coef: 0.3697\n",
      "Epoch 496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7997 - dice_coef: 0.7997 - val_loss: -0.7929 - val_dice_coef: 0.7929\n",
      "Epoch 497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.0672 - val_dice_coef: 0.0672\n",
      "Epoch 498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.0293 - val_dice_coef: 0.0293\n",
      "Epoch 499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.9266 - val_dice_coef: 0.9266\n",
      "Epoch 500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7841 - dice_coef: 0.7841 - val_loss: -0.1199 - val_dice_coef: 0.1199\n",
      "Epoch 501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8165 - dice_coef: 0.8165 - val_loss: -0.0417 - val_dice_coef: 0.0417\n",
      "Epoch 502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.4505 - val_dice_coef: 0.4505\n",
      "Epoch 503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8198 - dice_coef: 0.8198 - val_loss: -0.2722 - val_dice_coef: 0.2722\n",
      "Epoch 504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8236 - dice_coef: 0.8236 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8252 - dice_coef: 0.8252 - val_loss: -0.2344 - val_dice_coef: 0.2344\n",
      "Epoch 506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8219 - dice_coef: 0.8219 - val_loss: -0.3935 - val_dice_coef: 0.3935\n",
      "Epoch 507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8250 - dice_coef: 0.8250 - val_loss: -0.0641 - val_dice_coef: 0.0641\n",
      "Epoch 508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.4545 - val_dice_coef: 0.4545\n",
      "Epoch 509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8205 - dice_coef: 0.8205 - val_loss: -0.3286 - val_dice_coef: 0.3286\n",
      "Epoch 510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8140 - dice_coef: 0.8140 - val_loss: -0.1836 - val_dice_coef: 0.1836\n",
      "Epoch 511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8239 - dice_coef: 0.8239 - val_loss: -0.2571 - val_dice_coef: 0.2571\n",
      "Epoch 512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8244 - dice_coef: 0.8244 - val_loss: -0.1180 - val_dice_coef: 0.1180\n",
      "Epoch 513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.2087 - val_dice_coef: 0.2087\n",
      "Epoch 514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8267 - dice_coef: 0.8267 - val_loss: -0.1494 - val_dice_coef: 0.1494\n",
      "Epoch 515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8282 - dice_coef: 0.8282 - val_loss: -0.1149 - val_dice_coef: 0.1149\n",
      "Epoch 516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8282 - dice_coef: 0.8282 - val_loss: -0.4932 - val_dice_coef: 0.4932\n",
      "Epoch 517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8136 - dice_coef: 0.8136 - val_loss: -0.5778 - val_dice_coef: 0.5778\n",
      "Epoch 518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8171 - dice_coef: 0.8171 - val_loss: -0.1004 - val_dice_coef: 0.1004\n",
      "Epoch 519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8237 - dice_coef: 0.8237 - val_loss: -0.1345 - val_dice_coef: 0.1345\n",
      "Epoch 520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.1655 - val_dice_coef: 0.1655\n",
      "Epoch 521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8269 - dice_coef: 0.8269 - val_loss: -0.7545 - val_dice_coef: 0.7545\n",
      "Epoch 522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8210 - dice_coef: 0.8210 - val_loss: -0.3689 - val_dice_coef: 0.3689\n",
      "Epoch 523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.2003 - val_dice_coef: 0.2003\n",
      "Epoch 524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.0712 - val_dice_coef: 0.0712\n",
      "Epoch 525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8176 - dice_coef: 0.8176 - val_loss: -0.0582 - val_dice_coef: 0.0582\n",
      "Epoch 526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8188 - dice_coef: 0.8188 - val_loss: -0.0770 - val_dice_coef: 0.0770\n",
      "Epoch 527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8180 - dice_coef: 0.8180 - val_loss: -0.2046 - val_dice_coef: 0.2046\n",
      "Epoch 528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8192 - dice_coef: 0.8192 - val_loss: -0.9066 - val_dice_coef: 0.9066\n",
      "Epoch 529/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7969 - dice_coef: 0.7969 - val_loss: -0.0630 - val_dice_coef: 0.0630\n",
      "Epoch 530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.0144 - val_dice_coef: 0.0144\n",
      "Epoch 531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.6773 - val_dice_coef: 0.6773\n",
      "Epoch 532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.4786 - val_dice_coef: 0.4786\n",
      "Epoch 533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8136 - dice_coef: 0.8136 - val_loss: -0.0916 - val_dice_coef: 0.0916\n",
      "Epoch 534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8265 - dice_coef: 0.8265 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.2900 - val_dice_coef: 0.2900\n",
      "Epoch 536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8082 - dice_coef: 0.8082 - val_loss: -0.0148 - val_dice_coef: 0.0148\n",
      "Epoch 537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.0460 - val_dice_coef: 0.0460\n",
      "Epoch 538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8138 - dice_coef: 0.8138 - val_loss: -0.7499 - val_dice_coef: 0.7499\n",
      "Epoch 539/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8153 - dice_coef: 0.8153 - val_loss: -0.0671 - val_dice_coef: 0.0671\n",
      "Epoch 540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8169 - dice_coef: 0.8169 - val_loss: -0.0314 - val_dice_coef: 0.0314\n",
      "Epoch 541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8112 - dice_coef: 0.8112 - val_loss: -0.7243 - val_dice_coef: 0.7243\n",
      "Epoch 542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8226 - dice_coef: 0.8226 - val_loss: -0.0891 - val_dice_coef: 0.0891\n",
      "Epoch 543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8200 - dice_coef: 0.8200 - val_loss: -0.0178 - val_dice_coef: 0.0178\n",
      "Epoch 544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.6045 - val_dice_coef: 0.6045\n",
      "Epoch 545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8159 - dice_coef: 0.8159 - val_loss: -0.5087 - val_dice_coef: 0.5087\n",
      "Epoch 546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8215 - dice_coef: 0.8215 - val_loss: -0.1051 - val_dice_coef: 0.1051\n",
      "Epoch 547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8251 - dice_coef: 0.8251 - val_loss: -0.3124 - val_dice_coef: 0.3124\n",
      "Epoch 548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8321 - dice_coef: 0.8321 - val_loss: -0.2700 - val_dice_coef: 0.2700\n",
      "Epoch 549/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8308 - dice_coef: 0.8308 - val_loss: -0.3569 - val_dice_coef: 0.3569\n",
      "Epoch 550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8291 - dice_coef: 0.8291 - val_loss: -0.2589 - val_dice_coef: 0.2589\n",
      "Epoch 551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8312 - dice_coef: 0.8312 - val_loss: -0.4501 - val_dice_coef: 0.4501\n",
      "Epoch 552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8288 - dice_coef: 0.8288 - val_loss: -0.2028 - val_dice_coef: 0.2028\n",
      "Epoch 553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8296 - dice_coef: 0.8296 - val_loss: -0.0799 - val_dice_coef: 0.0799\n",
      "Epoch 554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8302 - dice_coef: 0.8302 - val_loss: -0.5327 - val_dice_coef: 0.5327\n",
      "Epoch 555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8187 - dice_coef: 0.8187 - val_loss: -0.6675 - val_dice_coef: 0.6675\n",
      "Epoch 556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.1430 - val_dice_coef: 0.1430\n",
      "Epoch 557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.2106 - val_dice_coef: 0.2106\n",
      "Epoch 558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.2974 - val_dice_coef: 0.2974\n",
      "Epoch 559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8298 - dice_coef: 0.8298 - val_loss: -0.4039 - val_dice_coef: 0.4039\n",
      "Epoch 560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8331 - dice_coef: 0.8331 - val_loss: -0.6531 - val_dice_coef: 0.6531\n",
      "Epoch 561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.2544 - val_dice_coef: 0.2544\n",
      "Epoch 562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.0751 - val_dice_coef: 0.0751\n",
      "Epoch 563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.2586 - val_dice_coef: 0.2586\n",
      "Epoch 564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.5444 - val_dice_coef: 0.5444\n",
      "Epoch 565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.1186 - val_dice_coef: 0.1186\n",
      "Epoch 566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8259 - dice_coef: 0.8259 - val_loss: -0.1178 - val_dice_coef: 0.1178\n",
      "Epoch 567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.9145 - val_dice_coef: 0.9145\n",
      "Epoch 568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7752 - dice_coef: 0.7752 - val_loss: -0.6345 - val_dice_coef: 0.6345\n",
      "Epoch 569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7562 - dice_coef: 0.7562 - val_loss: -0.0040 - val_dice_coef: 0.0040\n",
      "Epoch 570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6895 - dice_coef: 0.6895 - val_loss: -0.1639 - val_dice_coef: 0.1639\n",
      "Epoch 571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7304 - dice_coef: 0.7304 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7258 - dice_coef: 0.7258 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7116 - dice_coef: 0.7116 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7699 - dice_coef: 0.7699 - val_loss: -0.0039 - val_dice_coef: 0.0039\n",
      "Epoch 575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7622 - dice_coef: 0.7622 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7658 - dice_coef: 0.7658 - val_loss: -0.0136 - val_dice_coef: 0.0136\n",
      "Epoch 577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7974 - dice_coef: 0.7974 - val_loss: -0.9098 - val_dice_coef: 0.9098\n",
      "Epoch 578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8113 - dice_coef: 0.8113 - val_loss: -0.0898 - val_dice_coef: 0.0898\n",
      "Epoch 579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.2365 - val_dice_coef: 0.2365\n",
      "Epoch 580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8177 - dice_coef: 0.8177 - val_loss: -0.6985 - val_dice_coef: 0.6985\n",
      "Epoch 581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8187 - dice_coef: 0.8187 - val_loss: -0.0752 - val_dice_coef: 0.0752\n",
      "Epoch 582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8180 - dice_coef: 0.8180 - val_loss: -0.7295 - val_dice_coef: 0.7295\n",
      "Epoch 583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.3519 - val_dice_coef: 0.3519\n",
      "Epoch 584/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.1809 - val_dice_coef: 0.1809\n",
      "Epoch 585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8238 - dice_coef: 0.8238 - val_loss: -0.6086 - val_dice_coef: 0.6086\n",
      "Epoch 586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8228 - dice_coef: 0.8228 - val_loss: -0.0682 - val_dice_coef: 0.0682\n",
      "Epoch 587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.3823 - val_dice_coef: 0.3823\n",
      "Epoch 588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8308 - dice_coef: 0.8308 - val_loss: -0.4799 - val_dice_coef: 0.4799\n",
      "Epoch 589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.1169 - val_dice_coef: 0.1169\n",
      "Epoch 590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8199 - dice_coef: 0.8199 - val_loss: -0.3753 - val_dice_coef: 0.3753\n",
      "Epoch 591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.4125 - val_dice_coef: 0.4125\n",
      "Epoch 592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8271 - dice_coef: 0.8271 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.6504 - val_dice_coef: 0.6504\n",
      "Epoch 594/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.3559 - val_dice_coef: 0.3559\n",
      "Epoch 595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8261 - dice_coef: 0.8261 - val_loss: -0.1354 - val_dice_coef: 0.1354\n",
      "Epoch 596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8276 - dice_coef: 0.8276 - val_loss: -0.6209 - val_dice_coef: 0.6209\n",
      "Epoch 597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8263 - dice_coef: 0.8263 - val_loss: -0.6462 - val_dice_coef: 0.6462\n",
      "Epoch 598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.2361 - val_dice_coef: 0.2361\n",
      "Epoch 599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.4628 - val_dice_coef: 0.4628\n",
      "Epoch 600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8351 - dice_coef: 0.8351 - val_loss: -0.3246 - val_dice_coef: 0.3246\n",
      "Epoch 601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.2202 - val_dice_coef: 0.2202\n",
      "Epoch 602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8328 - dice_coef: 0.8328 - val_loss: -0.2158 - val_dice_coef: 0.2158\n",
      "Epoch 603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.3146 - val_dice_coef: 0.3146\n",
      "Epoch 604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.6112 - val_dice_coef: 0.6112\n",
      "Epoch 605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8333 - dice_coef: 0.8333 - val_loss: -0.2770 - val_dice_coef: 0.2770\n",
      "Epoch 606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8330 - dice_coef: 0.8330 - val_loss: -0.1664 - val_dice_coef: 0.1664\n",
      "Epoch 607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.4966 - val_dice_coef: 0.4966\n",
      "Epoch 608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.2649 - val_dice_coef: 0.2649\n",
      "Epoch 609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8364 - dice_coef: 0.8364 - val_loss: -0.5426 - val_dice_coef: 0.5426\n",
      "Epoch 610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.2237 - val_dice_coef: 0.2237\n",
      "Epoch 611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8365 - dice_coef: 0.8365 - val_loss: -0.3087 - val_dice_coef: 0.3087\n",
      "Epoch 612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8360 - dice_coef: 0.8360 - val_loss: -0.6877 - val_dice_coef: 0.6877\n",
      "Epoch 613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8360 - dice_coef: 0.8360 - val_loss: -0.2832 - val_dice_coef: 0.2832\n",
      "Epoch 614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8373 - dice_coef: 0.8373 - val_loss: -0.2565 - val_dice_coef: 0.2565\n",
      "Epoch 615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8374 - dice_coef: 0.8374 - val_loss: -0.4029 - val_dice_coef: 0.4029\n",
      "Epoch 616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8396 - dice_coef: 0.8396 - val_loss: -0.4864 - val_dice_coef: 0.4864\n",
      "Epoch 617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8393 - dice_coef: 0.8393 - val_loss: -0.3034 - val_dice_coef: 0.3034\n",
      "Epoch 618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.2535 - val_dice_coef: 0.2535\n",
      "Epoch 619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.2476 - val_dice_coef: 0.2476\n",
      "Epoch 620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.6186 - val_dice_coef: 0.6186\n",
      "Epoch 621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.4832 - val_dice_coef: 0.4832\n",
      "Epoch 622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8194 - dice_coef: 0.8194 - val_loss: -0.0482 - val_dice_coef: 0.0482\n",
      "Epoch 623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8163 - dice_coef: 0.8163 - val_loss: -0.0297 - val_dice_coef: 0.0297\n",
      "Epoch 624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8084 - dice_coef: 0.8084 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7976 - dice_coef: 0.7976 - val_loss: -0.0325 - val_dice_coef: 0.0325\n",
      "Epoch 626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8020 - dice_coef: 0.8020 - val_loss: -0.0371 - val_dice_coef: 0.0371\n",
      "Epoch 627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8027 - dice_coef: 0.8027 - val_loss: -0.9913 - val_dice_coef: 0.9913\n",
      "Epoch 628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8093 - dice_coef: 0.8093 - val_loss: -0.0275 - val_dice_coef: 0.0275\n",
      "Epoch 629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8198 - dice_coef: 0.8198 - val_loss: -0.6022 - val_dice_coef: 0.6022\n",
      "Epoch 630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8278 - dice_coef: 0.8278 - val_loss: -0.3513 - val_dice_coef: 0.3513\n",
      "Epoch 631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.2364 - val_dice_coef: 0.2364\n",
      "Epoch 632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.5728 - val_dice_coef: 0.5728\n",
      "Epoch 633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.6481 - val_dice_coef: 0.6481\n",
      "Epoch 634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.2212 - val_dice_coef: 0.2212\n",
      "Epoch 635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8379 - dice_coef: 0.8379 - val_loss: -0.5144 - val_dice_coef: 0.5144\n",
      "Epoch 636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.3816 - val_dice_coef: 0.3816\n",
      "Epoch 637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.3823 - val_dice_coef: 0.3823\n",
      "Epoch 638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8392 - dice_coef: 0.8392 - val_loss: -0.3142 - val_dice_coef: 0.3142\n",
      "Epoch 639/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.3412 - val_dice_coef: 0.3412\n",
      "Epoch 640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8413 - dice_coef: 0.8413 - val_loss: -0.7510 - val_dice_coef: 0.7510\n",
      "Epoch 641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8342 - dice_coef: 0.8342 - val_loss: -0.5192 - val_dice_coef: 0.5192\n",
      "Epoch 642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8389 - dice_coef: 0.8389 - val_loss: -0.0560 - val_dice_coef: 0.0560\n",
      "Epoch 643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8275 - dice_coef: 0.8275 - val_loss: -0.6707 - val_dice_coef: 0.6707\n",
      "Epoch 644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8334 - dice_coef: 0.8334 - val_loss: -0.7639 - val_dice_coef: 0.7639\n",
      "Epoch 645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8363 - dice_coef: 0.8363 - val_loss: -0.4404 - val_dice_coef: 0.4404\n",
      "Epoch 646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.2856 - val_dice_coef: 0.2856\n",
      "Epoch 647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.5237 - val_dice_coef: 0.5237\n",
      "Epoch 648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8352 - dice_coef: 0.8352 - val_loss: -0.7274 - val_dice_coef: 0.7274\n",
      "Epoch 649/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.1787 - val_dice_coef: 0.1787\n",
      "Epoch 650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8377 - dice_coef: 0.8377 - val_loss: -0.3011 - val_dice_coef: 0.3011\n",
      "Epoch 651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.6969 - val_dice_coef: 0.6969\n",
      "Epoch 652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8369 - dice_coef: 0.8369 - val_loss: -0.1611 - val_dice_coef: 0.1611\n",
      "Epoch 653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8373 - dice_coef: 0.8373 - val_loss: -0.4017 - val_dice_coef: 0.4017\n",
      "Epoch 654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.7956 - val_dice_coef: 0.7956\n",
      "Epoch 655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.2720 - val_dice_coef: 0.2720\n",
      "Epoch 656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8399 - dice_coef: 0.8399 - val_loss: -0.3397 - val_dice_coef: 0.3397\n",
      "Epoch 657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.8481 - val_dice_coef: 0.8481\n",
      "Epoch 658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.5583 - val_dice_coef: 0.5583\n",
      "Epoch 659/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.0544 - val_dice_coef: 0.0544\n",
      "Epoch 660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8261 - dice_coef: 0.8261 - val_loss: -0.6444 - val_dice_coef: 0.6444\n",
      "Epoch 661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8272 - dice_coef: 0.8272 - val_loss: -0.7144 - val_dice_coef: 0.7144\n",
      "Epoch 662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8157 - dice_coef: 0.8157 - val_loss: -0.0158 - val_dice_coef: 0.0158\n",
      "Epoch 663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7752 - dice_coef: 0.7752 - val_loss: -0.2079 - val_dice_coef: 0.2079\n",
      "Epoch 664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.6270 - val_dice_coef: 0.6270\n",
      "Epoch 665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8258 - dice_coef: 0.8258 - val_loss: -0.1171 - val_dice_coef: 0.1171\n",
      "Epoch 666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.8650 - val_dice_coef: 0.8650\n",
      "Epoch 667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8395 - dice_coef: 0.8395 - val_loss: -0.6320 - val_dice_coef: 0.6320\n",
      "Epoch 668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8424 - dice_coef: 0.8424 - val_loss: -0.5525 - val_dice_coef: 0.5525\n",
      "Epoch 669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8391 - dice_coef: 0.8391 - val_loss: -0.8774 - val_dice_coef: 0.8774\n",
      "Epoch 670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.5239 - val_dice_coef: 0.5239\n",
      "Epoch 671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.1818 - val_dice_coef: 0.1818\n",
      "Epoch 672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8286 - dice_coef: 0.8286 - val_loss: -0.2185 - val_dice_coef: 0.2185\n",
      "Epoch 673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8309 - dice_coef: 0.8309 - val_loss: -0.9362 - val_dice_coef: 0.9362\n",
      "Epoch 674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.2254 - val_dice_coef: 0.2254\n",
      "Epoch 675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8384 - dice_coef: 0.8384 - val_loss: -0.3132 - val_dice_coef: 0.3132\n",
      "Epoch 676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8433 - dice_coef: 0.8433 - val_loss: -0.8573 - val_dice_coef: 0.8573\n",
      "Epoch 677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.2573 - val_dice_coef: 0.2573\n",
      "Epoch 678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.4857 - val_dice_coef: 0.4857\n",
      "Epoch 679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8445 - dice_coef: 0.8445 - val_loss: -0.7931 - val_dice_coef: 0.7931\n",
      "Epoch 680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8336 - dice_coef: 0.8336 - val_loss: -0.1880 - val_dice_coef: 0.1880\n",
      "Epoch 681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8396 - dice_coef: 0.8396 - val_loss: -0.2356 - val_dice_coef: 0.2356\n",
      "Epoch 682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8431 - dice_coef: 0.8431 - val_loss: -0.7485 - val_dice_coef: 0.7485\n",
      "Epoch 683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8439 - dice_coef: 0.8439 - val_loss: -0.2251 - val_dice_coef: 0.2251\n",
      "Epoch 684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8401 - dice_coef: 0.8401 - val_loss: -0.4985 - val_dice_coef: 0.4985\n",
      "Epoch 685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.7831 - val_dice_coef: 0.7831\n",
      "Epoch 686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.0811 - val_dice_coef: 0.0811\n",
      "Epoch 687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8300 - dice_coef: 0.8300 - val_loss: -0.3282 - val_dice_coef: 0.3282\n",
      "Epoch 688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8425 - dice_coef: 0.8425 - val_loss: -0.8692 - val_dice_coef: 0.8692\n",
      "Epoch 689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8402 - dice_coef: 0.8402 - val_loss: -0.5329 - val_dice_coef: 0.5329\n",
      "Epoch 690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.3908 - val_dice_coef: 0.3908\n",
      "Epoch 691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8451 - dice_coef: 0.8451 - val_loss: -0.7364 - val_dice_coef: 0.7364\n",
      "Epoch 692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.6834 - val_dice_coef: 0.6834\n",
      "Epoch 693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.2906 - val_dice_coef: 0.2906\n",
      "Epoch 694/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8452 - dice_coef: 0.8452 - val_loss: -0.3159 - val_dice_coef: 0.3159\n",
      "Epoch 695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.5617 - val_dice_coef: 0.5617\n",
      "Epoch 696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.6209 - val_dice_coef: 0.6209\n",
      "Epoch 697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.3204 - val_dice_coef: 0.3204\n",
      "Epoch 698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8416 - dice_coef: 0.8416 - val_loss: -0.3793 - val_dice_coef: 0.3793\n",
      "Epoch 699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8408 - dice_coef: 0.8408 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "Epoch 700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.3962 - val_dice_coef: 0.3962\n",
      "Epoch 701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.6602 - val_dice_coef: 0.6602\n",
      "Epoch 702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8473 - dice_coef: 0.8473 - val_loss: -0.6013 - val_dice_coef: 0.6013\n",
      "Epoch 703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.6774 - val_dice_coef: 0.6774\n",
      "Epoch 704/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8363 - dice_coef: 0.8363 - val_loss: -0.5603 - val_dice_coef: 0.5603\n",
      "Epoch 705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8423 - dice_coef: 0.8423 - val_loss: -0.0642 - val_dice_coef: 0.0642\n",
      "Epoch 706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8324 - dice_coef: 0.8324 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.6630 - val_dice_coef: 0.6630\n",
      "Epoch 708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.2338 - val_dice_coef: 0.2338\n",
      "Epoch 709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.5562 - val_dice_coef: 0.5562\n",
      "Epoch 710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8441 - dice_coef: 0.8441 - val_loss: -0.6202 - val_dice_coef: 0.6202\n",
      "Epoch 711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.6704 - val_dice_coef: 0.6704\n",
      "Epoch 712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.6614 - val_dice_coef: 0.6614\n",
      "Epoch 713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.6289 - val_dice_coef: 0.6289\n",
      "Epoch 714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8457 - dice_coef: 0.8457 - val_loss: -0.1529 - val_dice_coef: 0.1529\n",
      "Epoch 715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8384 - dice_coef: 0.8384 - val_loss: -0.1108 - val_dice_coef: 0.1108\n",
      "Epoch 716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.9756 - val_dice_coef: 0.9756\n",
      "Epoch 717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8264 - dice_coef: 0.8264 - val_loss: -0.5430 - val_dice_coef: 0.5430\n",
      "Epoch 718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.1765 - val_dice_coef: 0.1765\n",
      "Epoch 719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.4790 - val_dice_coef: 0.4790\n",
      "Epoch 721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8463 - dice_coef: 0.8463 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8418 - dice_coef: 0.8418 - val_loss: -0.9695 - val_dice_coef: 0.9695\n",
      "Epoch 723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8085 - dice_coef: 0.8085 - val_loss: -0.4149 - val_dice_coef: 0.4149\n",
      "Epoch 724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0183 - val_dice_coef: 0.0183\n",
      "Epoch 725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8203 - dice_coef: 0.8203 - val_loss: -0.9363 - val_dice_coef: 0.9363\n",
      "Epoch 726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.1106 - val_dice_coef: 0.1106\n",
      "Epoch 727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.0991 - val_dice_coef: 0.0991\n",
      "Epoch 728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.9815 - val_dice_coef: 0.9815\n",
      "Epoch 729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.4321 - val_dice_coef: 0.4321\n",
      "Epoch 730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8383 - dice_coef: 0.8383 - val_loss: -0.1485 - val_dice_coef: 0.1485\n",
      "Epoch 731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8358 - dice_coef: 0.8358 - val_loss: -0.9855 - val_dice_coef: 0.9855\n",
      "Epoch 732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.1318 - val_dice_coef: 0.1318\n",
      "Epoch 733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8332 - dice_coef: 0.8332 - val_loss: -0.3812 - val_dice_coef: 0.3812\n",
      "Epoch 734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8412 - dice_coef: 0.8412 - val_loss: -0.8816 - val_dice_coef: 0.8816\n",
      "Epoch 735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8430 - dice_coef: 0.8430 - val_loss: -0.3899 - val_dice_coef: 0.3899\n",
      "Epoch 736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.3458 - val_dice_coef: 0.3458\n",
      "Epoch 737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.9369 - val_dice_coef: 0.9369\n",
      "Epoch 738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8434 - dice_coef: 0.8434 - val_loss: -0.3495 - val_dice_coef: 0.3495\n",
      "Epoch 739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8411 - dice_coef: 0.8411 - val_loss: -0.5169 - val_dice_coef: 0.5169\n",
      "Epoch 740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8492 - dice_coef: 0.8492 - val_loss: -0.8756 - val_dice_coef: 0.8756\n",
      "Epoch 741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.5438 - val_dice_coef: 0.5438\n",
      "Epoch 742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.4142 - val_dice_coef: 0.4142\n",
      "Epoch 743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.6685 - val_dice_coef: 0.6685\n",
      "Epoch 744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.8682 - val_dice_coef: 0.8682\n",
      "Epoch 745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8460 - dice_coef: 0.8460 - val_loss: -0.5560 - val_dice_coef: 0.5560\n",
      "Epoch 746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.2725 - val_dice_coef: 0.2725\n",
      "Epoch 747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8489 - dice_coef: 0.8489 - val_loss: -0.6455 - val_dice_coef: 0.6455\n",
      "Epoch 748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.6092 - val_dice_coef: 0.6092\n",
      "Epoch 749/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.2267 - val_dice_coef: 0.2267\n",
      "Epoch 750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8472 - dice_coef: 0.8472 - val_loss: -0.7079 - val_dice_coef: 0.7079\n",
      "Epoch 751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8482 - dice_coef: 0.8482 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8464 - dice_coef: 0.8464 - val_loss: -0.3359 - val_dice_coef: 0.3359\n",
      "Epoch 753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8483 - dice_coef: 0.8483 - val_loss: -0.4852 - val_dice_coef: 0.4852\n",
      "Epoch 754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.8795 - val_dice_coef: 0.8795\n",
      "Epoch 755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.6648 - val_dice_coef: 0.6648\n",
      "Epoch 756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8470 - dice_coef: 0.8470 - val_loss: -0.2681 - val_dice_coef: 0.2681\n",
      "Epoch 757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.6538 - val_dice_coef: 0.6538\n",
      "Epoch 758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.7737 - val_dice_coef: 0.7737\n",
      "Epoch 759/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8458 - dice_coef: 0.8458 - val_loss: -0.5625 - val_dice_coef: 0.5625\n",
      "Epoch 760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.7626 - val_dice_coef: 0.7626\n",
      "Epoch 761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8480 - dice_coef: 0.8480 - val_loss: -0.6463 - val_dice_coef: 0.6463\n",
      "Epoch 762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.2825 - val_dice_coef: 0.2825\n",
      "Epoch 763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.4971 - val_dice_coef: 0.4971\n",
      "Epoch 764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.6287 - val_dice_coef: 0.6287\n",
      "Epoch 765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.6401 - val_dice_coef: 0.6401\n",
      "Epoch 766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.6936 - val_dice_coef: 0.6936\n",
      "Epoch 767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.4167 - val_dice_coef: 0.4167\n",
      "Epoch 768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.4295 - val_dice_coef: 0.4295\n",
      "Epoch 769/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.7763 - val_dice_coef: 0.7763\n",
      "Epoch 770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8509 - dice_coef: 0.8509 - val_loss: -0.8231 - val_dice_coef: 0.8231\n",
      "Epoch 771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8507 - dice_coef: 0.8507 - val_loss: -0.7932 - val_dice_coef: 0.7932\n",
      "Epoch 772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.3768 - val_dice_coef: 0.3768\n",
      "Epoch 773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.4115 - val_dice_coef: 0.4115\n",
      "Epoch 774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.5884 - val_dice_coef: 0.5884\n",
      "Epoch 775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8531 - dice_coef: 0.8531 - val_loss: -0.6688 - val_dice_coef: 0.6688\n",
      "Epoch 776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.8369 - val_dice_coef: 0.8369\n",
      "Epoch 777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.6895 - val_dice_coef: 0.6895\n",
      "Epoch 778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8514 - dice_coef: 0.8514 - val_loss: -0.6263 - val_dice_coef: 0.6263\n",
      "Epoch 779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.4246 - val_dice_coef: 0.4246\n",
      "Epoch 780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.3193 - val_dice_coef: 0.3193\n",
      "Epoch 781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.6160 - val_dice_coef: 0.6160\n",
      "Epoch 782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9589 - val_dice_coef: 0.9589\n",
      "Epoch 783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.8186 - val_dice_coef: 0.8186\n",
      "Epoch 784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8436 - dice_coef: 0.8436 - val_loss: -0.1388 - val_dice_coef: 0.1388\n",
      "Epoch 785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8456 - dice_coef: 0.8456 - val_loss: -0.3074 - val_dice_coef: 0.3074\n",
      "Epoch 786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.9070 - val_dice_coef: 0.9070\n",
      "Epoch 787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8455 - dice_coef: 0.8455 - val_loss: -0.8317 - val_dice_coef: 0.8317\n",
      "Epoch 788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.5644 - val_dice_coef: 0.5644\n",
      "Epoch 789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8536 - dice_coef: 0.8536 - val_loss: -0.3972 - val_dice_coef: 0.3972\n",
      "Epoch 790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.4738 - val_dice_coef: 0.4738\n",
      "Epoch 791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8553 - dice_coef: 0.8553 - val_loss: -0.6124 - val_dice_coef: 0.6124\n",
      "Epoch 792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8535 - dice_coef: 0.8535 - val_loss: -0.9356 - val_dice_coef: 0.9356\n",
      "Epoch 793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8499 - dice_coef: 0.8499 - val_loss: -0.7161 - val_dice_coef: 0.7161\n",
      "Epoch 794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.1549 - val_dice_coef: 0.1549\n",
      "Epoch 795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8453 - dice_coef: 0.8453 - val_loss: -0.2801 - val_dice_coef: 0.2801\n",
      "Epoch 796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8504 - dice_coef: 0.8504 - val_loss: -0.5559 - val_dice_coef: 0.5559\n",
      "Epoch 797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8556 - dice_coef: 0.8556 - val_loss: -0.8554 - val_dice_coef: 0.8554\n",
      "Epoch 798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8528 - dice_coef: 0.8528 - val_loss: -0.3655 - val_dice_coef: 0.3655\n",
      "Epoch 799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.1151 - val_dice_coef: 0.1151\n",
      "Epoch 800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8386 - dice_coef: 0.8386 - val_loss: -0.2047 - val_dice_coef: 0.2047\n",
      "Epoch 801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8109 - dice_coef: 0.8109 - val_loss: -0.9355 - val_dice_coef: 0.9355\n",
      "Epoch 803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8212 - dice_coef: 0.8212 - val_loss: -0.0244 - val_dice_coef: 0.0244\n",
      "Epoch 804/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8173 - dice_coef: 0.8173 - val_loss: -0.3989 - val_dice_coef: 0.3989\n",
      "Epoch 805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8277 - dice_coef: 0.8277 - val_loss: -0.8731 - val_dice_coef: 0.8731\n",
      "Epoch 806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8146 - dice_coef: 0.8146 - val_loss: -0.0170 - val_dice_coef: 0.0170\n",
      "Epoch 807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8062 - dice_coef: 0.8062 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.1861 - val_dice_coef: 0.1861\n",
      "Epoch 809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8280 - dice_coef: 0.8280 - val_loss: -0.1426 - val_dice_coef: 0.1426\n",
      "Epoch 810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8269 - dice_coef: 0.8269 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.4603 - val_dice_coef: 0.4603\n",
      "Epoch 812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8461 - dice_coef: 0.8461 - val_loss: -0.5005 - val_dice_coef: 0.5005\n",
      "Epoch 813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8460 - dice_coef: 0.8460 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 814/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.6413 - val_dice_coef: 0.6413\n",
      "Epoch 815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8526 - dice_coef: 0.8526 - val_loss: -0.6075 - val_dice_coef: 0.6075\n",
      "Epoch 816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.8333 - val_dice_coef: 0.8333\n",
      "Epoch 817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.4402 - val_dice_coef: 0.4402\n",
      "Epoch 818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.4477 - val_dice_coef: 0.4477\n",
      "Epoch 819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8514 - dice_coef: 0.8514 - val_loss: -0.9301 - val_dice_coef: 0.9301\n",
      "Epoch 820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.3854 - val_dice_coef: 0.3854\n",
      "Epoch 821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8519 - dice_coef: 0.8519 - val_loss: -0.6451 - val_dice_coef: 0.6451\n",
      "Epoch 822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8548 - dice_coef: 0.8548 - val_loss: -0.8534 - val_dice_coef: 0.8534\n",
      "Epoch 823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.5227 - val_dice_coef: 0.5227\n",
      "Epoch 824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8531 - dice_coef: 0.8531 - val_loss: -0.7357 - val_dice_coef: 0.7357\n",
      "Epoch 825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.8460 - val_dice_coef: 0.8460\n",
      "Epoch 826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8563 - dice_coef: 0.8563 - val_loss: -0.7245 - val_dice_coef: 0.7245\n",
      "Epoch 827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.3914 - val_dice_coef: 0.3914\n",
      "Epoch 828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8482 - dice_coef: 0.8482 - val_loss: -0.7330 - val_dice_coef: 0.7330\n",
      "Epoch 830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.6213 - val_dice_coef: 0.6213\n",
      "Epoch 831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.7375 - val_dice_coef: 0.7375\n",
      "Epoch 832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8554 - dice_coef: 0.8554 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8388 - dice_coef: 0.8388 - val_loss: -0.6835 - val_dice_coef: 0.6835\n",
      "Epoch 834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.0724 - val_dice_coef: 0.0724\n",
      "Epoch 835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.7645 - val_dice_coef: 0.7645\n",
      "Epoch 836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.9822 - val_dice_coef: 0.9822\n",
      "Epoch 837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8433 - dice_coef: 0.8433 - val_loss: -0.3740 - val_dice_coef: 0.3740\n",
      "Epoch 838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.3880 - val_dice_coef: 0.3880\n",
      "Epoch 839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.9392 - val_dice_coef: 0.9392\n",
      "Epoch 840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.6092 - val_dice_coef: 0.6092\n",
      "Epoch 841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.2208 - val_dice_coef: 0.2208\n",
      "Epoch 842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.9423 - val_dice_coef: 0.9423\n",
      "Epoch 843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8536 - dice_coef: 0.8536 - val_loss: -0.2052 - val_dice_coef: 0.2052\n",
      "Epoch 845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.6049 - val_dice_coef: 0.6049\n",
      "Epoch 846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.8703 - val_dice_coef: 0.8703\n",
      "Epoch 847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8554 - dice_coef: 0.8554 - val_loss: -0.6792 - val_dice_coef: 0.6792\n",
      "Epoch 848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.5180 - val_dice_coef: 0.5180\n",
      "Epoch 849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.8877 - val_dice_coef: 0.8877\n",
      "Epoch 850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8568 - dice_coef: 0.8568 - val_loss: -0.8671 - val_dice_coef: 0.8671\n",
      "Epoch 851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8534 - dice_coef: 0.8534 - val_loss: -0.2253 - val_dice_coef: 0.2253\n",
      "Epoch 852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.4381 - val_dice_coef: 0.4381\n",
      "Epoch 853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.9643 - val_dice_coef: 0.9643\n",
      "Epoch 854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -0.6585 - val_dice_coef: 0.6585\n",
      "Epoch 855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8537 - dice_coef: 0.8537 - val_loss: -0.5929 - val_dice_coef: 0.5929\n",
      "Epoch 856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.4989 - val_dice_coef: 0.4989\n",
      "Epoch 857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.8995 - val_dice_coef: 0.8995\n",
      "Epoch 858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.9217 - val_dice_coef: 0.9217\n",
      "Epoch 859/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8558 - dice_coef: 0.8558 - val_loss: -0.2018 - val_dice_coef: 0.2018\n",
      "Epoch 860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.4001 - val_dice_coef: 0.4001\n",
      "Epoch 861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.7284 - val_dice_coef: 0.7284\n",
      "Epoch 863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.3112 - val_dice_coef: 0.3112\n",
      "Epoch 864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8516 - dice_coef: 0.8516 - val_loss: -0.1725 - val_dice_coef: 0.1725\n",
      "Epoch 865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.7859 - val_dice_coef: 0.7859\n",
      "Epoch 866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.7054 - val_dice_coef: 0.7054\n",
      "Epoch 867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.3892 - val_dice_coef: 0.3892\n",
      "Epoch 868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8555 - dice_coef: 0.8555 - val_loss: -0.7265 - val_dice_coef: 0.7265\n",
      "Epoch 869/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8555 - dice_coef: 0.8555 - val_loss: -0.9342 - val_dice_coef: 0.9342\n",
      "Epoch 870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.8625 - val_dice_coef: 0.8625\n",
      "Epoch 871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8576 - dice_coef: 0.8576 - val_loss: -0.6924 - val_dice_coef: 0.6924\n",
      "Epoch 872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8590 - dice_coef: 0.8590 - val_loss: -0.3277 - val_dice_coef: 0.3277\n",
      "Epoch 873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8561 - dice_coef: 0.8561 - val_loss: -0.9711 - val_dice_coef: 0.9711\n",
      "Epoch 874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.7968 - val_dice_coef: 0.7968\n",
      "Epoch 875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8313 - dice_coef: 0.8313 - val_loss: -0.0267 - val_dice_coef: 0.0267\n",
      "Epoch 876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8287 - dice_coef: 0.8287 - val_loss: -0.6550 - val_dice_coef: 0.6550\n",
      "Epoch 877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9616 - val_dice_coef: 0.9616\n",
      "Epoch 878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8542 - dice_coef: 0.8542 - val_loss: -0.4779 - val_dice_coef: 0.4779\n",
      "Epoch 879/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.5987 - val_dice_coef: 0.5987\n",
      "Epoch 880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8575 - dice_coef: 0.8575 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.7415 - val_dice_coef: 0.7415\n",
      "Epoch 882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8557 - dice_coef: 0.8557 - val_loss: -0.3103 - val_dice_coef: 0.3103\n",
      "Epoch 883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9463 - val_dice_coef: 0.9463\n",
      "Epoch 884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8585 - dice_coef: 0.8585 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8585 - dice_coef: 0.8585 - val_loss: -0.6874 - val_dice_coef: 0.6874\n",
      "Epoch 886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.0696 - val_dice_coef: 0.0696\n",
      "Epoch 887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8335 - dice_coef: 0.8335 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "Epoch 888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8458 - dice_coef: 0.8458 - val_loss: -0.9836 - val_dice_coef: 0.9836\n",
      "Epoch 889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.1278 - val_dice_coef: 0.1278\n",
      "Epoch 890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.1465 - val_dice_coef: 0.1465\n",
      "Epoch 891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8288 - dice_coef: 0.8288 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.9762 - val_dice_coef: 0.9762\n",
      "Epoch 893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8296 - dice_coef: 0.8296 - val_loss: -0.0449 - val_dice_coef: 0.0449\n",
      "Epoch 894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8268 - dice_coef: 0.8268 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7870 - dice_coef: 0.7870 - val_loss: -0.5563 - val_dice_coef: 0.5563\n",
      "Epoch 896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.0207 - val_dice_coef: 0.0207\n",
      "Epoch 897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7943 - dice_coef: 0.7943 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7990 - dice_coef: 0.7990 - val_loss: -0.0056 - val_dice_coef: 0.0056\n",
      "Epoch 899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7997 - dice_coef: 0.7997 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8140 - dice_coef: 0.8140 - val_loss: -0.0163 - val_dice_coef: 0.0163\n",
      "Epoch 901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8278 - dice_coef: 0.8278 - val_loss: -0.1731 - val_dice_coef: 0.1731\n",
      "Epoch 903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8410 - dice_coef: 0.8410 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.0969 - val_dice_coef: 0.0969\n",
      "Epoch 905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8331 - dice_coef: 0.8331 - val_loss: -0.9669 - val_dice_coef: 0.9669\n",
      "Epoch 906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8434 - dice_coef: 0.8434 - val_loss: -0.6003 - val_dice_coef: 0.6003\n",
      "Epoch 907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8463 - dice_coef: 0.8463 - val_loss: -0.8600 - val_dice_coef: 0.8600\n",
      "Epoch 908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.4440 - val_dice_coef: 0.4440\n",
      "Epoch 910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9277 - val_dice_coef: 0.9277\n",
      "Epoch 913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.9548 - val_dice_coef: 0.9548\n",
      "Epoch 914/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8631 - dice_coef: 0.8631 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9537 - val_dice_coef: 0.9537\n",
      "Epoch 916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9325 - val_dice_coef: 0.9325\n",
      "Epoch 917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.6866 - val_dice_coef: 0.6866\n",
      "Epoch 918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8566 - dice_coef: 0.8566 - val_loss: -0.8557 - val_dice_coef: 0.8557\n",
      "Epoch 919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.7017 - val_dice_coef: 0.7017\n",
      "Epoch 921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8570 - dice_coef: 0.8570 - val_loss: -0.9189 - val_dice_coef: 0.9189\n",
      "Epoch 922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.9010 - val_dice_coef: 0.9010\n",
      "Epoch 923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8594 - dice_coef: 0.8594 - val_loss: -0.9313 - val_dice_coef: 0.9313\n",
      "Epoch 924/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8615 - dice_coef: 0.8615 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.9542 - val_dice_coef: 0.9542\n",
      "Epoch 926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.9186 - val_dice_coef: 0.9186\n",
      "Epoch 927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.9228 - val_dice_coef: 0.9228\n",
      "Epoch 928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8612 - dice_coef: 0.8612 - val_loss: -0.8624 - val_dice_coef: 0.8624\n",
      "Epoch 929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8621 - dice_coef: 0.8621 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8621 - dice_coef: 0.8621 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.9413 - val_dice_coef: 0.9413\n",
      "Epoch 932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8624 - dice_coef: 0.8624 - val_loss: -0.6561 - val_dice_coef: 0.6561\n",
      "Epoch 933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8547 - dice_coef: 0.8547 - val_loss: -0.2725 - val_dice_coef: 0.2725\n",
      "Epoch 936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8480 - dice_coef: 0.8480 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -0.4746 - val_dice_coef: 0.4746\n",
      "Epoch 938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8517 - dice_coef: 0.8517 - val_loss: -0.5272 - val_dice_coef: 0.5272\n",
      "Epoch 939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.5573 - val_dice_coef: 0.5573\n",
      "Epoch 941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.8822 - val_dice_coef: 0.8822\n",
      "Epoch 942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.9764 - val_dice_coef: 0.9764\n",
      "Epoch 943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8608 - dice_coef: 0.8608 - val_loss: -0.6972 - val_dice_coef: 0.6972\n",
      "Epoch 944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.9316 - val_dice_coef: 0.9316\n",
      "Epoch 945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.5515 - val_dice_coef: 0.5515\n",
      "Epoch 947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8560 - dice_coef: 0.8560 - val_loss: -0.7683 - val_dice_coef: 0.7683\n",
      "Epoch 948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8602 - dice_coef: 0.8602 - val_loss: -0.9385 - val_dice_coef: 0.9385\n",
      "Epoch 949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.8939 - val_dice_coef: 0.8939\n",
      "Epoch 950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.8332 - val_dice_coef: 0.8332\n",
      "Epoch 951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8623 - dice_coef: 0.8623 - val_loss: -0.7924 - val_dice_coef: 0.7924\n",
      "Epoch 952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.8816 - val_dice_coef: 0.8816\n",
      "Epoch 954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.9252 - val_dice_coef: 0.9252\n",
      "Epoch 955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9265 - val_dice_coef: 0.9265\n",
      "Epoch 956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.8976 - val_dice_coef: 0.8976\n",
      "Epoch 957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8627 - dice_coef: 0.8627 - val_loss: -0.9492 - val_dice_coef: 0.9492\n",
      "Epoch 958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8616 - dice_coef: 0.8616 - val_loss: -0.9407 - val_dice_coef: 0.9407\n",
      "Epoch 959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.8555 - val_dice_coef: 0.8555\n",
      "Epoch 960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8579 - dice_coef: 0.8579 - val_loss: -0.8050 - val_dice_coef: 0.8050\n",
      "Epoch 961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8629 - dice_coef: 0.8629 - val_loss: -0.8673 - val_dice_coef: 0.8673\n",
      "Epoch 962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.8563 - val_dice_coef: 0.8563\n",
      "Epoch 963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.2059 - val_dice_coef: 0.2059\n",
      "Epoch 964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9696 - val_dice_coef: 0.9696\n",
      "Epoch 965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8543 - dice_coef: 0.8543 - val_loss: -0.9292 - val_dice_coef: 0.9292\n",
      "Epoch 966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8556 - dice_coef: 0.8556 - val_loss: -0.3905 - val_dice_coef: 0.3905\n",
      "Epoch 967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8597 - dice_coef: 0.8597 - val_loss: -0.6444 - val_dice_coef: 0.6444\n",
      "Epoch 968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8627 - dice_coef: 0.8627 - val_loss: -0.9868 - val_dice_coef: 0.9868\n",
      "Epoch 969/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -0.9687 - val_dice_coef: 0.9687\n",
      "Epoch 970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8599 - dice_coef: 0.8599 - val_loss: -0.7404 - val_dice_coef: 0.7404\n",
      "Epoch 971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.8665 - val_dice_coef: 0.8665\n",
      "Epoch 972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.1268 - val_dice_coef: 0.1268\n",
      "Epoch 974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.8072 - val_dice_coef: 0.8072\n",
      "Epoch 975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.9781 - val_dice_coef: 0.9781\n",
      "Epoch 976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8661 - dice_coef: 0.8661 - val_loss: -0.6156 - val_dice_coef: 0.6156\n",
      "Epoch 977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8617 - dice_coef: 0.8617 - val_loss: -0.9634 - val_dice_coef: 0.9634\n",
      "Epoch 978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8646 - dice_coef: 0.8646 - val_loss: -0.9197 - val_dice_coef: 0.9197\n",
      "Epoch 979/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.6328 - val_dice_coef: 0.6328\n",
      "Epoch 980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.8507 - val_dice_coef: 0.8507\n",
      "Epoch 981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8634 - dice_coef: 0.8634 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.7881 - val_dice_coef: 0.7881\n",
      "Epoch 983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8595 - dice_coef: 0.8595 - val_loss: -0.9413 - val_dice_coef: 0.9413\n",
      "Epoch 984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8638 - dice_coef: 0.8638 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8649 - dice_coef: 0.8649 - val_loss: -0.5486 - val_dice_coef: 0.5486\n",
      "Epoch 986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8647 - dice_coef: 0.8647 - val_loss: -0.9300 - val_dice_coef: 0.9300\n",
      "Epoch 988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 989/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.8006 - val_dice_coef: 0.8006\n",
      "Epoch 990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.7084 - val_dice_coef: 0.7084\n",
      "Epoch 991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8947 - val_dice_coef: 0.8947\n",
      "Epoch 992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9819 - val_dice_coef: 0.9819\n",
      "Epoch 993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.8766 - val_dice_coef: 0.8766\n",
      "Epoch 994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.5579 - val_dice_coef: 0.5579\n",
      "Epoch 995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8679 - dice_coef: 0.8679 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8581 - dice_coef: 0.8581 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.7333 - val_dice_coef: 0.7333\n",
      "Epoch 998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.4334 - val_dice_coef: 0.4334\n",
      "Epoch 999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8604 - dice_coef: 0.8604 - val_loss: -0.8550 - val_dice_coef: 0.8550\n",
      "Epoch 1000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.9571 - val_dice_coef: 0.9571\n",
      "Epoch 1001/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8622 - dice_coef: 0.8622 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 1002/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8472 - dice_coef: 0.8472 - val_loss: -0.0536 - val_dice_coef: 0.0536\n",
      "Epoch 1003/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8317 - dice_coef: 0.8317 - val_loss: -0.1666 - val_dice_coef: 0.1666\n",
      "Epoch 1004/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1005/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.1120 - val_dice_coef: 0.1120\n",
      "Epoch 1006/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8338 - dice_coef: 0.8338 - val_loss: -0.6016 - val_dice_coef: 0.6016\n",
      "Epoch 1007/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8502 - dice_coef: 0.8502 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1008/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.0098 - val_dice_coef: 0.0098\n",
      "Epoch 1009/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1010/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8097 - dice_coef: 0.8097 - val_loss: -0.6957 - val_dice_coef: 0.6957\n",
      "Epoch 1011/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8291 - dice_coef: 0.8291 - val_loss: -0.0575 - val_dice_coef: 0.0575\n",
      "Epoch 1012/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1013/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.3387 - val_dice_coef: 0.3387\n",
      "Epoch 1014/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8446 - dice_coef: 0.8446 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 1015/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8405 - dice_coef: 0.8405 - val_loss: -0.9880 - val_dice_coef: 0.9880\n",
      "Epoch 1016/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8426 - dice_coef: 0.8426 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 1017/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1018/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.4361 - val_dice_coef: 0.4361\n",
      "Epoch 1019/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8579 - dice_coef: 0.8579 - val_loss: -0.8517 - val_dice_coef: 0.8517\n",
      "Epoch 1020/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8610 - dice_coef: 0.8610 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 1021/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8625 - dice_coef: 0.8625 - val_loss: -0.6310 - val_dice_coef: 0.6310\n",
      "Epoch 1022/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8658 - dice_coef: 0.8658 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1023/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8412 - dice_coef: 0.8412 - val_loss: -0.5694 - val_dice_coef: 0.5694\n",
      "Epoch 1024/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.1939 - val_dice_coef: 0.1939\n",
      "Epoch 1025/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1026/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.5309 - val_dice_coef: 0.5309\n",
      "Epoch 1027/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8594 - dice_coef: 0.8594 - val_loss: -0.8949 - val_dice_coef: 0.8949\n",
      "Epoch 1028/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.9792 - val_dice_coef: 0.9792\n",
      "Epoch 1029/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8665 - dice_coef: 0.8665 - val_loss: -0.7203 - val_dice_coef: 0.7203\n",
      "Epoch 1030/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 1031/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8660 - dice_coef: 0.8660 - val_loss: -0.9150 - val_dice_coef: 0.9150\n",
      "Epoch 1032/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8670 - dice_coef: 0.8670 - val_loss: -0.7944 - val_dice_coef: 0.7944\n",
      "Epoch 1033/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.8140 - val_dice_coef: 0.8140\n",
      "Epoch 1034/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.9357 - val_dice_coef: 0.9357\n",
      "Epoch 1035/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.7574 - val_dice_coef: 0.7574\n",
      "Epoch 1036/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8654 - dice_coef: 0.8654 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 1037/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 1038/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8660 - dice_coef: 0.8660 - val_loss: -0.3575 - val_dice_coef: 0.3575\n",
      "Epoch 1039/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8628 - dice_coef: 0.8628 - val_loss: -0.9336 - val_dice_coef: 0.9336\n",
      "Epoch 1040/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 1041/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.8473 - val_dice_coef: 0.8473\n",
      "Epoch 1042/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.6599 - val_dice_coef: 0.6599\n",
      "Epoch 1043/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8600 - dice_coef: 0.8600 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1044/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8666 - dice_coef: 0.8666 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1045/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8676 - dice_coef: 0.8676 - val_loss: -0.6482 - val_dice_coef: 0.6482\n",
      "Epoch 1046/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.6694 - val_dice_coef: 0.6694\n",
      "Epoch 1047/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.9896 - val_dice_coef: 0.9896\n",
      "Epoch 1048/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9164 - val_dice_coef: 0.9164\n",
      "Epoch 1049/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8592 - dice_coef: 0.8592 - val_loss: -0.5549 - val_dice_coef: 0.5549\n",
      "Epoch 1050/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8654 - dice_coef: 0.8654 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 1051/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8705 - dice_coef: 0.8705 - val_loss: -0.9049 - val_dice_coef: 0.9049\n",
      "Epoch 1052/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8694 - dice_coef: 0.8694 - val_loss: -0.9109 - val_dice_coef: 0.9109\n",
      "Epoch 1053/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.8367 - val_dice_coef: 0.8367\n",
      "Epoch 1054/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8696 - dice_coef: 0.8696 - val_loss: -0.9657 - val_dice_coef: 0.9657\n",
      "Epoch 1055/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9415 - val_dice_coef: 0.9415\n",
      "Epoch 1056/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8690 - dice_coef: 0.8690 - val_loss: -0.7286 - val_dice_coef: 0.7286\n",
      "Epoch 1057/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8688 - dice_coef: 0.8688 - val_loss: -0.9478 - val_dice_coef: 0.9478\n",
      "Epoch 1058/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8705 - dice_coef: 0.8705 - val_loss: -0.9559 - val_dice_coef: 0.9559\n",
      "Epoch 1059/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.7451 - val_dice_coef: 0.7451\n",
      "Epoch 1060/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8699 - dice_coef: 0.8699 - val_loss: -0.8512 - val_dice_coef: 0.8512\n",
      "Epoch 1061/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1062/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.9079 - val_dice_coef: 0.9079\n",
      "Epoch 1063/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.7620 - val_dice_coef: 0.7620\n",
      "Epoch 1064/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.7545 - val_dice_coef: 0.7545\n",
      "Epoch 1065/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 1066/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8601 - dice_coef: 0.8601 - val_loss: -0.9141 - val_dice_coef: 0.9141\n",
      "Epoch 1067/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.4374 - val_dice_coef: 0.4374\n",
      "Epoch 1068/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8572 - dice_coef: 0.8572 - val_loss: -0.9088 - val_dice_coef: 0.9088\n",
      "Epoch 1069/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1070/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8502 - dice_coef: 0.8502 - val_loss: -0.0892 - val_dice_coef: 0.0892\n",
      "Epoch 1071/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.3519 - val_dice_coef: 0.3519\n",
      "Epoch 1072/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1073/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.1056 - val_dice_coef: 0.1056\n",
      "Epoch 1074/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.9048 - val_dice_coef: 0.9048\n",
      "Epoch 1075/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1076/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.0317 - val_dice_coef: 0.0317\n",
      "Epoch 1077/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8090 - dice_coef: 0.8090 - val_loss: -0.4089 - val_dice_coef: 0.4089\n",
      "Epoch 1078/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1079/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.1518 - val_dice_coef: 0.1518\n",
      "Epoch 1080/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8499 - dice_coef: 0.8499 - val_loss: -0.7791 - val_dice_coef: 0.7791\n",
      "Epoch 1081/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8526 - dice_coef: 0.8526 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1082/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.0804 - val_dice_coef: 0.0804\n",
      "Epoch 1083/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8449 - dice_coef: 0.8449 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 1084/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.8349 - val_dice_coef: 0.8349\n",
      "Epoch 1085/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.1126 - val_dice_coef: 0.1126\n",
      "Epoch 1086/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8385 - dice_coef: 0.8385 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1087/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8254 - dice_coef: 0.8254 - val_loss: -0.5600 - val_dice_coef: 0.5600\n",
      "Epoch 1088/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8609 - dice_coef: 0.8609 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 1089/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8603 - dice_coef: 0.8603 - val_loss: -0.9614 - val_dice_coef: 0.9614\n",
      "Epoch 1090/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8645 - dice_coef: 0.8645 - val_loss: -0.8877 - val_dice_coef: 0.8877\n",
      "Epoch 1091/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 1092/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8304 - val_dice_coef: 0.8304\n",
      "Epoch 1093/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9045 - val_dice_coef: 0.9045\n",
      "Epoch 1094/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1095/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8688 - dice_coef: 0.8688 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "Epoch 1096/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.8798 - val_dice_coef: 0.8798\n",
      "Epoch 1097/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1098/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.6924 - val_dice_coef: 0.6924\n",
      "Epoch 1099/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.9647 - val_dice_coef: 0.9647\n",
      "Epoch 1100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8693 - dice_coef: 0.8693 - val_loss: -0.9751 - val_dice_coef: 0.9751\n",
      "Epoch 1101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8683 - dice_coef: 0.8683 - val_loss: -0.8918 - val_dice_coef: 0.8918\n",
      "Epoch 1102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8741 - dice_coef: 0.8741 - val_loss: -0.9223 - val_dice_coef: 0.9223\n",
      "Epoch 1103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "Epoch 1104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.9560 - val_dice_coef: 0.9560\n",
      "Epoch 1105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8715 - dice_coef: 0.8715 - val_loss: -0.9793 - val_dice_coef: 0.9793\n",
      "Epoch 1106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.7256 - val_dice_coef: 0.7256\n",
      "Epoch 1107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.8245 - val_dice_coef: 0.8245\n",
      "Epoch 1108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8672 - dice_coef: 0.8672 - val_loss: -0.7725 - val_dice_coef: 0.7725\n",
      "Epoch 1110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9215 - val_dice_coef: 0.9215\n",
      "Epoch 1111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8685 - dice_coef: 0.8685 - val_loss: -0.8775 - val_dice_coef: 0.8775\n",
      "Epoch 1113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.9527 - val_dice_coef: 0.9527\n",
      "Epoch 1114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.4950 - val_dice_coef: 0.4950\n",
      "Epoch 1116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8658 - dice_coef: 0.8658 - val_loss: -0.9236 - val_dice_coef: 0.9236\n",
      "Epoch 1117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8686 - dice_coef: 0.8686 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8689 - dice_coef: 0.8689 - val_loss: -0.7843 - val_dice_coef: 0.7843\n",
      "Epoch 1119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.9836 - val_dice_coef: 0.9836\n",
      "Epoch 1120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8718 - dice_coef: 0.8718 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.9663 - val_dice_coef: 0.9663\n",
      "Epoch 1122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8737 - dice_coef: 0.8737 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 1123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.8007 - val_dice_coef: 0.8007\n",
      "Epoch 1124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.9861 - val_dice_coef: 0.9861\n",
      "Epoch 1125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8616 - dice_coef: 0.8616 - val_loss: -0.0640 - val_dice_coef: 0.0640\n",
      "Epoch 1127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.8262 - val_dice_coef: 0.8262\n",
      "Epoch 1128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.1988 - val_dice_coef: 0.1988\n",
      "Epoch 1130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8562 - dice_coef: 0.8562 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8604 - dice_coef: 0.8604 - val_loss: -0.7498 - val_dice_coef: 0.7498\n",
      "Epoch 1132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8689 - dice_coef: 0.8689 - val_loss: -0.3435 - val_dice_coef: 0.3435\n",
      "Epoch 1135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.9566 - val_dice_coef: 0.9566\n",
      "Epoch 1136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8607 - dice_coef: 0.8607 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.8013 - val_dice_coef: 0.8013\n",
      "Epoch 1138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.8925 - val_dice_coef: 0.8925\n",
      "Epoch 1139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8708 - dice_coef: 0.8708 - val_loss: -0.9755 - val_dice_coef: 0.9755\n",
      "Epoch 1140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9490 - val_dice_coef: 0.9490\n",
      "Epoch 1141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9386 - val_dice_coef: 0.9386\n",
      "Epoch 1142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.8723 - val_dice_coef: 0.8723\n",
      "Epoch 1143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 1144/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.9019 - val_dice_coef: 0.9019\n",
      "Epoch 1145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.8416 - val_dice_coef: 0.8416\n",
      "Epoch 1146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 1147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 1148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8733 - dice_coef: 0.8733 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9353 - val_dice_coef: 0.9353\n",
      "Epoch 1150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.8787 - val_dice_coef: 0.8787\n",
      "Epoch 1151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9200 - val_dice_coef: 0.9200\n",
      "Epoch 1152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8685 - dice_coef: 0.8685 - val_loss: -0.9765 - val_dice_coef: 0.9765\n",
      "Epoch 1153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8744 - dice_coef: 0.8744 - val_loss: -0.8773 - val_dice_coef: 0.8773\n",
      "Epoch 1154/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.9595 - val_dice_coef: 0.9595\n",
      "Epoch 1155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 1156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.5922 - val_dice_coef: 0.5922\n",
      "Epoch 1158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.7393 - val_dice_coef: 0.7393\n",
      "Epoch 1159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8656 - dice_coef: 0.8656 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 1160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 1161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.4817 - val_dice_coef: 0.4817\n",
      "Epoch 1162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 1163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 1164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8684 - dice_coef: 0.8684 - val_loss: -0.1108 - val_dice_coef: 0.1108\n",
      "Epoch 1165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8624 - dice_coef: 0.8624 - val_loss: -0.9803 - val_dice_coef: 0.9803\n",
      "Epoch 1167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.1844 - val_dice_coef: 0.1844\n",
      "Epoch 1168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 1169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.6831 - val_dice_coef: 0.6831\n",
      "Epoch 1170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -0.5705 - val_dice_coef: 0.5705\n",
      "Epoch 1171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.6655 - val_dice_coef: 0.6655\n",
      "Epoch 1173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.8917 - val_dice_coef: 0.8917\n",
      "Epoch 1174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8692 - dice_coef: 0.8692 - val_loss: -0.9620 - val_dice_coef: 0.9620\n",
      "Epoch 1175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 1176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9668 - val_dice_coef: 0.9668\n",
      "Epoch 1177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8760 - dice_coef: 0.8760 - val_loss: -0.4225 - val_dice_coef: 0.4225\n",
      "Epoch 1178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8568 - dice_coef: 0.8568 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8617 - dice_coef: 0.8617 - val_loss: -0.2472 - val_dice_coef: 0.2472\n",
      "Epoch 1181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.9606 - val_dice_coef: 0.9606\n",
      "Epoch 1182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 1183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.8566 - val_dice_coef: 0.8566\n",
      "Epoch 1184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.7026 - val_dice_coef: 0.7026\n",
      "Epoch 1185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "Epoch 1187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9058 - val_dice_coef: 0.9058\n",
      "Epoch 1188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.4322 - val_dice_coef: 0.4322\n",
      "Epoch 1190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.7995 - val_dice_coef: 0.7995\n",
      "Epoch 1191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.9844 - val_dice_coef: 0.9844\n",
      "Epoch 1192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9046 - val_dice_coef: 0.9046\n",
      "Epoch 1193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.5496 - val_dice_coef: 0.5496\n",
      "Epoch 1194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8648 - dice_coef: 0.8648 - val_loss: -0.9909 - val_dice_coef: 0.9909\n",
      "Epoch 1195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 1196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.0458 - val_dice_coef: 0.0458\n",
      "Epoch 1197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8235 - dice_coef: 0.8235 - val_loss: -0.0956 - val_dice_coef: 0.0956\n",
      "Epoch 1198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8426 - dice_coef: 0.8426 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1199/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.0376 - val_dice_coef: 0.0376\n",
      "Epoch 1200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9591 - val_dice_coef: 0.9591\n",
      "Epoch 1202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.3772 - val_dice_coef: 0.3772\n",
      "Epoch 1203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8635 - dice_coef: 0.8635 - val_loss: -0.8594 - val_dice_coef: 0.8594\n",
      "Epoch 1205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9872 - val_dice_coef: 0.9872\n",
      "Epoch 1206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 1207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.6851 - val_dice_coef: 0.6851\n",
      "Epoch 1208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9956 - val_dice_coef: 0.9956\n",
      "Epoch 1209/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.9248 - val_dice_coef: 0.9248\n",
      "Epoch 1210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -0.5337 - val_dice_coef: 0.5337\n",
      "Epoch 1211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.9769 - val_dice_coef: 0.9769\n",
      "Epoch 1212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8773 - dice_coef: 0.8773 - val_loss: -0.7920 - val_dice_coef: 0.7920\n",
      "Epoch 1213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9271 - val_dice_coef: 0.9271\n",
      "Epoch 1214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.9746 - val_dice_coef: 0.9746\n",
      "Epoch 1215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8755 - dice_coef: 0.8755 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "Epoch 1216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.8132 - val_dice_coef: 0.8132\n",
      "Epoch 1217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.9755 - val_dice_coef: 0.9755\n",
      "Epoch 1218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9377 - val_dice_coef: 0.9377\n",
      "Epoch 1219/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 1220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9523 - val_dice_coef: 0.9523\n",
      "Epoch 1221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.9513 - val_dice_coef: 0.9513\n",
      "Epoch 1222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9321 - val_dice_coef: 0.9321\n",
      "Epoch 1223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9393 - val_dice_coef: 0.9393\n",
      "Epoch 1224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8780 - dice_coef: 0.8780 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 1225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.9235 - val_dice_coef: 0.9235\n",
      "Epoch 1226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.9359 - val_dice_coef: 0.9359\n",
      "Epoch 1227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9820 - val_dice_coef: 0.9820\n",
      "Epoch 1228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8799 - dice_coef: 0.8799 - val_loss: -0.6893 - val_dice_coef: 0.6893\n",
      "Epoch 1229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 1231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9458 - val_dice_coef: 0.9458\n",
      "Epoch 1232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9079 - val_dice_coef: 0.9079\n",
      "Epoch 1233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8787 - dice_coef: 0.8787 - val_loss: -0.9396 - val_dice_coef: 0.9396\n",
      "Epoch 1234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9063 - val_dice_coef: 0.9063\n",
      "Epoch 1235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8770 - dice_coef: 0.8770 - val_loss: -0.5947 - val_dice_coef: 0.5947\n",
      "Epoch 1238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.9679 - val_dice_coef: 0.9679\n",
      "Epoch 1239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 1240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8702 - dice_coef: 0.8702 - val_loss: -0.2189 - val_dice_coef: 0.2189\n",
      "Epoch 1241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.9456 - val_dice_coef: 0.9456\n",
      "Epoch 1242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8687 - dice_coef: 0.8687 - val_loss: -0.4867 - val_dice_coef: 0.4867\n",
      "Epoch 1244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8629 - dice_coef: 0.8629 - val_loss: -0.2168 - val_dice_coef: 0.2168\n",
      "Epoch 1245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.6962 - val_dice_coef: 0.6962\n",
      "Epoch 1247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.1174 - val_dice_coef: 0.1174\n",
      "Epoch 1248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8549 - dice_coef: 0.8549 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.9383 - val_dice_coef: 0.9383\n",
      "Epoch 1250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8724 - dice_coef: 0.8724 - val_loss: -0.5627 - val_dice_coef: 0.5627\n",
      "Epoch 1251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 1253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8777 - dice_coef: 0.8777 - val_loss: -0.7830 - val_dice_coef: 0.7830\n",
      "Epoch 1254/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9698 - val_dice_coef: 0.9698\n",
      "Epoch 1255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8799 - dice_coef: 0.8799 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.8652 - val_dice_coef: 0.8652\n",
      "Epoch 1257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9314 - val_dice_coef: 0.9314\n",
      "Epoch 1258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8762 - dice_coef: 0.8762 - val_loss: -0.9479 - val_dice_coef: 0.9479\n",
      "Epoch 1261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.8223 - val_dice_coef: 0.8223\n",
      "Epoch 1262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.7438 - val_dice_coef: 0.7438\n",
      "Epoch 1264/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8679 - dice_coef: 0.8679 - val_loss: -0.2187 - val_dice_coef: 0.2187\n",
      "Epoch 1265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8427 - dice_coef: 0.8427 - val_loss: -0.5254 - val_dice_coef: 0.5254\n",
      "Epoch 1267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.0585 - val_dice_coef: 0.0585\n",
      "Epoch 1268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0653 - val_dice_coef: 0.0653\n",
      "Epoch 1270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.5930 - val_dice_coef: 0.5930\n",
      "Epoch 1271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.4535 - val_dice_coef: 0.4535\n",
      "Epoch 1273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8697 - dice_coef: 0.8697 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9800 - val_dice_coef: 0.9800\n",
      "Epoch 1275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.6696 - val_dice_coef: 0.6696\n",
      "Epoch 1276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8661 - dice_coef: 0.8661 - val_loss: -0.1610 - val_dice_coef: 0.1610\n",
      "Epoch 1279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8699 - dice_coef: 0.8699 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.7982 - val_dice_coef: 0.7982\n",
      "Epoch 1281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.9349 - val_dice_coef: 0.9349\n",
      "Epoch 1282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8737 - dice_coef: 0.8737 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.8544 - val_dice_coef: 0.8544\n",
      "Epoch 1284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9820 - val_dice_coef: 0.9820\n",
      "Epoch 1285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8794 - dice_coef: 0.8794 - val_loss: -0.7478 - val_dice_coef: 0.7478\n",
      "Epoch 1287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 1288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.7808 - val_dice_coef: 0.7808\n",
      "Epoch 1290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.9448 - val_dice_coef: 0.9448\n",
      "Epoch 1292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.7170 - val_dice_coef: 0.7170\n",
      "Epoch 1293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9073 - val_dice_coef: 0.9073\n",
      "Epoch 1295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.5361 - val_dice_coef: 0.5361\n",
      "Epoch 1296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8763 - dice_coef: 0.8763 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9063 - val_dice_coef: 0.9063\n",
      "Epoch 1298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8755 - dice_coef: 0.8755 - val_loss: -0.8915 - val_dice_coef: 0.8915\n",
      "Epoch 1299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -0.5298 - val_dice_coef: 0.5298\n",
      "Epoch 1301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8740 - dice_coef: 0.8740 - val_loss: -0.9875 - val_dice_coef: 0.9875\n",
      "Epoch 1302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 1303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.8967 - val_dice_coef: 0.8967\n",
      "Epoch 1304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9702 - val_dice_coef: 0.9702\n",
      "Epoch 1305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 1306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8818 - dice_coef: 0.8818 - val_loss: -0.7640 - val_dice_coef: 0.7640\n",
      "Epoch 1307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9842 - val_dice_coef: 0.9842\n",
      "Epoch 1309/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8804 - dice_coef: 0.8804 - val_loss: -0.8562 - val_dice_coef: 0.8562\n",
      "Epoch 1310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8779 - dice_coef: 0.8779 - val_loss: -0.8712 - val_dice_coef: 0.8712\n",
      "Epoch 1311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 1313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
      "Epoch 1314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.8932 - val_dice_coef: 0.8932\n",
      "Epoch 1316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.7943 - val_dice_coef: 0.7943\n",
      "Epoch 1317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9017 - val_dice_coef: 0.9017\n",
      "Epoch 1319/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8702 - dice_coef: 0.8702 - val_loss: -0.8048 - val_dice_coef: 0.8048\n",
      "Epoch 1320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 1321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.7515 - val_dice_coef: 0.7515\n",
      "Epoch 1322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.4710 - val_dice_coef: 0.4710\n",
      "Epoch 1323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8622 - dice_coef: 0.8622 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 1325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.0405 - val_dice_coef: 0.0405\n",
      "Epoch 1326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8495 - dice_coef: 0.8495 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8563 - dice_coef: 0.8563 - val_loss: -0.9283 - val_dice_coef: 0.9283\n",
      "Epoch 1328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8684 - dice_coef: 0.8684 - val_loss: -0.4080 - val_dice_coef: 0.4080\n",
      "Epoch 1329/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8703 - dice_coef: 0.8703 - val_loss: -0.7567 - val_dice_coef: 0.7567\n",
      "Epoch 1331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9764 - val_dice_coef: 0.9764\n",
      "Epoch 1332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 1333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.2174 - val_dice_coef: 0.2174\n",
      "Epoch 1334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8640 - dice_coef: 0.8640 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.7884 - val_dice_coef: 0.7884\n",
      "Epoch 1336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.8379 - val_dice_coef: 0.8379\n",
      "Epoch 1337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8759 - dice_coef: 0.8759 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 1339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.9426 - val_dice_coef: 0.9426\n",
      "Epoch 1340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8823 - dice_coef: 0.8823 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -0.5192 - val_dice_coef: 0.5192\n",
      "Epoch 1342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9811 - val_dice_coef: 0.9811\n",
      "Epoch 1343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.8578 - val_dice_coef: 0.8578\n",
      "Epoch 1345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 1346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9368 - val_dice_coef: 0.9368\n",
      "Epoch 1348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8851 - dice_coef: 0.8851 - val_loss: -0.9873 - val_dice_coef: 0.9873\n",
      "Epoch 1349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8815 - dice_coef: 0.8815 - val_loss: -0.8931 - val_dice_coef: 0.8931\n",
      "Epoch 1350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8831 - dice_coef: 0.8831 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 1351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 1353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.8807 - val_dice_coef: 0.8807\n",
      "Epoch 1354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 1355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9674 - val_dice_coef: 0.9674\n",
      "Epoch 1356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9875 - val_dice_coef: 0.9875\n",
      "Epoch 1357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8847 - dice_coef: 0.8847 - val_loss: -0.9623 - val_dice_coef: 0.9623\n",
      "Epoch 1358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9287 - val_dice_coef: 0.9287\n",
      "Epoch 1359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9515 - val_dice_coef: 0.9515\n",
      "Epoch 1360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8842 - dice_coef: 0.8842 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 1361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.9364 - val_dice_coef: 0.9364\n",
      "Epoch 1362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.8061 - val_dice_coef: 0.8061\n",
      "Epoch 1363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 1364/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.8924 - val_dice_coef: 0.8924\n",
      "Epoch 1366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.8853 - val_dice_coef: 0.8853\n",
      "Epoch 1367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.7476 - val_dice_coef: 0.7476\n",
      "Epoch 1370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 1371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8656 - dice_coef: 0.8656 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.2390 - val_dice_coef: 0.2390\n",
      "Epoch 1374/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8795 - dice_coef: 0.8795 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.6036 - val_dice_coef: 0.6036\n",
      "Epoch 1377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.8611 - val_dice_coef: 0.8611\n",
      "Epoch 1378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9521 - val_dice_coef: 0.9521\n",
      "Epoch 1380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9455 - val_dice_coef: 0.9455\n",
      "Epoch 1381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9195 - val_dice_coef: 0.9195\n",
      "Epoch 1383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.7753 - val_dice_coef: 0.7753\n",
      "Epoch 1384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.9845 - val_dice_coef: 0.9845\n",
      "Epoch 1386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.6840 - val_dice_coef: 0.6840\n",
      "Epoch 1387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.5232 - val_dice_coef: 0.5232\n",
      "Epoch 1390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 1391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 1393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8864 - dice_coef: 0.8864 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9704 - val_dice_coef: 0.9704\n",
      "Epoch 1395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8829 - dice_coef: 0.8829 - val_loss: -0.8821 - val_dice_coef: 0.8821\n",
      "Epoch 1396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8823 - dice_coef: 0.8823 - val_loss: -0.8286 - val_dice_coef: 0.8286\n",
      "Epoch 1398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.7954 - val_dice_coef: 0.7954\n",
      "Epoch 1399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.7331 - val_dice_coef: 0.7331\n",
      "Epoch 1401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.2798 - val_dice_coef: 0.2798\n",
      "Epoch 1402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.5671 - val_dice_coef: 0.5671\n",
      "Epoch 1404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.8881 - val_dice_coef: 0.8881\n",
      "Epoch 1405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8686 - dice_coef: 0.8686 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 1407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8757 - dice_coef: 0.8757 - val_loss: -0.8560 - val_dice_coef: 0.8560\n",
      "Epoch 1408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.5029 - val_dice_coef: 0.5029\n",
      "Epoch 1410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 1411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8750 - dice_coef: 0.8750 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.8011 - val_dice_coef: 0.8011\n",
      "Epoch 1413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8780 - dice_coef: 0.8780 - val_loss: -0.7275 - val_dice_coef: 0.7275\n",
      "Epoch 1414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.8300 - val_dice_coef: 0.8300\n",
      "Epoch 1416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9668 - val_dice_coef: 0.9668\n",
      "Epoch 1417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.7602 - val_dice_coef: 0.7602\n",
      "Epoch 1419/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 1420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8869 - dice_coef: 0.8869 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9878 - val_dice_coef: 0.9878\n",
      "Epoch 1422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8874 - dice_coef: 0.8874 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 1423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9813 - val_dice_coef: 0.9813\n",
      "Epoch 1425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8862 - dice_coef: 0.8862 - val_loss: -0.9892 - val_dice_coef: 0.9892\n",
      "Epoch 1426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.7790 - val_dice_coef: 0.7790\n",
      "Epoch 1428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1429/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.5066 - val_dice_coef: 0.5066\n",
      "Epoch 1431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 1432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 1433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.9503 - val_dice_coef: 0.9503\n",
      "Epoch 1434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9680 - val_dice_coef: 0.9680\n",
      "Epoch 1435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.9775 - val_dice_coef: 0.9775\n",
      "Epoch 1437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 1438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1439/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9406 - val_dice_coef: 0.9406\n",
      "Epoch 1440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9496 - val_dice_coef: 0.9496\n",
      "Epoch 1441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.7550 - val_dice_coef: 0.7550\n",
      "Epoch 1444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9906 - val_dice_coef: 0.9906\n",
      "Epoch 1445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8869 - dice_coef: 0.8869 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8820 - dice_coef: 0.8820 - val_loss: -0.9122 - val_dice_coef: 0.9122\n",
      "Epoch 1447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9654 - val_dice_coef: 0.9654\n",
      "Epoch 1448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 1450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "Epoch 1451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 1452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 1453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8880 - dice_coef: 0.8880 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 1454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8853 - dice_coef: 0.8853 - val_loss: -0.9077 - val_dice_coef: 0.9077\n",
      "Epoch 1455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8872 - dice_coef: 0.8872 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 1457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8854 - dice_coef: 0.8854 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 1458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.8697 - val_dice_coef: 0.8697\n",
      "Epoch 1459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 1462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9592 - val_dice_coef: 0.9592\n",
      "Epoch 1463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8878 - dice_coef: 0.8878 - val_loss: -0.9028 - val_dice_coef: 0.9028\n",
      "Epoch 1466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.9455 - val_dice_coef: 0.9455\n",
      "Epoch 1471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.9116 - val_dice_coef: 0.9116\n",
      "Epoch 1472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1474/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9324 - val_dice_coef: 0.9324\n",
      "Epoch 1475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9858 - val_dice_coef: 0.9858\n",
      "Epoch 1476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8901 - dice_coef: 0.8901 - val_loss: -0.9861 - val_dice_coef: 0.9860\n",
      "Epoch 1477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8898 - dice_coef: 0.8898 - val_loss: -0.9476 - val_dice_coef: 0.9476\n",
      "Epoch 1478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 1479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8847 - dice_coef: 0.8847 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 1480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -0.4743 - val_dice_coef: 0.4743\n",
      "Epoch 1481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8806 - dice_coef: 0.8806 - val_loss: -0.8402 - val_dice_coef: 0.8402\n",
      "Epoch 1482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8809 - dice_coef: 0.8809 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1484/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.2526 - val_dice_coef: 0.2526\n",
      "Epoch 1485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.9901 - val_dice_coef: 0.9901\n",
      "Epoch 1486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.8856 - val_dice_coef: 0.8856\n",
      "Epoch 1488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8830 - dice_coef: 0.8830 - val_loss: -0.0971 - val_dice_coef: 0.0971\n",
      "Epoch 1489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.3692 - val_dice_coef: 0.3692\n",
      "Epoch 1492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 1493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9403 - val_dice_coef: 0.9403\n",
      "Epoch 1495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8871 - dice_coef: 0.8871 - val_loss: -0.9277 - val_dice_coef: 0.9277\n",
      "Epoch 1497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.5883 - val_dice_coef: 0.5883\n",
      "Epoch 1498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8878 - dice_coef: 0.8878 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 1500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.4534 - val_dice_coef: 0.4534\n",
      "Epoch 1501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8789 - dice_coef: 0.8789 - val_loss: -0.9245 - val_dice_coef: 0.9245\n",
      "Epoch 1502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8800 - dice_coef: 0.8800 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9635 - val_dice_coef: 0.9635\n",
      "Epoch 1504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.6363 - val_dice_coef: 0.6363\n",
      "Epoch 1505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 1507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 1508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.6256 - val_dice_coef: 0.6256\n",
      "Epoch 1509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8813 - dice_coef: 0.8813 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9877 - val_dice_coef: 0.9877\n",
      "Epoch 1511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8885 - dice_coef: 0.8885 - val_loss: -0.7086 - val_dice_coef: 0.7086\n",
      "Epoch 1512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 1513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8889 - dice_coef: 0.8889 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8842 - dice_coef: 0.8842 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 1515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.8409 - val_dice_coef: 0.8409\n",
      "Epoch 1516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.8782 - val_dice_coef: 0.8782\n",
      "Epoch 1520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.9585 - val_dice_coef: 0.9585\n",
      "Epoch 1523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.5229 - val_dice_coef: 0.5229\n",
      "Epoch 1524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9806 - val_dice_coef: 0.9806\n",
      "Epoch 1526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8927 - dice_coef: 0.8927 - val_loss: -0.9602 - val_dice_coef: 0.9602\n",
      "Epoch 1529/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 1531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 1532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8910 - dice_coef: 0.8910 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 1535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9702 - val_dice_coef: 0.9702\n",
      "Epoch 1537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 1539/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 1541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9630 - val_dice_coef: 0.9630\n",
      "Epoch 1542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9517 - val_dice_coef: 0.9517\n",
      "Epoch 1543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8925 - dice_coef: 0.8925 - val_loss: -0.9853 - val_dice_coef: 0.9853\n",
      "Epoch 1548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8915 - dice_coef: 0.8915 - val_loss: -0.9361 - val_dice_coef: 0.9361\n",
      "Epoch 1549/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "Epoch 1550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8800 - dice_coef: 0.8800 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 1553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9578 - val_dice_coef: 0.9578\n",
      "Epoch 1554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 1555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8939 - dice_coef: 0.8939 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 1556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8935 - dice_coef: 0.8935 - val_loss: -0.9822 - val_dice_coef: 0.9822\n",
      "Epoch 1557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.8629 - val_dice_coef: 0.8629\n",
      "Epoch 1558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 1559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 1560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8905 - dice_coef: 0.8905 - val_loss: -0.9371 - val_dice_coef: 0.9371\n",
      "Epoch 1562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.3627 - val_dice_coef: 0.3627\n",
      "Epoch 1563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.8936 - val_dice_coef: 0.8936\n",
      "Epoch 1566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.5421 - val_dice_coef: 0.5421\n",
      "Epoch 1567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.8160 - val_dice_coef: 0.8160\n",
      "Epoch 1570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.8215 - val_dice_coef: 0.8215\n",
      "Epoch 1571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8777 - dice_coef: 0.8777 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 1573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.8056 - val_dice_coef: 0.8056\n",
      "Epoch 1574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8813 - dice_coef: 0.8813 - val_loss: -0.7738 - val_dice_coef: 0.7738\n",
      "Epoch 1575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8851 - dice_coef: 0.8851 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8876 - dice_coef: 0.8876 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 1578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.9532 - val_dice_coef: 0.9532\n",
      "Epoch 1579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8855 - dice_coef: 0.8855 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 1583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.8843 - val_dice_coef: 0.8843\n",
      "Epoch 1584/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8898 - dice_coef: 0.8898 - val_loss: -0.9842 - val_dice_coef: 0.9842\n",
      "Epoch 1585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9646 - val_dice_coef: 0.9646\n",
      "Epoch 1588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9435 - val_dice_coef: 0.9435\n",
      "Epoch 1589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9877 - val_dice_coef: 0.9877\n",
      "Epoch 1590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9839 - val_dice_coef: 0.9839\n",
      "Epoch 1591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9308 - val_dice_coef: 0.9308\n",
      "Epoch 1592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 1594/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 1596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 1599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8889 - dice_coef: 0.8889 - val_loss: -0.8511 - val_dice_coef: 0.8511\n",
      "Epoch 1600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.8326 - val_dice_coef: 0.8326\n",
      "Epoch 1601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 1604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.0651 - val_dice_coef: 0.0651\n",
      "Epoch 1605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 1606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8809 - dice_coef: 0.8809 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 1608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.8713 - val_dice_coef: 0.8713\n",
      "Epoch 1609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8924 - dice_coef: 0.8924 - val_loss: -0.9309 - val_dice_coef: 0.9309\n",
      "Epoch 1613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 1614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.8763 - val_dice_coef: 0.8763\n",
      "Epoch 1616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 1618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 1620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 1621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8843 - dice_coef: 0.8843 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.4770 - val_dice_coef: 0.4770\n",
      "Epoch 1631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.9613 - val_dice_coef: 0.9613\n",
      "Epoch 1632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9713 - val_dice_coef: 0.9713\n",
      "Epoch 1634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 1635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8920 - dice_coef: 0.8920 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 1639/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8924 - dice_coef: 0.8924 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 1646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9299 - val_dice_coef: 0.9299\n",
      "Epoch 1647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9878 - val_dice_coef: 0.9878\n",
      "Epoch 1649/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 1650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9784 - val_dice_coef: 0.9784\n",
      "Epoch 1651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 1652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 1655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9644 - val_dice_coef: 0.9644\n",
      "Epoch 1659/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 1660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9716 - val_dice_coef: 0.9716\n",
      "Epoch 1661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 1662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9715 - val_dice_coef: 0.9715\n",
      "Epoch 1665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.7468 - val_dice_coef: 0.7468\n",
      "Epoch 1666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.5739 - val_dice_coef: 0.5739\n",
      "Epoch 1667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8676 - dice_coef: 0.8676 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8680 - dice_coef: 0.8680 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8694 - dice_coef: 0.8694 - val_loss: -0.8318 - val_dice_coef: 0.8318\n",
      "Epoch 1670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.1576 - val_dice_coef: 0.1576\n",
      "Epoch 1671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8592 - dice_coef: 0.8592 - val_loss: -0.5521 - val_dice_coef: 0.5521\n",
      "Epoch 1672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.5260 - val_dice_coef: 0.5260\n",
      "Epoch 1674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.8793 - val_dice_coef: 0.8793\n",
      "Epoch 1677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9944 - val_dice_coef: 0.9944\n",
      "Epoch 1679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9348 - val_dice_coef: 0.9348\n",
      "Epoch 1680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 1681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8935 - dice_coef: 0.8935 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 1684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8958 - dice_coef: 0.8958 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 1685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9341 - val_dice_coef: 0.9341\n",
      "Epoch 1688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9782 - val_dice_coef: 0.9782\n",
      "Epoch 1690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 1691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9905 - val_dice_coef: 0.9905\n",
      "Epoch 1692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1694/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9083 - val_dice_coef: 0.9083\n",
      "Epoch 1699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8951 - dice_coef: 0.8951 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 1700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 1703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1704/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 1708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 1709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9008 - dice_coef: 0.9008 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9001 - dice_coef: 0.9001 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9852 - val_dice_coef: 0.9852\n",
      "Epoch 1715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9847 - val_dice_coef: 0.9847\n",
      "Epoch 1716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9677 - val_dice_coef: 0.9677\n",
      "Epoch 1721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.7673 - val_dice_coef: 0.7673\n",
      "Epoch 1722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.9616 - val_dice_coef: 0.9616\n",
      "Epoch 1723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9504 - val_dice_coef: 0.9504\n",
      "Epoch 1727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.8598 - val_dice_coef: 0.8598\n",
      "Epoch 1728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 1729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8903 - dice_coef: 0.8903 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9930 - val_dice_coef: 0.9930\n",
      "Epoch 1732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9200 - val_dice_coef: 0.9200\n",
      "Epoch 1733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8996 - dice_coef: 0.8996 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 1738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8996 - dice_coef: 0.8996 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8981 - dice_coef: 0.8981 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8969 - dice_coef: 0.8969 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 1745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 1746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8970 - dice_coef: 0.8970 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 1748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1749/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 1753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9865 - val_dice_coef: 0.9865\n",
      "Epoch 1754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9000 - dice_coef: 0.9000 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 1759/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8883 - dice_coef: 0.8883 - val_loss: -0.3491 - val_dice_coef: 0.3491\n",
      "Epoch 1760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8696 - dice_coef: 0.8696 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8764 - dice_coef: 0.8764 - val_loss: -0.9459 - val_dice_coef: 0.9459\n",
      "Epoch 1763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.3883 - val_dice_coef: 0.3883\n",
      "Epoch 1764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8882 - dice_coef: 0.8882 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9517 - val_dice_coef: 0.9517\n",
      "Epoch 1768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8930 - dice_coef: 0.8930 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1769/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 1771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9906 - val_dice_coef: 0.9906\n",
      "Epoch 1772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8914 - dice_coef: 0.8914 - val_loss: -0.9747 - val_dice_coef: 0.9747\n",
      "Epoch 1774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9855 - val_dice_coef: 0.9855\n",
      "Epoch 1775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9271 - val_dice_coef: 0.9271\n",
      "Epoch 1779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.7942 - val_dice_coef: 0.7942\n",
      "Epoch 1780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.7378 - val_dice_coef: 0.7378\n",
      "Epoch 1783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.8769 - val_dice_coef: 0.8769\n",
      "Epoch 1784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9462 - val_dice_coef: 0.9462\n",
      "Epoch 1788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.9004 - val_dice_coef: 0.9004\n",
      "Epoch 1789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.8421 - val_dice_coef: 0.8421\n",
      "Epoch 1792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 1796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 1800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1804/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9086 - val_dice_coef: 0.9086\n",
      "Epoch 1805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.8330 - val_dice_coef: 0.8330\n",
      "Epoch 1806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9029 - val_dice_coef: 0.9029\n",
      "Epoch 1809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8934 - dice_coef: 0.8934 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 1810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.8401 - val_dice_coef: 0.8401\n",
      "Epoch 1813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9761 - val_dice_coef: 0.9761\n",
      "Epoch 1814/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 1821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 1822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8930 - dice_coef: 0.8930 - val_loss: -0.6426 - val_dice_coef: 0.6426\n",
      "Epoch 1826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9610 - val_dice_coef: 0.9610\n",
      "Epoch 1827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8910 - dice_coef: 0.8910 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.7763 - val_dice_coef: 0.7763\n",
      "Epoch 1830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.7866 - val_dice_coef: 0.7866\n",
      "Epoch 1834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9697 - val_dice_coef: 0.9697\n",
      "Epoch 1839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.9662 - val_dice_coef: 0.9662\n",
      "Epoch 1842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9009 - dice_coef: 0.9009 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 1846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 1849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9014 - dice_coef: 0.9014 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 1859/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "Epoch 1860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9030 - dice_coef: 0.9030 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 1864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 1865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9025 - dice_coef: 0.9025 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8992 - dice_coef: 0.8992 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1869/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8931 - dice_coef: 0.8931 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 1871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.5848 - val_dice_coef: 0.5848\n",
      "Epoch 1872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.7944 - val_dice_coef: 0.7944\n",
      "Epoch 1876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9835 - val_dice_coef: 0.9835\n",
      "Epoch 1877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 1879/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9046 - dice_coef: 0.9046 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.8094 - val_dice_coef: 0.8094\n",
      "Epoch 1883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.7506 - val_dice_coef: 0.7506\n",
      "Epoch 1884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9655 - val_dice_coef: 0.9655\n",
      "Epoch 1887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.9596 - val_dice_coef: 0.9596\n",
      "Epoch 1888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9808 - val_dice_coef: 0.9808\n",
      "Epoch 1891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9312 - val_dice_coef: 0.9312\n",
      "Epoch 1892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9297 - val_dice_coef: 0.9297\n",
      "Epoch 1893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9009 - dice_coef: 0.9009 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 1895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 1896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 1897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 1898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.8928 - val_dice_coef: 0.8928\n",
      "Epoch 1900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.7940 - val_dice_coef: 0.7940\n",
      "Epoch 1901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.1956 - val_dice_coef: 0.1956\n",
      "Epoch 1904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8806 - dice_coef: 0.8806 - val_loss: -0.8431 - val_dice_coef: 0.8431\n",
      "Epoch 1905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8834 - dice_coef: 0.8834 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8751 - dice_coef: 0.8751 - val_loss: -0.4669 - val_dice_coef: 0.4669\n",
      "Epoch 1907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.0583 - val_dice_coef: 0.0583\n",
      "Epoch 1908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8623 - dice_coef: 0.8623 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8566 - dice_coef: 0.8566 - val_loss: -0.6860 - val_dice_coef: 0.6860\n",
      "Epoch 1910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8841 - dice_coef: 0.8841 - val_loss: -0.6182 - val_dice_coef: 0.6182\n",
      "Epoch 1911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8912 - dice_coef: 0.8912 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 1913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8914 - dice_coef: 0.8914 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1914/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8970 - dice_coef: 0.8970 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 1916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9619 - val_dice_coef: 0.9619\n",
      "Epoch 1919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 1922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 1923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1924/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8939 - dice_coef: 0.8939 - val_loss: -0.6276 - val_dice_coef: 0.6276\n",
      "Epoch 1926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.3067 - val_dice_coef: 0.3067\n",
      "Epoch 1929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.4411 - val_dice_coef: 0.4411\n",
      "Epoch 1932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8760 - dice_coef: 0.8760 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 1933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8610 - dice_coef: 0.8610 - val_loss: -0.4877 - val_dice_coef: 0.4877\n",
      "Epoch 1935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 1936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8883 - dice_coef: 0.8883 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9485 - val_dice_coef: 0.9485\n",
      "Epoch 1938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8948 - dice_coef: 0.8948 - val_loss: -0.9521 - val_dice_coef: 0.9521\n",
      "Epoch 1939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.9690 - val_dice_coef: 0.9690\n",
      "Epoch 1942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 1947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 1948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 1950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9722 - val_dice_coef: 0.9722\n",
      "Epoch 1951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9008 - dice_coef: 0.9008 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9876 - val_dice_coef: 0.9876\n",
      "Epoch 1954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 1955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9396 - val_dice_coef: 0.9396\n",
      "Epoch 1958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 1959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9052 - dice_coef: 0.9052 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 1961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9805 - val_dice_coef: 0.9805\n",
      "Epoch 1962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9029 - dice_coef: 0.9029 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 1967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 1968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1969/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9753 - val_dice_coef: 0.9753\n",
      "Epoch 1971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 1978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9037 - dice_coef: 0.9037 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1979/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 1980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.8670 - val_dice_coef: 0.8670\n",
      "Epoch 1981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.8830 - val_dice_coef: 0.8830\n",
      "Epoch 1982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.9545 - val_dice_coef: 0.9545\n",
      "Epoch 1986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 1987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 1989/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 1995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9783 - val_dice_coef: 0.9783\n",
      "Epoch 1996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8885 - dice_coef: 0.8885 - val_loss: -0.9682 - val_dice_coef: 0.9682\n",
      "Epoch 1998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.2416 - val_dice_coef: 0.2416\n",
      "Epoch 1999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 2000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9014 - dice_coef: 0.9014 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2001/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.7513 - val_dice_coef: 0.7513\n",
      "Epoch 2002/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.8799 - val_dice_coef: 0.8799\n",
      "Epoch 2003/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2004/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2005/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9047 - dice_coef: 0.9047 - val_loss: -0.9774 - val_dice_coef: 0.9774\n",
      "Epoch 2006/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9044 - dice_coef: 0.9044 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2007/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2008/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2009/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2010/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9712 - val_dice_coef: 0.9712\n",
      "Epoch 2011/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2012/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2013/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2014/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2015/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9602 - val_dice_coef: 0.9602\n",
      "Epoch 2016/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 2017/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2018/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2019/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2020/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 2021/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2022/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.9562 - val_dice_coef: 0.9562\n",
      "Epoch 2023/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9831 - val_dice_coef: 0.9831\n",
      "Epoch 2024/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9445 - val_dice_coef: 0.9445\n",
      "Epoch 2025/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9607 - val_dice_coef: 0.9607\n",
      "Epoch 2026/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2027/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9814 - val_dice_coef: 0.9814\n",
      "Epoch 2028/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9624 - val_dice_coef: 0.9624\n",
      "Epoch 2029/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2030/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2031/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2032/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8233 - val_dice_coef: 0.8233\n",
      "Epoch 2033/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.0927 - val_dice_coef: 0.0927\n",
      "Epoch 2034/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2035/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2036/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.3486 - val_dice_coef: 0.3486\n",
      "Epoch 2037/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 2038/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2039/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2040/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.8120 - val_dice_coef: 0.8120\n",
      "Epoch 2041/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2042/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2043/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2044/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 2045/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.7585 - val_dice_coef: 0.7585\n",
      "Epoch 2046/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9634 - val_dice_coef: 0.9634\n",
      "Epoch 2047/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2048/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2049/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9001 - dice_coef: 0.9001 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2050/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9299 - val_dice_coef: 0.9299\n",
      "Epoch 2051/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.7435 - val_dice_coef: 0.7435\n",
      "Epoch 2052/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 2053/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2054/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 2055/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "Epoch 2056/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8979 - dice_coef: 0.8979 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2057/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2058/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.0455 - val_dice_coef: 0.0455\n",
      "Epoch 2059/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 2060/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2061/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 2062/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.8678 - val_dice_coef: 0.8678\n",
      "Epoch 2063/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2064/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2065/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.6703 - val_dice_coef: 0.6703\n",
      "Epoch 2066/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2067/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2068/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.6828 - val_dice_coef: 0.6828\n",
      "Epoch 2069/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8999 - dice_coef: 0.8999 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2070/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2071/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.6301 - val_dice_coef: 0.6301\n",
      "Epoch 2072/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2073/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 2074/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.3043 - val_dice_coef: 0.3043\n",
      "Epoch 2075/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2076/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2077/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.7334 - val_dice_coef: 0.7334\n",
      "Epoch 2078/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 2079/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2080/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8992 - dice_coef: 0.8992 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2081/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.7743 - val_dice_coef: 0.7743\n",
      "Epoch 2082/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.9696 - val_dice_coef: 0.9696\n",
      "Epoch 2083/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9059 - dice_coef: 0.9059 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2084/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.8784 - val_dice_coef: 0.8784\n",
      "Epoch 2085/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.6214 - val_dice_coef: 0.6214\n",
      "Epoch 2086/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2087/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 2088/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.7279 - val_dice_coef: 0.7279\n",
      "Epoch 2089/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.8486 - val_dice_coef: 0.8486\n",
      "Epoch 2090/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2091/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2092/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.5195 - val_dice_coef: 0.5195\n",
      "Epoch 2093/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9506 - val_dice_coef: 0.9506\n",
      "Epoch 2094/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2095/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.6622 - val_dice_coef: 0.6622\n",
      "Epoch 2096/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9161 - val_dice_coef: 0.9161\n",
      "Epoch 2097/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9048 - dice_coef: 0.9048 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2098/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2099/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.4942 - val_dice_coef: 0.4942\n",
      "Epoch 2100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8958 - dice_coef: 0.8958 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.0474 - val_dice_coef: 0.0474\n",
      "Epoch 2103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8718 - dice_coef: 0.8718 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9472 - val_dice_coef: 0.9472\n",
      "Epoch 2105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.0916 - val_dice_coef: 0.0916\n",
      "Epoch 2106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8903 - dice_coef: 0.8903 - val_loss: -0.9310 - val_dice_coef: 0.9310\n",
      "Epoch 2108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9342 - val_dice_coef: 0.9342\n",
      "Epoch 2109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.2731 - val_dice_coef: 0.2731\n",
      "Epoch 2111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.8293 - val_dice_coef: 0.8293\n",
      "Epoch 2114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9751 - val_dice_coef: 0.9751\n",
      "Epoch 2115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "Epoch 2117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9895 - val_dice_coef: 0.9895\n",
      "Epoch 2118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9381 - val_dice_coef: 0.9381\n",
      "Epoch 2120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.9411 - val_dice_coef: 0.9411\n",
      "Epoch 2123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.6858 - val_dice_coef: 0.6858\n",
      "Epoch 2124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.7141 - val_dice_coef: 0.7141\n",
      "Epoch 2126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.8951 - val_dice_coef: 0.8951\n",
      "Epoch 2127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.8321 - val_dice_coef: 0.8321\n",
      "Epoch 2129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 2130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9442 - val_dice_coef: 0.9442\n",
      "Epoch 2132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 2134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9257 - val_dice_coef: 0.9257\n",
      "Epoch 2135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9563 - val_dice_coef: 0.9563\n",
      "Epoch 2138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9310 - val_dice_coef: 0.9310\n",
      "Epoch 2141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9590 - val_dice_coef: 0.9590\n",
      "Epoch 2142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2144/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9518 - val_dice_coef: 0.9518\n",
      "Epoch 2145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9400 - val_dice_coef: 0.9400\n",
      "Epoch 2146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 2150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 2151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9562 - val_dice_coef: 0.9562\n",
      "Epoch 2152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 2154/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 2155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9573 - val_dice_coef: 0.9573\n",
      "Epoch 2156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 2157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 2158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9833 - val_dice_coef: 0.9833\n",
      "Epoch 2160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.6026 - val_dice_coef: 0.6026\n",
      "Epoch 2161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.6253 - val_dice_coef: 0.6253\n",
      "Epoch 2162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 2163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9053 - dice_coef: 0.9053 - val_loss: -0.9454 - val_dice_coef: 0.9454\n",
      "Epoch 2166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.8475 - val_dice_coef: 0.8475\n",
      "Epoch 2167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.9166 - val_dice_coef: 0.9166\n",
      "Epoch 2170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.6904 - val_dice_coef: 0.6904\n",
      "Epoch 2171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9470 - val_dice_coef: 0.9470\n",
      "Epoch 2172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9489 - val_dice_coef: 0.9489\n",
      "Epoch 2174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 2175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9062 - dice_coef: 0.9062 - val_loss: -0.8374 - val_dice_coef: 0.8374\n",
      "Epoch 2178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.6803 - val_dice_coef: 0.6803\n",
      "Epoch 2179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.9183 - val_dice_coef: 0.9183\n",
      "Epoch 2180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9088 - dice_coef: 0.9088 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 2181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9816 - val_dice_coef: 0.9816\n",
      "Epoch 2182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 2183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9761 - val_dice_coef: 0.9761\n",
      "Epoch 2185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 2186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 2187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 2188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 2190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9784 - val_dice_coef: 0.9784\n",
      "Epoch 2191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 2192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9600 - val_dice_coef: 0.9600\n",
      "Epoch 2193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9814 - val_dice_coef: 0.9814\n",
      "Epoch 2194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.4542 - val_dice_coef: 0.4542\n",
      "Epoch 2197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.1773 - val_dice_coef: 0.1773\n",
      "Epoch 2198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 2199/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9010 - dice_coef: 0.9010 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 2201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.0938 - val_dice_coef: 0.0938\n",
      "Epoch 2202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8848 - dice_coef: 0.8848 - val_loss: -0.9051 - val_dice_coef: 0.9051\n",
      "Epoch 2204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8954 - dice_coef: 0.8954 - val_loss: -0.1643 - val_dice_coef: 0.1643\n",
      "Epoch 2205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 2207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9123 - val_dice_coef: 0.9123\n",
      "Epoch 2208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2209/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 2210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 2211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9094 - dice_coef: 0.9094 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 2213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.7664 - val_dice_coef: 0.7664\n",
      "Epoch 2214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.7833 - val_dice_coef: 0.7833\n",
      "Epoch 2217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9089 - dice_coef: 0.9089 - val_loss: -0.9804 - val_dice_coef: 0.9804\n",
      "Epoch 2218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2219/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9089 - dice_coef: 0.9089 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9301 - val_dice_coef: 0.9301\n",
      "Epoch 2221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.5832 - val_dice_coef: 0.5832\n",
      "Epoch 2222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9064 - dice_coef: 0.9064 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9178 - val_dice_coef: 0.9178\n",
      "Epoch 2225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.8188 - val_dice_coef: 0.8188\n",
      "Epoch 2226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9806 - val_dice_coef: 0.9806\n",
      "Epoch 2227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 2228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9689 - val_dice_coef: 0.9689\n",
      "Epoch 2229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 2232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 2234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9120 - val_dice_coef: 0.9120\n",
      "Epoch 2235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.8574 - val_dice_coef: 0.8574\n",
      "Epoch 2236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.6431 - val_dice_coef: 0.6431\n",
      "Epoch 2237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 2240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.9571 - val_dice_coef: 0.9571\n",
      "Epoch 2241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 2242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9239 - val_dice_coef: 0.9239\n",
      "Epoch 2243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 2244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9133 - dice_coef: 0.9133 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9028 - val_dice_coef: 0.9028\n",
      "Epoch 2246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.9756 - val_dice_coef: 0.9756\n",
      "Epoch 2247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 2249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9026 - val_dice_coef: 0.9026\n",
      "Epoch 2250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.6725 - val_dice_coef: 0.6725\n",
      "Epoch 2251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9062 - val_dice_coef: 0.9062\n",
      "Epoch 2252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 2254/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9481 - val_dice_coef: 0.9481\n",
      "Epoch 2255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 2258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9205 - val_dice_coef: 0.9205\n",
      "Epoch 2260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.8805 - val_dice_coef: 0.8805\n",
      "Epoch 2261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9302 - val_dice_coef: 0.9302\n",
      "Epoch 2263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9021 - val_dice_coef: 0.9021\n",
      "Epoch 2264/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9340 - val_dice_coef: 0.9340\n",
      "Epoch 2265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 2266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 2267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9082 - val_dice_coef: 0.9082\n",
      "Epoch 2268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.5658 - val_dice_coef: 0.5658\n",
      "Epoch 2269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.7773 - val_dice_coef: 0.7773\n",
      "Epoch 2272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9052 - dice_coef: 0.9052 - val_loss: -0.6216 - val_dice_coef: 0.6216\n",
      "Epoch 2273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.9831 - val_dice_coef: 0.9831\n",
      "Epoch 2274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.8679 - val_dice_coef: 0.8679\n",
      "Epoch 2276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.3709 - val_dice_coef: 0.3709\n",
      "Epoch 2277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.7028 - val_dice_coef: 0.7028\n",
      "Epoch 2278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 2280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.8944 - val_dice_coef: 0.8944\n",
      "Epoch 2281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.8804 - val_dice_coef: 0.8804\n",
      "Epoch 2286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.4114 - val_dice_coef: 0.4114\n",
      "Epoch 2287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9617 - val_dice_coef: 0.9617\n",
      "Epoch 2288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9088 - dice_coef: 0.9088 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.7745 - val_dice_coef: 0.7745\n",
      "Epoch 2291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9046 - dice_coef: 0.9046 - val_loss: -0.2139 - val_dice_coef: 0.2139\n",
      "Epoch 2292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 2293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.8347 - val_dice_coef: 0.8347\n",
      "Epoch 2295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9288 - val_dice_coef: 0.9288\n",
      "Epoch 2296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9366 - val_dice_coef: 0.9366\n",
      "Epoch 2297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9793 - val_dice_coef: 0.9793\n",
      "Epoch 2298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9966 - val_dice_coef: 0.9966\n",
      "Epoch 2300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9266 - val_dice_coef: 0.9266\n",
      "Epoch 2301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.5115 - val_dice_coef: 0.5115\n",
      "Epoch 2302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 2303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9819 - val_dice_coef: 0.9819\n",
      "Epoch 2305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.7982 - val_dice_coef: 0.7982\n",
      "Epoch 2306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9093 - dice_coef: 0.9093 - val_loss: -0.6480 - val_dice_coef: 0.6480\n",
      "Epoch 2307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2309/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.5058 - val_dice_coef: 0.5058\n",
      "Epoch 2310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.6644 - val_dice_coef: 0.6644\n",
      "Epoch 2311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.4163 - val_dice_coef: 0.4163\n",
      "Epoch 2314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.3054 - val_dice_coef: 0.3054\n",
      "Epoch 2315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.9825 - val_dice_coef: 0.9825\n",
      "Epoch 2317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.4694 - val_dice_coef: 0.4694\n",
      "Epoch 2318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.9431 - val_dice_coef: 0.9431\n",
      "Epoch 2319/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9846 - val_dice_coef: 0.9846\n",
      "Epoch 2321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 2322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9565 - val_dice_coef: 0.9565\n",
      "Epoch 2323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.2464 - val_dice_coef: 0.2464\n",
      "Epoch 2324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9622 - val_dice_coef: 0.9622\n",
      "Epoch 2325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9629 - val_dice_coef: 0.9629\n",
      "Epoch 2327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.2290 - val_dice_coef: 0.2290\n",
      "Epoch 2328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8977 - dice_coef: 0.8977 - val_loss: -0.9703 - val_dice_coef: 0.9703\n",
      "Epoch 2329/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9872 - val_dice_coef: 0.9872\n",
      "Epoch 2331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.4349 - val_dice_coef: 0.4349\n",
      "Epoch 2332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.8048 - val_dice_coef: 0.8048\n",
      "Epoch 2333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8969 - dice_coef: 0.8969 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 2335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.6067 - val_dice_coef: 0.6067\n",
      "Epoch 2336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9059 - dice_coef: 0.9059 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 2337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9061 - dice_coef: 0.9061 - val_loss: -0.9525 - val_dice_coef: 0.9525\n",
      "Epoch 2339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.4830 - val_dice_coef: 0.4830\n",
      "Epoch 2340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9852 - val_dice_coef: 0.9852\n",
      "Epoch 2341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9791 - val_dice_coef: 0.9791\n",
      "Epoch 2343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.8013 - val_dice_coef: 0.8013\n",
      "Epoch 2344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 2346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9789 - val_dice_coef: 0.9789\n",
      "Epoch 2347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.7830 - val_dice_coef: 0.7830\n",
      "Epoch 2348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9232 - val_dice_coef: 0.9232\n",
      "Epoch 2349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9580 - val_dice_coef: 0.9580\n",
      "Epoch 2350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9480 - val_dice_coef: 0.9480\n",
      "Epoch 2351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9031 - val_dice_coef: 0.9031\n",
      "Epoch 2352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 2353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9660 - val_dice_coef: 0.9660\n",
      "Epoch 2356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 2357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 2358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 2359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9811 - val_dice_coef: 0.9811\n",
      "Epoch 2360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9651 - val_dice_coef: 0.9651\n",
      "Epoch 2361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9843 - val_dice_coef: 0.9843\n",
      "Epoch 2362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9917 - val_dice_coef: 0.9917\n",
      "Epoch 2364/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9901 - val_dice_coef: 0.9901\n",
      "Epoch 2367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9768 - val_dice_coef: 0.9768\n",
      "Epoch 2370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.8090 - val_dice_coef: 0.8090\n",
      "Epoch 2371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.2923 - val_dice_coef: 0.2923\n",
      "Epoch 2372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2374/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.4193 - val_dice_coef: 0.4193\n",
      "Epoch 2375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8951 - dice_coef: 0.8951 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 2376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.5547 - val_dice_coef: 0.5547\n",
      "Epoch 2378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.0490 - val_dice_coef: 0.0490\n",
      "Epoch 2379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.0556 - val_dice_coef: 0.0556\n",
      "Epoch 2381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 2383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 2384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9010 - dice_coef: 0.9010 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9729 - val_dice_coef: 0.9729\n",
      "Epoch 2386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.6195 - val_dice_coef: 0.6195\n",
      "Epoch 2387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.9684 - val_dice_coef: 0.9684\n",
      "Epoch 2389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9320 - val_dice_coef: 0.9320\n",
      "Epoch 2390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.5473 - val_dice_coef: 0.5473\n",
      "Epoch 2393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9727 - val_dice_coef: 0.9727\n",
      "Epoch 2394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9716 - val_dice_coef: 0.9716\n",
      "Epoch 2396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 2398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9745 - val_dice_coef: 0.9745\n",
      "Epoch 2400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9131 - dice_coef: 0.9131 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 2405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 2406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 2407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 2408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9826 - val_dice_coef: 0.9826\n",
      "Epoch 2409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9905 - val_dice_coef: 0.9905\n",
      "Epoch 2412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9138 - dice_coef: 0.9138 - val_loss: -0.7774 - val_dice_coef: 0.7774\n",
      "Epoch 2413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9553 - val_dice_coef: 0.9553\n",
      "Epoch 2417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2419/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9930 - val_dice_coef: 0.9930\n",
      "Epoch 2420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 2421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.8831 - val_dice_coef: 0.8831\n",
      "Epoch 2422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 2423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.9650 - val_dice_coef: 0.9650\n",
      "Epoch 2426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.7634 - val_dice_coef: 0.7634\n",
      "Epoch 2427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9733 - val_dice_coef: 0.9733\n",
      "Epoch 2428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2429/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 2431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "Epoch 2432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.6367 - val_dice_coef: 0.6367\n",
      "Epoch 2433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9871 - val_dice_coef: 0.9871\n",
      "Epoch 2434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 2436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.7614 - val_dice_coef: 0.7614\n",
      "Epoch 2437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.6913 - val_dice_coef: 0.6913\n",
      "Epoch 2438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 2439/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.6776 - val_dice_coef: 0.6776\n",
      "Epoch 2443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.1864 - val_dice_coef: 0.1864\n",
      "Epoch 2444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9498 - val_dice_coef: 0.9498\n",
      "Epoch 2447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9039 - val_dice_coef: 0.9039\n",
      "Epoch 2448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.7625 - val_dice_coef: 0.7625\n",
      "Epoch 2449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.7575 - val_dice_coef: 0.7575\n",
      "Epoch 2450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 2453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9336 - val_dice_coef: 0.9336\n",
      "Epoch 2454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.5875 - val_dice_coef: 0.5875\n",
      "Epoch 2458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.3099 - val_dice_coef: 0.3099\n",
      "Epoch 2459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9698 - val_dice_coef: 0.9698\n",
      "Epoch 2460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9670 - val_dice_coef: 0.9670\n",
      "Epoch 2462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.3318 - val_dice_coef: 0.3318\n",
      "Epoch 2463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.4738 - val_dice_coef: 0.4738\n",
      "Epoch 2464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.6963 - val_dice_coef: 0.6963\n",
      "Epoch 2466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.2105 - val_dice_coef: 0.2105\n",
      "Epoch 2467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 2469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.6050 - val_dice_coef: 0.6050\n",
      "Epoch 2470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 2472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.8910 - val_dice_coef: 0.8910\n",
      "Epoch 2473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.6591 - val_dice_coef: 0.6591\n",
      "Epoch 2474/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.3696 - val_dice_coef: 0.3696\n",
      "Epoch 2477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.4352 - val_dice_coef: 0.4352\n",
      "Epoch 2478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9402 - val_dice_coef: 0.9402\n",
      "Epoch 2481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.3410 - val_dice_coef: 0.3410\n",
      "Epoch 2482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 2483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2484/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.1221 - val_dice_coef: 0.1221\n",
      "Epoch 2485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.8153 - val_dice_coef: 0.8153\n",
      "Epoch 2488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9361 - val_dice_coef: 0.9361\n",
      "Epoch 2491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 2494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.8146 - val_dice_coef: 0.8146\n",
      "Epoch 2495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9127 - val_dice_coef: 0.9127\n",
      "Epoch 2498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.3409 - val_dice_coef: 0.3409\n",
      "Epoch 2499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9138 - val_dice_coef: 0.9138\n",
      "Epoch 2501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.5536 - val_dice_coef: 0.5536\n",
      "Epoch 2502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.2602 - val_dice_coef: 0.2602\n",
      "Epoch 2505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9884 - val_dice_coef: 0.9884\n",
      "Epoch 2507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.2527 - val_dice_coef: 0.2527\n",
      "Epoch 2508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 2509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -0.7993 - val_dice_coef: 0.7993\n",
      "Epoch 2511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.5294 - val_dice_coef: 0.5294\n",
      "Epoch 2512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 2514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.8441 - val_dice_coef: 0.8441\n",
      "Epoch 2515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9006 - val_dice_coef: 0.9006\n",
      "Epoch 2516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9769 - val_dice_coef: 0.9769\n",
      "Epoch 2517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9760 - val_dice_coef: 0.9760\n",
      "Epoch 2518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9511 - val_dice_coef: 0.9511\n",
      "Epoch 2521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8498 - val_dice_coef: 0.8498\n",
      "Epoch 2522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 2523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9138 - dice_coef: 0.9138 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 2525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9139 - dice_coef: 0.9139 - val_loss: -0.9584 - val_dice_coef: 0.9584\n",
      "Epoch 2526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9207 - val_dice_coef: 0.9207\n",
      "Epoch 2527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9138 - val_dice_coef: 0.9138\n",
      "Epoch 2528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2529/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 2530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 2531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9574 - val_dice_coef: 0.9574\n",
      "Epoch 2532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9499 - val_dice_coef: 0.9499\n",
      "Epoch 2534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 2535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9387 - val_dice_coef: 0.9387\n",
      "Epoch 2538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.7852 - val_dice_coef: 0.7852\n",
      "Epoch 2539/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.8365 - val_dice_coef: 0.8365\n",
      "Epoch 2540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 2541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.6630 - val_dice_coef: 0.6630\n",
      "Epoch 2543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.2535 - val_dice_coef: 0.2535\n",
      "Epoch 2544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.3855 - val_dice_coef: 0.3855\n",
      "Epoch 2546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.0618 - val_dice_coef: 0.0618\n",
      "Epoch 2547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.0220 - val_dice_coef: 0.0220\n",
      "Epoch 2549/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8882 - dice_coef: 0.8882 - val_loss: -0.1945 - val_dice_coef: 0.1945\n",
      "Epoch 2552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.0718 - val_dice_coef: 0.0718\n",
      "Epoch 2554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.8228 - val_dice_coef: 0.8228\n",
      "Epoch 2556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9731 - val_dice_coef: 0.9731\n",
      "Epoch 2557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9399 - val_dice_coef: 0.9399\n",
      "Epoch 2559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 2562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.8389 - val_dice_coef: 0.8389\n",
      "Epoch 2563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9534 - val_dice_coef: 0.9534\n",
      "Epoch 2566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9137 - dice_coef: 0.9137 - val_loss: -0.9694 - val_dice_coef: 0.9694\n",
      "Epoch 2567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 2570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9725 - val_dice_coef: 0.9725\n",
      "Epoch 2571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9186 - dice_coef: 0.9186 - val_loss: -0.9791 - val_dice_coef: 0.9791\n",
      "Epoch 2574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 2578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9523 - val_dice_coef: 0.9523\n",
      "Epoch 2579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9673 - val_dice_coef: 0.9673\n",
      "Epoch 2580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 2581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2584/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9705 - val_dice_coef: 0.9705\n",
      "Epoch 2585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.7353 - val_dice_coef: 0.7353\n",
      "Epoch 2586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 2589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9493 - val_dice_coef: 0.9493\n",
      "Epoch 2591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9382 - val_dice_coef: 0.9382\n",
      "Epoch 2592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9844 - val_dice_coef: 0.9844\n",
      "Epoch 2593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2594/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9159 - dice_coef: 0.9159 - val_loss: -0.9854 - val_dice_coef: 0.9854\n",
      "Epoch 2595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9117 - val_dice_coef: 0.9117\n",
      "Epoch 2596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 2597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9594 - val_dice_coef: 0.9594\n",
      "Epoch 2601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.8438 - val_dice_coef: 0.8438\n",
      "Epoch 2602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9817 - val_dice_coef: 0.9817\n",
      "Epoch 2606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9159 - dice_coef: 0.9159 - val_loss: -0.7647 - val_dice_coef: 0.7647\n",
      "Epoch 2607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8983 - val_dice_coef: 0.8983\n",
      "Epoch 2608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9884 - val_dice_coef: 0.9884\n",
      "Epoch 2609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9188 - dice_coef: 0.9188 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9389 - val_dice_coef: 0.9389\n",
      "Epoch 2612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9502 - val_dice_coef: 0.9502\n",
      "Epoch 2613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9673 - val_dice_coef: 0.9673\n",
      "Epoch 2614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 2615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.9213 - val_dice_coef: 0.9213\n",
      "Epoch 2618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.8335 - val_dice_coef: 0.8335\n",
      "Epoch 2619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 2620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9193 - dice_coef: 0.9193 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 2622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 2623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9428 - val_dice_coef: 0.9428\n",
      "Epoch 2624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9559 - val_dice_coef: 0.9559\n",
      "Epoch 2625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9580 - val_dice_coef: 0.9580\n",
      "Epoch 2626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 2627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 2631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9049 - val_dice_coef: 0.9049\n",
      "Epoch 2632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8991 - val_dice_coef: 0.8991\n",
      "Epoch 2633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9495 - val_dice_coef: 0.9495\n",
      "Epoch 2634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 2635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.2885 - val_dice_coef: 0.2885\n",
      "Epoch 2638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.2576 - val_dice_coef: 0.2576\n",
      "Epoch 2639/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9048 - dice_coef: 0.9048 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9642 - val_dice_coef: 0.9642\n",
      "Epoch 2642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.8795 - val_dice_coef: 0.8795\n",
      "Epoch 2643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9816 - val_dice_coef: 0.9816\n",
      "Epoch 2644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.7112 - val_dice_coef: 0.7112\n",
      "Epoch 2647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.7026 - val_dice_coef: 0.7026\n",
      "Epoch 2648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.7975 - val_dice_coef: 0.7975\n",
      "Epoch 2649/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9131 - dice_coef: 0.9131 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 2652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9450 - val_dice_coef: 0.9450\n",
      "Epoch 2653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9080 - val_dice_coef: 0.9080\n",
      "Epoch 2654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9741 - val_dice_coef: 0.9741\n",
      "Epoch 2655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 2656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 2657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9289 - val_dice_coef: 0.9289\n",
      "Epoch 2658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 2659/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 2661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9839 - val_dice_coef: 0.9839\n",
      "Epoch 2662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.8275 - val_dice_coef: 0.8275\n",
      "Epoch 2664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.7169 - val_dice_coef: 0.7169\n",
      "Epoch 2665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9956 - val_dice_coef: 0.9956\n",
      "Epoch 2668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9465 - val_dice_coef: 0.9465\n",
      "Epoch 2670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.6517 - val_dice_coef: 0.6517\n",
      "Epoch 2671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.6271 - val_dice_coef: 0.6271\n",
      "Epoch 2672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 2675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9111 - dice_coef: 0.9111 - val_loss: -0.8553 - val_dice_coef: 0.8553\n",
      "Epoch 2676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.6418 - val_dice_coef: 0.6418\n",
      "Epoch 2677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9451 - val_dice_coef: 0.9451\n",
      "Epoch 2678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9378 - val_dice_coef: 0.9378\n",
      "Epoch 2679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9139 - dice_coef: 0.9139 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9474 - val_dice_coef: 0.9474\n",
      "Epoch 2684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9631 - val_dice_coef: 0.9631\n",
      "Epoch 2686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9537 - val_dice_coef: 0.9537\n",
      "Epoch 2687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 2688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9706 - val_dice_coef: 0.9706\n",
      "Epoch 2689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2694/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9513 - val_dice_coef: 0.9513\n",
      "Epoch 2695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.8110 - val_dice_coef: 0.8110\n",
      "Epoch 2696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9871 - val_dice_coef: 0.9871\n",
      "Epoch 2697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 2700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 2701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9530 - val_dice_coef: 0.9530\n",
      "Epoch 2704/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9678 - val_dice_coef: 0.9678\n",
      "Epoch 2705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9263 - val_dice_coef: 0.9263\n",
      "Epoch 2707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9615 - val_dice_coef: 0.9615\n",
      "Epoch 2708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9825 - val_dice_coef: 0.9825\n",
      "Epoch 2709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9718 - val_dice_coef: 0.9718\n",
      "Epoch 2710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9606 - val_dice_coef: 0.9606\n",
      "Epoch 2711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9210 - dice_coef: 0.9210 - val_loss: -0.9876 - val_dice_coef: 0.9876\n",
      "Epoch 2712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.9686 - val_dice_coef: 0.9686\n",
      "Epoch 2713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.9230 - val_dice_coef: 0.9230\n",
      "Epoch 2714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.6055 - val_dice_coef: 0.6055\n",
      "Epoch 2715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.7039 - val_dice_coef: 0.7039\n",
      "Epoch 2716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 2717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 2718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9753 - val_dice_coef: 0.9753\n",
      "Epoch 2719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9210 - dice_coef: 0.9210 - val_loss: -0.9767 - val_dice_coef: 0.9767\n",
      "Epoch 2720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 2721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9204 - dice_coef: 0.9204 - val_loss: -0.9916 - val_dice_coef: 0.9916\n",
      "Epoch 2722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9181 - dice_coef: 0.9181 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9895 - val_dice_coef: 0.9895\n",
      "Epoch 2725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 2726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9553 - val_dice_coef: 0.9553\n",
      "Epoch 2727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 2728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.5576 - val_dice_coef: 0.5576\n",
      "Epoch 2730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.0683 - val_dice_coef: 0.0683\n",
      "Epoch 2731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9944 - val_dice_coef: 0.9944\n",
      "Epoch 2733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.2141 - val_dice_coef: 0.2141\n",
      "Epoch 2734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.5150 - val_dice_coef: 0.5150\n",
      "Epoch 2735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.9897 - val_dice_coef: 0.9897\n",
      "Epoch 2737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.4916 - val_dice_coef: 0.4916\n",
      "Epoch 2738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 2739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9206 - dice_coef: 0.9206 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 2740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9186 - dice_coef: 0.9186 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 2741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9199 - dice_coef: 0.9199 - val_loss: -0.9775 - val_dice_coef: 0.9775\n",
      "Epoch 2742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 2744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9773 - val_dice_coef: 0.9773\n",
      "Epoch 2748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9449 - val_dice_coef: 0.9449\n",
      "Epoch 2749/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.6856 - val_dice_coef: 0.6856\n",
      "Epoch 2750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.1605 - val_dice_coef: 0.1605\n",
      "Epoch 2751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9913 - val_dice_coef: 0.9913\n",
      "Epoch 2753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.1673 - val_dice_coef: 0.1673\n",
      "Epoch 2754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 2755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.8341 - val_dice_coef: 0.8341\n",
      "Epoch 2757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.3254 - val_dice_coef: 0.3254\n",
      "Epoch 2758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 2759/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 2760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.6873 - val_dice_coef: 0.6873\n",
      "Epoch 2761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.2790 - val_dice_coef: 0.2790\n",
      "Epoch 2762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.8434 - val_dice_coef: 0.8434\n",
      "Epoch 2765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.6315 - val_dice_coef: 0.6315\n",
      "Epoch 2766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.8974 - val_dice_coef: 0.8974\n",
      "Epoch 2767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9656 - val_dice_coef: 0.9656\n",
      "Epoch 2769/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 2770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9206 - dice_coef: 0.9206 - val_loss: -0.8701 - val_dice_coef: 0.8701\n",
      "Epoch 2771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 2772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 2773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.8602 - val_dice_coef: 0.8602\n",
      "Epoch 2774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.9125 - val_dice_coef: 0.9125\n",
      "Epoch 2775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 2776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9193 - dice_coef: 0.9193 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 2777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9188 - dice_coef: 0.9188 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9551 - val_dice_coef: 0.9551\n",
      "Epoch 2780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 2781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.8195 - val_dice_coef: 0.8195\n",
      "Epoch 2782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.8337 - val_dice_coef: 0.8337\n",
      "Epoch 2783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9586 - val_dice_coef: 0.9586\n",
      "Epoch 2784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.8526 - val_dice_coef: 0.8526\n",
      "Epoch 2785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9293 - val_dice_coef: 0.9293\n",
      "Epoch 2786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 2787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9813 - val_dice_coef: 0.9813\n",
      "Epoch 2788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 2789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9026 - val_dice_coef: 0.9026\n",
      "Epoch 2790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.8888 - val_dice_coef: 0.8888\n",
      "Epoch 2791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.4764 - val_dice_coef: 0.4764\n",
      "Epoch 2792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.5740 - val_dice_coef: 0.5740\n",
      "Epoch 2795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9747 - val_dice_coef: 0.9747\n",
      "Epoch 2796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.3430 - val_dice_coef: 0.3430\n",
      "Epoch 2798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.5994 - val_dice_coef: 0.5994\n",
      "Epoch 2799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.6466 - val_dice_coef: 0.6466\n",
      "Epoch 2802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.8355 - val_dice_coef: 0.8355\n",
      "Epoch 2803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9594 - val_dice_coef: 0.9594\n",
      "Epoch 2804/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.7488 - val_dice_coef: 0.7488\n",
      "Epoch 2805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9708 - val_dice_coef: 0.9708\n",
      "Epoch 2806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.0411 - val_dice_coef: 0.0411\n",
      "Epoch 2809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.5443 - val_dice_coef: 0.5443\n",
      "Epoch 2810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.8374 - val_dice_coef: 0.8374\n",
      "Epoch 2812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9044 - val_dice_coef: 0.9044\n",
      "Epoch 2813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2814/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9197 - val_dice_coef: 0.9197\n",
      "Epoch 2815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.6469 - val_dice_coef: 0.6469\n",
      "Epoch 2816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.7670 - val_dice_coef: 0.7670\n",
      "Epoch 2819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9133 - dice_coef: 0.9133 - val_loss: -0.3303 - val_dice_coef: 0.3303\n",
      "Epoch 2820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8931 - dice_coef: 0.8931 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.0246 - val_dice_coef: 0.0246\n",
      "Epoch 2823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.3323 - val_dice_coef: 0.3323\n",
      "Epoch 2825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.0754 - val_dice_coef: 0.0754\n",
      "Epoch 2826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9044 - dice_coef: 0.9044 - val_loss: -0.2435 - val_dice_coef: 0.2435\n",
      "Epoch 2828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9496 - val_dice_coef: 0.9496\n",
      "Epoch 2831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9773 - val_dice_coef: 0.9773\n",
      "Epoch 2832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9168 - dice_coef: 0.9168 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.7813 - val_dice_coef: 0.7813\n",
      "Epoch 2834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9454 - val_dice_coef: 0.9454\n",
      "Epoch 2835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.8028 - val_dice_coef: 0.8028\n",
      "Epoch 2838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 2839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9359 - val_dice_coef: 0.9359\n",
      "Epoch 2841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9202 - val_dice_coef: 0.9202\n",
      "Epoch 2842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 2843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9515 - val_dice_coef: 0.9515\n",
      "Epoch 2846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 2847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9468 - val_dice_coef: 0.9468\n",
      "Epoch 2848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.7922 - val_dice_coef: 0.7922\n",
      "Epoch 2849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9071 - val_dice_coef: 0.9071\n",
      "Epoch 2850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9181 - dice_coef: 0.9181 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.6913 - val_dice_coef: 0.6913\n",
      "Epoch 2853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.2032 - val_dice_coef: 0.2032\n",
      "Epoch 2854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9037 - dice_coef: 0.9037 - val_loss: -0.8833 - val_dice_coef: 0.8833\n",
      "Epoch 2856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.1882 - val_dice_coef: 0.1882\n",
      "Epoch 2857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2859/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.8098 - val_dice_coef: 0.8098\n",
      "Epoch 2860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.4437 - val_dice_coef: 0.4437\n",
      "Epoch 2861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.7748 - val_dice_coef: 0.7748\n",
      "Epoch 2864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.7879 - val_dice_coef: 0.7879\n",
      "Epoch 2865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.2887 - val_dice_coef: 0.2887\n",
      "Epoch 2868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9497 - val_dice_coef: 0.9497\n",
      "Epoch 2869/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9258 - val_dice_coef: 0.9258\n",
      "Epoch 2871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.6020 - val_dice_coef: 0.6020\n",
      "Epoch 2872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 2873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 2874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9841 - val_dice_coef: 0.9841\n",
      "Epoch 2875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.7869 - val_dice_coef: 0.7869\n",
      "Epoch 2876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9667 - val_dice_coef: 0.9667\n",
      "Epoch 2877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 2878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9676 - val_dice_coef: 0.9676\n",
      "Epoch 2879/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 2880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9508 - val_dice_coef: 0.9508\n",
      "Epoch 2881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.9433 - val_dice_coef: 0.9433\n",
      "Epoch 2882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9675 - val_dice_coef: 0.9675\n",
      "Epoch 2883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9897 - val_dice_coef: 0.9897\n",
      "Epoch 2884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9507 - val_dice_coef: 0.9507\n",
      "Epoch 2885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9471 - val_dice_coef: 0.9471\n",
      "Epoch 2886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9889 - val_dice_coef: 0.9889\n",
      "Epoch 2887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9220 - dice_coef: 0.9220 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9233 - dice_coef: 0.9233 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 2889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9916 - val_dice_coef: 0.9916\n",
      "Epoch 2890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 2892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9199 - dice_coef: 0.9199 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9610 - val_dice_coef: 0.9610\n",
      "Epoch 2894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9166 - dice_coef: 0.9166 - val_loss: -0.5778 - val_dice_coef: 0.5778\n",
      "Epoch 2895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.7792 - val_dice_coef: 0.7792\n",
      "Epoch 2896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 2897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 2898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9207 - dice_coef: 0.9207 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 2900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9542 - val_dice_coef: 0.9542\n",
      "Epoch 2901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9624 - val_dice_coef: 0.9624\n",
      "Epoch 2902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9215 - dice_coef: 0.9215 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9230 - dice_coef: 0.9230 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.8969 - val_dice_coef: 0.8969\n",
      "Epoch 2909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.7985 - val_dice_coef: 0.7985\n",
      "Epoch 2910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9008 - val_dice_coef: 0.9008\n",
      "Epoch 2911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.8960 - val_dice_coef: 0.8960\n",
      "Epoch 2912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9213 - dice_coef: 0.9213 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2914/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.5299 - val_dice_coef: 0.5299\n",
      "Epoch 2917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.4511 - val_dice_coef: 0.4511\n",
      "Epoch 2918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9224 - dice_coef: 0.9224 - val_loss: -0.9183 - val_dice_coef: 0.9183\n",
      "Epoch 2923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9228 - dice_coef: 0.9228 - val_loss: -0.8274 - val_dice_coef: 0.8274\n",
      "Epoch 2924/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9805 - val_dice_coef: 0.9805\n",
      "Epoch 2925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9199 - val_dice_coef: 0.9199\n",
      "Epoch 2930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9224 - dice_coef: 0.9224 - val_loss: -0.9598 - val_dice_coef: 0.9598\n",
      "Epoch 2931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9249 - val_dice_coef: 0.9249\n",
      "Epoch 2932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9215 - dice_coef: 0.9215 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9232 - dice_coef: 0.9232 - val_loss: -0.9848 - val_dice_coef: 0.9848\n",
      "Epoch 2934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9229 - dice_coef: 0.9229 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 2935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9227 - dice_coef: 0.9227 - val_loss: -0.9853 - val_dice_coef: 0.9853\n",
      "Epoch 2936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9232 - dice_coef: 0.9232 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 2937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9238 - dice_coef: 0.9238 - val_loss: -0.9717 - val_dice_coef: 0.9717\n",
      "Epoch 2938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9040 - val_dice_coef: 0.9040\n",
      "Epoch 2939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 2940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9207 - dice_coef: 0.9207 - val_loss: -0.9860 - val_dice_coef: 0.9860\n",
      "Epoch 2941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9576 - val_dice_coef: 0.9576\n",
      "Epoch 2944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9229 - dice_coef: 0.9229 - val_loss: -0.8049 - val_dice_coef: 0.8049\n",
      "Epoch 2945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.4973 - val_dice_coef: 0.4973\n",
      "Epoch 2946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.5387 - val_dice_coef: 0.5387\n",
      "Epoch 2947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.6299 - val_dice_coef: 0.6299\n",
      "Epoch 2950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.5632 - val_dice_coef: 0.5632\n",
      "Epoch 2951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9418 - val_dice_coef: 0.9418\n",
      "Epoch 2952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.7234 - val_dice_coef: 0.7234\n",
      "Epoch 2954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.0527 - val_dice_coef: 0.0527\n",
      "Epoch 2955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.8292 - val_dice_coef: 0.8292\n",
      "Epoch 2958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.5083 - val_dice_coef: 0.5083\n",
      "Epoch 2959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.2455 - val_dice_coef: 0.2455\n",
      "Epoch 2962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.7099 - val_dice_coef: 0.7099\n",
      "Epoch 2963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 2965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.8014 - val_dice_coef: 0.8014\n",
      "Epoch 2966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.8227 - val_dice_coef: 0.8227\n",
      "Epoch 2967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9204 - dice_coef: 0.9204 - val_loss: -0.9774 - val_dice_coef: 0.9774\n",
      "Epoch 2968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 2969/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9790 - val_dice_coef: 0.9790\n",
      "Epoch 2970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9908 - val_dice_coef: 0.9908\n",
      "Epoch 2971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9236 - dice_coef: 0.9236 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9242 - dice_coef: 0.9242 - val_loss: -0.9597 - val_dice_coef: 0.9597\n",
      "Epoch 2974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9817 - val_dice_coef: 0.9817\n",
      "Epoch 2975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9244 - dice_coef: 0.9244 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 2977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9896 - val_dice_coef: 0.9896\n",
      "Epoch 2978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 2979/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.9339 - val_dice_coef: 0.9339\n",
      "Epoch 2980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9235 - dice_coef: 0.9235 - val_loss: -0.8915 - val_dice_coef: 0.8915\n",
      "Epoch 2981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.6100 - val_dice_coef: 0.6100\n",
      "Epoch 2982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.8801 - val_dice_coef: 0.8801\n",
      "Epoch 2983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 2984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9235 - dice_coef: 0.9235 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9561 - val_dice_coef: 0.9561\n",
      "Epoch 2986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.6162 - val_dice_coef: 0.6162\n",
      "Epoch 2987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.4257 - val_dice_coef: 0.4257\n",
      "Epoch 2988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.8258 - val_dice_coef: 0.8258\n",
      "Epoch 2989/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9841 - val_dice_coef: 0.9841\n",
      "Epoch 2990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9220 - dice_coef: 0.9220 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 2991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9827 - val_dice_coef: 0.9827\n",
      "Epoch 2993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.8863 - val_dice_coef: 0.8863\n",
      "Epoch 2994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.8742 - val_dice_coef: 0.8742\n",
      "Epoch 2995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9217 - dice_coef: 0.9217 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 2996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.8957 - val_dice_coef: 0.8957\n",
      "Epoch 2997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9598 - val_dice_coef: 0.9598\n",
      "Epoch 2998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9350 - val_dice_coef: 0.9350\n",
      "Epoch 2999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9240 - dice_coef: 0.9240 - val_loss: -0.9408 - val_dice_coef: 0.9408\n",
      "Epoch 3000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.8405 - val_dice_coef: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff126c17748>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "model = get_unet()\n",
    "print(model.summary())\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "model.fit(train_z, train_z_m, batch_size=32, epochs=3000, verbose=1, shuffle=True,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weights.h5',custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_train = model.predict(train_z[:int(train_z.shape[0]*0.9)], verbose=1)\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val = model.predict(train_z[int(train_z.shape[0]*0.9):], verbose=1)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Low image data range; displaying image with stretched contrast.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "ix = 70\n",
    "imshow(np.squeeze(train_z[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(train_z_m[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((IMG_H, IMG_W, 1))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "local_conv1 = Conv2D(64, (7, 7), activation='relu', padding='same')(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(64)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(1)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_18/Max:0' shape=(?, 1, 64, 64) dtype=float32>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_231/Relu:0' shape=(?, 64, 64, 64) dtype=float32>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('img3d_train', img_array)\n",
    "np.save('msk3d_train', msk_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 320, 232)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
