{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from medpy.io import load\n",
    "import os\n",
    "import itk\n",
    "import skimage\n",
    "import SimpleITK as sitk\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from keras.layers import Input, MaxoutDense\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, Conv3D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../patients/'\n",
    "IMG_H = 128\n",
    "IMG_W = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CengJia',\n",
       " 'GangZu',\n",
       " 'JiaHuiQiong',\n",
       " 'KongDan',\n",
       " 'LanDingKun',\n",
       " 'LiangChengJun',\n",
       " 'LiuGuangQiong',\n",
       " 'LiuQuanXing',\n",
       " 'LiuYanMu',\n",
       " 'ShenXin',\n",
       " 'TanHongJun',\n",
       " 'XiaGang',\n",
       " 'XiaoChangLun',\n",
       " 'YangChuanFu',\n",
       " 'YangXia',\n",
       " 'YangYunFei',\n",
       " 'ZhangJianMing',\n",
       " 'ZhouDaoMing',\n",
       " 'ZhouLiangYong']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = next(os.walk(data_path))[1]\n",
    "train_ids.sort()\n",
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CengJiaT1SegRAIROIResampling.mha',\n",
       " 'bak_CengJiaT1SegRAIROIResampling.mha',\n",
       " 'CengJiaT1SegDistanceMap.mha',\n",
       " 'CengJiaT1RAIROIResamplingNormalize.mha']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_prof = next(os.walk(data_path + '/' + train_ids[0]))[2]\n",
    "ind_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CengJiaT1RAIROIResamplingNormalize.mha'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "#ind_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMQAAAD0CAYAAADE3InGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsvWmQJOl53/d78866u7r6mu6ea2dmd3YWWAALQIuDOExCoGmS8AUG+UVyWGHQNmSbEaYiZPuDHdYXO8JHhEMOSVCYpkiJhxA2g7BEEyRhkuCxALgLLPeeu+fsu7rrzMzK4/WHJyu7ZjAD7DW7vZj6R3R0d3V1VlZlPu/7HP/n/yitNVNMMYXAeLdPYIopDhOmBjHFFBOYGsQUU0xgahBTTDGBqUFMMcUEpgYxxRQTeGAGoZT6SaXUeaXUJaXU339QrzPFFG8n1IOoQyilTOAC8DngJvBXwC9orV95219siineRjyoHeKjwCWt9RWt9Qj4LeALD+i1ppjibYP1gI67DNyY+P0m8Dcmn6CU+hLwJQAT66myWX9ApzLFw44g6zPKQvV6nvugDOKHQmv9FeArAHWrpT9WmW4gUzwYPNP/3df93AflMt0CVid+X8kfm2KKQ40HZRB/BZxWSp1QSjnAzwNfe0CvNcUUbxseiMuktU6UUn8X+DpgAr+itX75QbzWFFO8nXhgMYTW+veA33tQx59iigeBaaV6iikmMDWIKaaYwNQgpphiAlODmGKKCUwNYoopJjA1iCmmmMDUIKaYYgJTg5hiiglMDWKKKSYwNYgpppjA1CCmmGICU4OYYooJTA1iiikmMDWIKaaYwNQgpphiAlODmGKKCUwNYoopJjA1iCmmmMDUIKaYYgJTg5hiiglMDWKKKSYwNYgpppjA1CCmmGICU4OYYooJvCWhMqXUGtADUiDRWn9YKdUEfhs4DqwBP6e13ntrpznFFO8M3o4d4rNa6w9orT+c//73gW9orU8D38h/n2KK9wQehMv0BeCf5T//M+DffgCvMYVjv9tn8COJt2oQGvgDpdRz+QAUgAWt9Xr+8wawcK9/VEp9SSn1rFLq2VEWvsXTeAgxit/tM/iRxFsVO/6k1vqWUmoe+EOl1GuTf9Raa6XUPYfY3T0w5S2ex48mHHt647/DeEs7hNb6Vv59C/gdZLbcplJqCSD/vvVWT/Khxf2M4c26S1M364fiTRuEUqqslKqOfwb+JvASMhjlb+dP+9vA659nNMXrw3TXeGB4Ky7TAvA7SqnxcX5Da/37Sqm/Av6lUurvANeAn3vrp/kQYewm3e0uTf4+udK/EeO413GnuANv2iC01leAJ+/x+C7w42/lpB5qjG/Wu2/aid+VbaPj+M3d2FNj+IF416aQTvEG4dgo34ckQQ+GB4/Vquhu743d6PfbJcY7z0NsNFPqxruJu4Pc+wW9+eM6CMA6WMOUbUMQyvfJ//1hwfP9bvjRm9x1foQw3SHeTfwAtwg4WMknHteTP493ivscV5VL3/+cyV1gMl653zk8ZJjuEG8Erzdt+XalRe8Oqu9xXFUu3fc49zSYSQOb/D7dHYDpDvHG8HpvmNfzvHv58ff4v+EnHqV91qZ3JkElCm/DZPbllKhusP3xBCyNuWfhbxis/pOX7n2cHxQzTI3gDkwN4p2GY0uW6H7uzsTzRu87xq3PWCT1BHMgm/loJmP3nElS0lh7FiqFZDkiWk7Y+XfPMffNdfRO+86b/a6b/o5dJc9YFed0v7TvQ4KpQTwo3OfG/0HGoMolBh9YpXfUovOpENuJ4YpL83sm9asxUd0kqhkMVkClMPuiMF70Kw69VY/tpxMGS0c4/tuIUeTncfeNfa+UrX4jscSPsLFMDeJBYRTfEQCPcU9jcGyS0ysMVjw2n1ak5RR6NlniUL+ucLoZmakwEjBSKG1oVAJGIgZh72cARC2DpKTRvgvkQXWzDps7d97APyjLdI9zez2u3Y8KpgbxduAHrJjjTI+q1wDQvosuuaS+TVK16ZywGdUUwWJGWk0xywn0bOqvWJTXUzIrQ5sQVwzissFgSaFN2SGipolKwekYGCk0XoGoqXjtP2lg7zUxEkW4HENWx79pMXM+xe2k+Jd2IE7QvotKUjkvy5Sf40TSu/BQBtpTg3ij+CErpiqX0NUy8XyVuGoTNUwA4pJC55+2GUFcViQlSHJ33tkzYM8AxG0pr6fY/YxwVv5/OG+SlCBzwNsBe6AJ5hSxsMmwB7JrqBSsrkFS1eiZCK8UE/ZcwsWUPUzMyMQ/soQZ5e6WCZmlSN38/PNdyEg0lVsj7L0QdXPzoTGMqUG8UdwdcC7OMVqu0192iOoG2gSnq/F3U8woY+aFPYgTVG9QBK9YVrFTRPMl4rKJkWhUojFSTWYqrDAlatgM5w2Sktzo2hR3aeE3XwbHJvzQCfZOO/SPauKhwhiJsdUuAyi05ZK6HtWu3PxGkmEPNEaisfsJ7rW2VLnvem96ZYGk4jBccukecwk+1yB1wd2DhW93MW/t/OD6xnsYU4N4Mxhf9NUl1j8zy6gG5XXNzMUR/os376BWjDGOJ4q4ogNGvQbzpSIWsMIUI0xJqjZRwy4MDJCs0lDRfDkodiHvVo+aW2e4KFknOxV3SlvgtSWuiMtGcXwz0tiDFO+7V+U9lEuFEahaleBUC3OY4Nzexx5GNC5viLtXLhE9doTND3vc+mwNf7vK3DduoDvd7/9M3uOYGsTrxcSu0Pvxs/RWTbx2xtKvv1QEr0nNY/TIIirVaFNhhgmjpoe3tgcb23Kc1SW4sU749BmCWQttgtvJKJ/fRSUp0bEmcdmkf8QkdSF181V/TQOa4ZKL1W9idId0z7WI6gYz5+WG762KG2YNFVHNoLyVYveTwu0aLJnsnzJZbS9hXLh+YLijGG2ZOG3pXBwdaZCWLDKzCVDsWs3XEirPXkc361z/+aMkJVj9gwHWy1ffuevwgDE1iHvhPnFC+PQZ2o85NF8bsfzVa4weWSQ7c5TUs0hLFuYwQaWazDMxwhSVZBhxRjJbwaj5ZLaJvbaJBlLXwAo11W+8CkD8/pOoVKNiWdmNRIzK3YPSVkpv1USbsPTnA9Qwgjih9tebBKdabHzUISlpqtc0ZgTBnEKbisxSmIlm5qUu6uYmyvfpf+AIGx+vschRVJKh4pRwuUrqGrg7EdpUxFUbK0zJTBNtKUjF4FSi6X/4KCrRLD4zxH7hCp3Pn6X3sSdY+I78ft/P7z2CqUHcC/e6mItz7Dzh4LU1/os3yRaaaNsgS01UqjHiDG0baBsyW4po2lSoOEObitS0sPeCYlX214eY7T4awLGx9wLY3CH80AmG8wajmkKlUN7OSF0lr7ubYnVDaO8XrpcfhCyyUmSrKjczzEgRzUBmmXhtg9L1FOX76E6XyvPQPXqUYKlE+ZnLKNvGmC8DkHnmHW/ZSDWxZwAGZpSRukbx+GjGYfj5szS+dYvSeouNj5WoLZ2l/vVX37PGAKC0fvfbmetWS3+s8oV3+zTui71/63FGNcXCb75M+PSZIujNbIPUlZslMxVGqjGHCdo2sPdCtGXILrHZviMIVfXaQcozT3+ysY0+uUL3dBW7nxFXDIwEan+9ibbMwuXSJ1dQV24CMHrqFO5rt8H30DttknMniFoumaVIPEXYNAqXy2tnVNcC7Ju76CAgOy5uE1DEEGNXCcDIdyqAxJOdIvGU/C2BzLrze/Ubr5KcO8H+o6WDavkhwTP936WT7KjX89zpDvFDoFpN4pJi4Y+3GH7iUawwJS7b4kpAYQxAsUsAaMvACGK54eP4oHLdrJPZZuH2ANDeJztzlP3HKridjNL1LknNk+PcdWMZ3SHasWGhhf3t19CWBbGsyNbLV7FyyodtG4wv76imGNUUUcvFDGqoK3mmiJzGYVkQJ5ihnM9oxiEzVfEe7X5C4plYoaRoM0u+i+iKuHeDTz9G5eUtwo+V2fzsEvNfPTwG8UYwNYhJ3OX7dj5/lrhsMP+tNsNHmkUq1AwzrDAl8cx8JTUwh0nxf2aYYLb7xe+62ZAdYBSjF5qoOJXfQYLsTpfMNsXXj1MGJ+sSZPcG6MU5aO9DswG2RerbDJ5ckDrG002arwyxXr6KajXRO21UrYrz3CWyM0cBD+9WD+KEeL56x1vNFpoMV49i9+W8rd4IY20d07ZxLItstkZScSS4tg2MVJNaCnuQFsYy3olGFYXTzxg8OsfKv9okma3Q/tnHmf3G2g/nbB0yTOnfcF+6dlQzmH2+w/BoDSPVRI2cVm2pfMVMUXGG1YslIE41Vn8kO0MQyleckMxW0EnC6KlTAGS+TXbmKPrkCtxYh9Ul7Ju7qCs3Ud0BpRt9VG8AviffRzGjZcliGUFM+caA0laCtmDUcO54H2mzAoB5a4fUNdC2uFv2XkBastCWXPJ4xstvaFMMuxsQP7ZKutyCJEFduYm91cNb28Nph5IwSCTblHqG1EzyLyvUjCoG2lJ0nmxh7fYZzhvsf/LYA7xoDwbTGOIeUK0mux9fZPYvN4iONUk8k9Qz7tgZxjUDqyupShVEQE6B6A3oPn2M8o0B209Vmf92h70najS/9oq8wOIcKkkJTrXw1vaK/yVJJB7IW0JVuUS2IKnPpCI3vtUfFTEEQHbmKEnVwd4L89c3DmKDMfJULyDGv9BiNF/GudVBJSnbn1rCHmQFNeT4P79OcHYR/8WbUkTMqRzK90kXGmS2yajhFHGFFco9FMyaVG7HZKai/NI60al5+YxeT1r2AWampjHEm8HEBemfm0elkNVKxBULNVE4u2Nn2O3LzWxbshsA2XILVXJJPIW5uU/nUzb2oEbzO9vyGs2GxAwrC0VKVptVrP4IQG52xy4C79S3sXb7ON0hWa0kMcTEaWe2Ke7OZruogI/p3TqOUbUq0XwZZ1N6srXvkvm2UDLyc3c7GVFdAnDn6Tb6f++Sukck3vFtjK4r7lunixEEmLUqUCfzTFRysFi4naxIMgRnF/G+e5W9z51mZnfuoA5zPxySzNTUIMYYt13Wa0R1g+bXXmH4iUcxo7wuMJCskr8+kBhgTMfIfWTVauaZo4yk4uDvJgRnF3n0l2+SLrcYLddxk5RouU7wZIvMUkVRzu4naMsgqTo4i3PokktmGaSehRkmZHkNQ5uK0WqF8p9KwDr49GOMKgYzz+UZqCCAIEAvtCSYL7lwcxPnOemPGDyxVGTHorpJNc+C1Z69he50CZ8+Q+f3ZlDlfZw9MVBjbR0WWpJmtlqYm/vonTZWtwcLLSzfRiUZw9UKZpihLUVUN3E7KXufO011LWD9cwss/foPMYhDgoc3hrhP3BCcXaT5vT30yRW0pWTFywNmd2soK3GOcUONqtfIarIqq2EkQfVQvvRgKDcVEC/USTwTfyemfrFPdS1EJZq4YpF6E+IBcUpmmwyX3OIxe20T5/JGYaAgGS6nn6GSVM5lgp06fERcLeX78tqPrRJX5HJ7t3qUb4aknkU0X6L9yRU6nz9L6hos/uE60WNH8pqKibLtIuNldAOiU/MS+4xi2Nxh1PRIKk5u1AozynA7qVBA+hn2Zofa9QQW597CxXrn8PDuEJOiX/nPYzqF1fOIWi52PyGzDbRt4LSlroDvoboDstkaKv9fPYpRQQDNBiqIMDa2MRbnGDw6izp3QlyrOCNquZRuSPYpqTiYYYLVH5FUHEYzDomncF+TYDpZlnqEeWsHHR/0VviX8nRpSyge1Qv735/z39yhFCewsU187gS2bTFccqld7BXM1fGFtwHjqVPFrhGcauF99yrxY6tsP1Vn/lupVNfzpiKnvS+u1+IcWc0XWoptMZov4+5ERC0x4tR1MKOM3Y8vMvNSl/ZH52i85svicEjco3vhh+4QSqlfUUptKaVemnisqZT6Q6XUxfz7TP64Ukr9b0qpS0qpF5RSH3qQJ/+WcVcgF8xaVNcCyddHWVF4U3FGZksmRnd7xCuzRbZGtZoStI5iSaXmzTlZzcfdiTCDnNRnGweuUW4MmW0WwfI4/QlITWCY4OyPDlb+4iTz4Nl38bYjaf65G6O4CNTtzQ6jIw2G86bEJ/dQ/3OvtXG3htQu9rB6cuP3jntYkZbj+LJDqHpNYqAkgfY+ZrvP3lNzkjWzDTLPxO5LNkpNEAq7p6vYA81gtSxs30OM1+My/Srwk3c9dr+hKP8mcDr/+hLwj96e03xAGFO5HRtWlyhvjLA3O5hRhjlMMOIMdycSbk83ZOvH5tn6whmsl69iXLhO+KETbH9qicHJOr0fP0v7Zx8nvXCZ5NwJAIw4lQKcbUlqMxRXyAwTUs9C5wU9bRtktnCb9GCIDgLsvUB2lnoN1WoeBMqDIawuES5XcS5vyHtYXWLri+ek9uDYsDgnwfOZoxCEOJc3qNxO5Vh5o9IkfX1cIEwqDvZmBxbnqF0OaH5HDHx0pEFyegVsC11yCd63As0GeqdN/WKf9hM5F+paW95nekBjL61HWKGm9q1rEmPE8cE5HEL8UIPQWn8TuLvseL+hKF8Afk0LvgU0xkrghxa53z08WsN58RrRsSZWLy4oDNpUeNuBBKkWzJzPu8lWlwhmJUNjRhnedsTMS12MUgmrG6KSjNSzivqBFabF8VRyUNFWOXEudQ2iuoEql1C1Kqo7ACCbrZE2Kww+sFoYmrZN4rKJbtZR9Rq9Mw2GS0qMbGWBrOaDbWF0A0njxjHufr5TjbvhABbnJMtVK2N0h4xmHNJmRZIFpiKZrRAuV9G2gRnE6J02xmYbpx2SzFZgdQljbZ3Z5zt0j1r0z80X79PqxRjpeJfIGD2ySOl6F72ycCdt/JDhzcYQ9xuKsgzcmHjezfyxde5CPmDlSwCeKr/J03gb4Nhkx5eIGibe8SXZ+sc3a07F2D9eIXGr0pjDQQU7M4W2kJmK4XGP6hrwoTOYYYKxto49imFxjuEjTeKKgb8DRpgSz3gYYYoRp3ROSyEtdZV0seU0Ct3pkqwIN8hINImraISyyo9mPMwwk+fVyrQfMzEjqZAPVysknqzM9gtXip4H99IWgyeWKD9/A2rVIglgBuJeZbWSFNuCGB3HsvsA1jhxUKvKsZDguvPUHNr0qa75OJc3OPL/Dtn9+CLlKwNUu5O7WXWilouzNyKcc7H3AvbP1pgZvo407LuEt5xl0lLZe8PVPa31V7TWH9Zaf9gxvLd6Gm8ayrYJ53ycfkY45xcZpfEu4dzqkLiKuec6gBTCxsaQeoq4bBA1TMnjlyy0LanM+LFVVL3G3lNzhLMmYdNg74wrN+AEcS51Jf2aulBdC9CdLjoIJP3bcslMCJsGwyWpKusgwOpJShTbQttCC09KEM75JJ6IEYRzrtQycp6T7nSFm2RZZLUSqW9jdIeoYSTkQXJ264wverH5/6lWExZaAMTHF9DNOrrkFn3dcdWWlOxOm+b39hicrKMHQ6JjzbxOoYvdNql5soDU/EM7q+LN7hCbSqklrfX6XUNRbgGrE89byR87lBgLAMQVg8Zz0lugcsYqSHoS22L+q7IzbH3xHKknTThmBI2LMb2jFnHZwB5o/Es7BKdaGN0hpmWQzdYob4wwwpSo5bL9pMXNzzWwhlC5La5FMKcwI0XjYoy9tgl5s9HgaI3OCdFdMiONShX9Ixbe8SUxuIpBuCz8pNTVjOZS2mflJittSaEt/vQKze/twY11VL1G5fnbxCuzWN0Qe7NdVMG1ZTBqehhxRn/Vo3k5RK8sMFitFOTF8kvr7L6/hNf2it3MCjXhrElcqVK/acONdXzfRp9cwRi7Tggd3h7IZ+DvxEI9X3sHL/QbwJvdIe43FOVrwN/Ks01PA50J1+pQQpVL2P0MbZkF5dnqjwpXQrVlZ1D1GqO6kt7nVPqmx3n9SRhxJjRqT4h4434If31I5aYmmtFEMxA0JWZISkKh9tcHB0LGccLuEzbBnC5EALQJSVmRVB2pU1iK4bxFXDYZLccoP6F+NaW0lRGX5TyjusFoviyG77tgW1i7fXpnGsTHF6TACCRVh9QVynrjVfHvg6VyUfMYs15BzkXJvxHMmgznDQZLJvFjq+DYGN0AFaeSnAhiEs8s2MCJpw52t0Oaen09adffBJ4BHlVK3cwHofwPwOeUUheBn8h/B/g94ApwCfinwH/6QM76bYIeDMkWmlJ9TtJiVUv9iV7oOCZ+/0lu/+xRnI4oW9gDTVxWDOfF1UhdsAcZBCHutTZWf4S91cOIU5zLG1j9EaknAfjc9zJmzqfYQyHGzX83YfGZAcZuF2yL+PgCnSdbBB/I+UMpeSupGFL3mEv7gzOkrmLmpa7cZNs2OrDIxvZUVvRXoH9Us/lhDywJ7nW3J+8z0fSO+4zmyyQVh6hh4+yN6J6uoi2D/oeP5u/LIDMVdj8hXpnFHhx4xqmrsAciWpBZsPeoT/ihE6gkJZ7xC/ECf12SA0acYSQcsIDfqy6T1voX7vOn7xuKkscTX36rJ/WOIO9PSHxJqWa1kmRScsrEePUc5+TlppeHMgALzPBAysXuZ8Il2mmjdtqwKq6Nrpalem0ZeNuSYlVxlvcsK5z9EUacytwH3yVY9Nh71CSNTCrbCq+dEZcUYQvikhDwZi7GUh+5cpO6dRR336d/xMLfichsg8GSQ+aAtjRhC+FakasG7rSx+03MyCBo2Vih7CTuvug+hXNS2R7TvceZInuzQ8Uz6R5zDyRr0ly2JoFRXREMLbw1s8icTUIWGzGCcaPRYWw1fXipG/mFiFouqjsgqTgFZcLekh4CvdOGxTmiukFpK8OMNGakScqiY6QtcWPMnKw6OtZi9NQpqRt0BwXNQyUpqWcVBD57L8DdGlI+v13UIgB0yWX/lMnRf+Ma/hUHp6vpHjfQFiw9k9J4RTFc1AUVW7WaDFbLpJ5BUlbsn3QJZi36jyRoS6MSRVoWt8e91hbjrNeweiO8tT1K61Fxc6o4k10OKRI67RB3R96Ye0lCxMGiU3TgZZZ05NlDjTXQlLYyoYEv1w/qK5ZB6tvYPfmsC6XB/kFS4bDh4aVuOLaQ7iqGkPJSjbZNWa1tSX0OP/EoccXA7cgFDJsiCyOGIW6D09U0zg/RpqJ33KNya3Tn62xsQ6vJaMYpWkvD5WquuFFDpZJdMpr1g10J8LdFiGzU0BiJYpCYktWaSemc8mn95RbBqRabHzFoviKG2jsOTtfAboufbw0VcWoIHeNbF2B1CY2kTVVvgL2xTeNyqeBk1bcaqN6AdLmF2e5j+JIVi1dm6R33qV/sc/tTtbxtVBefCcjCMJyH6g2oXh2QHZfykzZVXnPJRBCtWTmIvQ7Z7gAP2w4x4bcq2yapOpLjn62IEMA4dsiZrFHDxMgZFUmeHgUIm4rUlVVw3PjvXN6g+b09qWEEoaREY+lp0DttyfGHKdF8iWDWElJeCsGcQe+4uCmZbzNcFuNTiaRS7Z7sQGM1PW1J/KKCiM2nHLJjYWGwaUmTlKB6DZyu/F9pQxVZs6TmSUEN0NWyGEizXnweKohkF0kyCcJvrEs/uClBurm5j9OR2MeM5By1SZGCNSNpqkqqjrTJJpkIMISpqJKEGcFSqeifOIx4uAzirhUpaNnF9m2GCUacyuoZRNI5htyEYdMoZChBYgmVSnbIjLKiqjzmIOlmvWjyGa++3nZAsCj1lupaQOX528z861c48o1dZl7YYzRfpneijJqL6I9cZs4HeTZLdqTMhPrVmOoFi97JjNGxFtmHeqibHs7eCJVA4xWRrekdg8GxFK8t7sxwyQXHlp7r3T7h8RmhmPs2qt0pGpG07xLPVwt6O0jiwX7tBo3nNiFJikr92GU0I42TKwO6nYxRXUmbbc7hMvJdz2mHlC6LC1l59vqh3B3gYTOICeg4FnmX7UBWwCCW1k+E3jAOLsdN9fKzfB9nfswIWX3zQYgqiKTCe2O9oF0DMIox233cfekmCxa9ItAdI/Gkh4ANl0HkSD0kGhudFAFT12Dl67uwGLH9Iakazz+bsfNkiaSs8NsZ1kATtxKoxpiRJhrvZs1GIbvpre1JUS4RblG20MTYbJPVfJHDiRMh9Tm2GMvxpcJArP6oiJnGGLtPiStFwcRTqDgtVEe0qTDbYojlK51D3Wf9cMYQeXZDpdJ7bORuw7ipxujZhLMm9kBL51s0FigWQ3C6unClnMsbBWFNd7rE7z9JWrLwX904eJ16Db3TxtlpY59ckVTnsSb9jy+SuAp7qAnmDPztDHfHoNMqcWTtNksscOsz5WKHMKNMil/PP8H7f+Eltv6zoxgXXmXn750jcyCaMWlcyChdtYmrFv5uTH/Fybv//LyGkdF5siXSMX92SarSF9ZIHz9Z9G0wigvqgW5Ky6hpW9Ixt2vhdqpEdVlLszymEncur16XlBiQb6Mtg7hqw5EGUd3E+9b6wey7Q5hleigNQtk22DZOPxPOTZwUTE4ArHwyjydxw3gFNBJQ+eo4VvDGsmAwLPoVpJm/WnSnjavUleeFPmF0h9hxSlLzKG0lDOetovI7pnG4pfxYmx20WUabUN5Ki16I1X/yEhdvPs7M2kVA4gQj0cRlGCwZZA64e1K4G9WkopzZZiGSEDYN6lfzqUGWibIs1Nr6wdjfnAU8/MhJwlmT0laCtXsgYmaGGdTvdC4yK48zQi208SRn9gZxQfiD+wyCPER4KA1CD4Yk506IdKNlFvMarG5I5tvoWpm4pDBSWQFVIt+tvDCVeqJJVLsuJDx9ckWkImtVRjM+cdkk8RRD12JUk0xU9OkVzEiLsh1gnDlKd7WEFYki30Gzvsn2SZd0uYVx4TonfgMx2CS5YyRv43dfkJ1nFFO5nbJ/ysRta0Z1Repq5r+bsv2khTZll0uqIp+TemIMRpzJjZnPrgjOLsp7cw1GFSNX1KCQxB+7eDoIJI26YIkR1w4SDOPPJvVkhzCDGKM7hBkP59oOnVOrd+ymh213gIc1hnBkWInVlQs9me4EoVen3kR9wJIsj7Yogussb5fEsaXesNAiXhDXy0jEBQqbqog3eqsHH7VqNdl5ssr+4xp7oKk8e112n1zWRQ0PVmO90xajy/skxv0OamVJdrJWk9qzt5h9KcbtZpTXM+yeUEW0KVkqK9SkroGzP6J6YZ/+EZvOEUUBAAAgAElEQVRkQrZy99MrOf3cpHPCImwahE2jqFEES2WGR2vSkzGKsbd6xXyJ8WdxLyQVB+IEqzeS3THRxS50WPFQ7hCqViWqm/iXIqJjTZytgWRF4oSs5qE9UeUeM1oP5ORFBS91wRrv+qMYfJ9rPzsrK+pNqSxnVh5vdDTlrZTKbRhVDM7/94+jLY0RaYxIUf3GK2jg1o+D1bVovqJxt6U7r1DVy+VpxqobaS46YMS+UCGShNJfnC+EDprfjqR34XNP4G9JmjZsmjQSjbXbJy4rtp6yWUxFvLn7VIi54VK7kme08hs8dRVxxWLvtEVSgnlWKf3VFdGWNeck/ZvkCYZQYw81YTP/vBKR1ScR0Ta9ukTtsvRku6/dfncu/OvAQ2kQWa0k23ycSHuob5N6Fk53iBGnjKrfT0fPTLAmCnKj2oH+aXRqHifveQnmRM4lsyQ9O/dch9S3ufWZMpkD5lCYqzL8RDF66hSDRQddSohLKd2hBMEqiMSlWZxDBRStqQQhKimBbRa/43soDmQvxwLKtTURIWg/ZpG6MFywMNIZvHbGcFHRXbXx2hlRKSY9lmC+WiYzQbtAIsZvJEZOTxcyo6pV0Tttqdi7MhUpsxTuICvqC4ULlct4Kssia1awNzv0z83jxIfPVRrj4TGIccanXGK4VCZxFelCQxT38gJScdPl0HlFVuU7fFzOaQ4phMsZccXCPrnC/kn5PyPReFsZ/k4sVAnf5ebnZwkWNM6+TOAJcvGJ5isSBF/592zMgRD0rKEiamWYQ0W8Mou528YIInStDJs7GLVqEUeMNaHGN9yB8UTiYq0ssP1hcHcs4qqkYp2uzeaSg7+lqa5BMK+wBwr3z6qoFPorUvdwurLSOx2pwThdTeNSRueESWm9gb3TLrJsYySuuIdGoonHBpEkIkgQBKikBnHCqGJQyY3qjizTIck4PTwGMfFhRw0TK9K52yHxgxGnIvsIZKbKC2+y/Y+Da2F2KuIymEOFszci9W20RcEEbT9uYvdMZirz9I/IXDhvR2ENYVQDM5LdIWyKW+Vum1hDqUq7e6BSg2AloXfcp/HXSNbHNlGjXB7TslDDqBiWeAfGerGIVOXq+9e5dn4Re+8gfhnXNOzBeLc7eNwairGPauOej3wBSGQxSF0RQrYX54o0Kxywf8fPNRIKRfI7WK127orWSqi8cHmv6/Nu4uEIqscXJf+uTaiuhSRVEdmS7rGgCK6tMC1SiCqRCqzbzWRXceWCz76osV+7IdmbPBWbuhRz3rY+ZDFcVMVNNx6uCPKcaAaCBV3EIu4e1K8mmBHMre4V7oceDO+QrtSdrvCjghDd6UrqNMjjjVwwQdVr7J1x2fmDZeqvmpiRwtqzcoOUc+mviGFaw4N4KHXlvOLyOF4S169xJcLbTWUYy6xk5caqGlKT0TIFaSsl9cTQ9U77jgHxahgVO3CwNKG+ccho4A+HQdxj9RGqRq7KF6dSg4gTjG6QT/8Rlyn1FGYoXP7JzJMVahEnmLfYPyOr6riRJ3XzaaDDg16GpHTA+QH5buQ8wCynQACELc32Zp3K119EWdYdAl+T+fuiNTQf5HivYezjzjx/W2OMZE7duNvP6VIE/uMveyB/M/JppuV1Oafdxz20pSivH7BUrVAMxAp1nnGTQY5jntPk+SrbRiVSe7EHupjMer9r827i4TCIHMWNA5ib+3LjDyOMIBa5GKSia+32saI7CWjZhHNpDbRoIjkyJdQ83S+628zozhtfCnviMsnqrElKcmx/O6eR5+5Y96hF5krade3vfYCL/805Xv3lJte+/IQcLKdSAHdMQy20m/LJpLpWxh5oyj+zwcbTQl23htKqOu72q95IGTU0w+Xc2F0xyrHbNHbr7IEuzm1UUzTODzG6Q8nMReIqZaYE0uNUrtfO5DzHelUAQYgRp5RvCO+rqFQfMjxUBjGGPdDoTndCRCxfscaNNEl6R549aphENckexWWhWthb0hHWO5PwvqXbGIm6Y8U1owOjSF3pKlOpzJlOS7pgzo4Rl6UJyIgU5sAgPDYiqafYtYjhsUSa/cc3/xh5kkCVSyTnTjD8yEk6J2zaH5whsxS3NxvFsWXaj7zuqKZE8iaFtJwVO9o4ZoID9mpcVsRlaVRKXSXy+4EIJUt1XBUxlLYkDevvSsRdkB4tqxA7G/PF7jCGQ2QYD5dBWBaqVsXdj6WJJ05RSSrfg0iaeroBeqdN+aYo5JW2UqFUWFJTAGh+ewM2tlG2jd02+e61o5Q2xj619DIA+cp7cPNHMxq9EpK5skv0TmZYQ4kfuiflJnT2Ff6m4pFfzyhds8hSE7Ma0/4bUkm+Y5dAVtrtz5/g5o+Xuf1jYtDjQexHf8ukfEvRecTAbct5BItCOw+biqSWYYQGo5omcyBs3bkrwEHMIVOIIJw1hToeJ5TWD1h+mQWDeRO/neF996rIb3a6skvYVtFSqm2zMLoCh8htergMIm/TzOy8KSiYGGuVJBKc9gbSVdYNGdWU6Kvmxao0J/qNsyd6MKS0oWDDLbIsmTW5IlO4KV47z9FHJubAIHM17o6B1/7+3cIeSA9B5kA6sMj2HII5Q3YJJmKJfGXtryhGMzJsUYiIeUCeG0bqalLvQBzADLX0NURKvhKhe4yR5Ss9HGSh4rK4fZmlyGp5KrWYTprPw07B3wjlBm82RDkwToQv5fuo5M5OucMoa/nwpF1zZL4twXSckDYrkl1qd4o8frRcx3nxGnS6zL4kk4OMRDOqwaihqV/IhyYGAdmZowyWNZVrRpFJGscKIDd2NCM/q0RcpdJFmWSaugbVGymbHzHI3IysNcI7EzJ6qU6/BN2TJdJyirVnkZYzOh8YUb2xQPUbEyKK+coarCTYjZA0KrN3FirXpZgWzIqAmexICqerUHsKbcmNXL+gimmn1lDd0TeeegcNUeOYwowk/QxS7TfitKjet14McW51CgGyrR+bx4o0s9/YQVfLYkCxCNIVGbRDWKB7qHYIHcfFgBFs62DFsixUvcbg0Vm6x9xi5SpdbuO/eBMrFKKbv6kob6VFutMI4iKFakaSNRrrKI2D8NFcStwSGUx3x6D1UsLccz0W/7KLtx1JVqqc4ZZiksQkLWnimYy0nKGdgxW1MjNk95wp4gV53KDKJVS9hjcb0KgGRd1gsKwJ5jSlzQSvnZG5uljp4aDjb9xvYQ90kX41I10wfMe9GGOkrhTzUk9cIHNzH8gzZmF6MAlpdYnUU9LJZ9215o535EPkJk3i4dohRjFJ1cZ/dZd0oSEcG0vU8JRtY/cTzEiaZlhdKloqtz5k0XwlpfHn1yQ4rNdElmVtk+U/q9I5YRdu0jhoVal0rqlE4d+yqNxOmLmQyBir3oDNnzpB58xYuUIR7nmokYEyJbBOyxlqZBRiAf29Epwc8ep/UcMYzpDVEiozQ+p+yGl/m6vtJnEtQyVKDGAm4eZPWNhdA3tPM5rJmHsWZl7Yo3emUWi9gkvj/JCkatNdte8gLxbts/nOJxX3PPW80IIgovWXW2S13B1KElS9Rv9knSP/9xXZdcslVC/JRwaIwahEH6pAehIPl0Hk0EFAZs9i5BKO4xkPznOXCq3XUdPDW8sbhkYwnDdpQDFX2gxi8D3crSEVt0LnhIXTlkaeYF4RPBFiuQmV71Rovhpj92KGSy7OLUQnqa7QVkZa1mgnw65FJJEFew5pNYUsd21mRijABLJEYZUSEteC1MB35KZ+ae0IOjWgnGF1TOyuQf2CzXBRkZTEzUvKhtBG3j9D80/WAIgeO4K/m7L+SXFlUhfiqqZyXYqRUpVXRZIgGsHx374t7uZCA7PdQfkyCDLzbZHh6XQp/2n3oMEop5cDBdV+/JkfRjxULhMILWPyYhQXKMdkoBcen0FbBv6WxBAglWLVG8jgEcDY7VI+v0v1Rk4ByQNXtxQTDx0Zmr4dYL9wBX8nFspFklBez6hcM9BOhlnO+5fT/HJYGgwNucuUJYq0Zx/8PUcwshlEDjo1hDJuaJKZBHcPZl8Y4u7lh4s0jYsx/WMZ4c/vky630IMh7rU25fO7RDOawbGUqJWRLkb0j2qG80aRKEhdcbGqa/ln4LuSjRsMi0mrwVKJbDb/kMaS/CdXJPkwVvtu7xPNl0i9w3vb/dAdQin1K8BPA1ta6yfyx/474D8CxhLO/7XW+vfyv/1XwN8BUuA/11p//QGc95uDY8vAxFZTpCp7A3GL8j+HT5+RmQbXu1i9XJXPs6Rbra1EnmVzv7jAeixIFkTsvN9k8ZO3WLs6jzE0KX2nyrGXYuJKyu1P1ZivnsK9tIUOApLTK3SPG5TXNWpkYM8kREMbZWZktQTTzWdBBxbuxXygykD8++GiA2f7JJFFf7MChsbesbB7CiMxhdW6qLnxN8uEyzFkCpCRuY1XFINuE5WI768tk6zms/InUnHf+twIw9I88pHrzPs9Xmsv0N6vkPZsVKI4/rU0N4C8Oo7EZclsBXcnEo5VPixytCzjw1g6KeICbXlNI85w99/buky/CvxD4Nfuevx/1Vr/T5MPKKUeB34eOAccAf5IKXVGa30PJtq7gJEob2vLlGmeOVN0jNQ1CGZNrLAssvimKNdlliJoGtgDD6/ropLSHVQJ7buUNjRb/98yi2tCg/a2h9h7Qa547eE8dwmNqIdb3ZC55x0hGXYNQstH+Umx0qeAuZf7/4ODHgUzgsaFjLZVxotEYWMcLI8JdhIYS8bI7JmoRMiImSWExtYLmXSx1WvEuSSN/+JNeN8KOjKxr9hcvnmU83Mxjdk+zUafnaSKjmSBGKd8x4uI8n1RK8lHZWnHRiUJKq5i5BOYsK3iszLClMy7K898iPB6pCy/qZQ6/jqP9wXgt7TWEXBVKXUJ+CiiDfuuQ9VrONd2ijkJBTGu1URbJuVnLqM+crKQp0k9A8KM259WOMt9Rs9UKc/OAXOUN0aFrP1wycXpahb+eKtwwYzNNvgedhBh7fZhdUkGp3Slyrt/2s7dMI0RGjjreSV3BGZkFmlO6bhThdBAaT+lumYBmtoNWdmjulHUHzLzoKuvtK5IyoruSeEyZY7CGhpUrpYwNtsyO65ZJz6+gLe2x+n/s4I2Y+zXZMTH6H3H6B5z4bMRZs/E3cpdnwkqfXRqnrhiMTp9GiPR+DsxcUVOwIxkApPqDgoDsrohOjAPDd37bryVoPrvKqX+FvAs8F9qrfeQ4SjfmnjOeGDK9+FdGZiSSMNKXDFk+k4QoUA65ZoVjI1tyue36T65wHDBIjOhvCUFtLRXISlB5xEjp0i7ortaNjAjTXUtkIqsZUiQmUvNG5ttcTFqVfmw44TRkQbBnFSH08UIy01QO5XCAIxE9GPHTNKxOp7bzTDSXN0iEQkclVq5YUma00ggtoRoiCXM1cyV/0lnElIzI1gqUxpGUjMYDLHyQfKTA9ZVuYR7aQu3sYxODapXDJGVWV1CtTtkKwskvk33mFv0TliRyF2O+9FLm/pACTGHtk05zjtzxd8w3qxB/CPgHyA75z8A/mfgP3wjB9BafwX4CkDdar0jUm56MJQL3UnZerrJwh/cKFo0zc199vPJQKkrN5zbzUg8xfxzMalnsH9Kehf0WHjAUgyWFF4b2o+X0FaJ+tUYd0vcEm2Z4pb5ft7Z5nLjCwv425qZ89Jx1i7buLWQsKpziRuFiiTbkbrg74rCtrctmk/ZQpO59kFQ2vz2Bv5ui7hsEjQN3G5G7XJA9xFftFcHMCylYGnsDRszUrTPQlxpUW/vHwyLBEZPnWL/pCu9IpaicltGca38PzZmGHP1C1VaL2T4O2Wuf84lqWXULoyNQd5Pkgfi1RspccWgdF36OLIzRzG6AfGMJ6IFhxRvKtzXWm9qrVOtdYbI3n80/9PhHZgy7oUYDPEv7WAPtUwTDQJ0tczoWKtofRxLRw7nhdRnhSnedkR5PROZlYE0DWlTKNJmJNqmTldjxBnxjDTHqN5ABMKAdLlF+4Mz9B9J6K9InaJxJWLpTyH7TiMPinOR4FzrSCUUChjO5Q2wrDxLM7HiWibed69SvjEgaip6qyajhlP0bhQFuZGRz5qQImNv1Sz0V8f8qKhhF2p8ZqTpnLDZO+Pmr6Oo3JRFoL/sYA0V/q2DWGBsDDLcRSR87ic+oIbRAVv3kOFN7RDj6UH5r/8OMB7Z+zXgN5RS/wsSVJ8GvvOWz/LtwGSqdafNzL9u0/7Zx7EXTxHVDforiuDkCLs0wnqpQv1yRu2ayMt3j7kH6nRlmfaTegbDeaPw7xsX5fhWb4TRDRjls5/drSHxfJXhkstgyeAjT1wkPGtz3j1BMOcdKABGkvv3dlO0Jd14Y7Xw4WqF+PgCZhCLNpNlFuO0wuMzODWfwWpZNJiGiv3T9h0Sk6WrNlFLKtbW0CCY06QnQy4vVJl59Rxz31xHd3tUrvaoXpD5DnHVxt/VBLMWSa4aqJJchAyYOZ8WKn2jmjxWXpdBLu3HYf99GXbbJHWbuJ0G1Zd3SGYrEnflGaf3ZAyRD0z5DNBSSt0E/lvgM0qpDyAu0xrwiwBa65eVUv8SeAVIgC8fmgwTfF8gV10Lias2pqcorUNp3caKLFQqzfnOlhB7UrfOqGLg9OWGjSsyS0ElQL4C++sy9CRemSWdr5J4Jt62dOGFcy52P8PfNnh1e4EoskhmMuIZaH5PJOX7KwalLY2dz7azt3qSEg4CKt1hwRaN3neMxDNJPQN/I8TqxSRVp6gZjEmF1kB2OVHBALsrzoDdE1arZI8U6RVXJo/WSpI2DSLszR0c3yddaBCXy0XPw1hwORvHKBwwYkubMle7/XgJf1tRv2wWNJC4rBgt11FxJkZ+CA1hDCUzTt5d1K2W/ljlC+/46xbs0cn+XscWN8e22PlIk9JmQvmldRmP69tknlk0wgwXZCrQWL+ouhZgxAezIFLfLuTgtz7ooU0JlHvH4AOfuoBnxry4dYTByzMs/FXG1ocMRssxjeccFv9iv3g9I0yL44zTlmM/PPVtyRYNhgw/8SjtszaxjJ6jtHFA4x6fZ/e4WbSz2j2YuSh0lbhsUn15pzDCcRYpW2iyf7ZWjPYaH8dINHZfZt1Zoaby/O3iM7LXNu9IS6t6jWy2Jq7SOG55B/FM/3fpJDuvK44/vCXDdwJjolkOVa9JpXpjG26ss/10ytZTtlzMfG6aEYpLM55xIE1BirgkIsapZ2GGctxRw5EpnbbB4GhG/3RMMKdIliPOVmXs7U+snqfx5A7rn1TMfWQTc89i9pUQFYvM/nhGndWX4Y1WNxQi3aS4Wt58U37+Bke+2aW0Idyl4U/0aT+uqNwaUT6/i78TF/3TpQ0ZctI/YhLVTcwwI5mtSLV5oSWtq76HilPc/VSoHKa8X6ef4XZS7F6MFWpRQKyV6Z6uMljxZLD7RIwwlvBUQXSodwd4SLlMY3zfAPFcxXsMq2OSlHQxV9pud7A3wQxkrG2w6NE/YlK7nlB5WabsaMsUOf2FBlaYEjVsNt9vcvr91wCoPR4Spja//mefxN4zOPGJ6zy9sIa7dInT/iZf+eoXcG51DgSJX94BIJ6XZX9wsi7Eu5Y0+hupZtSYw1moYwaiMr7wxwGLXxsQH1/g2k/B9V9MMF9dkM69YwH2BZ/OGc3iuS3m/SGvrc9T/eMyVYCGI5Vl2yKtiRCaty1q6OWtlMG8SVyG2rUEM0woXxG18L2n5uivGPjb+mBC0F1x23sBD7VB3I1Jfr4ql7CGkg0aLDq4+ynmQlPkGZFZcUHToHI7pXx+t3C7VLlUDB0xwpS47BDXMmqOGIJn5tXtUoruGvRHLsvuPjtxBU+NirRlZilK6+IWDR6dZVQxcPdTmQWR6sI1G8+AHjUcdMul8vJQ5kDXpIKcOfDBlVs8Gx0D4Nh8m9tXjgBwpNKhbof0Zl12apVClFj4VinpjI+qlTBv7eDRIqk62GPd1zAt6PNZzT+gkx/eIvTrwsPtMt0D4/ZMPRgSLiVF3SFqmOyfrdE77mGGCe6lLeb/bIvas7cO+gCA0SOLDB9pEs94JFWb5ne2WfmjlO2gwoLXwzVSFr2cC2XCv7/6XX6p+Qolc8TlaIGZn7nF1o/N0/z2BnHV5tJ/MM/2kxbNP1mj/NI62jYK6oO9F2D1YkqX2xLnWIrNzy6JcsiF61z/yRoLT27y/DfP4F7x+OlzL7Ja2RNRg67B7b5o0d7+1hHm/nokGbIwJW1WyGoltG0wXK2gB0PMWzv0lx383YTyzTAfQC8ZqXDOxx5keG2R6/HXBweyOO8xTHeIHwQnKxQxQFKM9kBj3tqRIl9SOhhJlSToZoNw7iBFm5kKXXLxtgPOX15g7ok+x0ptosyiMjMk3K7zD3//Jyn91Ihh6vD7186yXO+wV1YQhPSOWjQuQP3SEF0tk9V8bn/CY/blFOdW52A8VklmUFeu9ki8WkFYDE6OaPpDbrUS3LkBF7rzXHhlhdYFqWDf3mzQCTwWv5Pire3RO9fC3Y/vGAQ5qhhUWk30TpvqWshoxiEzHWxT5XP5jLyrEECk98c8MfkMDydF436YGsQY+ZjeyQ4vrxoxqtn0Vk1UCnPfHcjMhglNJG7IAJB0uUU458uI204ms+YQUS4j1Tz2j/vcOHsavnyR7aDCBxdvEs5tMviizb/4k58m/fIOvhNz+18do3lRqB/Nl6VvedRwsLeg/USVL37xT/n2738QXXKxNzsMHp3j+n9sMvOXLotfu0rdMshmayTHWji3bF5khcrcgPBCHeP/iHisfUkapc6dYFQr47RdKs9eRVfL2IO0GKw+Lv45fZk3p+o1nMsbOIBu1hkerRUD3c0ow92P6S87uJ20SBEDd8jlvBcwdZngvlt72DvolTBDLXOs75ZgZKI1NZRsjLcdYfWkKah0vYu7NUTd3KT55zdZ6zSZ8/ssuD08MxZKeZTR/vNFRl+fY/Wr1ym/tE48I5kjbSqhrCdy7H/xRz+GubkvWaYgFG5TmtdELAsjiEl9GzNMOPG7PWb/wia4UmP+WSmI6ZUFQMTZopZIy4yzVDJqK8AIYsxQZOzNSOIE3ekKPytfMMrP36B8pZM3EUkq2ox0MeDxMMpUvh5Mdwg4uGC+f5B5Wpyj8qqDNYTa9QS7n0hT0OSKN/6/UYx9c1dYtDcGGBeu33F4lR8vK7k4ZsjZ6gbD1GErqBaB6fHf2YXNHbBt8L1ipQYwtgK071J9eQcjmS2mE2XLVYw44/Q/TTGDoYgik08e8kWJcP6r15nPmbZjGokql7j12Rr/48/8c375z3+OI786ITzs2CIggBDxnHbOO3Js1DAiOjVP4pnok3VKN/p42xFmmJB6FkZqyQjehRbcWH9PGcIYU4OYgA6C4ud4vooZiRRkwcm5e/uf+HmsW2p0g+JvyrYZfGCV/hGLvfdp9MyIT9ZvcnU4y0/MvMJmVGV3M8XLp34q32d0rIXVH90h2aJLLknFIS1ZOYtVFe5K6hpQsVCJQ+l69+Bc4oTRch07n46kTZGPAYqRYS8Eq5Aoob+P3ZxCVNlE+6J9Oz43fdegyHhGDDezTRnGGCYkVUdo7m/bVXln8V497zeHu33ZiVURcqnL3L/ur3qizr0fk+UVYuD7XIFxh9jg0VkyS7H+uQUGy/OcfPo6f2N2jY+V/xiAQeaym1Z4abBMkDoctds07ICb7zuD0w5lUIsptYZieqdlkNkmSdUmqpsHtIyJOc8q0dK3YSmGR2s4+yOMOEXl6iLjUWFjFb2x4Y5F1+aW9zn/5UUyd4GT/5fI+Ge1EipOpTswf772XWl2ClMsKGgY6spNOHNUaO6WReq15PXHRvYeiyEeLoO4+6KMqQW+j/Zd9MY2g08/Rvsxi2Axo/miFjKabYgbco9D3vjiUXpnEsyqHKtaCThZ7fFLR/+I0/YuF+NZ/jo4yq1I3JUglTrGl377F5n7XoZtZnROV2QAJOMxwC7VqwOpZSDS+0bZJLMoCHXFfIYJRqmRHpxhPOOReBLXxKZPulyVrJd1wEL9tWc+gfITrOUhBrD7SyMWqjHtIGZnp4qxM4PdNVh6ZoR3q4d18SaqViVtVkSKxjIwyiXMTenTzmyTcM7F24bkWBPnxd57yhjgYTOIe8GxiVdmyTyT4MkW2x800KYmczWV21KNjasyrfNuJOdOEH60T8VNSBKTaikkGNnc6tT5lY1P8lT9OsPMYS8usR/7XOm02PruAtVrsHJVbpKoLscdVQ7yG0aiGTW9wn8XV+lAaXu8Q6hE9FTHXCojzjCDmGi+RFwWychx99q4qm2EKYln4rfzSryhiSMT5abY1YD+yKXpD4kbJh0gXtTcKHnMvNpk7usdWfWbFaGSdP//9s41Rq7zvO+/91zmvjPLvXC5EimKlGjKkl3ZsuIqleGmdp3E/lAlQAPYHxqjCJoAddAERT84yRcX6IemaBI0QGHAQQ3YQVA3aBxYyKWqohpp3fhSydaNokRRJCWS2vtwZ3fnei5vPzzve+bMiCuupCV3V3z/wGJmzpzZc3b2POd9rv9/J1NxtVob0mRYlPO9e/4t8dR+x+1hENvdpcz2hU9U6c1o1PE2XKhSXpKB/UKzzeqDE9QvR9BcFzoVw1Oqj85x+V+nkAhn0uT0FlHsUy5EbHZKvPDkac52TlNsivZaYSvFB+aRmKTf8LMLHIbSv2kuNrDi8ToYCqILzGfM/vb3xCUfrxxKXAGZhgPI6pH6iqQYZMc48oMUvyesIGno0z0yRb/hceEDEE0l+BMReqWId7xN4cEtrtZPcuefvyEX+ZFZ0agwLN7aV3gbEcVWSndajHzp79eZ465s3vog4PYwiPF/hp0JLpehXKZ9PEFXEvyrFabOQW9KulLjiQKdecXsM0I3H506it+NiO+Y5OrPVJiorLBydZKw3icMEqLYZ+3VaapveEydjfASSUPa9oqoOrrK5AdoxuMD226uTLu1GIwwjFvXaZE0s+8AAB4sSURBVPTzslrYKrbfM+lSo5aa+lbhR2eGZGFrDuXFHuVFqL8umtbLD5WIJzRRp8CaXyWd1UOG9G7/uqx85YUOccnyPHm0TtVocHBWitvDIMZhAj3d7RLdJwN+4WLI7E9SQNOe95l8pUPz/gpxRQs7eLWC343YODXB8sMewclNuoOQ2qwEq+vPzTB5Du55pSNdrjVP5puN6xLnxFbybs9wZSCLC2wH7QDP3P3BGkPQ0/j9FC9K6U+GI0zaaaBGCBLse/YcrIsFQ4MBiCZCwk1hNbTwYs2d/0f0rK9+skT/ZEoIWYew7nblhlIITQbKY2B4cSulY0QTIRMXZYVdv69G+qEHKLZSJp46u1v/xZuC27cwZ9OloSeaDH1h+u5NCV9SeGmJtpGd0qFQwMe1AtdOG76mV2v0zjXYulZha6nG9Auaxvku3SOlbEYgDYYDNRZezIgxJEWV0UZaPlgvhjCn6unFQ8Px+ynFZREssXSUwtZt5XfNIFA7QRkj8HupUHQGw8ZBnfsBE6eYVcTvSN3Ful4zzyf4i0XSgvkjTK0i05sOg5EsXLi8Sc+4TdVlcREHdaHy2e+4PVcIAxWG9CdDkmpKedEj3IyAgNknpJWhP5tQWvSJDpUomPmD7skBpdcLHH2qQ/jyZVr/6F7SQFFei2Uyrp2QFEX0fHQVyK8Q2RkYIUe7XabQrNFIxmnoHgU9ccF0IBdWYbmN1yvRn5HUaLGVUmzJ75KRz+GKYNcDFWt8k6oN2/I3pb7KjAHEOJKiR7gVE9UCiusRh58O6deFY0lRlpXCyAFHpvU8vLQE1Qp0+4RtzeaJKpWFPoNaicbFhMrlrV38790c7H+T3W3kBRiND1xY8SlsaKKJMGuBUF0hADjyo4FUZkNfVIMGHqmhk1dhSHk1Mko6Ji1qdevGZWtLQ/8/TyRs97Wryfj+FvZzkRGKVJFotg0mC9kdX8V6ZCWwj/ng2m7PNyBeD/Yz9rHYSig30yzbplsbMuNQLqF9NRxYCgJ0uSiSY4hxBT2jP7fReeuB9hluP4PItVvobpeJc+vc9USXqTNd1k+FGTerLheZ/N7rhg4/YevEBCyucPw7Gu++LVYekoa+/mRo6PKl07M/GWZ3dss8kc8EWfdnuCoM6wr5QNkajHW9UpNe7U8Kr1FaDmkfLY3wpGrTV5Q3gHFjSEpeFqhbl2jEdSp6eFEqrSGmQTENZZsXaxFLMe0tqlGnf3yKpBIM5bPCALXZJrzWZeJim87hIDO+cR3w/YjbzyDGoJotwuVNdCgEZOW1REZG40SEPiaqeEamlyOzlBfa9DaLtO/U2XC/vejzGm3j8GI9Zggqt1psL/A4nkmyNYrBVGlk/5H9kmG7ug5GVwAv50bZ2sT16GKsMYCseipKRS6gKW6PqlaIjk5LU18nluxTEJDWK7JKhD7+0jphWxIK4bVhtXw/4/Y0COs2GRFDXSnSnwyZf3KJ2rNvEtcKUmuoFFGbbVHPvNBi4TNzLD46yb1fj4kbCW/8WkztqjTh2YvdXuhWZMViPLC2Q/vjxmA/l45Fd2IMVrfOy35PGkC4lQ6D7l5KUvSyVcnGEdalsitGPgOVD7qVKealvpJVIdGkoSerQJRmo6Dtjxxj8+4yhfWBuJJRLCO4gSfulHmceOosk997HXXhyltHdvchbk+DGKtLqCtL1C5uCoNdt0s0YeRuAy9r7U7LIXEFNk+m+L2Y8pWAk4fXiGoBUVWNFsHi0Yt9+Dh0hdQYpUs+/WoDaete2SDbpm/TYBgEezEj7RjDc9ieTSVzmUxq1hbt7IphEZf8LCZKfZXVUyiE9KZ9kqISqkokDaujSCSOG3VpCsyRwx0U3J4GMY5BhLpwRSSqwpCo5tF59DReN0IfnSNY2yINfeqX5J//5ifrqAT6SSDaEJd6hJsRxZa4VvkcP4wG1HFJZTQu+XpEv+GNZZtk/0HNG/mcNQxxdYZGZQ3AxhQ25khKXo5HaRho588zW3ESYR5Usc7mq0GMIap5lK5uysz40TmRJ26nJKVAFITKZWkvX1plcHwGb23jwFSn87ihQSiljimlvquUekkpdUYp9Rtm+5RS6kml1Kvm8ZDZrpRSf6iUOq+Uel4p9dDN/iPeNcYGg3RbRh/DrZStOyRQVFECzXX8boQXS6NdXBGXZ3WrmlVue7PFt2RsruebeyMrSS74TYarh3W/Rl2roYukYkm/5l2y61FHDlcYPXKs8bhC5VaJ1IyE5h/B1E6iGD3VYOvEhGEaTITwoBuJumtdjGJwqCCt9AdwpnonK0SMsHvfDzwCfMnoQHwZeEprfQp4yrwG+CxCYXkKYff+6q6f9W7hevyig4jqiwsEfS2jk82WSMpGCcX1iMZrQyHC6a9V6dxVH5mjhuFdOn9h590lGyeMpl7HA25ZVUprCYWtdOS9wvrAzB+k2WfD3D52m4V152yMkPVLlYa1ikwLI2fUXpRmGadwK0bFCUufmGLxEbMK+YpgowdLq6T1Ml43ytrgRwaoDhBuaBBa6wWt9Y/N803gLEJx/xjwDbPbN4BfMM8fA76pBT8AJpVS87t+5ruF6/zTdGuD2tUB7dPTsmp0Rbo3vNajvCZStNGEzqqxcUmN5P/thZqvN+TrDOM1htFVYxgvDF0nlRExBz2hoNGBZ0ZLhxe7F8ux8w2D+VXDulDjx806YU0QbZGGHipKs0eimMKGCC9mn222UKGpjTRbhi7n4BmCxTuKIYxwykeBHwJzOcLjRWDOPL8TuJz72HU1IpRSv6qUelop9fQg3X/06IVnzrN1h8/SFx6QADuSWeW4pCg1Uw6dFa2IymtNymtxlv+3F10+SLaw9QY7+2C35TEaVJu7t/kdxfWI0kpfLr44JbzWo7A+nHu2sH1LNrYYrlhDF+p6nbC23gDD1cE+93uSRSquJ0yeT6gsx0JoBjLLvSYz18X1RMQrDyh2bBBKqRrwZ8Bvaq1H8mdaCGLfEUms1vprWuuHtdYPF7zSjT9wM5GvXudQaqYisVutwCAiWNuivCp3P7+vCTel67O43BnpQxoPdG0a1hbZ3trWMcxMjadnrcFUlmO8XoLfG7Zu6MDDi5JsbiIN3hof5FeZ/IpgM1NZkJ3VLiSzZGMHbR69jW5W2U8DScnSXJdaTbmIbm3QP1yhtNLlIGNHBqGUChFj+BOt9bfN5iXrCpnHZbN9/2pEbIdc9TqPxhNnmXu6x9qn70bNTAnzxfnl7H0vhujoNOqCEXdPdO4CF6OQGsEw6LWxQz5rBEOjsWnW8Xgi2IzEX4ds3tquFLZIZykkR1PAo4ZnoWKdNQDauMHGEXHJz7ZFtYDi601Ut0/zE0fpzAXC7Xp+WRr8gHi6Rvsf3idV6QPS5r0ddpJlUsB/Ac5qrX8/99bjwBfN8y8C38lt/2WTbXoEaOVcqwOHwtUW/YYnY5NTQgxWbAl9i0qgfVQuRr+fZg11+bv8+B3bwqZcs2m3ESPIHX8rzVwsHUrMYvuGdOCRlEPTRyUXcz6m8HuSQr1eTSJ/XjZ+yPdAeYkp0AUKvdpkcHwGbcY5VKwli9TtkdbLBGtbJo7aeyb594qdrBCPAv8M+JRS6lnz8zng3wOfUUq9Cvxj8xrgr4ALwHlEXehf7v5p3ySMu04FYQKPK9A6VRO3IQyoPfsm5bWEsK1Z+ajULMrnV7OLMp/9scYxDJQZeT0adA8D6KRoepcaXmY0KkoykXQdeMQTBfoz0mFbXI+Iqv5IX5J9blent2SbchmlNPQoXBtIvNBPCTZltaxd3KTz6Gmu/kwlYzAMN4crqdeNMirPxnOru/nf2BPsRIX0e7CtRt6nr7O/Br70Hs9rbzDuOhlWjdqVlPa8x6HFFfSRWdjYpHqhRb9xCO0rlj4ecuL/Nqn/oMfWw3fJapGrQKtcYBtupbk56GGbRz4z5PVGB4YAow8ht2ivG6FD0Y0oRKlJ+3ojwbLOGUC4pbO7Psmwy3U8zWpnIuywUPWVNVhcofmpD4nMWKyZ+btlWFwRtpF6FS4v0H70NNUrPZEROOBwleobQHe71C4b393EEfroHFxeIGxrwk1FGmihXTEtCtZ18sbcF5vxyXe9wmhlOj8UJI/yeutYif7hysi5eTmNiHzcYI3BS0ZbMeQzZvXKGUO+PQMkkE59JRp5hVBEJhMIt2IxhpkpKcSVQ/TJo/QnfcKl1rv+jvcTnEHcCAPRbZ64nLDx4JyIKUYJHJunvNij8VpK8Zqwbg8+di+1p9+guNofyfdbqHgYQOfnIvIZqrxx5GOJ4npCcblDXCuIeOOJCZJSQDQRjmSP8o9R1ScpeiOrhVU/sitEPogWARQxssL6AB1FdH7qJCqB6oIJ2GemSOsV0noZ/+oqax9pSHr4gOg/3AjOIHaCQcTExTbr9/rED5xAm2a/4MxFM+MMnXnFtQ8U0e0O4aWl4TSauRiTkkdS8vB7w9FQ2L4JL2sCNCtNuBmhOn2unS5z7bSMY6pkdFXIp1Btxst2uL6lCj3mOgW9RFYGk2YNl1owN0PrZEjY1lQXhSo/rVeGRGqG9LmyMJQDOOhwBrFDeOfewO/DykNV1IUrMhdwTLhca28mBB3oziqa/+R+KJcov3CFwrUBcUka48J2Iq3ZxmUqtpKsqmwD7HxToN9LMw23uCSTcpsPzLD2aMSJR9+g9YHR88u7THYkNL8tKXrZhZ8UvWwfaxhRLSAuCZdr4QVRO7ryc9N0jmgaFyNRULq0JOfW3MJbatL5qZNMviKjtO8XOIN4O4wV6sorKZ0jWviZgLQc4p17g9rFTUpNTdCR6vX6x+bQ7Q6F11cpr8mt3l6QFsP27WFAbUc7bYVaB8PaRVISw5h4scC5y9IUMJgsjMQL10N+GCj1hbspm4kwNDmprxjUZKbcv7qKqk/QPj1LXIHiNUWhKQIplEuoTl8KcVMNetM+4ZW1A9mztB1ua5KBG2LsH33oL18i6H2QlU8fY/aJi6i4Akdm8Zaa1N6s4PcDWhWPlY96hFunKS+0KZ9dpFQu0npwhkEtoLguoo22vWO8QzWfJbLkBZaCcvLsJof+8gqqUSc6Os1gsjDiDll6mmz001eEWzGpCZJhGEzbx/58kfJqRPlsW3haqxXW/sEROoc96pdSDr24IduB9OTRjAF9+ZcekBnrAzD0807gVoh3iPpzS3RnFd0PH5We/zAgnZuifH6ViUtdyisint46GbJxagJdr6K6fapXehQMX5KNC8an1/JQORcqqnn4/RR1ZUmkhMMgc1+S0vBiF7YP3zD0Deeh8wE0DI3C0uUUrraEAODYPN0PH6Vz2JPVoZUKiXEhlKGfjqiIqpkpvAQmzq3f9O/7VsOtEG+H61Bg6tUmk+fnWHmwwJ3NSfyrqzAhTHXBmYtM+SfZvLtE6x6PuOIT9BoUrpUpvLlOeKlH/747skyPDbItkpKHByN1i07Do7yWUD67CGFouFUnIRJtud7dh4YXvCEGSIpextaXfw7k3DAthbTmOszNEE3XMjqb6oJU4qvffw1tajGEwkTS/9i9bBwvMvvU5ffd6gDOIN4e2/jGE2dWiaqztE7VOHTuDRQiM6UadcLlTWqhR1wcMkzo0COtV/CA4vllwuk63fkqfqxHWyhsUyDDwlx5TfiMdGtDVod2Z1gAa65TrBTpHKtJITBfeR57nsUYiaa4GklM0FxHhSGDQ+WRv68978nMR84YQNri20eO4vf1+9IYwBnEu8PiClP/Y53L//w0tb93ksJri6hmS5iwm+sUFlcYfPRD9A9pqsvQnwyJagGFawXZ98oS1aUwE1JMSgGDQwX8fpo16JUXRDTFWzLcR8fmSUOfZK6RNfnF9RLBRo/iap+05Gcrj+2r8vsp2DkHI/quun2ppVQr6KlJ0koRvxdLo6AxmkrDkCVXK0Ic0O3CIKLz6GkKWym1Z998Z63NBwjOIN4J8i7UIKK6kNK6t8xkMkdw5iKqXELVJ9CrTZl72JBepH7Do7Kc4FcCorvnCDZ66KVVWFzBa4Z4U5P4PZk4yxDJhBrlEtFcAy9K8JtbxLXJzBB8s394ZQ1dr+LVSxnZsaWOUYkWA4pi1GZb1FOrFSiXMhVTm62qPfsmuttl+spwxdAT1aw63Zv2mfrJtfft6gCgpPVob9EIZvRP1x7b69N4V1j6wgOkgeKOv37TSFEFGRHw4PiM6Fr3NZvHRAEoaGt0AI2LkaQzm1sZrbyqVjJ6eRWalG8QvPUCPDY/eqcf/0y5JL8zyo1xGj5WHfgM7mwQl3whPfMxrCEw992F66r+xA+cYOOeMrWrgwM5/PP9re/Qile368cbgVshdoptNCZqbyZcOxXQPj1LaaWbzQNoIHz5MrXwOCpKac9XSIoQtOUC7BwOiKpVihOFzJ3RUYyyFPNxvC19i2oaaeBCmBkDMNSGHvucjQOiuUYmz2VJlkGq6b7NdOUlxqoV9ESVjXtkxbAFu/cznEHsFNtoTFT/9mXKC3fx5ifrhHcFHGmKyLndv/jymwzuOUJ5Jc2a5IK+Nq4UbN1h9RwqeImkOm1F2++lhJsRSSWg0OxJ+3lz/bqGkl9RMCtBPF0TZaSZMGsrT33QgehfhH1pI5n5u7XMnbJ/q5qZon16lv6kT7GVUjuzjH4fFeC2gzOIXYB37g1KH3qA3pSifXqWSuBnmSDd7lB4bZFy5eiIalAaaFIfkpJlwFAkWC0Hz/AeeajY6EIXPZivULlclHqE0cWzGaA09IVxMJRaRH4OIqoodIAQOSPGYAt+QS8Rgrbc32OFJHvTMnhU++Hy+6Z570ZwBvFuMXa3nPn2GdIPyEqxeddhDp1rZP0/ut2h9INzlED0qutliuuFrGYgElvDGmnqkw3jwHBFiYuK7nSDhpHo7U4Ls3Z3yssueG3EViwzIIgBDKkwhYk72BzgN7dGLnTJPDVYv3+Sft2jfjmi/MKVA8W8917hDGIX4Z17g4kTH6Q977N1Z0GIAe6cEVfH1g4WV/A3K6i5KZJyiBdJujQvAW1nrq2LZS/msG1EUQwPlJ2syz6XAAnZKKcXa/y+FkbBKBUCgUQTXuvhbXSGxmAC7mSqxmCqRL/u4SVQPrt4WxkDOIPYHeQC7sYTZ5ls1Fn62WOsfqjAxGWfYqtEsVLEW9sQIuB2B3Whk335xUaddLqODjzax6rZyKjf10RVT5g/xoiTk+KQMK24keeB0plbVlyPUFEqNY5OTPX1ZpbR0ohrlE7XUVFC/3CVjeNFUh8OvdIlfPnybREzjMMZxG5gvL2jtcHsMy3WP1inX/eIqh5+p0AYVdHT9dG7s9nfi2N0FFFlnu58JUcbkxK2oV8XtwhEDcgaSNiWFnK7msj8hehbp6FHWvIpXBtQeH01K7BZJHOTDKZKeFFK+0gBv69pXO5JO/dtaAzgDOKmQV24wqELksNvHy3RfKCMissUN1LCrSpVu2MUZ6sGiNtVPfc2v9iKHNar6NCnO1+ldTIU8rRnVmTE1dYScrARiU2lpvUyvdkyUc0jKQYUWynVv315t7+GAwdnEDcZwZmLNM5A/eRROsdqtE4EgE9/8giFrZTyQgfmJrM2DWsYqlHPahFZ8Q2ERXAQQWsDdWweL9HM//GL2Wd0a2NkjiP7PcYIBlMl+g0/q0GU12JKP754264I43AGcYugLlyh2pml35iVbNGsR1RRgLhHYTuhCHhLUmDT9aqIkFhDyA8r2Yv38gKlpSH1Szpdx4OMeVuFoWHlnhTKmkmh4owqiqCvmbjUE1dqmxrL7QhnELcSiytMPb4igiMPnaBzOKB9WApzncMe/h0NoIHf14bxW1E6PCGU81FCUgpExNDwIoVLLYhi+h8+Thp6ogY0X6WwPhgpyEUVhZcMs05TL3UJl1ro1eb1m/RuU2MAZxC3BuN33EFE+ewiheYkvdky2tQh4qIiKYmms72IO4fLqBjCTo5Q4HAgFe8jpYyZIykKc15a89i6Q+hqkpLC7+lMSLKyHEvF+9LCbZlB2gluaBBKqWPANxF2bw18TWv9n5RSXwH+BWDZqX5ba/1X5jO/BfwKkAD/Smv9xE0494ODbSj3vdYGFRNA16oiVpjMTZKGPoPJAkEvIaoFDGqSerXZJJCU7KAucUCpmRK2dSaMHnYk9Vpa6aMSLavBeKB9G7tFb4edrBBWMOXHSqkJ4Bml1JPmvT/QWv/H/M5GTOXzwAPAHcDfKKU+oLVOcNgWWZaptYFXCAnLpqGuXKRSKRKb6nTqqxydTYKKUoItEX4srRQACLYGqCjJmgBdjLBz7ITKcgFYMM83lVJWMGU7PAZ8S2vdBy4qpc4DHwe+vwvne3tgkLuIW8IjGpqft8P4+3vf2H/w8F4EUwB+3ejIfd1qzPE+EUzZE9wqTTa3OmyL9yKY8lXgHuAjyArye+/kwPtKMGW/YNzHH0chHP3Jbxv/zAEUPNwP2FGW6XqCKVrrpdz7fwT8hXl58ART9iOudxe/nsGMZa/e9vMON8S7FkwZE1L8ReBF8/xx4PNKqaJS6gSiRvqj3TtlB8Bd8DcJO1khrGDKC0qpZ8223wa+oJT6CBK7XQJ+DUBrfUYp9afAS0iG6ksuw+RwUOBIBhze93gnJAOOytLBIQdnEA4OOTiDcHDIwRmEg0MOziAcHHJwBuHgkIMzCAeHHJxBODjk4AzCwSEHZxAODjk4g3BwyMEZhINDDs4gHBxycAbh4JCDMwgHhxycQTg45OAMwsEhB2cQDg45OINwcMjBGYSDQw7OIBwccnAG4eCQgzMIB4ccnEE4OOSwEyrLklLqR0qp55RSZ5RS/9ZsP6GU+qFS6rxS6r8ppQpme9G8Pm/ev/vm/gkODruHnawQfeBTWusHEabvn1dKPQL8LiKYci9wDVEMwjxeM9v/wOzn4HAgcEOD0IIt89LqdmjgU8B/N9u/AfyCef6YeY15/9OGMNnBYd9jRzGEUso3RMfLwJPAa8C61jo2u+RFUTLBFPN+C5i+zu90gikO+w47MgitdaK1/gii9fBx4L73emAnmOKwH/GOskxa63Xgu8BPA5NKKUunnxdFyQRTzPsNYG1XztbB4SZjJ1mmWaXUpHleBj4DnEUM45+a3b4IfMc8f9y8xrz/v/R+4Nx3cNgBdiKYMg98QynlIwb0p1rrv1BKvQR8Syn174CfICpDmMc/NuqjTUSi18HhQGAnsrzPI8qj49svIPHE+PYe8Eu7cnYODrcYrlLt4JCDMwgHhxycQTg45OAMwsEhB2cQDg45OINwcMjBGYSDQw77QrhdKbUCtIHVPTyNmT0+vjuHm3cOx7XWszvZcV8YBIBS6mmt9cO36/HdOeyPc3Auk4NDDs4gHBxy2E8G8bXb/PjgzsFiz85h38QQDg77AftphXBw2HM4g3BwyGHPDUIp9fNKqVcMj9OXb+FxLymlXlBKPauUetpsm1JKPamUetU8HtrlY35dKbWslHoxt+26x1SCPzTfy/NKqYdu4jl8RSl11XwXzyqlPpd777fMObyilPq5XTj+MaXUd5VSLxmer98w22/p97AttNZ79gP4CIPHSaAAPAfcf4uOfQmYGdv2H4Avm+dfBn53l4/5SeAh4MUbHRP4HPDXgAIeAX54E8/hK8C/uc6+95v/SRE4Yf5X/ns8/jzwkHk+AZwzx7ml38N2P3u9QnwcOK+1vqC1HgDfQnid9gp5Tqk819SuQGv9v5Gx2p0c8zHgm1rwA4TUYf4mncN2eAz4lta6r7W+CJznOlOS7/D4C1rrH5vnm8h8/p3c4u9hO+y1QWQcTgZ5fqebDQ38T6XUM0qpXzXb5rTWC+b5IjB3C85ju2Pe6u/m141L8vWcq3hTz8HQnH4U+CH75HvYa4PYS3xCa/0Q8FngS0qpT+bf1LJe39Kc9F4c0+CrwD0IVekC8Hs3+4BKqRrwZ8Bvaq038u/t4few5waRcTgZ5Pmdbiq01lfN4zLw54grsGSXY/O4fAtOZbtj3rLvRmu9pIWMLgX+iKFbdFPOQSkVIsbwJ1rrb5vNe/49wN4bxP8DThkm8QJCWfP4zT6oUqqqlJqwz4GfBV5klFMqzzV1M7HdMR8HftlkWR4BWjmXYlcx5pP/IvJd2HP4vGF0PwGcAn70Ho+lEKqis1rr38+9teffA7C3WaZcFuEcksH4nVt0zJNI9uQ54Iw9LsJB+xTwKvA3wNQuH/e/Ii5JhPjCv7LdMZGsyn8238sLwMM38Rz+2BzjeeQCnM/t/zvmHF4BPrsLx/8E4g49Dzxrfj53q7+H7X5c64aDQw577TI5OOwrOINwcMjBGYSDQw7OIBwccnAG4eCQgzMIB4ccnEE4OOTw/wEpamKfrFvXxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = next(file_name for file_name in ind_prof if 'Seg' not in file_name)\n",
    "msk_b = next(file_name for file_name in ind_prof if 'bak_' in file_name)\n",
    "img = sitk.ReadImage(data_path + train_ids[0] + '/' + img_name)\n",
    "msk = sitk.ReadImage(data_path + train_ids[0] + '/' + msk_b)\n",
    "img_array = sitk.GetArrayFromImage(img)\n",
    "msk_array = sitk.GetArrayFromImage(msk)\n",
    "\n",
    "%pylab inline\n",
    "subplot(121)\n",
    "imgplot = plt.imshow(img_array[63,:,:])\n",
    "plt.show()\n",
    "subplot(122)\n",
    "plt.imshow(msk_array[63,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7125d91ac8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data = np.ndarray((img_array.shape[0], img_array.shape[1], img_array.shape[2], 1), dtype=np.uint8)\n",
    "for i in range(img_array.shape[0]):\n",
    "    X_data[i,:,:,0] = img_array[i,:,:]\n",
    "for i in range(img_array.shape[1]):\n",
    "    X_data[:,i,:,0] = img_array[:,i,:]\n",
    "for i in range(img_array.shape[0]):\n",
    "    X_data[:,:,i,0] = img_array[:,:,i]\n",
    "imshow(X_data[64,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7125a64b70>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data = np.ndarray((img_array.shape[0], img_array.shape[1], img_array.shape[2], 1), dtype=np.uint8)\n",
    "for i in range(img_array.shape[0]):\n",
    "    X_data[i,:,:,0] = img_array[i,:,:]\n",
    "for i in range(img_array.shape[1]):\n",
    "    X_data[:,i,:,0] = img_array[:,i,:]\n",
    "for i in range(img_array.shape[0]):\n",
    "    X_data[:,:,i,0] = img_array[:,:,i]\n",
    "imshow(X_data[63,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7125c7cba8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_mask = np.ndarray((msk_array.shape[0], msk_array.shape[1], msk_array.shape[2], 1), dtype=np.uint8)\n",
    "for i in range(msk_array.shape[0]):\n",
    "    Y_mask[i,:,:,0] = msk_array[i,:,:]\n",
    "for i in range(msk_array.shape[1]):\n",
    "    Y_mask[:,i,:,0] = msk_array[:,i,:]\n",
    "for i in range(msk_array.shape[0]):\n",
    "    Y_mask[:,:,i,0] = msk_array[:,:,i]\n",
    "imshow(Y_mask[63,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_path3D(X_input, arch_type):\n",
    "    if arch_type == 'input':\n",
    "        #upper path\n",
    "        X = Conv3D(64, (7, 7, 7), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X1 = Conv3D(64, (7, 7, 7), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X1 = Maximum()([X,X1])\n",
    "        X1 = MaxPooling3D((4,4,4), strides=(1,1,1), padding='valid')(X1)\n",
    "        \n",
    "        X = Conv3D(64, (3,3,3), strides=(1,1,1), padding='valid')(X1)\n",
    "        X1 = Conv3D(64, (3,3,3), strides=(1,1,1), padding='valid')(X1)\n",
    "        X1 = Maximum()([X,X1])\n",
    "        X1 = MaxPooling3D((2,2,2), strides=(1,1,1), padding='valid')(X1)\n",
    "        \n",
    "        #lower path\n",
    "        X = Conv3D(160, (13, 13, 13), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X2 = Conv3D(160, (13, 13, 13), strides=(1,1,1), padding='valid')(X_input)\n",
    "        X2 = Maximum()([X,X2])\n",
    "        \n",
    "        #concatenation\n",
    "        X = concatenate([X1,X2], axis=4)\n",
    "        X = Conv3D(5, (21, 21, 21), strides=(1,1,1), padding='valid')(X)\n",
    "        X = Activation('softmax')(X)\n",
    "    \n",
    "        #model = Model(inputs=X_input, outputs=X)\n",
    "        return X\n",
    "def InputCascadeCNN(shape1, shape2):\n",
    "    #concatenate input and output of the 1st two path network\n",
    "    X1 = Input(shape1)\n",
    "    X = two_path3D(X1, 'input')\n",
    "    \n",
    "    X2 = Input(shape2)\n",
    "    X = concatenate([X, X2], axis=3)\n",
    "    X = two_path3D(X, 'input')\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=[X1,X2], outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 7 from 1 for 'conv3d_3/convolution' (op: 'Conv3D') with input shapes: [?,65,65,65,1], [7,7,7,65,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1588\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 7 from 1 for 'conv3d_3/convolution' (op: 'Conv3D') with input shapes: [?,65,65,65,1], [7,7,7,65,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-9eb35d8554d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Creating and compiling model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputCascadeCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-9d8a85802fd2>\u001b[0m in \u001b[0;36mInputCascadeCNN\u001b[0;34m(shape1, shape2)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#concatenate input and output of the 1st two path network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_path3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-9d8a85802fd2>\u001b[0m in \u001b[0;36mtwo_path3D\u001b[0;34m(X_input, arch_type)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0march_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m#upper path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3787\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3788\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3789\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3790\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NDHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         data_format=data_format)\n\u001b[0;32m--> 780\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;34m\"Conv3D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3412\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3413\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3414\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1754\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1755\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1756\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1757\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 7 from 1 for 'conv3d_3/convolution' (op: 'Conv3D') with input shapes: [?,65,65,65,1], [7,7,7,65,64]."
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "model = InputCascadeCNN((65,65,65,1), (33,33,33,1))\n",
    "print(model.summary())\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "model.fit(img_array, msk_array, batch_size=32, epochs=3000, verbose=1, shuffle=True,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Processed_Data/img_z', oz)\n",
    "np.save('../Processed_Data/img_y', oy)\n",
    "np.save('../Processed_Data/img_x', ox)\n",
    "np.save('../Processed_Data/msk_z', oz_msk)\n",
    "np.save('../Processed_Data/msk_y', oy_msk)\n",
    "np.save('../Processed_Data/msk_x', ox_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_z = np.ndarray((len(oz), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y = np.ndarray((len(oy), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x = np.ndarray((len(ox), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_z_m = np.ndarray((len(oz_msk), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_y_m = np.ndarray((len(oy_msk), IMG_H, IMG_W, 1), dtype=np.uint8)\n",
    "train_x_m = np.ndarray((len(ox_msk), IMG_H, IMG_W, 1), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n"
     ]
    }
   ],
   "source": [
    "for n, img in enumerate(oz):\n",
    "    train_z[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oy):\n",
    "    train_y[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(ox):\n",
    "    train_x[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oz_msk):\n",
    "    train_z_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(oy_msk):\n",
    "    train_y_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)\n",
    "for n, img in enumerate(ox_msk):\n",
    "    train_x_m[n] = resize(img, (IMG_H, IMG_W, 1), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 128, 128, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 1)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 32) 320         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 32)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 16, 16, 256)  524544      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 512)  0           conv2d_transpose_13[0][0]        \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 32, 32, 128)  131200      conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 256)  0           conv2d_transpose_14[0][0]        \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 64, 64, 64)   32832       conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 64, 128)  0           conv2d_transpose_15[0][0]        \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTran (None, 128, 128, 32) 8224        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 128, 128, 64) 0           conv2d_transpose_16[0][0]        \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 128, 128, 1)  33          conv2d_75[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,759,521\n",
      "Trainable params: 7,759,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Train on 92 samples, validate on 11 samples\n",
      "Epoch 1/3000\n",
      "92/92 [==============================] - 6s 61ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1107e-05 - val_dice_coef: 1.1107e-05\n",
      "Epoch 2/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1105e-05 - val_dice_coef: 1.1105e-05\n",
      "Epoch 3/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1103e-05 - val_dice_coef: 1.1103e-05\n",
      "Epoch 4/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1101e-05 - val_dice_coef: 1.1101e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1099e-05 - val_dice_coef: 1.1099e-05\n",
      "Epoch 6/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1098e-05 - val_dice_coef: 1.1098e-05\n",
      "Epoch 7/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1096e-05 - val_dice_coef: 1.1096e-05\n",
      "Epoch 8/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1094e-05 - val_dice_coef: 1.1094e-05\n",
      "Epoch 9/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1092e-05 - val_dice_coef: 1.1092e-05\n",
      "Epoch 10/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1091e-05 - val_dice_coef: 1.1091e-05\n",
      "Epoch 11/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1089e-05 - val_dice_coef: 1.1089e-05\n",
      "Epoch 12/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0100 - dice_coef: 0.0100 - val_loss: -1.1088e-05 - val_dice_coef: 1.1088e-05\n",
      "Epoch 13/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1087e-05 - val_dice_coef: 1.1087e-05\n",
      "Epoch 14/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1085e-05 - val_dice_coef: 1.1085e-05\n",
      "Epoch 15/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1084e-05 - val_dice_coef: 1.1084e-05\n",
      "Epoch 16/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1082e-05 - val_dice_coef: 1.1082e-05\n",
      "Epoch 17/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1081e-05 - val_dice_coef: 1.1081e-05\n",
      "Epoch 18/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 19/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1079e-05 - val_dice_coef: 1.1079e-05\n",
      "Epoch 20/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 21/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 22/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1076e-05 - val_dice_coef: 1.1076e-05\n",
      "Epoch 23/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 24/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1074e-05 - val_dice_coef: 1.1074e-05\n",
      "Epoch 25/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 26/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 27/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 28/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 29/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 30/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 31/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 32/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 33/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 34/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0101 - dice_coef: 0.0101 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 35/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 36/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1070e-05 - val_dice_coef: 1.1070e-05\n",
      "Epoch 37/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 38/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 39/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 40/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1071e-05 - val_dice_coef: 1.1071e-05\n",
      "Epoch 41/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 42/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 43/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1072e-05 - val_dice_coef: 1.1072e-05\n",
      "Epoch 44/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 45/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1073e-05 - val_dice_coef: 1.1073e-05\n",
      "Epoch 46/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1074e-05 - val_dice_coef: 1.1074e-05\n",
      "Epoch 47/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 48/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1075e-05 - val_dice_coef: 1.1075e-05\n",
      "Epoch 49/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1076e-05 - val_dice_coef: 1.1076e-05\n",
      "Epoch 50/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0102 - dice_coef: 0.0102 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 51/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1077e-05 - val_dice_coef: 1.1077e-05\n",
      "Epoch 52/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1078e-05 - val_dice_coef: 1.1078e-05\n",
      "Epoch 53/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1078e-05 - val_dice_coef: 1.1078e-05\n",
      "Epoch 54/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1079e-05 - val_dice_coef: 1.1079e-05\n",
      "Epoch 55/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 56/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1080e-05 - val_dice_coef: 1.1080e-05\n",
      "Epoch 57/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1081e-05 - val_dice_coef: 1.1081e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1082e-05 - val_dice_coef: 1.1082e-05\n",
      "Epoch 59/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1083e-05 - val_dice_coef: 1.1083e-05\n",
      "Epoch 60/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1083e-05 - val_dice_coef: 1.1083e-05\n",
      "Epoch 61/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0103 - dice_coef: 0.0103 - val_loss: -1.1084e-05 - val_dice_coef: 1.1084e-05\n",
      "Epoch 62/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1085e-05 - val_dice_coef: 1.1085e-05\n",
      "Epoch 63/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1086e-05 - val_dice_coef: 1.1086e-05\n",
      "Epoch 64/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1087e-05 - val_dice_coef: 1.1087e-05\n",
      "Epoch 65/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1088e-05 - val_dice_coef: 1.1088e-05\n",
      "Epoch 66/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1089e-05 - val_dice_coef: 1.1089e-05\n",
      "Epoch 67/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1090e-05 - val_dice_coef: 1.1090e-05\n",
      "Epoch 68/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1091e-05 - val_dice_coef: 1.1091e-05\n",
      "Epoch 69/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1092e-05 - val_dice_coef: 1.1092e-05\n",
      "Epoch 70/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0104 - dice_coef: 0.0104 - val_loss: -1.1093e-05 - val_dice_coef: 1.1093e-05\n",
      "Epoch 71/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1094e-05 - val_dice_coef: 1.1094e-05\n",
      "Epoch 72/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1096e-05 - val_dice_coef: 1.1096e-05\n",
      "Epoch 73/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1097e-05 - val_dice_coef: 1.1097e-05\n",
      "Epoch 74/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1098e-05 - val_dice_coef: 1.1098e-05\n",
      "Epoch 75/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1100e-05 - val_dice_coef: 1.1100e-05\n",
      "Epoch 76/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1101e-05 - val_dice_coef: 1.1101e-05\n",
      "Epoch 77/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0105 - dice_coef: 0.0105 - val_loss: -1.1102e-05 - val_dice_coef: 1.1102e-05\n",
      "Epoch 78/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1104e-05 - val_dice_coef: 1.1104e-05\n",
      "Epoch 79/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1105e-05 - val_dice_coef: 1.1105e-05\n",
      "Epoch 80/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1106e-05 - val_dice_coef: 1.1106e-05\n",
      "Epoch 81/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1108e-05 - val_dice_coef: 1.1108e-05\n",
      "Epoch 82/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1109e-05 - val_dice_coef: 1.1109e-05\n",
      "Epoch 83/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0106 - dice_coef: 0.0106 - val_loss: -1.1110e-05 - val_dice_coef: 1.1110e-05\n",
      "Epoch 84/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1112e-05 - val_dice_coef: 1.1112e-05\n",
      "Epoch 85/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1113e-05 - val_dice_coef: 1.1113e-05\n",
      "Epoch 86/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1115e-05 - val_dice_coef: 1.1115e-05\n",
      "Epoch 87/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0107 - dice_coef: 0.0107 - val_loss: -1.1116e-05 - val_dice_coef: 1.1116e-05\n",
      "Epoch 88/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1117e-05 - val_dice_coef: 1.1117e-05\n",
      "Epoch 89/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1118e-05 - val_dice_coef: 1.1118e-05\n",
      "Epoch 90/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0108 - dice_coef: 0.0108 - val_loss: -1.1120e-05 - val_dice_coef: 1.1120e-05\n",
      "Epoch 91/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1121e-05 - val_dice_coef: 1.1121e-05\n",
      "Epoch 92/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1123e-05 - val_dice_coef: 1.1123e-05\n",
      "Epoch 93/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0109 - dice_coef: 0.0109 - val_loss: -1.1125e-05 - val_dice_coef: 1.1125e-05\n",
      "Epoch 94/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1126e-05 - val_dice_coef: 1.1126e-05\n",
      "Epoch 95/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1128e-05 - val_dice_coef: 1.1128e-05\n",
      "Epoch 96/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0110 - dice_coef: 0.0110 - val_loss: -1.1130e-05 - val_dice_coef: 1.1130e-05\n",
      "Epoch 97/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0111 - dice_coef: 0.0111 - val_loss: -1.1133e-05 - val_dice_coef: 1.1133e-05\n",
      "Epoch 98/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0111 - dice_coef: 0.0111 - val_loss: -1.1135e-05 - val_dice_coef: 1.1135e-05\n",
      "Epoch 99/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0112 - dice_coef: 0.0112 - val_loss: -1.1138e-05 - val_dice_coef: 1.1138e-05\n",
      "Epoch 100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0112 - dice_coef: 0.0112 - val_loss: -1.1140e-05 - val_dice_coef: 1.1140e-05\n",
      "Epoch 101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0113 - dice_coef: 0.0113 - val_loss: -1.1144e-05 - val_dice_coef: 1.1144e-05\n",
      "Epoch 102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0114 - dice_coef: 0.0114 - val_loss: -1.1148e-05 - val_dice_coef: 1.1148e-05\n",
      "Epoch 103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0115 - dice_coef: 0.0115 - val_loss: -1.1151e-05 - val_dice_coef: 1.1151e-05\n",
      "Epoch 104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0115 - dice_coef: 0.0115 - val_loss: -1.1156e-05 - val_dice_coef: 1.1156e-05\n",
      "Epoch 105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0116 - dice_coef: 0.0116 - val_loss: -1.1162e-05 - val_dice_coef: 1.1162e-05\n",
      "Epoch 106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0117 - dice_coef: 0.0117 - val_loss: -1.1167e-05 - val_dice_coef: 1.1167e-05\n",
      "Epoch 107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0118 - dice_coef: 0.0118 - val_loss: -1.1175e-05 - val_dice_coef: 1.1175e-05\n",
      "Epoch 108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0119 - dice_coef: 0.0119 - val_loss: -1.1183e-05 - val_dice_coef: 1.1183e-05\n",
      "Epoch 109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0121 - dice_coef: 0.0121 - val_loss: -1.1193e-05 - val_dice_coef: 1.1193e-05\n",
      "Epoch 110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0122 - dice_coef: 0.0122 - val_loss: -1.1207e-05 - val_dice_coef: 1.1207e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0124 - dice_coef: 0.0124 - val_loss: -1.1224e-05 - val_dice_coef: 1.1224e-05\n",
      "Epoch 112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0125 - dice_coef: 0.0125 - val_loss: -1.1242e-05 - val_dice_coef: 1.1242e-05\n",
      "Epoch 113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0128 - dice_coef: 0.0128 - val_loss: -1.1271e-05 - val_dice_coef: 1.1271e-05\n",
      "Epoch 114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0130 - dice_coef: 0.0130 - val_loss: -1.1302e-05 - val_dice_coef: 1.1302e-05\n",
      "Epoch 115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0133 - dice_coef: 0.0133 - val_loss: -1.1336e-05 - val_dice_coef: 1.1336e-05\n",
      "Epoch 116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0136 - dice_coef: 0.0136 - val_loss: -1.1398e-05 - val_dice_coef: 1.1398e-05\n",
      "Epoch 117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0139 - dice_coef: 0.0139 - val_loss: -1.1497e-05 - val_dice_coef: 1.1497e-05\n",
      "Epoch 118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0143 - dice_coef: 0.0143 - val_loss: -1.1565e-05 - val_dice_coef: 1.1565e-05\n",
      "Epoch 119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0149 - dice_coef: 0.0149 - val_loss: -1.1802e-05 - val_dice_coef: 1.1802e-05\n",
      "Epoch 120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0155 - dice_coef: 0.0155 - val_loss: -1.1994e-05 - val_dice_coef: 1.1994e-05\n",
      "Epoch 121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0161 - dice_coef: 0.0161 - val_loss: -1.2419e-05 - val_dice_coef: 1.2419e-05\n",
      "Epoch 122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0172 - dice_coef: 0.0172 - val_loss: -1.2878e-05 - val_dice_coef: 1.2878e-05\n",
      "Epoch 123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0185 - dice_coef: 0.0185 - val_loss: -1.4198e-05 - val_dice_coef: 1.4198e-05\n",
      "Epoch 124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0202 - dice_coef: 0.0202 - val_loss: -1.5069e-05 - val_dice_coef: 1.5069e-05\n",
      "Epoch 125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0230 - dice_coef: 0.0230 - val_loss: -1.8830e-05 - val_dice_coef: 1.8830e-05\n",
      "Epoch 126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0277 - dice_coef: 0.0277 - val_loss: -2.5383e-05 - val_dice_coef: 2.5383e-05\n",
      "Epoch 127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0338 - dice_coef: 0.0338 - val_loss: -3.0613e-05 - val_dice_coef: 3.0613e-05\n",
      "Epoch 128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0440 - dice_coef: 0.0440 - val_loss: -3.7309e-05 - val_dice_coef: 3.7309e-05\n",
      "Epoch 129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0589 - dice_coef: 0.0589 - val_loss: -5.4508e-05 - val_dice_coef: 5.4508e-05\n",
      "Epoch 130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0796 - dice_coef: 0.0796 - val_loss: -8.9018e-05 - val_dice_coef: 8.9018e-05\n",
      "Epoch 131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.0968 - dice_coef: 0.0968 - val_loss: -7.3245e-05 - val_dice_coef: 7.3245e-05\n",
      "Epoch 132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1158 - dice_coef: 0.1158 - val_loss: -1.5367e-04 - val_dice_coef: 1.5367e-04\n",
      "Epoch 133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1511 - dice_coef: 0.1511 - val_loss: -2.6846e-04 - val_dice_coef: 2.6846e-04\n",
      "Epoch 134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1832 - dice_coef: 0.1832 - val_loss: -3.1565e-04 - val_dice_coef: 3.1565e-04\n",
      "Epoch 135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1991 - dice_coef: 0.1991 - val_loss: -1.4018e-04 - val_dice_coef: 1.4018e-04\n",
      "Epoch 136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.1806 - dice_coef: 0.1806 - val_loss: -4.9281e-04 - val_dice_coef: 4.9281e-04\n",
      "Epoch 137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2291 - dice_coef: 0.2291 - val_loss: -2.9947e-04 - val_dice_coef: 2.9947e-04\n",
      "Epoch 138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2629 - dice_coef: 0.2629 - val_loss: -2.4638e-04 - val_dice_coef: 2.4638e-04\n",
      "Epoch 139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2359 - dice_coef: 0.2359 - val_loss: -7.2372e-04 - val_dice_coef: 7.2372e-04\n",
      "Epoch 140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2803 - dice_coef: 0.2803 - val_loss: -2.6312e-04 - val_dice_coef: 2.6312e-04\n",
      "Epoch 141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.2769 - dice_coef: 0.2769 - val_loss: -0.0012 - val_dice_coef: 0.0012\n",
      "Epoch 142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3336 - dice_coef: 0.3336 - val_loss: -4.0191e-04 - val_dice_coef: 4.0191e-04\n",
      "Epoch 143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3543 - dice_coef: 0.3543 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 144/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3593 - dice_coef: 0.3593 - val_loss: -3.4966e-04 - val_dice_coef: 3.4966e-04\n",
      "Epoch 145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3690 - dice_coef: 0.3690 - val_loss: -0.0038 - val_dice_coef: 0.0038\n",
      "Epoch 146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3731 - dice_coef: 0.3731 - val_loss: -5.3135e-04 - val_dice_coef: 5.3135e-04\n",
      "Epoch 147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.3957 - dice_coef: 0.3957 - val_loss: -0.0028 - val_dice_coef: 0.0028\n",
      "Epoch 148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4610 - dice_coef: 0.4610 - val_loss: -0.0023 - val_dice_coef: 0.0023\n",
      "Epoch 149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4710 - dice_coef: 0.4710 - val_loss: -0.0014 - val_dice_coef: 0.0014\n",
      "Epoch 150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4698 - dice_coef: 0.4698 - val_loss: -0.0074 - val_dice_coef: 0.0074\n",
      "Epoch 151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4465 - dice_coef: 0.4465 - val_loss: -0.0016 - val_dice_coef: 0.0016\n",
      "Epoch 152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.4922 - dice_coef: 0.4922 - val_loss: -0.0030 - val_dice_coef: 0.0030\n",
      "Epoch 153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5099 - dice_coef: 0.5099 - val_loss: -0.0074 - val_dice_coef: 0.0074\n",
      "Epoch 154/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5115 - dice_coef: 0.5115 - val_loss: -0.0033 - val_dice_coef: 0.0033\n",
      "Epoch 155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5275 - dice_coef: 0.5275 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5467 - dice_coef: 0.5467 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5057 - dice_coef: 0.5057 - val_loss: -0.0020 - val_dice_coef: 0.0020\n",
      "Epoch 158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5405 - dice_coef: 0.5405 - val_loss: -0.0041 - val_dice_coef: 0.0041\n",
      "Epoch 159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5680 - dice_coef: 0.5680 - val_loss: -0.0095 - val_dice_coef: 0.0095\n",
      "Epoch 160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5403 - dice_coef: 0.5403 - val_loss: -0.0082 - val_dice_coef: 0.0082\n",
      "Epoch 161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5418 - dice_coef: 0.5418 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5725 - dice_coef: 0.5725 - val_loss: -0.0022 - val_dice_coef: 0.0022\n",
      "Epoch 163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5570 - dice_coef: 0.5570 - val_loss: -0.0157 - val_dice_coef: 0.0157\n",
      "Epoch 164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5478 - dice_coef: 0.5478 - val_loss: -0.0057 - val_dice_coef: 0.0057\n",
      "Epoch 165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5625 - dice_coef: 0.5625 - val_loss: -0.0017 - val_dice_coef: 0.0017\n",
      "Epoch 166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5734 - dice_coef: 0.5734 - val_loss: -0.0263 - val_dice_coef: 0.0263\n",
      "Epoch 167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5060 - dice_coef: 0.5060 - val_loss: -0.0012 - val_dice_coef: 0.0012\n",
      "Epoch 168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5289 - dice_coef: 0.5289 - val_loss: -0.0095 - val_dice_coef: 0.0095\n",
      "Epoch 169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5431 - dice_coef: 0.5431 - val_loss: -0.0043 - val_dice_coef: 0.0043\n",
      "Epoch 170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5746 - dice_coef: 0.5746 - val_loss: -0.0021 - val_dice_coef: 0.0021\n",
      "Epoch 171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5672 - dice_coef: 0.5672 - val_loss: -0.0185 - val_dice_coef: 0.0185\n",
      "Epoch 172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5998 - dice_coef: 0.5998 - val_loss: -0.0021 - val_dice_coef: 0.0021\n",
      "Epoch 173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5934 - dice_coef: 0.5934 - val_loss: -0.0227 - val_dice_coef: 0.0227\n",
      "Epoch 174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5620 - dice_coef: 0.5620 - val_loss: -0.0024 - val_dice_coef: 0.0024\n",
      "Epoch 175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.5871 - dice_coef: 0.5871 - val_loss: -0.0051 - val_dice_coef: 0.0051\n",
      "Epoch 176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6136 - dice_coef: 0.6136 - val_loss: -0.0080 - val_dice_coef: 0.0080\n",
      "Epoch 177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6234 - dice_coef: 0.6234 - val_loss: -0.0028 - val_dice_coef: 0.0028\n",
      "Epoch 178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6085 - dice_coef: 0.6085 - val_loss: -0.0268 - val_dice_coef: 0.0268\n",
      "Epoch 179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6012 - dice_coef: 0.6012 - val_loss: -0.0029 - val_dice_coef: 0.0029\n",
      "Epoch 180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6337 - dice_coef: 0.6337 - val_loss: -0.0189 - val_dice_coef: 0.0189\n",
      "Epoch 181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6154 - dice_coef: 0.6154 - val_loss: -0.0062 - val_dice_coef: 0.0062\n",
      "Epoch 182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6435 - dice_coef: 0.6435 - val_loss: -0.0052 - val_dice_coef: 0.0052\n",
      "Epoch 183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6477 - dice_coef: 0.6477 - val_loss: -0.0080 - val_dice_coef: 0.0080\n",
      "Epoch 184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6506 - dice_coef: 0.6506 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6532 - dice_coef: 0.6532 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6516 - dice_coef: 0.6516 - val_loss: -0.0236 - val_dice_coef: 0.0236\n",
      "Epoch 187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6464 - dice_coef: 0.6464 - val_loss: -0.0035 - val_dice_coef: 0.0035\n",
      "Epoch 188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6166 - dice_coef: 0.6166 - val_loss: -0.0066 - val_dice_coef: 0.0066\n",
      "Epoch 189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6000 - dice_coef: 0.6000 - val_loss: -0.0093 - val_dice_coef: 0.0093\n",
      "Epoch 190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6448 - dice_coef: 0.6448 - val_loss: -0.0034 - val_dice_coef: 0.0034\n",
      "Epoch 191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6118 - dice_coef: 0.6118 - val_loss: -0.0278 - val_dice_coef: 0.0278\n",
      "Epoch 192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6444 - dice_coef: 0.6444 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6396 - dice_coef: 0.6396 - val_loss: -0.0102 - val_dice_coef: 0.0102\n",
      "Epoch 194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6707 - dice_coef: 0.6707 - val_loss: -0.0072 - val_dice_coef: 0.0072\n",
      "Epoch 195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6327 - dice_coef: 0.6327 - val_loss: -0.0024 - val_dice_coef: 0.0024\n",
      "Epoch 196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6094 - dice_coef: 0.6094 - val_loss: -0.0249 - val_dice_coef: 0.0249\n",
      "Epoch 197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6616 - dice_coef: 0.6616 - val_loss: -0.0029 - val_dice_coef: 0.0029\n",
      "Epoch 198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6442 - dice_coef: 0.6442 - val_loss: -0.0407 - val_dice_coef: 0.0407\n",
      "Epoch 199/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6436 - dice_coef: 0.6436 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6376 - dice_coef: 0.6376 - val_loss: -0.0210 - val_dice_coef: 0.0210\n",
      "Epoch 201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6463 - dice_coef: 0.6463 - val_loss: -0.0057 - val_dice_coef: 0.0057\n",
      "Epoch 202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6588 - dice_coef: 0.6588 - val_loss: -0.0055 - val_dice_coef: 0.0055\n",
      "Epoch 203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6548 - dice_coef: 0.6548 - val_loss: -0.0221 - val_dice_coef: 0.0221\n",
      "Epoch 204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6466 - dice_coef: 0.6466 - val_loss: -0.0026 - val_dice_coef: 0.0026\n",
      "Epoch 205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6399 - dice_coef: 0.6399 - val_loss: -0.0501 - val_dice_coef: 0.0501\n",
      "Epoch 206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6406 - dice_coef: 0.6406 - val_loss: -0.0042 - val_dice_coef: 0.0042\n",
      "Epoch 207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6891 - dice_coef: 0.6891 - val_loss: -0.0334 - val_dice_coef: 0.0334\n",
      "Epoch 208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6813 - dice_coef: 0.6813 - val_loss: -0.0030 - val_dice_coef: 0.0030\n",
      "Epoch 209/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6654 - dice_coef: 0.6654 - val_loss: -0.0236 - val_dice_coef: 0.0236\n",
      "Epoch 210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6557 - dice_coef: 0.6557 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6867 - dice_coef: 0.6867 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6828 - dice_coef: 0.6828 - val_loss: -0.0213 - val_dice_coef: 0.0213\n",
      "Epoch 213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6963 - dice_coef: 0.6963 - val_loss: -0.0047 - val_dice_coef: 0.0047\n",
      "Epoch 214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6900 - dice_coef: 0.6900 - val_loss: -0.0160 - val_dice_coef: 0.0160\n",
      "Epoch 215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7085 - dice_coef: 0.7085 - val_loss: -0.0060 - val_dice_coef: 0.0060\n",
      "Epoch 216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7012 - dice_coef: 0.7012 - val_loss: -0.0172 - val_dice_coef: 0.0172\n",
      "Epoch 217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7031 - dice_coef: 0.7031 - val_loss: -0.0050 - val_dice_coef: 0.0050\n",
      "Epoch 218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7066 - dice_coef: 0.7066 - val_loss: -0.0333 - val_dice_coef: 0.0333\n",
      "Epoch 219/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7029 - dice_coef: 0.7029 - val_loss: -0.0038 - val_dice_coef: 0.0038\n",
      "Epoch 220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6974 - dice_coef: 0.6974 - val_loss: -0.0762 - val_dice_coef: 0.0762\n",
      "Epoch 221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6840 - dice_coef: 0.6840 - val_loss: -0.0042 - val_dice_coef: 0.0042\n",
      "Epoch 222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7095 - dice_coef: 0.7095 - val_loss: -0.0456 - val_dice_coef: 0.0456\n",
      "Epoch 223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6927 - dice_coef: 0.6927 - val_loss: -0.0048 - val_dice_coef: 0.0048\n",
      "Epoch 224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6993 - dice_coef: 0.6993 - val_loss: -0.0125 - val_dice_coef: 0.0125\n",
      "Epoch 225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7147 - dice_coef: 0.7147 - val_loss: -0.0098 - val_dice_coef: 0.0098\n",
      "Epoch 226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7212 - dice_coef: 0.7212 - val_loss: -0.0073 - val_dice_coef: 0.0073\n",
      "Epoch 227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7165 - dice_coef: 0.7165 - val_loss: -0.0154 - val_dice_coef: 0.0154\n",
      "Epoch 228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7287 - dice_coef: 0.7287 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7251 - dice_coef: 0.7251 - val_loss: -0.0087 - val_dice_coef: 0.0087\n",
      "Epoch 230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7258 - dice_coef: 0.7258 - val_loss: -0.0120 - val_dice_coef: 0.0120\n",
      "Epoch 231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7331 - dice_coef: 0.7331 - val_loss: -0.0119 - val_dice_coef: 0.0119\n",
      "Epoch 232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7328 - dice_coef: 0.7328 - val_loss: -0.0118 - val_dice_coef: 0.0118\n",
      "Epoch 233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7270 - dice_coef: 0.7270 - val_loss: -0.0081 - val_dice_coef: 0.0081\n",
      "Epoch 234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7355 - dice_coef: 0.7355 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7344 - dice_coef: 0.7344 - val_loss: -0.0076 - val_dice_coef: 0.0076\n",
      "Epoch 236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7305 - dice_coef: 0.7305 - val_loss: -0.0531 - val_dice_coef: 0.0531\n",
      "Epoch 237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7165 - dice_coef: 0.7165 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7345 - dice_coef: 0.7345 - val_loss: -0.0081 - val_dice_coef: 0.0081\n",
      "Epoch 239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7349 - dice_coef: 0.7349 - val_loss: -0.0205 - val_dice_coef: 0.0205\n",
      "Epoch 240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7402 - dice_coef: 0.7402 - val_loss: -0.0069 - val_dice_coef: 0.0069\n",
      "Epoch 241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7214 - dice_coef: 0.7214 - val_loss: -0.0201 - val_dice_coef: 0.0201\n",
      "Epoch 242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7329 - dice_coef: 0.7329 - val_loss: -0.0245 - val_dice_coef: 0.0245\n",
      "Epoch 243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7348 - dice_coef: 0.7348 - val_loss: -0.0086 - val_dice_coef: 0.0086\n",
      "Epoch 244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7320 - dice_coef: 0.7320 - val_loss: -0.0145 - val_dice_coef: 0.0145\n",
      "Epoch 245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7330 - dice_coef: 0.7330 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7447 - dice_coef: 0.7447 - val_loss: -0.0222 - val_dice_coef: 0.0222\n",
      "Epoch 247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7501 - dice_coef: 0.7501 - val_loss: -0.0142 - val_dice_coef: 0.0142\n",
      "Epoch 248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7491 - dice_coef: 0.7491 - val_loss: -0.0147 - val_dice_coef: 0.0147\n",
      "Epoch 249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7529 - dice_coef: 0.7529 - val_loss: -0.0142 - val_dice_coef: 0.0142\n",
      "Epoch 250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7491 - dice_coef: 0.7491 - val_loss: -0.0514 - val_dice_coef: 0.0514\n",
      "Epoch 251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7485 - dice_coef: 0.7485 - val_loss: -0.0105 - val_dice_coef: 0.0105\n",
      "Epoch 252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7539 - dice_coef: 0.7539 - val_loss: -0.0343 - val_dice_coef: 0.0343\n",
      "Epoch 253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7467 - dice_coef: 0.7467 - val_loss: -0.0375 - val_dice_coef: 0.0375\n",
      "Epoch 254/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7548 - dice_coef: 0.7548 - val_loss: -0.0094 - val_dice_coef: 0.0094\n",
      "Epoch 255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7531 - dice_coef: 0.7531 - val_loss: -0.0179 - val_dice_coef: 0.0179\n",
      "Epoch 256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7568 - dice_coef: 0.7568 - val_loss: -0.0368 - val_dice_coef: 0.0368\n",
      "Epoch 257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7534 - dice_coef: 0.7534 - val_loss: -0.0270 - val_dice_coef: 0.0270\n",
      "Epoch 258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7571 - dice_coef: 0.7571 - val_loss: -0.0097 - val_dice_coef: 0.0097\n",
      "Epoch 259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7560 - dice_coef: 0.7560 - val_loss: -0.0201 - val_dice_coef: 0.0201\n",
      "Epoch 260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7627 - dice_coef: 0.7627 - val_loss: -0.0293 - val_dice_coef: 0.0293\n",
      "Epoch 261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7637 - dice_coef: 0.7637 - val_loss: -0.0101 - val_dice_coef: 0.0101\n",
      "Epoch 262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7538 - dice_coef: 0.7538 - val_loss: -0.0205 - val_dice_coef: 0.0205\n",
      "Epoch 263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7650 - dice_coef: 0.7650 - val_loss: -0.0238 - val_dice_coef: 0.0238\n",
      "Epoch 264/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7660 - dice_coef: 0.7660 - val_loss: -0.0292 - val_dice_coef: 0.0292\n",
      "Epoch 265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.0419 - val_dice_coef: 0.0419\n",
      "Epoch 266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7528 - dice_coef: 0.7528 - val_loss: -0.0428 - val_dice_coef: 0.0428\n",
      "Epoch 267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7596 - dice_coef: 0.7596 - val_loss: -0.0121 - val_dice_coef: 0.0121\n",
      "Epoch 268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7546 - dice_coef: 0.7546 - val_loss: -0.0121 - val_dice_coef: 0.0121\n",
      "Epoch 269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7489 - dice_coef: 0.7489 - val_loss: -0.0822 - val_dice_coef: 0.0822\n",
      "Epoch 270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7523 - dice_coef: 0.7523 - val_loss: -0.0180 - val_dice_coef: 0.0180\n",
      "Epoch 271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7621 - dice_coef: 0.7621 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7515 - dice_coef: 0.7515 - val_loss: -0.0182 - val_dice_coef: 0.0182\n",
      "Epoch 273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7665 - dice_coef: 0.7665 - val_loss: -0.1468 - val_dice_coef: 0.1468\n",
      "Epoch 274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7493 - dice_coef: 0.7493 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7508 - dice_coef: 0.7508 - val_loss: -0.0054 - val_dice_coef: 0.0054\n",
      "Epoch 276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7320 - dice_coef: 0.7320 - val_loss: -0.0317 - val_dice_coef: 0.0317\n",
      "Epoch 277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7667 - dice_coef: 0.7667 - val_loss: -0.0886 - val_dice_coef: 0.0886\n",
      "Epoch 278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7651 - dice_coef: 0.7651 - val_loss: -0.0332 - val_dice_coef: 0.0332\n",
      "Epoch 279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7680 - dice_coef: 0.7680 - val_loss: -0.0117 - val_dice_coef: 0.0117\n",
      "Epoch 280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7641 - dice_coef: 0.7641 - val_loss: -0.0450 - val_dice_coef: 0.0450\n",
      "Epoch 281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7727 - dice_coef: 0.7727 - val_loss: -0.0529 - val_dice_coef: 0.0529\n",
      "Epoch 282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7684 - dice_coef: 0.7684 - val_loss: -0.0181 - val_dice_coef: 0.0181\n",
      "Epoch 283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7581 - dice_coef: 0.7581 - val_loss: -0.0128 - val_dice_coef: 0.0128\n",
      "Epoch 284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7690 - dice_coef: 0.7690 - val_loss: -0.1661 - val_dice_coef: 0.1661\n",
      "Epoch 285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7511 - dice_coef: 0.7511 - val_loss: -0.0575 - val_dice_coef: 0.0575\n",
      "Epoch 286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7490 - dice_coef: 0.7490 - val_loss: -0.0060 - val_dice_coef: 0.0060\n",
      "Epoch 287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7464 - dice_coef: 0.7464 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7570 - dice_coef: 0.7570 - val_loss: -0.1159 - val_dice_coef: 0.1159\n",
      "Epoch 289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7589 - dice_coef: 0.7589 - val_loss: -0.0304 - val_dice_coef: 0.0304\n",
      "Epoch 290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7723 - dice_coef: 0.7723 - val_loss: -0.0227 - val_dice_coef: 0.0227\n",
      "Epoch 291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.1234 - val_dice_coef: 0.1234\n",
      "Epoch 292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7605 - dice_coef: 0.7605 - val_loss: -0.0438 - val_dice_coef: 0.0438\n",
      "Epoch 293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7657 - dice_coef: 0.7657 - val_loss: -0.0111 - val_dice_coef: 0.0111\n",
      "Epoch 294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7631 - dice_coef: 0.7631 - val_loss: -0.0315 - val_dice_coef: 0.0315\n",
      "Epoch 295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7672 - dice_coef: 0.7672 - val_loss: -0.1202 - val_dice_coef: 0.1202\n",
      "Epoch 296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7644 - dice_coef: 0.7644 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7772 - dice_coef: 0.7772 - val_loss: -0.0368 - val_dice_coef: 0.0368\n",
      "Epoch 298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7811 - dice_coef: 0.7811 - val_loss: -0.0406 - val_dice_coef: 0.0406\n",
      "Epoch 299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7793 - dice_coef: 0.7793 - val_loss: -0.0366 - val_dice_coef: 0.0366\n",
      "Epoch 300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7765 - dice_coef: 0.7765 - val_loss: -0.0462 - val_dice_coef: 0.0462\n",
      "Epoch 301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7801 - dice_coef: 0.7801 - val_loss: -0.0380 - val_dice_coef: 0.0380\n",
      "Epoch 302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7843 - dice_coef: 0.7843 - val_loss: -0.0308 - val_dice_coef: 0.0308\n",
      "Epoch 303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.0704 - val_dice_coef: 0.0704\n",
      "Epoch 304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7836 - dice_coef: 0.7836 - val_loss: -0.0287 - val_dice_coef: 0.0287\n",
      "Epoch 305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7746 - dice_coef: 0.7746 - val_loss: -0.0166 - val_dice_coef: 0.0166\n",
      "Epoch 306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7803 - dice_coef: 0.7803 - val_loss: -0.0775 - val_dice_coef: 0.0775\n",
      "Epoch 307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7800 - dice_coef: 0.7800 - val_loss: -0.1300 - val_dice_coef: 0.1300\n",
      "Epoch 308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7711 - dice_coef: 0.7711 - val_loss: -0.0263 - val_dice_coef: 0.0263\n",
      "Epoch 309/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7825 - dice_coef: 0.7825 - val_loss: -0.0347 - val_dice_coef: 0.0347\n",
      "Epoch 310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7814 - dice_coef: 0.7814 - val_loss: -0.1873 - val_dice_coef: 0.1873\n",
      "Epoch 311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7737 - dice_coef: 0.7737 - val_loss: -0.0234 - val_dice_coef: 0.0234\n",
      "Epoch 312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7865 - dice_coef: 0.7865 - val_loss: -0.0305 - val_dice_coef: 0.0305\n",
      "Epoch 313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7862 - dice_coef: 0.7862 - val_loss: -0.1655 - val_dice_coef: 0.1655\n",
      "Epoch 314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7647 - dice_coef: 0.7647 - val_loss: -0.0500 - val_dice_coef: 0.0500\n",
      "Epoch 315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7715 - dice_coef: 0.7715 - val_loss: -0.0116 - val_dice_coef: 0.0116\n",
      "Epoch 316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7758 - dice_coef: 0.7758 - val_loss: -0.0337 - val_dice_coef: 0.0337\n",
      "Epoch 317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7726 - dice_coef: 0.7726 - val_loss: -0.3706 - val_dice_coef: 0.3706\n",
      "Epoch 318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7635 - dice_coef: 0.7635 - val_loss: -0.0253 - val_dice_coef: 0.0253\n",
      "Epoch 319/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7743 - dice_coef: 0.7743 - val_loss: -0.0220 - val_dice_coef: 0.0220\n",
      "Epoch 320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7790 - dice_coef: 0.7790 - val_loss: -0.3092 - val_dice_coef: 0.3092\n",
      "Epoch 321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7765 - dice_coef: 0.7765 - val_loss: -0.0460 - val_dice_coef: 0.0460\n",
      "Epoch 322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.0553 - val_dice_coef: 0.0553\n",
      "Epoch 323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7894 - dice_coef: 0.7894 - val_loss: -0.0739 - val_dice_coef: 0.0739\n",
      "Epoch 324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7897 - dice_coef: 0.7897 - val_loss: -0.0448 - val_dice_coef: 0.0448\n",
      "Epoch 325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7875 - dice_coef: 0.7875 - val_loss: -0.1956 - val_dice_coef: 0.1956\n",
      "Epoch 326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7813 - dice_coef: 0.7813 - val_loss: -0.0695 - val_dice_coef: 0.0695\n",
      "Epoch 327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7855 - dice_coef: 0.7855 - val_loss: -0.0172 - val_dice_coef: 0.0172\n",
      "Epoch 328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7796 - dice_coef: 0.7796 - val_loss: -0.1357 - val_dice_coef: 0.1357\n",
      "Epoch 329/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.0997 - val_dice_coef: 0.0997\n",
      "Epoch 330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7906 - dice_coef: 0.7906 - val_loss: -0.0891 - val_dice_coef: 0.0891\n",
      "Epoch 331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0921 - val_dice_coef: 0.0921\n",
      "Epoch 332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0405 - val_dice_coef: 0.0405\n",
      "Epoch 333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7855 - dice_coef: 0.7855 - val_loss: -0.0510 - val_dice_coef: 0.0510\n",
      "Epoch 334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7910 - dice_coef: 0.7910 - val_loss: -0.1837 - val_dice_coef: 0.1837\n",
      "Epoch 335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7908 - dice_coef: 0.7908 - val_loss: -0.0455 - val_dice_coef: 0.0455\n",
      "Epoch 336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7915 - dice_coef: 0.7915 - val_loss: -0.0512 - val_dice_coef: 0.0512\n",
      "Epoch 337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7943 - dice_coef: 0.7943 - val_loss: -0.0565 - val_dice_coef: 0.0565\n",
      "Epoch 338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7922 - dice_coef: 0.7922 - val_loss: -0.1822 - val_dice_coef: 0.1822\n",
      "Epoch 339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7888 - dice_coef: 0.7888 - val_loss: -0.1480 - val_dice_coef: 0.1480\n",
      "Epoch 340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0323 - val_dice_coef: 0.0323\n",
      "Epoch 341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7877 - dice_coef: 0.7877 - val_loss: -0.0631 - val_dice_coef: 0.0631\n",
      "Epoch 342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7904 - dice_coef: 0.7904 - val_loss: -0.2945 - val_dice_coef: 0.2945\n",
      "Epoch 343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7871 - dice_coef: 0.7871 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7925 - dice_coef: 0.7925 - val_loss: -0.0235 - val_dice_coef: 0.0235\n",
      "Epoch 345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.2343 - val_dice_coef: 0.2343\n",
      "Epoch 346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7834 - dice_coef: 0.7834 - val_loss: -0.3386 - val_dice_coef: 0.3386\n",
      "Epoch 347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7806 - dice_coef: 0.7806 - val_loss: -0.0261 - val_dice_coef: 0.0261\n",
      "Epoch 348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7710 - dice_coef: 0.7710 - val_loss: -0.0138 - val_dice_coef: 0.0138\n",
      "Epoch 349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7821 - dice_coef: 0.7821 - val_loss: -0.1816 - val_dice_coef: 0.1816\n",
      "Epoch 350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7889 - dice_coef: 0.7889 - val_loss: -0.1050 - val_dice_coef: 0.1050\n",
      "Epoch 351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.0298 - val_dice_coef: 0.0298\n",
      "Epoch 352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0611 - val_dice_coef: 0.0611\n",
      "Epoch 353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7945 - dice_coef: 0.7945 - val_loss: -0.2319 - val_dice_coef: 0.2319\n",
      "Epoch 354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7917 - dice_coef: 0.7917 - val_loss: -0.0280 - val_dice_coef: 0.0280\n",
      "Epoch 355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7923 - dice_coef: 0.7923 - val_loss: -0.0318 - val_dice_coef: 0.0318\n",
      "Epoch 356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7939 - dice_coef: 0.7939 - val_loss: -0.3564 - val_dice_coef: 0.3564\n",
      "Epoch 357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7757 - dice_coef: 0.7757 - val_loss: -0.2784 - val_dice_coef: 0.2784\n",
      "Epoch 358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7842 - dice_coef: 0.7842 - val_loss: -0.0262 - val_dice_coef: 0.0262\n",
      "Epoch 359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7891 - dice_coef: 0.7891 - val_loss: -0.0401 - val_dice_coef: 0.0401\n",
      "Epoch 360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7981 - dice_coef: 0.7981 - val_loss: -0.1451 - val_dice_coef: 0.1451\n",
      "Epoch 361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7965 - dice_coef: 0.7965 - val_loss: -0.1857 - val_dice_coef: 0.1857\n",
      "Epoch 362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7975 - dice_coef: 0.7975 - val_loss: -0.1279 - val_dice_coef: 0.1279\n",
      "Epoch 363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7960 - dice_coef: 0.7960 - val_loss: -0.0669 - val_dice_coef: 0.0669\n",
      "Epoch 364/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7950 - dice_coef: 0.7950 - val_loss: -0.0174 - val_dice_coef: 0.0174\n",
      "Epoch 365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7857 - dice_coef: 0.7857 - val_loss: -0.2840 - val_dice_coef: 0.2840\n",
      "Epoch 366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7901 - dice_coef: 0.7901 - val_loss: -0.1057 - val_dice_coef: 0.1057\n",
      "Epoch 367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7978 - dice_coef: 0.7978 - val_loss: -0.0326 - val_dice_coef: 0.0326\n",
      "Epoch 368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8003 - dice_coef: 0.8003 - val_loss: -0.2679 - val_dice_coef: 0.2679\n",
      "Epoch 369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7977 - dice_coef: 0.7977 - val_loss: -0.0832 - val_dice_coef: 0.0832\n",
      "Epoch 370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7953 - dice_coef: 0.7953 - val_loss: -0.0212 - val_dice_coef: 0.0212\n",
      "Epoch 371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7756 - dice_coef: 0.7756 - val_loss: -0.0832 - val_dice_coef: 0.0832\n",
      "Epoch 372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7952 - dice_coef: 0.7952 - val_loss: -0.2984 - val_dice_coef: 0.2984\n",
      "Epoch 373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7982 - dice_coef: 0.7982 - val_loss: -0.0264 - val_dice_coef: 0.0264\n",
      "Epoch 374/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7899 - dice_coef: 0.7899 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7938 - dice_coef: 0.7938 - val_loss: -0.4212 - val_dice_coef: 0.4212\n",
      "Epoch 376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7856 - dice_coef: 0.7856 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7869 - dice_coef: 0.7869 - val_loss: -0.0200 - val_dice_coef: 0.0200\n",
      "Epoch 378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7932 - dice_coef: 0.7932 - val_loss: -0.1871 - val_dice_coef: 0.1871\n",
      "Epoch 379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8004 - dice_coef: 0.8004 - val_loss: -0.0478 - val_dice_coef: 0.0478\n",
      "Epoch 380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7945 - dice_coef: 0.7945 - val_loss: -0.1252 - val_dice_coef: 0.1252\n",
      "Epoch 381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8001 - dice_coef: 0.8001 - val_loss: -0.0781 - val_dice_coef: 0.0781\n",
      "Epoch 382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8039 - dice_coef: 0.8039 - val_loss: -0.0673 - val_dice_coef: 0.0673\n",
      "Epoch 383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8036 - dice_coef: 0.8036 - val_loss: -0.2480 - val_dice_coef: 0.2480\n",
      "Epoch 384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8073 - dice_coef: 0.8073 - val_loss: -0.1304 - val_dice_coef: 0.1304\n",
      "Epoch 385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.0706 - val_dice_coef: 0.0706\n",
      "Epoch 386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8046 - dice_coef: 0.8046 - val_loss: -0.1223 - val_dice_coef: 0.1223\n",
      "Epoch 387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7970 - dice_coef: 0.7970 - val_loss: -0.0542 - val_dice_coef: 0.0542\n",
      "Epoch 388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.0396 - val_dice_coef: 0.0396\n",
      "Epoch 389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.0432 - val_dice_coef: 0.0432\n",
      "Epoch 390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8010 - dice_coef: 0.8010 - val_loss: -0.0633 - val_dice_coef: 0.0633\n",
      "Epoch 391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7970 - dice_coef: 0.7970 - val_loss: -0.2965 - val_dice_coef: 0.2965\n",
      "Epoch 392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8006 - dice_coef: 0.8006 - val_loss: -0.0632 - val_dice_coef: 0.0632\n",
      "Epoch 393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.0993 - val_dice_coef: 0.0993\n",
      "Epoch 394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8019 - dice_coef: 0.8019 - val_loss: -0.1495 - val_dice_coef: 0.1495\n",
      "Epoch 395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8043 - dice_coef: 0.8043 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.1207 - val_dice_coef: 0.1207\n",
      "Epoch 397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8080 - dice_coef: 0.8080 - val_loss: -0.2400 - val_dice_coef: 0.2400\n",
      "Epoch 398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.0589 - val_dice_coef: 0.0589\n",
      "Epoch 399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7983 - dice_coef: 0.7983 - val_loss: -0.0306 - val_dice_coef: 0.0306\n",
      "Epoch 400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7974 - dice_coef: 0.7974 - val_loss: -0.2292 - val_dice_coef: 0.2292\n",
      "Epoch 401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7948 - dice_coef: 0.7948 - val_loss: -0.1820 - val_dice_coef: 0.1820\n",
      "Epoch 402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.0473 - val_dice_coef: 0.0473\n",
      "Epoch 403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7961 - dice_coef: 0.7961 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8052 - dice_coef: 0.8052 - val_loss: -0.1058 - val_dice_coef: 0.1058\n",
      "Epoch 405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.1093 - val_dice_coef: 0.1093\n",
      "Epoch 407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8056 - dice_coef: 0.8056 - val_loss: -0.1696 - val_dice_coef: 0.1696\n",
      "Epoch 408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7967 - dice_coef: 0.7967 - val_loss: -0.2107 - val_dice_coef: 0.2107\n",
      "Epoch 409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.2258 - val_dice_coef: 0.2258\n",
      "Epoch 410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.0673 - val_dice_coef: 0.0673\n",
      "Epoch 411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8081 - dice_coef: 0.8081 - val_loss: -0.0421 - val_dice_coef: 0.0421\n",
      "Epoch 412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7927 - dice_coef: 0.7927 - val_loss: -0.0356 - val_dice_coef: 0.0356\n",
      "Epoch 413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7405 - dice_coef: 0.7405 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7844 - dice_coef: 0.7844 - val_loss: -0.6107 - val_dice_coef: 0.6107\n",
      "Epoch 415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7791 - dice_coef: 0.7791 - val_loss: -0.0159 - val_dice_coef: 0.0159\n",
      "Epoch 416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7898 - dice_coef: 0.7898 - val_loss: -0.0370 - val_dice_coef: 0.0370\n",
      "Epoch 417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8034 - dice_coef: 0.8034 - val_loss: -0.2351 - val_dice_coef: 0.2351\n",
      "Epoch 418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8086 - dice_coef: 0.8086 - val_loss: -0.1190 - val_dice_coef: 0.1190\n",
      "Epoch 419/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.0477 - val_dice_coef: 0.0477\n",
      "Epoch 420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8046 - dice_coef: 0.8046 - val_loss: -0.2101 - val_dice_coef: 0.2101\n",
      "Epoch 421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8109 - dice_coef: 0.8109 - val_loss: -0.2076 - val_dice_coef: 0.2076\n",
      "Epoch 422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8069 - dice_coef: 0.8069 - val_loss: -0.0993 - val_dice_coef: 0.0993\n",
      "Epoch 423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.0434 - val_dice_coef: 0.0434\n",
      "Epoch 424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8075 - dice_coef: 0.8075 - val_loss: -0.1762 - val_dice_coef: 0.1762\n",
      "Epoch 425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8059 - dice_coef: 0.8059 - val_loss: -0.1748 - val_dice_coef: 0.1748\n",
      "Epoch 426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.0394 - val_dice_coef: 0.0394\n",
      "Epoch 427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8040 - dice_coef: 0.8040 - val_loss: -0.1564 - val_dice_coef: 0.1564\n",
      "Epoch 428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8008 - dice_coef: 0.8008 - val_loss: -0.4271 - val_dice_coef: 0.4271\n",
      "Epoch 429/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7984 - dice_coef: 0.7984 - val_loss: -0.1725 - val_dice_coef: 0.1725\n",
      "Epoch 430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8074 - dice_coef: 0.8074 - val_loss: -0.0370 - val_dice_coef: 0.0370\n",
      "Epoch 431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8131 - dice_coef: 0.8131 - val_loss: -0.1404 - val_dice_coef: 0.1404\n",
      "Epoch 433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8154 - dice_coef: 0.8154 - val_loss: -0.0652 - val_dice_coef: 0.0652\n",
      "Epoch 434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8114 - dice_coef: 0.8114 - val_loss: -0.2139 - val_dice_coef: 0.2139\n",
      "Epoch 435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8117 - dice_coef: 0.8117 - val_loss: -0.1163 - val_dice_coef: 0.1163\n",
      "Epoch 436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8121 - dice_coef: 0.8121 - val_loss: -0.0403 - val_dice_coef: 0.0403\n",
      "Epoch 437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8067 - dice_coef: 0.8067 - val_loss: -0.1288 - val_dice_coef: 0.1288\n",
      "Epoch 438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8150 - dice_coef: 0.8150 - val_loss: -0.1334 - val_dice_coef: 0.1334\n",
      "Epoch 439/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8177 - dice_coef: 0.8177 - val_loss: -0.1014 - val_dice_coef: 0.1014\n",
      "Epoch 440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8152 - dice_coef: 0.8152 - val_loss: -0.2299 - val_dice_coef: 0.2299\n",
      "Epoch 441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.1904 - val_dice_coef: 0.1904\n",
      "Epoch 442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8164 - dice_coef: 0.8164 - val_loss: -0.0625 - val_dice_coef: 0.0625\n",
      "Epoch 443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.1399 - val_dice_coef: 0.1399\n",
      "Epoch 444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8148 - dice_coef: 0.8148 - val_loss: -0.1434 - val_dice_coef: 0.1434\n",
      "Epoch 445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.3043 - val_dice_coef: 0.3043\n",
      "Epoch 446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8101 - dice_coef: 0.8101 - val_loss: -0.0396 - val_dice_coef: 0.0396\n",
      "Epoch 447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8028 - dice_coef: 0.8028 - val_loss: -0.0283 - val_dice_coef: 0.0283\n",
      "Epoch 448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8115 - dice_coef: 0.8115 - val_loss: -0.0963 - val_dice_coef: 0.0963\n",
      "Epoch 449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8078 - dice_coef: 0.8078 - val_loss: -0.4016 - val_dice_coef: 0.4016\n",
      "Epoch 450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.0483 - val_dice_coef: 0.0483\n",
      "Epoch 451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.0221 - val_dice_coef: 0.0221\n",
      "Epoch 452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.1492 - val_dice_coef: 0.1492\n",
      "Epoch 453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8146 - dice_coef: 0.8146 - val_loss: -0.5575 - val_dice_coef: 0.5575\n",
      "Epoch 454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8078 - dice_coef: 0.8078 - val_loss: -0.1795 - val_dice_coef: 0.1795\n",
      "Epoch 455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7962 - dice_coef: 0.7962 - val_loss: -0.0179 - val_dice_coef: 0.0179\n",
      "Epoch 456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.0442 - val_dice_coef: 0.0442\n",
      "Epoch 457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8024 - dice_coef: 0.8024 - val_loss: -0.6116 - val_dice_coef: 0.6116\n",
      "Epoch 458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8017 - dice_coef: 0.8017 - val_loss: -0.3085 - val_dice_coef: 0.3085\n",
      "Epoch 459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8160 - dice_coef: 0.8160 - val_loss: -0.0279 - val_dice_coef: 0.0279\n",
      "Epoch 460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8097 - dice_coef: 0.8097 - val_loss: -0.0992 - val_dice_coef: 0.0992\n",
      "Epoch 461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8141 - dice_coef: 0.8141 - val_loss: -0.5515 - val_dice_coef: 0.5515\n",
      "Epoch 462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8051 - dice_coef: 0.8051 - val_loss: -0.3915 - val_dice_coef: 0.3915\n",
      "Epoch 463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8133 - dice_coef: 0.8133 - val_loss: -0.0291 - val_dice_coef: 0.0291\n",
      "Epoch 464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.1182 - val_dice_coef: 0.1182\n",
      "Epoch 465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8176 - dice_coef: 0.8176 - val_loss: -0.2284 - val_dice_coef: 0.2284\n",
      "Epoch 466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8167 - dice_coef: 0.8167 - val_loss: -0.0484 - val_dice_coef: 0.0484\n",
      "Epoch 467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8147 - dice_coef: 0.8147 - val_loss: -0.1196 - val_dice_coef: 0.1196\n",
      "Epoch 468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.5032 - val_dice_coef: 0.5032\n",
      "Epoch 469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8130 - dice_coef: 0.8130 - val_loss: -0.0393 - val_dice_coef: 0.0393\n",
      "Epoch 470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8060 - dice_coef: 0.8060 - val_loss: -0.0320 - val_dice_coef: 0.0320\n",
      "Epoch 471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8117 - dice_coef: 0.8117 - val_loss: -0.5914 - val_dice_coef: 0.5914\n",
      "Epoch 472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.6983 - val_dice_coef: 0.6983\n",
      "Epoch 473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7959 - dice_coef: 0.7959 - val_loss: -0.0990 - val_dice_coef: 0.0990\n",
      "Epoch 474/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8124 - dice_coef: 0.8124 - val_loss: -0.0336 - val_dice_coef: 0.0336\n",
      "Epoch 475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8132 - dice_coef: 0.8132 - val_loss: -0.4476 - val_dice_coef: 0.4476\n",
      "Epoch 476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.1058 - val_dice_coef: 0.1058\n",
      "Epoch 477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.1145 - val_dice_coef: 0.1145\n",
      "Epoch 478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.2891 - val_dice_coef: 0.2891\n",
      "Epoch 479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8193 - dice_coef: 0.8193 - val_loss: -0.1217 - val_dice_coef: 0.1217\n",
      "Epoch 480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8199 - dice_coef: 0.8199 - val_loss: -0.2064 - val_dice_coef: 0.2064\n",
      "Epoch 481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8178 - dice_coef: 0.8178 - val_loss: -0.2016 - val_dice_coef: 0.2016\n",
      "Epoch 482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8206 - dice_coef: 0.8206 - val_loss: -0.2538 - val_dice_coef: 0.2538\n",
      "Epoch 483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8219 - dice_coef: 0.8219 - val_loss: -0.2956 - val_dice_coef: 0.2956\n",
      "Epoch 484/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8207 - dice_coef: 0.8207 - val_loss: -0.1771 - val_dice_coef: 0.1771\n",
      "Epoch 485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.2624 - val_dice_coef: 0.2624\n",
      "Epoch 486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8105 - dice_coef: 0.8105 - val_loss: -0.4911 - val_dice_coef: 0.4911\n",
      "Epoch 487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8167 - dice_coef: 0.8167 - val_loss: -0.0686 - val_dice_coef: 0.0686\n",
      "Epoch 488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8197 - dice_coef: 0.8197 - val_loss: -0.0760 - val_dice_coef: 0.0760\n",
      "Epoch 489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8223 - dice_coef: 0.8223 - val_loss: -0.0500 - val_dice_coef: 0.0500\n",
      "Epoch 490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8048 - dice_coef: 0.8048 - val_loss: -0.0601 - val_dice_coef: 0.0601\n",
      "Epoch 491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8160 - dice_coef: 0.8160 - val_loss: -0.4535 - val_dice_coef: 0.4535\n",
      "Epoch 492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.2184 - val_dice_coef: 0.2184\n",
      "Epoch 493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0320 - val_dice_coef: 0.0320\n",
      "Epoch 494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7959 - dice_coef: 0.7959 - val_loss: -0.0186 - val_dice_coef: 0.0186\n",
      "Epoch 495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8054 - dice_coef: 0.8054 - val_loss: -0.3697 - val_dice_coef: 0.3697\n",
      "Epoch 496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7997 - dice_coef: 0.7997 - val_loss: -0.7929 - val_dice_coef: 0.7929\n",
      "Epoch 497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.0672 - val_dice_coef: 0.0672\n",
      "Epoch 498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.0293 - val_dice_coef: 0.0293\n",
      "Epoch 499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.9266 - val_dice_coef: 0.9266\n",
      "Epoch 500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7841 - dice_coef: 0.7841 - val_loss: -0.1199 - val_dice_coef: 0.1199\n",
      "Epoch 501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8165 - dice_coef: 0.8165 - val_loss: -0.0417 - val_dice_coef: 0.0417\n",
      "Epoch 502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.4505 - val_dice_coef: 0.4505\n",
      "Epoch 503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8198 - dice_coef: 0.8198 - val_loss: -0.2722 - val_dice_coef: 0.2722\n",
      "Epoch 504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8236 - dice_coef: 0.8236 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8252 - dice_coef: 0.8252 - val_loss: -0.2344 - val_dice_coef: 0.2344\n",
      "Epoch 506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8219 - dice_coef: 0.8219 - val_loss: -0.3935 - val_dice_coef: 0.3935\n",
      "Epoch 507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8250 - dice_coef: 0.8250 - val_loss: -0.0641 - val_dice_coef: 0.0641\n",
      "Epoch 508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.4545 - val_dice_coef: 0.4545\n",
      "Epoch 509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8205 - dice_coef: 0.8205 - val_loss: -0.3286 - val_dice_coef: 0.3286\n",
      "Epoch 510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8140 - dice_coef: 0.8140 - val_loss: -0.1836 - val_dice_coef: 0.1836\n",
      "Epoch 511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8239 - dice_coef: 0.8239 - val_loss: -0.2571 - val_dice_coef: 0.2571\n",
      "Epoch 512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8244 - dice_coef: 0.8244 - val_loss: -0.1180 - val_dice_coef: 0.1180\n",
      "Epoch 513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.2087 - val_dice_coef: 0.2087\n",
      "Epoch 514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8267 - dice_coef: 0.8267 - val_loss: -0.1494 - val_dice_coef: 0.1494\n",
      "Epoch 515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8282 - dice_coef: 0.8282 - val_loss: -0.1149 - val_dice_coef: 0.1149\n",
      "Epoch 516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8282 - dice_coef: 0.8282 - val_loss: -0.4932 - val_dice_coef: 0.4932\n",
      "Epoch 517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8136 - dice_coef: 0.8136 - val_loss: -0.5778 - val_dice_coef: 0.5778\n",
      "Epoch 518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8171 - dice_coef: 0.8171 - val_loss: -0.1004 - val_dice_coef: 0.1004\n",
      "Epoch 519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8237 - dice_coef: 0.8237 - val_loss: -0.1345 - val_dice_coef: 0.1345\n",
      "Epoch 520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.1655 - val_dice_coef: 0.1655\n",
      "Epoch 521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8269 - dice_coef: 0.8269 - val_loss: -0.7545 - val_dice_coef: 0.7545\n",
      "Epoch 522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8210 - dice_coef: 0.8210 - val_loss: -0.3689 - val_dice_coef: 0.3689\n",
      "Epoch 523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.2003 - val_dice_coef: 0.2003\n",
      "Epoch 524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.0712 - val_dice_coef: 0.0712\n",
      "Epoch 525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8176 - dice_coef: 0.8176 - val_loss: -0.0582 - val_dice_coef: 0.0582\n",
      "Epoch 526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8188 - dice_coef: 0.8188 - val_loss: -0.0770 - val_dice_coef: 0.0770\n",
      "Epoch 527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8180 - dice_coef: 0.8180 - val_loss: -0.2046 - val_dice_coef: 0.2046\n",
      "Epoch 528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8192 - dice_coef: 0.8192 - val_loss: -0.9066 - val_dice_coef: 0.9066\n",
      "Epoch 529/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7969 - dice_coef: 0.7969 - val_loss: -0.0630 - val_dice_coef: 0.0630\n",
      "Epoch 530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8100 - dice_coef: 0.8100 - val_loss: -0.0144 - val_dice_coef: 0.0144\n",
      "Epoch 531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.6773 - val_dice_coef: 0.6773\n",
      "Epoch 532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.4786 - val_dice_coef: 0.4786\n",
      "Epoch 533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8136 - dice_coef: 0.8136 - val_loss: -0.0916 - val_dice_coef: 0.0916\n",
      "Epoch 534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8265 - dice_coef: 0.8265 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.2900 - val_dice_coef: 0.2900\n",
      "Epoch 536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8082 - dice_coef: 0.8082 - val_loss: -0.0148 - val_dice_coef: 0.0148\n",
      "Epoch 537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7957 - dice_coef: 0.7957 - val_loss: -0.0460 - val_dice_coef: 0.0460\n",
      "Epoch 538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8138 - dice_coef: 0.8138 - val_loss: -0.7499 - val_dice_coef: 0.7499\n",
      "Epoch 539/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8153 - dice_coef: 0.8153 - val_loss: -0.0671 - val_dice_coef: 0.0671\n",
      "Epoch 540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8169 - dice_coef: 0.8169 - val_loss: -0.0314 - val_dice_coef: 0.0314\n",
      "Epoch 541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8112 - dice_coef: 0.8112 - val_loss: -0.7243 - val_dice_coef: 0.7243\n",
      "Epoch 542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8226 - dice_coef: 0.8226 - val_loss: -0.0891 - val_dice_coef: 0.0891\n",
      "Epoch 543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8200 - dice_coef: 0.8200 - val_loss: -0.0178 - val_dice_coef: 0.0178\n",
      "Epoch 544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.6045 - val_dice_coef: 0.6045\n",
      "Epoch 545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8159 - dice_coef: 0.8159 - val_loss: -0.5087 - val_dice_coef: 0.5087\n",
      "Epoch 546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8215 - dice_coef: 0.8215 - val_loss: -0.1051 - val_dice_coef: 0.1051\n",
      "Epoch 547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8251 - dice_coef: 0.8251 - val_loss: -0.3124 - val_dice_coef: 0.3124\n",
      "Epoch 548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8321 - dice_coef: 0.8321 - val_loss: -0.2700 - val_dice_coef: 0.2700\n",
      "Epoch 549/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8308 - dice_coef: 0.8308 - val_loss: -0.3569 - val_dice_coef: 0.3569\n",
      "Epoch 550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8291 - dice_coef: 0.8291 - val_loss: -0.2589 - val_dice_coef: 0.2589\n",
      "Epoch 551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8312 - dice_coef: 0.8312 - val_loss: -0.4501 - val_dice_coef: 0.4501\n",
      "Epoch 552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8288 - dice_coef: 0.8288 - val_loss: -0.2028 - val_dice_coef: 0.2028\n",
      "Epoch 553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8296 - dice_coef: 0.8296 - val_loss: -0.0799 - val_dice_coef: 0.0799\n",
      "Epoch 554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8302 - dice_coef: 0.8302 - val_loss: -0.5327 - val_dice_coef: 0.5327\n",
      "Epoch 555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8187 - dice_coef: 0.8187 - val_loss: -0.6675 - val_dice_coef: 0.6675\n",
      "Epoch 556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.1430 - val_dice_coef: 0.1430\n",
      "Epoch 557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.2106 - val_dice_coef: 0.2106\n",
      "Epoch 558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.2974 - val_dice_coef: 0.2974\n",
      "Epoch 559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8298 - dice_coef: 0.8298 - val_loss: -0.4039 - val_dice_coef: 0.4039\n",
      "Epoch 560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8331 - dice_coef: 0.8331 - val_loss: -0.6531 - val_dice_coef: 0.6531\n",
      "Epoch 561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.2544 - val_dice_coef: 0.2544\n",
      "Epoch 562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.0751 - val_dice_coef: 0.0751\n",
      "Epoch 563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.2586 - val_dice_coef: 0.2586\n",
      "Epoch 564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.5444 - val_dice_coef: 0.5444\n",
      "Epoch 565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.1186 - val_dice_coef: 0.1186\n",
      "Epoch 566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8259 - dice_coef: 0.8259 - val_loss: -0.1178 - val_dice_coef: 0.1178\n",
      "Epoch 567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8230 - dice_coef: 0.8230 - val_loss: -0.9145 - val_dice_coef: 0.9145\n",
      "Epoch 568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7752 - dice_coef: 0.7752 - val_loss: -0.6345 - val_dice_coef: 0.6345\n",
      "Epoch 569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7562 - dice_coef: 0.7562 - val_loss: -0.0040 - val_dice_coef: 0.0040\n",
      "Epoch 570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.6895 - dice_coef: 0.6895 - val_loss: -0.1639 - val_dice_coef: 0.1639\n",
      "Epoch 571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7304 - dice_coef: 0.7304 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7258 - dice_coef: 0.7258 - val_loss: -0.0027 - val_dice_coef: 0.0027\n",
      "Epoch 573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7116 - dice_coef: 0.7116 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7699 - dice_coef: 0.7699 - val_loss: -0.0039 - val_dice_coef: 0.0039\n",
      "Epoch 575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7622 - dice_coef: 0.7622 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7658 - dice_coef: 0.7658 - val_loss: -0.0136 - val_dice_coef: 0.0136\n",
      "Epoch 577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7974 - dice_coef: 0.7974 - val_loss: -0.9098 - val_dice_coef: 0.9098\n",
      "Epoch 578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8113 - dice_coef: 0.8113 - val_loss: -0.0898 - val_dice_coef: 0.0898\n",
      "Epoch 579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.2365 - val_dice_coef: 0.2365\n",
      "Epoch 580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8177 - dice_coef: 0.8177 - val_loss: -0.6985 - val_dice_coef: 0.6985\n",
      "Epoch 581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8187 - dice_coef: 0.8187 - val_loss: -0.0752 - val_dice_coef: 0.0752\n",
      "Epoch 582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8180 - dice_coef: 0.8180 - val_loss: -0.7295 - val_dice_coef: 0.7295\n",
      "Epoch 583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.3519 - val_dice_coef: 0.3519\n",
      "Epoch 584/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.1809 - val_dice_coef: 0.1809\n",
      "Epoch 585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8238 - dice_coef: 0.8238 - val_loss: -0.6086 - val_dice_coef: 0.6086\n",
      "Epoch 586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8228 - dice_coef: 0.8228 - val_loss: -0.0682 - val_dice_coef: 0.0682\n",
      "Epoch 587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.3823 - val_dice_coef: 0.3823\n",
      "Epoch 588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8308 - dice_coef: 0.8308 - val_loss: -0.4799 - val_dice_coef: 0.4799\n",
      "Epoch 589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.1169 - val_dice_coef: 0.1169\n",
      "Epoch 590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8199 - dice_coef: 0.8199 - val_loss: -0.3753 - val_dice_coef: 0.3753\n",
      "Epoch 591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.4125 - val_dice_coef: 0.4125\n",
      "Epoch 592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8271 - dice_coef: 0.8271 - val_loss: -0.0345 - val_dice_coef: 0.0345\n",
      "Epoch 593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.6504 - val_dice_coef: 0.6504\n",
      "Epoch 594/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.3559 - val_dice_coef: 0.3559\n",
      "Epoch 595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8261 - dice_coef: 0.8261 - val_loss: -0.1354 - val_dice_coef: 0.1354\n",
      "Epoch 596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8276 - dice_coef: 0.8276 - val_loss: -0.6209 - val_dice_coef: 0.6209\n",
      "Epoch 597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8263 - dice_coef: 0.8263 - val_loss: -0.6462 - val_dice_coef: 0.6462\n",
      "Epoch 598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.2361 - val_dice_coef: 0.2361\n",
      "Epoch 599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.4628 - val_dice_coef: 0.4628\n",
      "Epoch 600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8351 - dice_coef: 0.8351 - val_loss: -0.3246 - val_dice_coef: 0.3246\n",
      "Epoch 601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.2202 - val_dice_coef: 0.2202\n",
      "Epoch 602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8328 - dice_coef: 0.8328 - val_loss: -0.2158 - val_dice_coef: 0.2158\n",
      "Epoch 603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.3146 - val_dice_coef: 0.3146\n",
      "Epoch 604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.6112 - val_dice_coef: 0.6112\n",
      "Epoch 605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8333 - dice_coef: 0.8333 - val_loss: -0.2770 - val_dice_coef: 0.2770\n",
      "Epoch 606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8330 - dice_coef: 0.8330 - val_loss: -0.1664 - val_dice_coef: 0.1664\n",
      "Epoch 607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.4966 - val_dice_coef: 0.4966\n",
      "Epoch 608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.2649 - val_dice_coef: 0.2649\n",
      "Epoch 609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8364 - dice_coef: 0.8364 - val_loss: -0.5426 - val_dice_coef: 0.5426\n",
      "Epoch 610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.2237 - val_dice_coef: 0.2237\n",
      "Epoch 611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8365 - dice_coef: 0.8365 - val_loss: -0.3087 - val_dice_coef: 0.3087\n",
      "Epoch 612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8360 - dice_coef: 0.8360 - val_loss: -0.6877 - val_dice_coef: 0.6877\n",
      "Epoch 613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8360 - dice_coef: 0.8360 - val_loss: -0.2832 - val_dice_coef: 0.2832\n",
      "Epoch 614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8373 - dice_coef: 0.8373 - val_loss: -0.2565 - val_dice_coef: 0.2565\n",
      "Epoch 615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8374 - dice_coef: 0.8374 - val_loss: -0.4029 - val_dice_coef: 0.4029\n",
      "Epoch 616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8396 - dice_coef: 0.8396 - val_loss: -0.4864 - val_dice_coef: 0.4864\n",
      "Epoch 617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8393 - dice_coef: 0.8393 - val_loss: -0.3034 - val_dice_coef: 0.3034\n",
      "Epoch 618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.2535 - val_dice_coef: 0.2535\n",
      "Epoch 619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.2476 - val_dice_coef: 0.2476\n",
      "Epoch 620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.6186 - val_dice_coef: 0.6186\n",
      "Epoch 621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.4832 - val_dice_coef: 0.4832\n",
      "Epoch 622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8194 - dice_coef: 0.8194 - val_loss: -0.0482 - val_dice_coef: 0.0482\n",
      "Epoch 623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8163 - dice_coef: 0.8163 - val_loss: -0.0297 - val_dice_coef: 0.0297\n",
      "Epoch 624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8084 - dice_coef: 0.8084 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7976 - dice_coef: 0.7976 - val_loss: -0.0325 - val_dice_coef: 0.0325\n",
      "Epoch 626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8020 - dice_coef: 0.8020 - val_loss: -0.0371 - val_dice_coef: 0.0371\n",
      "Epoch 627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8027 - dice_coef: 0.8027 - val_loss: -0.9913 - val_dice_coef: 0.9913\n",
      "Epoch 628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8093 - dice_coef: 0.8093 - val_loss: -0.0275 - val_dice_coef: 0.0275\n",
      "Epoch 629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8198 - dice_coef: 0.8198 - val_loss: -0.6022 - val_dice_coef: 0.6022\n",
      "Epoch 630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8278 - dice_coef: 0.8278 - val_loss: -0.3513 - val_dice_coef: 0.3513\n",
      "Epoch 631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.2364 - val_dice_coef: 0.2364\n",
      "Epoch 632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.5728 - val_dice_coef: 0.5728\n",
      "Epoch 633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8370 - dice_coef: 0.8370 - val_loss: -0.6481 - val_dice_coef: 0.6481\n",
      "Epoch 634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.2212 - val_dice_coef: 0.2212\n",
      "Epoch 635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8379 - dice_coef: 0.8379 - val_loss: -0.5144 - val_dice_coef: 0.5144\n",
      "Epoch 636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.3816 - val_dice_coef: 0.3816\n",
      "Epoch 637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.3823 - val_dice_coef: 0.3823\n",
      "Epoch 638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8392 - dice_coef: 0.8392 - val_loss: -0.3142 - val_dice_coef: 0.3142\n",
      "Epoch 639/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.3412 - val_dice_coef: 0.3412\n",
      "Epoch 640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8413 - dice_coef: 0.8413 - val_loss: -0.7510 - val_dice_coef: 0.7510\n",
      "Epoch 641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8342 - dice_coef: 0.8342 - val_loss: -0.5192 - val_dice_coef: 0.5192\n",
      "Epoch 642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8389 - dice_coef: 0.8389 - val_loss: -0.0560 - val_dice_coef: 0.0560\n",
      "Epoch 643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8275 - dice_coef: 0.8275 - val_loss: -0.6707 - val_dice_coef: 0.6707\n",
      "Epoch 644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8334 - dice_coef: 0.8334 - val_loss: -0.7639 - val_dice_coef: 0.7639\n",
      "Epoch 645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8363 - dice_coef: 0.8363 - val_loss: -0.4404 - val_dice_coef: 0.4404\n",
      "Epoch 646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.2856 - val_dice_coef: 0.2856\n",
      "Epoch 647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.5237 - val_dice_coef: 0.5237\n",
      "Epoch 648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8352 - dice_coef: 0.8352 - val_loss: -0.7274 - val_dice_coef: 0.7274\n",
      "Epoch 649/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.1787 - val_dice_coef: 0.1787\n",
      "Epoch 650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8377 - dice_coef: 0.8377 - val_loss: -0.3011 - val_dice_coef: 0.3011\n",
      "Epoch 651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.6969 - val_dice_coef: 0.6969\n",
      "Epoch 652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8369 - dice_coef: 0.8369 - val_loss: -0.1611 - val_dice_coef: 0.1611\n",
      "Epoch 653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8373 - dice_coef: 0.8373 - val_loss: -0.4017 - val_dice_coef: 0.4017\n",
      "Epoch 654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.7956 - val_dice_coef: 0.7956\n",
      "Epoch 655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.2720 - val_dice_coef: 0.2720\n",
      "Epoch 656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8399 - dice_coef: 0.8399 - val_loss: -0.3397 - val_dice_coef: 0.3397\n",
      "Epoch 657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8345 - dice_coef: 0.8345 - val_loss: -0.8481 - val_dice_coef: 0.8481\n",
      "Epoch 658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.5583 - val_dice_coef: 0.5583\n",
      "Epoch 659/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.0544 - val_dice_coef: 0.0544\n",
      "Epoch 660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8261 - dice_coef: 0.8261 - val_loss: -0.6444 - val_dice_coef: 0.6444\n",
      "Epoch 661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8272 - dice_coef: 0.8272 - val_loss: -0.7144 - val_dice_coef: 0.7144\n",
      "Epoch 662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8157 - dice_coef: 0.8157 - val_loss: -0.0158 - val_dice_coef: 0.0158\n",
      "Epoch 663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7752 - dice_coef: 0.7752 - val_loss: -0.2079 - val_dice_coef: 0.2079\n",
      "Epoch 664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8077 - dice_coef: 0.8077 - val_loss: -0.6270 - val_dice_coef: 0.6270\n",
      "Epoch 665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8258 - dice_coef: 0.8258 - val_loss: -0.1171 - val_dice_coef: 0.1171\n",
      "Epoch 666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.8650 - val_dice_coef: 0.8650\n",
      "Epoch 667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8395 - dice_coef: 0.8395 - val_loss: -0.6320 - val_dice_coef: 0.6320\n",
      "Epoch 668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8424 - dice_coef: 0.8424 - val_loss: -0.5525 - val_dice_coef: 0.5525\n",
      "Epoch 669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8391 - dice_coef: 0.8391 - val_loss: -0.8774 - val_dice_coef: 0.8774\n",
      "Epoch 670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.5239 - val_dice_coef: 0.5239\n",
      "Epoch 671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.1818 - val_dice_coef: 0.1818\n",
      "Epoch 672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8286 - dice_coef: 0.8286 - val_loss: -0.2185 - val_dice_coef: 0.2185\n",
      "Epoch 673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8309 - dice_coef: 0.8309 - val_loss: -0.9362 - val_dice_coef: 0.9362\n",
      "Epoch 674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.2254 - val_dice_coef: 0.2254\n",
      "Epoch 675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8384 - dice_coef: 0.8384 - val_loss: -0.3132 - val_dice_coef: 0.3132\n",
      "Epoch 676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8433 - dice_coef: 0.8433 - val_loss: -0.8573 - val_dice_coef: 0.8573\n",
      "Epoch 677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.2573 - val_dice_coef: 0.2573\n",
      "Epoch 678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.4857 - val_dice_coef: 0.4857\n",
      "Epoch 679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8445 - dice_coef: 0.8445 - val_loss: -0.7931 - val_dice_coef: 0.7931\n",
      "Epoch 680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8336 - dice_coef: 0.8336 - val_loss: -0.1880 - val_dice_coef: 0.1880\n",
      "Epoch 681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8396 - dice_coef: 0.8396 - val_loss: -0.2356 - val_dice_coef: 0.2356\n",
      "Epoch 682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8431 - dice_coef: 0.8431 - val_loss: -0.7485 - val_dice_coef: 0.7485\n",
      "Epoch 683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8439 - dice_coef: 0.8439 - val_loss: -0.2251 - val_dice_coef: 0.2251\n",
      "Epoch 684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8401 - dice_coef: 0.8401 - val_loss: -0.4985 - val_dice_coef: 0.4985\n",
      "Epoch 685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.7831 - val_dice_coef: 0.7831\n",
      "Epoch 686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.0811 - val_dice_coef: 0.0811\n",
      "Epoch 687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8300 - dice_coef: 0.8300 - val_loss: -0.3282 - val_dice_coef: 0.3282\n",
      "Epoch 688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8425 - dice_coef: 0.8425 - val_loss: -0.8692 - val_dice_coef: 0.8692\n",
      "Epoch 689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8402 - dice_coef: 0.8402 - val_loss: -0.5329 - val_dice_coef: 0.5329\n",
      "Epoch 690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.3908 - val_dice_coef: 0.3908\n",
      "Epoch 691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8451 - dice_coef: 0.8451 - val_loss: -0.7364 - val_dice_coef: 0.7364\n",
      "Epoch 692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.6834 - val_dice_coef: 0.6834\n",
      "Epoch 693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8415 - dice_coef: 0.8415 - val_loss: -0.2906 - val_dice_coef: 0.2906\n",
      "Epoch 694/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8452 - dice_coef: 0.8452 - val_loss: -0.3159 - val_dice_coef: 0.3159\n",
      "Epoch 695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.5617 - val_dice_coef: 0.5617\n",
      "Epoch 696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.6209 - val_dice_coef: 0.6209\n",
      "Epoch 697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.3204 - val_dice_coef: 0.3204\n",
      "Epoch 698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8416 - dice_coef: 0.8416 - val_loss: -0.3793 - val_dice_coef: 0.3793\n",
      "Epoch 699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8408 - dice_coef: 0.8408 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "Epoch 700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.3962 - val_dice_coef: 0.3962\n",
      "Epoch 701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.6602 - val_dice_coef: 0.6602\n",
      "Epoch 702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8473 - dice_coef: 0.8473 - val_loss: -0.6013 - val_dice_coef: 0.6013\n",
      "Epoch 703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.6774 - val_dice_coef: 0.6774\n",
      "Epoch 704/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8363 - dice_coef: 0.8363 - val_loss: -0.5603 - val_dice_coef: 0.5603\n",
      "Epoch 705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8423 - dice_coef: 0.8423 - val_loss: -0.0642 - val_dice_coef: 0.0642\n",
      "Epoch 706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8324 - dice_coef: 0.8324 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8394 - dice_coef: 0.8394 - val_loss: -0.6630 - val_dice_coef: 0.6630\n",
      "Epoch 708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.2338 - val_dice_coef: 0.2338\n",
      "Epoch 709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.5562 - val_dice_coef: 0.5562\n",
      "Epoch 710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8441 - dice_coef: 0.8441 - val_loss: -0.6202 - val_dice_coef: 0.6202\n",
      "Epoch 711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.6704 - val_dice_coef: 0.6704\n",
      "Epoch 712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.6614 - val_dice_coef: 0.6614\n",
      "Epoch 713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.6289 - val_dice_coef: 0.6289\n",
      "Epoch 714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8457 - dice_coef: 0.8457 - val_loss: -0.1529 - val_dice_coef: 0.1529\n",
      "Epoch 715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8384 - dice_coef: 0.8384 - val_loss: -0.1108 - val_dice_coef: 0.1108\n",
      "Epoch 716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.9756 - val_dice_coef: 0.9756\n",
      "Epoch 717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8264 - dice_coef: 0.8264 - val_loss: -0.5430 - val_dice_coef: 0.5430\n",
      "Epoch 718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.1765 - val_dice_coef: 0.1765\n",
      "Epoch 719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.4790 - val_dice_coef: 0.4790\n",
      "Epoch 721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8463 - dice_coef: 0.8463 - val_loss: -0.1548 - val_dice_coef: 0.1548\n",
      "Epoch 722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8418 - dice_coef: 0.8418 - val_loss: -0.9695 - val_dice_coef: 0.9695\n",
      "Epoch 723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8085 - dice_coef: 0.8085 - val_loss: -0.4149 - val_dice_coef: 0.4149\n",
      "Epoch 724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0183 - val_dice_coef: 0.0183\n",
      "Epoch 725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8203 - dice_coef: 0.8203 - val_loss: -0.9363 - val_dice_coef: 0.9363\n",
      "Epoch 726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8116 - dice_coef: 0.8116 - val_loss: -0.1106 - val_dice_coef: 0.1106\n",
      "Epoch 727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.0991 - val_dice_coef: 0.0991\n",
      "Epoch 728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.9815 - val_dice_coef: 0.9815\n",
      "Epoch 729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8367 - dice_coef: 0.8367 - val_loss: -0.4321 - val_dice_coef: 0.4321\n",
      "Epoch 730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8383 - dice_coef: 0.8383 - val_loss: -0.1485 - val_dice_coef: 0.1485\n",
      "Epoch 731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8358 - dice_coef: 0.8358 - val_loss: -0.9855 - val_dice_coef: 0.9855\n",
      "Epoch 732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.1318 - val_dice_coef: 0.1318\n",
      "Epoch 733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8332 - dice_coef: 0.8332 - val_loss: -0.3812 - val_dice_coef: 0.3812\n",
      "Epoch 734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8412 - dice_coef: 0.8412 - val_loss: -0.8816 - val_dice_coef: 0.8816\n",
      "Epoch 735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8430 - dice_coef: 0.8430 - val_loss: -0.3899 - val_dice_coef: 0.3899\n",
      "Epoch 736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.3458 - val_dice_coef: 0.3458\n",
      "Epoch 737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.9369 - val_dice_coef: 0.9369\n",
      "Epoch 738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8434 - dice_coef: 0.8434 - val_loss: -0.3495 - val_dice_coef: 0.3495\n",
      "Epoch 739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8411 - dice_coef: 0.8411 - val_loss: -0.5169 - val_dice_coef: 0.5169\n",
      "Epoch 740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8492 - dice_coef: 0.8492 - val_loss: -0.8756 - val_dice_coef: 0.8756\n",
      "Epoch 741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.5438 - val_dice_coef: 0.5438\n",
      "Epoch 742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.4142 - val_dice_coef: 0.4142\n",
      "Epoch 743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.6685 - val_dice_coef: 0.6685\n",
      "Epoch 744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.8682 - val_dice_coef: 0.8682\n",
      "Epoch 745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8460 - dice_coef: 0.8460 - val_loss: -0.5560 - val_dice_coef: 0.5560\n",
      "Epoch 746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.2725 - val_dice_coef: 0.2725\n",
      "Epoch 747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8489 - dice_coef: 0.8489 - val_loss: -0.6455 - val_dice_coef: 0.6455\n",
      "Epoch 748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.6092 - val_dice_coef: 0.6092\n",
      "Epoch 749/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.2267 - val_dice_coef: 0.2267\n",
      "Epoch 750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8472 - dice_coef: 0.8472 - val_loss: -0.7079 - val_dice_coef: 0.7079\n",
      "Epoch 751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8482 - dice_coef: 0.8482 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8464 - dice_coef: 0.8464 - val_loss: -0.3359 - val_dice_coef: 0.3359\n",
      "Epoch 753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8483 - dice_coef: 0.8483 - val_loss: -0.4852 - val_dice_coef: 0.4852\n",
      "Epoch 754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.8795 - val_dice_coef: 0.8795\n",
      "Epoch 755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.6648 - val_dice_coef: 0.6648\n",
      "Epoch 756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8470 - dice_coef: 0.8470 - val_loss: -0.2681 - val_dice_coef: 0.2681\n",
      "Epoch 757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.6538 - val_dice_coef: 0.6538\n",
      "Epoch 758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.7737 - val_dice_coef: 0.7737\n",
      "Epoch 759/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8458 - dice_coef: 0.8458 - val_loss: -0.5625 - val_dice_coef: 0.5625\n",
      "Epoch 760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.7626 - val_dice_coef: 0.7626\n",
      "Epoch 761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8480 - dice_coef: 0.8480 - val_loss: -0.6463 - val_dice_coef: 0.6463\n",
      "Epoch 762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.2825 - val_dice_coef: 0.2825\n",
      "Epoch 763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.4971 - val_dice_coef: 0.4971\n",
      "Epoch 764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.6287 - val_dice_coef: 0.6287\n",
      "Epoch 765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.6401 - val_dice_coef: 0.6401\n",
      "Epoch 766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.6936 - val_dice_coef: 0.6936\n",
      "Epoch 767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.4167 - val_dice_coef: 0.4167\n",
      "Epoch 768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.4295 - val_dice_coef: 0.4295\n",
      "Epoch 769/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.7763 - val_dice_coef: 0.7763\n",
      "Epoch 770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8509 - dice_coef: 0.8509 - val_loss: -0.8231 - val_dice_coef: 0.8231\n",
      "Epoch 771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8507 - dice_coef: 0.8507 - val_loss: -0.7932 - val_dice_coef: 0.7932\n",
      "Epoch 772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.3768 - val_dice_coef: 0.3768\n",
      "Epoch 773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.4115 - val_dice_coef: 0.4115\n",
      "Epoch 774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.5884 - val_dice_coef: 0.5884\n",
      "Epoch 775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8531 - dice_coef: 0.8531 - val_loss: -0.6688 - val_dice_coef: 0.6688\n",
      "Epoch 776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.8369 - val_dice_coef: 0.8369\n",
      "Epoch 777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.6895 - val_dice_coef: 0.6895\n",
      "Epoch 778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8514 - dice_coef: 0.8514 - val_loss: -0.6263 - val_dice_coef: 0.6263\n",
      "Epoch 779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.4246 - val_dice_coef: 0.4246\n",
      "Epoch 780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.3193 - val_dice_coef: 0.3193\n",
      "Epoch 781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.6160 - val_dice_coef: 0.6160\n",
      "Epoch 782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9589 - val_dice_coef: 0.9589\n",
      "Epoch 783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8368 - dice_coef: 0.8368 - val_loss: -0.8186 - val_dice_coef: 0.8186\n",
      "Epoch 784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8436 - dice_coef: 0.8436 - val_loss: -0.1388 - val_dice_coef: 0.1388\n",
      "Epoch 785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8456 - dice_coef: 0.8456 - val_loss: -0.3074 - val_dice_coef: 0.3074\n",
      "Epoch 786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.9070 - val_dice_coef: 0.9070\n",
      "Epoch 787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8455 - dice_coef: 0.8455 - val_loss: -0.8317 - val_dice_coef: 0.8317\n",
      "Epoch 788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.5644 - val_dice_coef: 0.5644\n",
      "Epoch 789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8536 - dice_coef: 0.8536 - val_loss: -0.3972 - val_dice_coef: 0.3972\n",
      "Epoch 790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.4738 - val_dice_coef: 0.4738\n",
      "Epoch 791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8553 - dice_coef: 0.8553 - val_loss: -0.6124 - val_dice_coef: 0.6124\n",
      "Epoch 792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8535 - dice_coef: 0.8535 - val_loss: -0.9356 - val_dice_coef: 0.9356\n",
      "Epoch 793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8499 - dice_coef: 0.8499 - val_loss: -0.7161 - val_dice_coef: 0.7161\n",
      "Epoch 794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.1549 - val_dice_coef: 0.1549\n",
      "Epoch 795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8453 - dice_coef: 0.8453 - val_loss: -0.2801 - val_dice_coef: 0.2801\n",
      "Epoch 796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8504 - dice_coef: 0.8504 - val_loss: -0.5559 - val_dice_coef: 0.5559\n",
      "Epoch 797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8556 - dice_coef: 0.8556 - val_loss: -0.8554 - val_dice_coef: 0.8554\n",
      "Epoch 798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8528 - dice_coef: 0.8528 - val_loss: -0.3655 - val_dice_coef: 0.3655\n",
      "Epoch 799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.1151 - val_dice_coef: 0.1151\n",
      "Epoch 800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8386 - dice_coef: 0.8386 - val_loss: -0.2047 - val_dice_coef: 0.2047\n",
      "Epoch 801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8404 - dice_coef: 0.8404 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8109 - dice_coef: 0.8109 - val_loss: -0.9355 - val_dice_coef: 0.9355\n",
      "Epoch 803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8212 - dice_coef: 0.8212 - val_loss: -0.0244 - val_dice_coef: 0.0244\n",
      "Epoch 804/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8173 - dice_coef: 0.8173 - val_loss: -0.3989 - val_dice_coef: 0.3989\n",
      "Epoch 805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8277 - dice_coef: 0.8277 - val_loss: -0.8731 - val_dice_coef: 0.8731\n",
      "Epoch 806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8146 - dice_coef: 0.8146 - val_loss: -0.0170 - val_dice_coef: 0.0170\n",
      "Epoch 807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8062 - dice_coef: 0.8062 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.1861 - val_dice_coef: 0.1861\n",
      "Epoch 809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8280 - dice_coef: 0.8280 - val_loss: -0.1426 - val_dice_coef: 0.1426\n",
      "Epoch 810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8269 - dice_coef: 0.8269 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8307 - dice_coef: 0.8307 - val_loss: -0.4603 - val_dice_coef: 0.4603\n",
      "Epoch 812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8461 - dice_coef: 0.8461 - val_loss: -0.5005 - val_dice_coef: 0.5005\n",
      "Epoch 813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8460 - dice_coef: 0.8460 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 814/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.6413 - val_dice_coef: 0.6413\n",
      "Epoch 815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8526 - dice_coef: 0.8526 - val_loss: -0.6075 - val_dice_coef: 0.6075\n",
      "Epoch 816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.8333 - val_dice_coef: 0.8333\n",
      "Epoch 817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.4402 - val_dice_coef: 0.4402\n",
      "Epoch 818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.4477 - val_dice_coef: 0.4477\n",
      "Epoch 819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8514 - dice_coef: 0.8514 - val_loss: -0.9301 - val_dice_coef: 0.9301\n",
      "Epoch 820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.3854 - val_dice_coef: 0.3854\n",
      "Epoch 821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8519 - dice_coef: 0.8519 - val_loss: -0.6451 - val_dice_coef: 0.6451\n",
      "Epoch 822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8548 - dice_coef: 0.8548 - val_loss: -0.8534 - val_dice_coef: 0.8534\n",
      "Epoch 823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.5227 - val_dice_coef: 0.5227\n",
      "Epoch 824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8531 - dice_coef: 0.8531 - val_loss: -0.7357 - val_dice_coef: 0.7357\n",
      "Epoch 825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.8460 - val_dice_coef: 0.8460\n",
      "Epoch 826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8563 - dice_coef: 0.8563 - val_loss: -0.7245 - val_dice_coef: 0.7245\n",
      "Epoch 827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.3914 - val_dice_coef: 0.3914\n",
      "Epoch 828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8482 - dice_coef: 0.8482 - val_loss: -0.7330 - val_dice_coef: 0.7330\n",
      "Epoch 830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.6213 - val_dice_coef: 0.6213\n",
      "Epoch 831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8529 - dice_coef: 0.8529 - val_loss: -0.7375 - val_dice_coef: 0.7375\n",
      "Epoch 832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8554 - dice_coef: 0.8554 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8388 - dice_coef: 0.8388 - val_loss: -0.6835 - val_dice_coef: 0.6835\n",
      "Epoch 834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.0724 - val_dice_coef: 0.0724\n",
      "Epoch 835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.7645 - val_dice_coef: 0.7645\n",
      "Epoch 836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.9822 - val_dice_coef: 0.9822\n",
      "Epoch 837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8433 - dice_coef: 0.8433 - val_loss: -0.3740 - val_dice_coef: 0.3740\n",
      "Epoch 838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.3880 - val_dice_coef: 0.3880\n",
      "Epoch 839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.9392 - val_dice_coef: 0.9392\n",
      "Epoch 840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.6092 - val_dice_coef: 0.6092\n",
      "Epoch 841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.2208 - val_dice_coef: 0.2208\n",
      "Epoch 842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.9423 - val_dice_coef: 0.9423\n",
      "Epoch 843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8477 - dice_coef: 0.8477 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8536 - dice_coef: 0.8536 - val_loss: -0.2052 - val_dice_coef: 0.2052\n",
      "Epoch 845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.6049 - val_dice_coef: 0.6049\n",
      "Epoch 846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.8703 - val_dice_coef: 0.8703\n",
      "Epoch 847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8554 - dice_coef: 0.8554 - val_loss: -0.6792 - val_dice_coef: 0.6792\n",
      "Epoch 848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.5180 - val_dice_coef: 0.5180\n",
      "Epoch 849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.8877 - val_dice_coef: 0.8877\n",
      "Epoch 850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8568 - dice_coef: 0.8568 - val_loss: -0.8671 - val_dice_coef: 0.8671\n",
      "Epoch 851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8534 - dice_coef: 0.8534 - val_loss: -0.2253 - val_dice_coef: 0.2253\n",
      "Epoch 852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.4381 - val_dice_coef: 0.4381\n",
      "Epoch 853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.9643 - val_dice_coef: 0.9643\n",
      "Epoch 854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -0.6585 - val_dice_coef: 0.6585\n",
      "Epoch 855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8537 - dice_coef: 0.8537 - val_loss: -0.5929 - val_dice_coef: 0.5929\n",
      "Epoch 856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.4989 - val_dice_coef: 0.4989\n",
      "Epoch 857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.8995 - val_dice_coef: 0.8995\n",
      "Epoch 858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.9217 - val_dice_coef: 0.9217\n",
      "Epoch 859/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8558 - dice_coef: 0.8558 - val_loss: -0.2018 - val_dice_coef: 0.2018\n",
      "Epoch 860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.4001 - val_dice_coef: 0.4001\n",
      "Epoch 861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.7284 - val_dice_coef: 0.7284\n",
      "Epoch 863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.3112 - val_dice_coef: 0.3112\n",
      "Epoch 864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8516 - dice_coef: 0.8516 - val_loss: -0.1725 - val_dice_coef: 0.1725\n",
      "Epoch 865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.7859 - val_dice_coef: 0.7859\n",
      "Epoch 866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.7054 - val_dice_coef: 0.7054\n",
      "Epoch 867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.3892 - val_dice_coef: 0.3892\n",
      "Epoch 868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8555 - dice_coef: 0.8555 - val_loss: -0.7265 - val_dice_coef: 0.7265\n",
      "Epoch 869/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8555 - dice_coef: 0.8555 - val_loss: -0.9342 - val_dice_coef: 0.9342\n",
      "Epoch 870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.8625 - val_dice_coef: 0.8625\n",
      "Epoch 871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8576 - dice_coef: 0.8576 - val_loss: -0.6924 - val_dice_coef: 0.6924\n",
      "Epoch 872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8590 - dice_coef: 0.8590 - val_loss: -0.3277 - val_dice_coef: 0.3277\n",
      "Epoch 873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8561 - dice_coef: 0.8561 - val_loss: -0.9711 - val_dice_coef: 0.9711\n",
      "Epoch 874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.7968 - val_dice_coef: 0.7968\n",
      "Epoch 875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8313 - dice_coef: 0.8313 - val_loss: -0.0267 - val_dice_coef: 0.0267\n",
      "Epoch 876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8287 - dice_coef: 0.8287 - val_loss: -0.6550 - val_dice_coef: 0.6550\n",
      "Epoch 877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9616 - val_dice_coef: 0.9616\n",
      "Epoch 878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8542 - dice_coef: 0.8542 - val_loss: -0.4779 - val_dice_coef: 0.4779\n",
      "Epoch 879/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.5987 - val_dice_coef: 0.5987\n",
      "Epoch 880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8575 - dice_coef: 0.8575 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8491 - dice_coef: 0.8491 - val_loss: -0.7415 - val_dice_coef: 0.7415\n",
      "Epoch 882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8557 - dice_coef: 0.8557 - val_loss: -0.3103 - val_dice_coef: 0.3103\n",
      "Epoch 883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9463 - val_dice_coef: 0.9463\n",
      "Epoch 884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8585 - dice_coef: 0.8585 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8585 - dice_coef: 0.8585 - val_loss: -0.6874 - val_dice_coef: 0.6874\n",
      "Epoch 886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.0696 - val_dice_coef: 0.0696\n",
      "Epoch 887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8335 - dice_coef: 0.8335 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "Epoch 888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8458 - dice_coef: 0.8458 - val_loss: -0.9836 - val_dice_coef: 0.9836\n",
      "Epoch 889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.1278 - val_dice_coef: 0.1278\n",
      "Epoch 890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.1465 - val_dice_coef: 0.1465\n",
      "Epoch 891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8288 - dice_coef: 0.8288 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8025 - dice_coef: 0.8025 - val_loss: -0.9762 - val_dice_coef: 0.9762\n",
      "Epoch 893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8296 - dice_coef: 0.8296 - val_loss: -0.0449 - val_dice_coef: 0.0449\n",
      "Epoch 894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8268 - dice_coef: 0.8268 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7870 - dice_coef: 0.7870 - val_loss: -0.5563 - val_dice_coef: 0.5563\n",
      "Epoch 896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.0207 - val_dice_coef: 0.0207\n",
      "Epoch 897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7943 - dice_coef: 0.7943 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7990 - dice_coef: 0.7990 - val_loss: -0.0056 - val_dice_coef: 0.0056\n",
      "Epoch 899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7997 - dice_coef: 0.7997 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8140 - dice_coef: 0.8140 - val_loss: -0.0163 - val_dice_coef: 0.0163\n",
      "Epoch 901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8278 - dice_coef: 0.8278 - val_loss: -0.1731 - val_dice_coef: 0.1731\n",
      "Epoch 903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8410 - dice_coef: 0.8410 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.0969 - val_dice_coef: 0.0969\n",
      "Epoch 905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8331 - dice_coef: 0.8331 - val_loss: -0.9669 - val_dice_coef: 0.9669\n",
      "Epoch 906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8434 - dice_coef: 0.8434 - val_loss: -0.6003 - val_dice_coef: 0.6003\n",
      "Epoch 907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8463 - dice_coef: 0.8463 - val_loss: -0.8600 - val_dice_coef: 0.8600\n",
      "Epoch 908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.4440 - val_dice_coef: 0.4440\n",
      "Epoch 910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8486 - dice_coef: 0.8486 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9277 - val_dice_coef: 0.9277\n",
      "Epoch 913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.9548 - val_dice_coef: 0.9548\n",
      "Epoch 914/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8631 - dice_coef: 0.8631 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9537 - val_dice_coef: 0.9537\n",
      "Epoch 916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9325 - val_dice_coef: 0.9325\n",
      "Epoch 917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.6866 - val_dice_coef: 0.6866\n",
      "Epoch 918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8566 - dice_coef: 0.8566 - val_loss: -0.8557 - val_dice_coef: 0.8557\n",
      "Epoch 919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.7017 - val_dice_coef: 0.7017\n",
      "Epoch 921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8570 - dice_coef: 0.8570 - val_loss: -0.9189 - val_dice_coef: 0.9189\n",
      "Epoch 922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8578 - dice_coef: 0.8578 - val_loss: -0.9010 - val_dice_coef: 0.9010\n",
      "Epoch 923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8594 - dice_coef: 0.8594 - val_loss: -0.9313 - val_dice_coef: 0.9313\n",
      "Epoch 924/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8615 - dice_coef: 0.8615 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.9542 - val_dice_coef: 0.9542\n",
      "Epoch 926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.9186 - val_dice_coef: 0.9186\n",
      "Epoch 927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.9228 - val_dice_coef: 0.9228\n",
      "Epoch 928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8612 - dice_coef: 0.8612 - val_loss: -0.8624 - val_dice_coef: 0.8624\n",
      "Epoch 929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8621 - dice_coef: 0.8621 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8621 - dice_coef: 0.8621 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.9413 - val_dice_coef: 0.9413\n",
      "Epoch 932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8624 - dice_coef: 0.8624 - val_loss: -0.6561 - val_dice_coef: 0.6561\n",
      "Epoch 933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8547 - dice_coef: 0.8547 - val_loss: -0.2725 - val_dice_coef: 0.2725\n",
      "Epoch 936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8480 - dice_coef: 0.8480 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -0.4746 - val_dice_coef: 0.4746\n",
      "Epoch 938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8517 - dice_coef: 0.8517 - val_loss: -0.5272 - val_dice_coef: 0.5272\n",
      "Epoch 939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8533 - dice_coef: 0.8533 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8494 - dice_coef: 0.8494 - val_loss: -0.5573 - val_dice_coef: 0.5573\n",
      "Epoch 941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.8822 - val_dice_coef: 0.8822\n",
      "Epoch 942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.9764 - val_dice_coef: 0.9764\n",
      "Epoch 943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8608 - dice_coef: 0.8608 - val_loss: -0.6972 - val_dice_coef: 0.6972\n",
      "Epoch 944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.9316 - val_dice_coef: 0.9316\n",
      "Epoch 945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.5515 - val_dice_coef: 0.5515\n",
      "Epoch 947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8560 - dice_coef: 0.8560 - val_loss: -0.7683 - val_dice_coef: 0.7683\n",
      "Epoch 948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8602 - dice_coef: 0.8602 - val_loss: -0.9385 - val_dice_coef: 0.9385\n",
      "Epoch 949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.8939 - val_dice_coef: 0.8939\n",
      "Epoch 950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.8332 - val_dice_coef: 0.8332\n",
      "Epoch 951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8623 - dice_coef: 0.8623 - val_loss: -0.7924 - val_dice_coef: 0.7924\n",
      "Epoch 952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.8816 - val_dice_coef: 0.8816\n",
      "Epoch 954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.9252 - val_dice_coef: 0.9252\n",
      "Epoch 955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9265 - val_dice_coef: 0.9265\n",
      "Epoch 956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.8976 - val_dice_coef: 0.8976\n",
      "Epoch 957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8627 - dice_coef: 0.8627 - val_loss: -0.9492 - val_dice_coef: 0.9492\n",
      "Epoch 958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8616 - dice_coef: 0.8616 - val_loss: -0.9407 - val_dice_coef: 0.9407\n",
      "Epoch 959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.8555 - val_dice_coef: 0.8555\n",
      "Epoch 960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8579 - dice_coef: 0.8579 - val_loss: -0.8050 - val_dice_coef: 0.8050\n",
      "Epoch 961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8629 - dice_coef: 0.8629 - val_loss: -0.8673 - val_dice_coef: 0.8673\n",
      "Epoch 962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.8563 - val_dice_coef: 0.8563\n",
      "Epoch 963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8538 - dice_coef: 0.8538 - val_loss: -0.2059 - val_dice_coef: 0.2059\n",
      "Epoch 964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.9696 - val_dice_coef: 0.9696\n",
      "Epoch 965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8543 - dice_coef: 0.8543 - val_loss: -0.9292 - val_dice_coef: 0.9292\n",
      "Epoch 966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8556 - dice_coef: 0.8556 - val_loss: -0.3905 - val_dice_coef: 0.3905\n",
      "Epoch 967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8597 - dice_coef: 0.8597 - val_loss: -0.6444 - val_dice_coef: 0.6444\n",
      "Epoch 968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8627 - dice_coef: 0.8627 - val_loss: -0.9868 - val_dice_coef: 0.9868\n",
      "Epoch 969/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -0.9687 - val_dice_coef: 0.9687\n",
      "Epoch 970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8599 - dice_coef: 0.8599 - val_loss: -0.7404 - val_dice_coef: 0.7404\n",
      "Epoch 971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.8665 - val_dice_coef: 0.8665\n",
      "Epoch 972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8541 - dice_coef: 0.8541 - val_loss: -0.1268 - val_dice_coef: 0.1268\n",
      "Epoch 974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.8072 - val_dice_coef: 0.8072\n",
      "Epoch 975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.9781 - val_dice_coef: 0.9781\n",
      "Epoch 976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8661 - dice_coef: 0.8661 - val_loss: -0.6156 - val_dice_coef: 0.6156\n",
      "Epoch 977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8617 - dice_coef: 0.8617 - val_loss: -0.9634 - val_dice_coef: 0.9634\n",
      "Epoch 978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8646 - dice_coef: 0.8646 - val_loss: -0.9197 - val_dice_coef: 0.9197\n",
      "Epoch 979/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.6328 - val_dice_coef: 0.6328\n",
      "Epoch 980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.8507 - val_dice_coef: 0.8507\n",
      "Epoch 981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8634 - dice_coef: 0.8634 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.7881 - val_dice_coef: 0.7881\n",
      "Epoch 983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8595 - dice_coef: 0.8595 - val_loss: -0.9413 - val_dice_coef: 0.9413\n",
      "Epoch 984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8638 - dice_coef: 0.8638 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8649 - dice_coef: 0.8649 - val_loss: -0.5486 - val_dice_coef: 0.5486\n",
      "Epoch 986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8647 - dice_coef: 0.8647 - val_loss: -0.9300 - val_dice_coef: 0.9300\n",
      "Epoch 988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.8817 - val_dice_coef: 0.8817\n",
      "Epoch 989/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.8006 - val_dice_coef: 0.8006\n",
      "Epoch 990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.7084 - val_dice_coef: 0.7084\n",
      "Epoch 991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8947 - val_dice_coef: 0.8947\n",
      "Epoch 992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9819 - val_dice_coef: 0.9819\n",
      "Epoch 993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8613 - dice_coef: 0.8613 - val_loss: -0.8766 - val_dice_coef: 0.8766\n",
      "Epoch 994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.5579 - val_dice_coef: 0.5579\n",
      "Epoch 995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8679 - dice_coef: 0.8679 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8581 - dice_coef: 0.8581 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8583 - dice_coef: 0.8583 - val_loss: -0.7333 - val_dice_coef: 0.7333\n",
      "Epoch 998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.4334 - val_dice_coef: 0.4334\n",
      "Epoch 999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8604 - dice_coef: 0.8604 - val_loss: -0.8550 - val_dice_coef: 0.8550\n",
      "Epoch 1000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.9571 - val_dice_coef: 0.9571\n",
      "Epoch 1001/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8622 - dice_coef: 0.8622 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 1002/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8472 - dice_coef: 0.8472 - val_loss: -0.0536 - val_dice_coef: 0.0536\n",
      "Epoch 1003/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8317 - dice_coef: 0.8317 - val_loss: -0.1666 - val_dice_coef: 0.1666\n",
      "Epoch 1004/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8362 - dice_coef: 0.8362 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1005/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.1120 - val_dice_coef: 0.1120\n",
      "Epoch 1006/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8338 - dice_coef: 0.8338 - val_loss: -0.6016 - val_dice_coef: 0.6016\n",
      "Epoch 1007/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8502 - dice_coef: 0.8502 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1008/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8382 - dice_coef: 0.8382 - val_loss: -0.0098 - val_dice_coef: 0.0098\n",
      "Epoch 1009/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.7742 - dice_coef: 0.7742 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1010/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8097 - dice_coef: 0.8097 - val_loss: -0.6957 - val_dice_coef: 0.6957\n",
      "Epoch 1011/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8291 - dice_coef: 0.8291 - val_loss: -0.0575 - val_dice_coef: 0.0575\n",
      "Epoch 1012/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1013/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.3387 - val_dice_coef: 0.3387\n",
      "Epoch 1014/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8446 - dice_coef: 0.8446 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 1015/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8405 - dice_coef: 0.8405 - val_loss: -0.9880 - val_dice_coef: 0.9880\n",
      "Epoch 1016/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8426 - dice_coef: 0.8426 - val_loss: -0.0397 - val_dice_coef: 0.0397\n",
      "Epoch 1017/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1018/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.4361 - val_dice_coef: 0.4361\n",
      "Epoch 1019/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8579 - dice_coef: 0.8579 - val_loss: -0.8517 - val_dice_coef: 0.8517\n",
      "Epoch 1020/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8610 - dice_coef: 0.8610 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 1021/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8625 - dice_coef: 0.8625 - val_loss: -0.6310 - val_dice_coef: 0.6310\n",
      "Epoch 1022/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8658 - dice_coef: 0.8658 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1023/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8412 - dice_coef: 0.8412 - val_loss: -0.5694 - val_dice_coef: 0.5694\n",
      "Epoch 1024/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8487 - dice_coef: 0.8487 - val_loss: -0.1939 - val_dice_coef: 0.1939\n",
      "Epoch 1025/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8591 - dice_coef: 0.8591 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1026/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.5309 - val_dice_coef: 0.5309\n",
      "Epoch 1027/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8594 - dice_coef: 0.8594 - val_loss: -0.8949 - val_dice_coef: 0.8949\n",
      "Epoch 1028/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.9792 - val_dice_coef: 0.9792\n",
      "Epoch 1029/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8665 - dice_coef: 0.8665 - val_loss: -0.7203 - val_dice_coef: 0.7203\n",
      "Epoch 1030/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 1031/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8660 - dice_coef: 0.8660 - val_loss: -0.9150 - val_dice_coef: 0.9150\n",
      "Epoch 1032/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8670 - dice_coef: 0.8670 - val_loss: -0.7944 - val_dice_coef: 0.7944\n",
      "Epoch 1033/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.8140 - val_dice_coef: 0.8140\n",
      "Epoch 1034/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.9357 - val_dice_coef: 0.9357\n",
      "Epoch 1035/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.7574 - val_dice_coef: 0.7574\n",
      "Epoch 1036/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8654 - dice_coef: 0.8654 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 1037/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 1038/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8660 - dice_coef: 0.8660 - val_loss: -0.3575 - val_dice_coef: 0.3575\n",
      "Epoch 1039/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8628 - dice_coef: 0.8628 - val_loss: -0.9336 - val_dice_coef: 0.9336\n",
      "Epoch 1040/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 1041/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.8473 - val_dice_coef: 0.8473\n",
      "Epoch 1042/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.6599 - val_dice_coef: 0.6599\n",
      "Epoch 1043/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8600 - dice_coef: 0.8600 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1044/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8666 - dice_coef: 0.8666 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1045/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8676 - dice_coef: 0.8676 - val_loss: -0.6482 - val_dice_coef: 0.6482\n",
      "Epoch 1046/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8639 - dice_coef: 0.8639 - val_loss: -0.6694 - val_dice_coef: 0.6694\n",
      "Epoch 1047/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.9896 - val_dice_coef: 0.9896\n",
      "Epoch 1048/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9164 - val_dice_coef: 0.9164\n",
      "Epoch 1049/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8592 - dice_coef: 0.8592 - val_loss: -0.5549 - val_dice_coef: 0.5549\n",
      "Epoch 1050/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8654 - dice_coef: 0.8654 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 1051/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8705 - dice_coef: 0.8705 - val_loss: -0.9049 - val_dice_coef: 0.9049\n",
      "Epoch 1052/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8694 - dice_coef: 0.8694 - val_loss: -0.9109 - val_dice_coef: 0.9109\n",
      "Epoch 1053/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.8367 - val_dice_coef: 0.8367\n",
      "Epoch 1054/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8696 - dice_coef: 0.8696 - val_loss: -0.9657 - val_dice_coef: 0.9657\n",
      "Epoch 1055/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9415 - val_dice_coef: 0.9415\n",
      "Epoch 1056/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8690 - dice_coef: 0.8690 - val_loss: -0.7286 - val_dice_coef: 0.7286\n",
      "Epoch 1057/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8688 - dice_coef: 0.8688 - val_loss: -0.9478 - val_dice_coef: 0.9478\n",
      "Epoch 1058/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8705 - dice_coef: 0.8705 - val_loss: -0.9559 - val_dice_coef: 0.9559\n",
      "Epoch 1059/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.7451 - val_dice_coef: 0.7451\n",
      "Epoch 1060/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8699 - dice_coef: 0.8699 - val_loss: -0.8512 - val_dice_coef: 0.8512\n",
      "Epoch 1061/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1062/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.9079 - val_dice_coef: 0.9079\n",
      "Epoch 1063/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.7620 - val_dice_coef: 0.7620\n",
      "Epoch 1064/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.7545 - val_dice_coef: 0.7545\n",
      "Epoch 1065/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 1066/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8601 - dice_coef: 0.8601 - val_loss: -0.9141 - val_dice_coef: 0.9141\n",
      "Epoch 1067/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.4374 - val_dice_coef: 0.4374\n",
      "Epoch 1068/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8572 - dice_coef: 0.8572 - val_loss: -0.9088 - val_dice_coef: 0.9088\n",
      "Epoch 1069/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1070/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8502 - dice_coef: 0.8502 - val_loss: -0.0892 - val_dice_coef: 0.0892\n",
      "Epoch 1071/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.3519 - val_dice_coef: 0.3519\n",
      "Epoch 1072/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1073/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.1056 - val_dice_coef: 0.1056\n",
      "Epoch 1074/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.9048 - val_dice_coef: 0.9048\n",
      "Epoch 1075/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8586 - dice_coef: 0.8586 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1076/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8469 - dice_coef: 0.8469 - val_loss: -0.0317 - val_dice_coef: 0.0317\n",
      "Epoch 1077/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8090 - dice_coef: 0.8090 - val_loss: -0.4089 - val_dice_coef: 0.4089\n",
      "Epoch 1078/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1079/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.1518 - val_dice_coef: 0.1518\n",
      "Epoch 1080/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8499 - dice_coef: 0.8499 - val_loss: -0.7791 - val_dice_coef: 0.7791\n",
      "Epoch 1081/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8526 - dice_coef: 0.8526 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1082/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.0804 - val_dice_coef: 0.0804\n",
      "Epoch 1083/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8449 - dice_coef: 0.8449 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 1084/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.8349 - val_dice_coef: 0.8349\n",
      "Epoch 1085/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.1126 - val_dice_coef: 0.1126\n",
      "Epoch 1086/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8385 - dice_coef: 0.8385 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1087/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8254 - dice_coef: 0.8254 - val_loss: -0.5600 - val_dice_coef: 0.5600\n",
      "Epoch 1088/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8609 - dice_coef: 0.8609 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 1089/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8603 - dice_coef: 0.8603 - val_loss: -0.9614 - val_dice_coef: 0.9614\n",
      "Epoch 1090/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8645 - dice_coef: 0.8645 - val_loss: -0.8877 - val_dice_coef: 0.8877\n",
      "Epoch 1091/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 1092/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8304 - val_dice_coef: 0.8304\n",
      "Epoch 1093/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9045 - val_dice_coef: 0.9045\n",
      "Epoch 1094/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1095/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8688 - dice_coef: 0.8688 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "Epoch 1096/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.8798 - val_dice_coef: 0.8798\n",
      "Epoch 1097/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1098/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.6924 - val_dice_coef: 0.6924\n",
      "Epoch 1099/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.9647 - val_dice_coef: 0.9647\n",
      "Epoch 1100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8693 - dice_coef: 0.8693 - val_loss: -0.9751 - val_dice_coef: 0.9751\n",
      "Epoch 1101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8683 - dice_coef: 0.8683 - val_loss: -0.8918 - val_dice_coef: 0.8918\n",
      "Epoch 1102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8741 - dice_coef: 0.8741 - val_loss: -0.9223 - val_dice_coef: 0.9223\n",
      "Epoch 1103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "Epoch 1104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.9560 - val_dice_coef: 0.9560\n",
      "Epoch 1105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8715 - dice_coef: 0.8715 - val_loss: -0.9793 - val_dice_coef: 0.9793\n",
      "Epoch 1106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.7256 - val_dice_coef: 0.7256\n",
      "Epoch 1107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.8245 - val_dice_coef: 0.8245\n",
      "Epoch 1108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8672 - dice_coef: 0.8672 - val_loss: -0.7725 - val_dice_coef: 0.7725\n",
      "Epoch 1110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9215 - val_dice_coef: 0.9215\n",
      "Epoch 1111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8685 - dice_coef: 0.8685 - val_loss: -0.8775 - val_dice_coef: 0.8775\n",
      "Epoch 1113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.9527 - val_dice_coef: 0.9527\n",
      "Epoch 1114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.4950 - val_dice_coef: 0.4950\n",
      "Epoch 1116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8658 - dice_coef: 0.8658 - val_loss: -0.9236 - val_dice_coef: 0.9236\n",
      "Epoch 1117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8686 - dice_coef: 0.8686 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8689 - dice_coef: 0.8689 - val_loss: -0.7843 - val_dice_coef: 0.7843\n",
      "Epoch 1119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.9836 - val_dice_coef: 0.9836\n",
      "Epoch 1120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8718 - dice_coef: 0.8718 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.9663 - val_dice_coef: 0.9663\n",
      "Epoch 1122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8737 - dice_coef: 0.8737 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 1123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.8007 - val_dice_coef: 0.8007\n",
      "Epoch 1124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.9861 - val_dice_coef: 0.9861\n",
      "Epoch 1125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8520 - dice_coef: 0.8520 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8616 - dice_coef: 0.8616 - val_loss: -0.0640 - val_dice_coef: 0.0640\n",
      "Epoch 1127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8467 - dice_coef: 0.8467 - val_loss: -0.8262 - val_dice_coef: 0.8262\n",
      "Epoch 1128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.1988 - val_dice_coef: 0.1988\n",
      "Epoch 1130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8562 - dice_coef: 0.8562 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8604 - dice_coef: 0.8604 - val_loss: -0.7498 - val_dice_coef: 0.7498\n",
      "Epoch 1132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8689 - dice_coef: 0.8689 - val_loss: -0.3435 - val_dice_coef: 0.3435\n",
      "Epoch 1135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8644 - dice_coef: 0.8644 - val_loss: -0.9566 - val_dice_coef: 0.9566\n",
      "Epoch 1136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8607 - dice_coef: 0.8607 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.8013 - val_dice_coef: 0.8013\n",
      "Epoch 1138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.8925 - val_dice_coef: 0.8925\n",
      "Epoch 1139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8708 - dice_coef: 0.8708 - val_loss: -0.9755 - val_dice_coef: 0.9755\n",
      "Epoch 1140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9490 - val_dice_coef: 0.9490\n",
      "Epoch 1141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9386 - val_dice_coef: 0.9386\n",
      "Epoch 1142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.8723 - val_dice_coef: 0.8723\n",
      "Epoch 1143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 1144/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.9019 - val_dice_coef: 0.9019\n",
      "Epoch 1145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.8416 - val_dice_coef: 0.8416\n",
      "Epoch 1146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 1147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 1148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8733 - dice_coef: 0.8733 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9353 - val_dice_coef: 0.9353\n",
      "Epoch 1150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.8787 - val_dice_coef: 0.8787\n",
      "Epoch 1151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9200 - val_dice_coef: 0.9200\n",
      "Epoch 1152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8685 - dice_coef: 0.8685 - val_loss: -0.9765 - val_dice_coef: 0.9765\n",
      "Epoch 1153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8744 - dice_coef: 0.8744 - val_loss: -0.8773 - val_dice_coef: 0.8773\n",
      "Epoch 1154/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.9595 - val_dice_coef: 0.9595\n",
      "Epoch 1155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 1156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.5922 - val_dice_coef: 0.5922\n",
      "Epoch 1158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8651 - dice_coef: 0.8651 - val_loss: -0.7393 - val_dice_coef: 0.7393\n",
      "Epoch 1159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8656 - dice_coef: 0.8656 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 1160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 1161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.4817 - val_dice_coef: 0.4817\n",
      "Epoch 1162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 1163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 1164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8684 - dice_coef: 0.8684 - val_loss: -0.1108 - val_dice_coef: 0.1108\n",
      "Epoch 1165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8630 - dice_coef: 0.8630 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8624 - dice_coef: 0.8624 - val_loss: -0.9803 - val_dice_coef: 0.9803\n",
      "Epoch 1167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.1844 - val_dice_coef: 0.1844\n",
      "Epoch 1168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 1169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.6831 - val_dice_coef: 0.6831\n",
      "Epoch 1170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -0.5705 - val_dice_coef: 0.5705\n",
      "Epoch 1171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.6655 - val_dice_coef: 0.6655\n",
      "Epoch 1173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.8917 - val_dice_coef: 0.8917\n",
      "Epoch 1174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8692 - dice_coef: 0.8692 - val_loss: -0.9620 - val_dice_coef: 0.9620\n",
      "Epoch 1175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 1176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9668 - val_dice_coef: 0.9668\n",
      "Epoch 1177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8760 - dice_coef: 0.8760 - val_loss: -0.4225 - val_dice_coef: 0.4225\n",
      "Epoch 1178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8568 - dice_coef: 0.8568 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8617 - dice_coef: 0.8617 - val_loss: -0.2472 - val_dice_coef: 0.2472\n",
      "Epoch 1181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8662 - dice_coef: 0.8662 - val_loss: -0.9606 - val_dice_coef: 0.9606\n",
      "Epoch 1182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 1183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.8566 - val_dice_coef: 0.8566\n",
      "Epoch 1184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.7026 - val_dice_coef: 0.7026\n",
      "Epoch 1185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8682 - dice_coef: 0.8682 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "Epoch 1187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9058 - val_dice_coef: 0.9058\n",
      "Epoch 1188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.4322 - val_dice_coef: 0.4322\n",
      "Epoch 1190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.7995 - val_dice_coef: 0.7995\n",
      "Epoch 1191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.9844 - val_dice_coef: 0.9844\n",
      "Epoch 1192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9046 - val_dice_coef: 0.9046\n",
      "Epoch 1193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.5496 - val_dice_coef: 0.5496\n",
      "Epoch 1194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8648 - dice_coef: 0.8648 - val_loss: -0.9909 - val_dice_coef: 0.9909\n",
      "Epoch 1195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8710 - dice_coef: 0.8710 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 1196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8450 - dice_coef: 0.8450 - val_loss: -0.0458 - val_dice_coef: 0.0458\n",
      "Epoch 1197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8235 - dice_coef: 0.8235 - val_loss: -0.0956 - val_dice_coef: 0.0956\n",
      "Epoch 1198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8426 - dice_coef: 0.8426 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1199/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.0376 - val_dice_coef: 0.0376\n",
      "Epoch 1200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8468 - dice_coef: 0.8468 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8706 - dice_coef: 0.8706 - val_loss: -0.9591 - val_dice_coef: 0.9591\n",
      "Epoch 1202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8695 - dice_coef: 0.8695 - val_loss: -0.3772 - val_dice_coef: 0.3772\n",
      "Epoch 1203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8635 - dice_coef: 0.8635 - val_loss: -0.8594 - val_dice_coef: 0.8594\n",
      "Epoch 1205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9872 - val_dice_coef: 0.9872\n",
      "Epoch 1206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 1207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.6851 - val_dice_coef: 0.6851\n",
      "Epoch 1208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9956 - val_dice_coef: 0.9956\n",
      "Epoch 1209/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.9248 - val_dice_coef: 0.9248\n",
      "Epoch 1210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -0.5337 - val_dice_coef: 0.5337\n",
      "Epoch 1211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.9769 - val_dice_coef: 0.9769\n",
      "Epoch 1212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8773 - dice_coef: 0.8773 - val_loss: -0.7920 - val_dice_coef: 0.7920\n",
      "Epoch 1213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8748 - dice_coef: 0.8748 - val_loss: -0.9271 - val_dice_coef: 0.9271\n",
      "Epoch 1214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.9746 - val_dice_coef: 0.9746\n",
      "Epoch 1215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8755 - dice_coef: 0.8755 - val_loss: -0.7655 - val_dice_coef: 0.7655\n",
      "Epoch 1216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.8132 - val_dice_coef: 0.8132\n",
      "Epoch 1217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.9755 - val_dice_coef: 0.9755\n",
      "Epoch 1218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9377 - val_dice_coef: 0.9377\n",
      "Epoch 1219/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 1220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9523 - val_dice_coef: 0.9523\n",
      "Epoch 1221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.9513 - val_dice_coef: 0.9513\n",
      "Epoch 1222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9321 - val_dice_coef: 0.9321\n",
      "Epoch 1223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9393 - val_dice_coef: 0.9393\n",
      "Epoch 1224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8780 - dice_coef: 0.8780 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 1225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.9235 - val_dice_coef: 0.9235\n",
      "Epoch 1226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.9359 - val_dice_coef: 0.9359\n",
      "Epoch 1227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9820 - val_dice_coef: 0.9820\n",
      "Epoch 1228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8799 - dice_coef: 0.8799 - val_loss: -0.6893 - val_dice_coef: 0.6893\n",
      "Epoch 1229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 1231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9458 - val_dice_coef: 0.9458\n",
      "Epoch 1232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9079 - val_dice_coef: 0.9079\n",
      "Epoch 1233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8787 - dice_coef: 0.8787 - val_loss: -0.9396 - val_dice_coef: 0.9396\n",
      "Epoch 1234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9063 - val_dice_coef: 0.9063\n",
      "Epoch 1235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8770 - dice_coef: 0.8770 - val_loss: -0.5947 - val_dice_coef: 0.5947\n",
      "Epoch 1238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.9679 - val_dice_coef: 0.9679\n",
      "Epoch 1239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8641 - dice_coef: 0.8641 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 1240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8702 - dice_coef: 0.8702 - val_loss: -0.2189 - val_dice_coef: 0.2189\n",
      "Epoch 1241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.9456 - val_dice_coef: 0.9456\n",
      "Epoch 1242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8687 - dice_coef: 0.8687 - val_loss: -0.4867 - val_dice_coef: 0.4867\n",
      "Epoch 1244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8629 - dice_coef: 0.8629 - val_loss: -0.2168 - val_dice_coef: 0.2168\n",
      "Epoch 1245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8435 - dice_coef: 0.8435 - val_loss: -0.6962 - val_dice_coef: 0.6962\n",
      "Epoch 1247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.1174 - val_dice_coef: 0.1174\n",
      "Epoch 1248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8549 - dice_coef: 0.8549 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.9383 - val_dice_coef: 0.9383\n",
      "Epoch 1250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8724 - dice_coef: 0.8724 - val_loss: -0.5627 - val_dice_coef: 0.5627\n",
      "Epoch 1251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 1253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8777 - dice_coef: 0.8777 - val_loss: -0.7830 - val_dice_coef: 0.7830\n",
      "Epoch 1254/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8775 - dice_coef: 0.8775 - val_loss: -0.9698 - val_dice_coef: 0.9698\n",
      "Epoch 1255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8799 - dice_coef: 0.8799 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.8652 - val_dice_coef: 0.8652\n",
      "Epoch 1257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9314 - val_dice_coef: 0.9314\n",
      "Epoch 1258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8762 - dice_coef: 0.8762 - val_loss: -0.9479 - val_dice_coef: 0.9479\n",
      "Epoch 1261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.8223 - val_dice_coef: 0.8223\n",
      "Epoch 1262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.7438 - val_dice_coef: 0.7438\n",
      "Epoch 1264/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8679 - dice_coef: 0.8679 - val_loss: -0.2187 - val_dice_coef: 0.2187\n",
      "Epoch 1265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8427 - dice_coef: 0.8427 - val_loss: -0.5254 - val_dice_coef: 0.5254\n",
      "Epoch 1267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.0585 - val_dice_coef: 0.0585\n",
      "Epoch 1268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8204 - dice_coef: 0.8204 - val_loss: -0.0653 - val_dice_coef: 0.0653\n",
      "Epoch 1270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.5930 - val_dice_coef: 0.5930\n",
      "Epoch 1271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8598 - dice_coef: 0.8598 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.4535 - val_dice_coef: 0.4535\n",
      "Epoch 1273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8697 - dice_coef: 0.8697 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9800 - val_dice_coef: 0.9800\n",
      "Epoch 1275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.6696 - val_dice_coef: 0.6696\n",
      "Epoch 1276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.9318 - val_dice_coef: 0.9318\n",
      "Epoch 1278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8661 - dice_coef: 0.8661 - val_loss: -0.1610 - val_dice_coef: 0.1610\n",
      "Epoch 1279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8699 - dice_coef: 0.8699 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.7982 - val_dice_coef: 0.7982\n",
      "Epoch 1281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.9349 - val_dice_coef: 0.9349\n",
      "Epoch 1282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8737 - dice_coef: 0.8737 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.8544 - val_dice_coef: 0.8544\n",
      "Epoch 1284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9820 - val_dice_coef: 0.9820\n",
      "Epoch 1285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8794 - dice_coef: 0.8794 - val_loss: -0.7478 - val_dice_coef: 0.7478\n",
      "Epoch 1287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 1288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.7808 - val_dice_coef: 0.7808\n",
      "Epoch 1290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.9448 - val_dice_coef: 0.9448\n",
      "Epoch 1292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.7170 - val_dice_coef: 0.7170\n",
      "Epoch 1293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8739 - dice_coef: 0.8739 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8650 - dice_coef: 0.8650 - val_loss: -0.9073 - val_dice_coef: 0.9073\n",
      "Epoch 1295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.5361 - val_dice_coef: 0.5361\n",
      "Epoch 1296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8763 - dice_coef: 0.8763 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8707 - dice_coef: 0.8707 - val_loss: -0.9063 - val_dice_coef: 0.9063\n",
      "Epoch 1298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8755 - dice_coef: 0.8755 - val_loss: -0.8915 - val_dice_coef: 0.8915\n",
      "Epoch 1299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -0.5298 - val_dice_coef: 0.5298\n",
      "Epoch 1301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8740 - dice_coef: 0.8740 - val_loss: -0.9875 - val_dice_coef: 0.9875\n",
      "Epoch 1302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 1303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.8967 - val_dice_coef: 0.8967\n",
      "Epoch 1304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8749 - dice_coef: 0.8749 - val_loss: -0.9702 - val_dice_coef: 0.9702\n",
      "Epoch 1305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 1306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8818 - dice_coef: 0.8818 - val_loss: -0.7640 - val_dice_coef: 0.7640\n",
      "Epoch 1307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9842 - val_dice_coef: 0.9842\n",
      "Epoch 1309/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8804 - dice_coef: 0.8804 - val_loss: -0.8562 - val_dice_coef: 0.8562\n",
      "Epoch 1310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8779 - dice_coef: 0.8779 - val_loss: -0.8712 - val_dice_coef: 0.8712\n",
      "Epoch 1311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 1313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.7603 - val_dice_coef: 0.7603\n",
      "Epoch 1314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.8932 - val_dice_coef: 0.8932\n",
      "Epoch 1316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8786 - dice_coef: 0.8786 - val_loss: -0.7943 - val_dice_coef: 0.7943\n",
      "Epoch 1317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9017 - val_dice_coef: 0.9017\n",
      "Epoch 1319/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8702 - dice_coef: 0.8702 - val_loss: -0.8048 - val_dice_coef: 0.8048\n",
      "Epoch 1320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 1321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.7515 - val_dice_coef: 0.7515\n",
      "Epoch 1322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.4710 - val_dice_coef: 0.4710\n",
      "Epoch 1323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8622 - dice_coef: 0.8622 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 1325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8493 - dice_coef: 0.8493 - val_loss: -0.0405 - val_dice_coef: 0.0405\n",
      "Epoch 1326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8495 - dice_coef: 0.8495 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8563 - dice_coef: 0.8563 - val_loss: -0.9283 - val_dice_coef: 0.9283\n",
      "Epoch 1328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8684 - dice_coef: 0.8684 - val_loss: -0.4080 - val_dice_coef: 0.4080\n",
      "Epoch 1329/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8698 - dice_coef: 0.8698 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8703 - dice_coef: 0.8703 - val_loss: -0.7567 - val_dice_coef: 0.7567\n",
      "Epoch 1331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.9764 - val_dice_coef: 0.9764\n",
      "Epoch 1332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8731 - dice_coef: 0.8731 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 1333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.2174 - val_dice_coef: 0.2174\n",
      "Epoch 1334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8640 - dice_coef: 0.8640 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.7884 - val_dice_coef: 0.7884\n",
      "Epoch 1336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.8379 - val_dice_coef: 0.8379\n",
      "Epoch 1337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8759 - dice_coef: 0.8759 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8754 - dice_coef: 0.8754 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 1339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.9426 - val_dice_coef: 0.9426\n",
      "Epoch 1340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8823 - dice_coef: 0.8823 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -0.5192 - val_dice_coef: 0.5192\n",
      "Epoch 1342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9811 - val_dice_coef: 0.9811\n",
      "Epoch 1343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.8578 - val_dice_coef: 0.8578\n",
      "Epoch 1345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 1346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9368 - val_dice_coef: 0.9368\n",
      "Epoch 1348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8851 - dice_coef: 0.8851 - val_loss: -0.9873 - val_dice_coef: 0.9873\n",
      "Epoch 1349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8815 - dice_coef: 0.8815 - val_loss: -0.8931 - val_dice_coef: 0.8931\n",
      "Epoch 1350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8831 - dice_coef: 0.8831 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 1351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 1353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.8807 - val_dice_coef: 0.8807\n",
      "Epoch 1354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 1355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9674 - val_dice_coef: 0.9674\n",
      "Epoch 1356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9875 - val_dice_coef: 0.9875\n",
      "Epoch 1357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8847 - dice_coef: 0.8847 - val_loss: -0.9623 - val_dice_coef: 0.9623\n",
      "Epoch 1358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9287 - val_dice_coef: 0.9287\n",
      "Epoch 1359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9515 - val_dice_coef: 0.9515\n",
      "Epoch 1360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8842 - dice_coef: 0.8842 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 1361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.9364 - val_dice_coef: 0.9364\n",
      "Epoch 1362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.8061 - val_dice_coef: 0.8061\n",
      "Epoch 1363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 1364/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.8924 - val_dice_coef: 0.8924\n",
      "Epoch 1366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.8853 - val_dice_coef: 0.8853\n",
      "Epoch 1367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8808 - dice_coef: 0.8808 - val_loss: -0.7476 - val_dice_coef: 0.7476\n",
      "Epoch 1370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 1371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8656 - dice_coef: 0.8656 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.2390 - val_dice_coef: 0.2390\n",
      "Epoch 1374/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8742 - dice_coef: 0.8742 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8795 - dice_coef: 0.8795 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.6036 - val_dice_coef: 0.6036\n",
      "Epoch 1377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.8611 - val_dice_coef: 0.8611\n",
      "Epoch 1378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9521 - val_dice_coef: 0.9521\n",
      "Epoch 1380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.9455 - val_dice_coef: 0.9455\n",
      "Epoch 1381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9195 - val_dice_coef: 0.9195\n",
      "Epoch 1383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.7753 - val_dice_coef: 0.7753\n",
      "Epoch 1384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8769 - dice_coef: 0.8769 - val_loss: -0.9845 - val_dice_coef: 0.9845\n",
      "Epoch 1386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.6840 - val_dice_coef: 0.6840\n",
      "Epoch 1387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.5232 - val_dice_coef: 0.5232\n",
      "Epoch 1390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8761 - dice_coef: 0.8761 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 1391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 1393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8864 - dice_coef: 0.8864 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9704 - val_dice_coef: 0.9704\n",
      "Epoch 1395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8829 - dice_coef: 0.8829 - val_loss: -0.8821 - val_dice_coef: 0.8821\n",
      "Epoch 1396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8823 - dice_coef: 0.8823 - val_loss: -0.8286 - val_dice_coef: 0.8286\n",
      "Epoch 1398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.7954 - val_dice_coef: 0.7954\n",
      "Epoch 1399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.7331 - val_dice_coef: 0.7331\n",
      "Epoch 1401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8655 - dice_coef: 0.8655 - val_loss: -0.2798 - val_dice_coef: 0.2798\n",
      "Epoch 1402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.5671 - val_dice_coef: 0.5671\n",
      "Epoch 1404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.8881 - val_dice_coef: 0.8881\n",
      "Epoch 1405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8772 - dice_coef: 0.8772 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8686 - dice_coef: 0.8686 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 1407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8757 - dice_coef: 0.8757 - val_loss: -0.8560 - val_dice_coef: 0.8560\n",
      "Epoch 1408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.5029 - val_dice_coef: 0.5029\n",
      "Epoch 1410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 1411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8750 - dice_coef: 0.8750 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.8011 - val_dice_coef: 0.8011\n",
      "Epoch 1413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8780 - dice_coef: 0.8780 - val_loss: -0.7275 - val_dice_coef: 0.7275\n",
      "Epoch 1414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.8300 - val_dice_coef: 0.8300\n",
      "Epoch 1416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.9668 - val_dice_coef: 0.9668\n",
      "Epoch 1417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.7602 - val_dice_coef: 0.7602\n",
      "Epoch 1419/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 1420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8869 - dice_coef: 0.8869 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9878 - val_dice_coef: 0.9878\n",
      "Epoch 1422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8874 - dice_coef: 0.8874 - val_loss: -0.9546 - val_dice_coef: 0.9546\n",
      "Epoch 1423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.9813 - val_dice_coef: 0.9813\n",
      "Epoch 1425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8862 - dice_coef: 0.8862 - val_loss: -0.9892 - val_dice_coef: 0.9892\n",
      "Epoch 1426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.7790 - val_dice_coef: 0.7790\n",
      "Epoch 1428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8803 - dice_coef: 0.8803 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1429/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 1430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.5066 - val_dice_coef: 0.5066\n",
      "Epoch 1431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 1432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 1433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.9503 - val_dice_coef: 0.9503\n",
      "Epoch 1434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9680 - val_dice_coef: 0.9680\n",
      "Epoch 1435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.9775 - val_dice_coef: 0.9775\n",
      "Epoch 1437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 1438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1439/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9406 - val_dice_coef: 0.9406\n",
      "Epoch 1440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9496 - val_dice_coef: 0.9496\n",
      "Epoch 1441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.7550 - val_dice_coef: 0.7550\n",
      "Epoch 1444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8814 - dice_coef: 0.8814 - val_loss: -0.9906 - val_dice_coef: 0.9906\n",
      "Epoch 1445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8869 - dice_coef: 0.8869 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8820 - dice_coef: 0.8820 - val_loss: -0.9122 - val_dice_coef: 0.9122\n",
      "Epoch 1447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9654 - val_dice_coef: 0.9654\n",
      "Epoch 1448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 1450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.7325 - val_dice_coef: 0.7325\n",
      "Epoch 1451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 1452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 1453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8880 - dice_coef: 0.8880 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 1454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8853 - dice_coef: 0.8853 - val_loss: -0.9077 - val_dice_coef: 0.9077\n",
      "Epoch 1455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8872 - dice_coef: 0.8872 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 1457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8854 - dice_coef: 0.8854 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 1458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.8697 - val_dice_coef: 0.8697\n",
      "Epoch 1459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9237 - val_dice_coef: 0.9237\n",
      "Epoch 1462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.9592 - val_dice_coef: 0.9592\n",
      "Epoch 1463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8878 - dice_coef: 0.8878 - val_loss: -0.9028 - val_dice_coef: 0.9028\n",
      "Epoch 1466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.9455 - val_dice_coef: 0.9455\n",
      "Epoch 1471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.9116 - val_dice_coef: 0.9116\n",
      "Epoch 1472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 1474/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9324 - val_dice_coef: 0.9324\n",
      "Epoch 1475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9858 - val_dice_coef: 0.9858\n",
      "Epoch 1476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8901 - dice_coef: 0.8901 - val_loss: -0.9861 - val_dice_coef: 0.9860\n",
      "Epoch 1477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8898 - dice_coef: 0.8898 - val_loss: -0.9476 - val_dice_coef: 0.9476\n",
      "Epoch 1478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 1479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8847 - dice_coef: 0.8847 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 1480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -0.4743 - val_dice_coef: 0.4743\n",
      "Epoch 1481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8806 - dice_coef: 0.8806 - val_loss: -0.8402 - val_dice_coef: 0.8402\n",
      "Epoch 1482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8809 - dice_coef: 0.8809 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1484/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.2526 - val_dice_coef: 0.2526\n",
      "Epoch 1485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8810 - dice_coef: 0.8810 - val_loss: -0.9901 - val_dice_coef: 0.9901\n",
      "Epoch 1486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.8856 - val_dice_coef: 0.8856\n",
      "Epoch 1488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8830 - dice_coef: 0.8830 - val_loss: -0.0971 - val_dice_coef: 0.0971\n",
      "Epoch 1489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.3692 - val_dice_coef: 0.3692\n",
      "Epoch 1492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 1493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9403 - val_dice_coef: 0.9403\n",
      "Epoch 1495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8871 - dice_coef: 0.8871 - val_loss: -0.9277 - val_dice_coef: 0.9277\n",
      "Epoch 1497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.5883 - val_dice_coef: 0.5883\n",
      "Epoch 1498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8878 - dice_coef: 0.8878 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 1500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8839 - dice_coef: 0.8839 - val_loss: -0.4534 - val_dice_coef: 0.4534\n",
      "Epoch 1501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8789 - dice_coef: 0.8789 - val_loss: -0.9245 - val_dice_coef: 0.9245\n",
      "Epoch 1502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8800 - dice_coef: 0.8800 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9635 - val_dice_coef: 0.9635\n",
      "Epoch 1504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.6363 - val_dice_coef: 0.6363\n",
      "Epoch 1505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 1507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 1508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.6256 - val_dice_coef: 0.6256\n",
      "Epoch 1509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8813 - dice_coef: 0.8813 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9877 - val_dice_coef: 0.9877\n",
      "Epoch 1511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8885 - dice_coef: 0.8885 - val_loss: -0.7086 - val_dice_coef: 0.7086\n",
      "Epoch 1512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 1513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8889 - dice_coef: 0.8889 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8842 - dice_coef: 0.8842 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 1515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.8409 - val_dice_coef: 0.8409\n",
      "Epoch 1516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 1517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 1519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.8782 - val_dice_coef: 0.8782\n",
      "Epoch 1520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 1521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.9585 - val_dice_coef: 0.9585\n",
      "Epoch 1523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.5229 - val_dice_coef: 0.5229\n",
      "Epoch 1524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9806 - val_dice_coef: 0.9806\n",
      "Epoch 1526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 1527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8927 - dice_coef: 0.8927 - val_loss: -0.9602 - val_dice_coef: 0.9602\n",
      "Epoch 1529/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 1530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 1531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 1532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8910 - dice_coef: 0.8910 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 1535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9702 - val_dice_coef: 0.9702\n",
      "Epoch 1537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 1539/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 1541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.9630 - val_dice_coef: 0.9630\n",
      "Epoch 1542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9517 - val_dice_coef: 0.9517\n",
      "Epoch 1543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8925 - dice_coef: 0.8925 - val_loss: -0.9853 - val_dice_coef: 0.9853\n",
      "Epoch 1548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8915 - dice_coef: 0.8915 - val_loss: -0.9361 - val_dice_coef: 0.9361\n",
      "Epoch 1549/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.7572 - val_dice_coef: 0.7572\n",
      "Epoch 1550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8800 - dice_coef: 0.8800 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 1553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.9578 - val_dice_coef: 0.9578\n",
      "Epoch 1554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 1555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8939 - dice_coef: 0.8939 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 1556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8935 - dice_coef: 0.8935 - val_loss: -0.9822 - val_dice_coef: 0.9822\n",
      "Epoch 1557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.8629 - val_dice_coef: 0.8629\n",
      "Epoch 1558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 1559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 1560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8905 - dice_coef: 0.8905 - val_loss: -0.9371 - val_dice_coef: 0.9371\n",
      "Epoch 1562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8888 - dice_coef: 0.8888 - val_loss: -0.3627 - val_dice_coef: 0.3627\n",
      "Epoch 1563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8783 - dice_coef: 0.8783 - val_loss: -0.8936 - val_dice_coef: 0.8936\n",
      "Epoch 1566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.5421 - val_dice_coef: 0.5421\n",
      "Epoch 1567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 1568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.8160 - val_dice_coef: 0.8160\n",
      "Epoch 1570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8857 - dice_coef: 0.8857 - val_loss: -0.8215 - val_dice_coef: 0.8215\n",
      "Epoch 1571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8777 - dice_coef: 0.8777 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 1573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.8056 - val_dice_coef: 0.8056\n",
      "Epoch 1574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8813 - dice_coef: 0.8813 - val_loss: -0.7738 - val_dice_coef: 0.7738\n",
      "Epoch 1575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8851 - dice_coef: 0.8851 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8876 - dice_coef: 0.8876 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 1578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.9532 - val_dice_coef: 0.9532\n",
      "Epoch 1579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8855 - dice_coef: 0.8855 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 1583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.8843 - val_dice_coef: 0.8843\n",
      "Epoch 1584/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8898 - dice_coef: 0.8898 - val_loss: -0.9842 - val_dice_coef: 0.9842\n",
      "Epoch 1585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9646 - val_dice_coef: 0.9646\n",
      "Epoch 1588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9435 - val_dice_coef: 0.9435\n",
      "Epoch 1589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9877 - val_dice_coef: 0.9877\n",
      "Epoch 1590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9839 - val_dice_coef: 0.9839\n",
      "Epoch 1591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9308 - val_dice_coef: 0.9308\n",
      "Epoch 1592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 1594/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 1596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 1599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8889 - dice_coef: 0.8889 - val_loss: -0.8511 - val_dice_coef: 0.8511\n",
      "Epoch 1600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.8326 - val_dice_coef: 0.8326\n",
      "Epoch 1601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8859 - dice_coef: 0.8859 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 1604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.0651 - val_dice_coef: 0.0651\n",
      "Epoch 1605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 1606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8809 - dice_coef: 0.8809 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 1608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.8713 - val_dice_coef: 0.8713\n",
      "Epoch 1609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8924 - dice_coef: 0.8924 - val_loss: -0.9309 - val_dice_coef: 0.9309\n",
      "Epoch 1613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 1614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.8763 - val_dice_coef: 0.8763\n",
      "Epoch 1616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 1618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 1620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 1621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8843 - dice_coef: 0.8843 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8850 - dice_coef: 0.8850 - val_loss: -0.4770 - val_dice_coef: 0.4770\n",
      "Epoch 1631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.9613 - val_dice_coef: 0.9613\n",
      "Epoch 1632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9713 - val_dice_coef: 0.9713\n",
      "Epoch 1634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 1635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8920 - dice_coef: 0.8920 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.8398 - val_dice_coef: 0.8398\n",
      "Epoch 1639/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 1641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8924 - dice_coef: 0.8924 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 1646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9299 - val_dice_coef: 0.9299\n",
      "Epoch 1647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9878 - val_dice_coef: 0.9878\n",
      "Epoch 1649/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 1650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9784 - val_dice_coef: 0.9784\n",
      "Epoch 1651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 1652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 1653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 1655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 1656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9644 - val_dice_coef: 0.9644\n",
      "Epoch 1659/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 1660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9716 - val_dice_coef: 0.9716\n",
      "Epoch 1661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 1662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9715 - val_dice_coef: 0.9715\n",
      "Epoch 1665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.7468 - val_dice_coef: 0.7468\n",
      "Epoch 1666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8825 - dice_coef: 0.8825 - val_loss: -0.5739 - val_dice_coef: 0.5739\n",
      "Epoch 1667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8676 - dice_coef: 0.8676 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8680 - dice_coef: 0.8680 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8694 - dice_coef: 0.8694 - val_loss: -0.8318 - val_dice_coef: 0.8318\n",
      "Epoch 1670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.1576 - val_dice_coef: 0.1576\n",
      "Epoch 1671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8592 - dice_coef: 0.8592 - val_loss: -0.5521 - val_dice_coef: 0.5521\n",
      "Epoch 1672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.5260 - val_dice_coef: 0.5260\n",
      "Epoch 1674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8836 - dice_coef: 0.8836 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 1675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.8793 - val_dice_coef: 0.8793\n",
      "Epoch 1677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9944 - val_dice_coef: 0.9944\n",
      "Epoch 1679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9348 - val_dice_coef: 0.9348\n",
      "Epoch 1680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 1681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 1682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8935 - dice_coef: 0.8935 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 1684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8958 - dice_coef: 0.8958 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 1685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -0.9341 - val_dice_coef: 0.9341\n",
      "Epoch 1688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9782 - val_dice_coef: 0.9782\n",
      "Epoch 1690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 1691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9905 - val_dice_coef: 0.9905\n",
      "Epoch 1692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1694/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 1695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 1698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9083 - val_dice_coef: 0.9083\n",
      "Epoch 1699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8951 - dice_coef: 0.8951 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 1700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 1701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 1703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1704/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 1705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 1708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 1709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9953 - val_dice_coef: 0.9953\n",
      "Epoch 1711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9008 - dice_coef: 0.9008 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9001 - dice_coef: 0.9001 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9852 - val_dice_coef: 0.9852\n",
      "Epoch 1715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9847 - val_dice_coef: 0.9847\n",
      "Epoch 1716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9677 - val_dice_coef: 0.9677\n",
      "Epoch 1721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.7673 - val_dice_coef: 0.7673\n",
      "Epoch 1722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.9616 - val_dice_coef: 0.9616\n",
      "Epoch 1723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9504 - val_dice_coef: 0.9504\n",
      "Epoch 1727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8928 - dice_coef: 0.8928 - val_loss: -0.8598 - val_dice_coef: 0.8598\n",
      "Epoch 1728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 1729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8903 - dice_coef: 0.8903 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9930 - val_dice_coef: 0.9930\n",
      "Epoch 1732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9200 - val_dice_coef: 0.9200\n",
      "Epoch 1733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8973 - dice_coef: 0.8973 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8996 - dice_coef: 0.8996 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 1738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8996 - dice_coef: 0.8996 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8981 - dice_coef: 0.8981 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8969 - dice_coef: 0.8969 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 1745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 1746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 1747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8970 - dice_coef: 0.8970 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 1748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1749/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 1753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9865 - val_dice_coef: 0.9865\n",
      "Epoch 1754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9000 - dice_coef: 0.9000 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 1755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8975 - dice_coef: 0.8975 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 1759/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8883 - dice_coef: 0.8883 - val_loss: -0.3491 - val_dice_coef: 0.3491\n",
      "Epoch 1760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8696 - dice_coef: 0.8696 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8776 - dice_coef: 0.8776 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8764 - dice_coef: 0.8764 - val_loss: -0.9459 - val_dice_coef: 0.9459\n",
      "Epoch 1763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.3883 - val_dice_coef: 0.3883\n",
      "Epoch 1764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8856 - dice_coef: 0.8856 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8882 - dice_coef: 0.8882 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9517 - val_dice_coef: 0.9517\n",
      "Epoch 1768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8930 - dice_coef: 0.8930 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1769/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 1771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9906 - val_dice_coef: 0.9906\n",
      "Epoch 1772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 1773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8914 - dice_coef: 0.8914 - val_loss: -0.9747 - val_dice_coef: 0.9747\n",
      "Epoch 1774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9855 - val_dice_coef: 0.9855\n",
      "Epoch 1775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8908 - dice_coef: 0.8908 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 1778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.9271 - val_dice_coef: 0.9271\n",
      "Epoch 1779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.7942 - val_dice_coef: 0.7942\n",
      "Epoch 1780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8972 - dice_coef: 0.8972 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.7378 - val_dice_coef: 0.7378\n",
      "Epoch 1783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8873 - dice_coef: 0.8873 - val_loss: -0.8769 - val_dice_coef: 0.8769\n",
      "Epoch 1784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9462 - val_dice_coef: 0.9462\n",
      "Epoch 1788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.9004 - val_dice_coef: 0.9004\n",
      "Epoch 1789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8899 - dice_coef: 0.8899 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.8421 - val_dice_coef: 0.8421\n",
      "Epoch 1792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 1793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 1796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 1797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 1798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 1800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 1802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1804/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8946 - dice_coef: 0.8946 - val_loss: -0.9086 - val_dice_coef: 0.9086\n",
      "Epoch 1805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.8330 - val_dice_coef: 0.8330\n",
      "Epoch 1806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9029 - val_dice_coef: 0.9029\n",
      "Epoch 1809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8934 - dice_coef: 0.8934 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 1810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.8401 - val_dice_coef: 0.8401\n",
      "Epoch 1813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8919 - dice_coef: 0.8919 - val_loss: -0.9761 - val_dice_coef: 0.9761\n",
      "Epoch 1814/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8942 - dice_coef: 0.8942 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 1818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 1821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 1822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9937 - val_dice_coef: 0.9937\n",
      "Epoch 1825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8930 - dice_coef: 0.8930 - val_loss: -0.6426 - val_dice_coef: 0.6426\n",
      "Epoch 1826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8828 - dice_coef: 0.8828 - val_loss: -0.9610 - val_dice_coef: 0.9610\n",
      "Epoch 1827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8910 - dice_coef: 0.8910 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.7763 - val_dice_coef: 0.7763\n",
      "Epoch 1830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8909 - dice_coef: 0.8909 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 1831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 1833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.7866 - val_dice_coef: 0.7866\n",
      "Epoch 1834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 1838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9697 - val_dice_coef: 0.9697\n",
      "Epoch 1839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 1840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.9662 - val_dice_coef: 0.9662\n",
      "Epoch 1842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 1843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9009 - dice_coef: 0.9009 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8936 - dice_coef: 0.8936 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 1846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 1849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 1850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 1851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9014 - dice_coef: 0.9014 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 1853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 1854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 1857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 1858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 1859/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.6750 - val_dice_coef: 0.6750\n",
      "Epoch 1860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9030 - dice_coef: 0.9030 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 1863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 1864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 1865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9025 - dice_coef: 0.9025 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 1866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8992 - dice_coef: 0.8992 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1869/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8931 - dice_coef: 0.8931 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 1871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.5848 - val_dice_coef: 0.5848\n",
      "Epoch 1872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8916 - dice_coef: 0.8916 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.7944 - val_dice_coef: 0.7944\n",
      "Epoch 1876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.9835 - val_dice_coef: 0.9835\n",
      "Epoch 1877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 1879/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9046 - dice_coef: 0.9046 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 1882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.8094 - val_dice_coef: 0.8094\n",
      "Epoch 1883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8890 - dice_coef: 0.8890 - val_loss: -0.7506 - val_dice_coef: 0.7506\n",
      "Epoch 1884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 1886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9655 - val_dice_coef: 0.9655\n",
      "Epoch 1887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.9596 - val_dice_coef: 0.9596\n",
      "Epoch 1888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9808 - val_dice_coef: 0.9808\n",
      "Epoch 1891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9312 - val_dice_coef: 0.9312\n",
      "Epoch 1892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8982 - dice_coef: 0.8982 - val_loss: -0.9297 - val_dice_coef: 0.9297\n",
      "Epoch 1893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9009 - dice_coef: 0.9009 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 1895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 1896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 1897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 1898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 1899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.8928 - val_dice_coef: 0.8928\n",
      "Epoch 1900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8956 - dice_coef: 0.8956 - val_loss: -0.7940 - val_dice_coef: 0.7940\n",
      "Epoch 1901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 1902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8782 - dice_coef: 0.8782 - val_loss: -0.1956 - val_dice_coef: 0.1956\n",
      "Epoch 1904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8806 - dice_coef: 0.8806 - val_loss: -0.8431 - val_dice_coef: 0.8431\n",
      "Epoch 1905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8834 - dice_coef: 0.8834 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8751 - dice_coef: 0.8751 - val_loss: -0.4669 - val_dice_coef: 0.4669\n",
      "Epoch 1907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8792 - dice_coef: 0.8792 - val_loss: -0.0583 - val_dice_coef: 0.0583\n",
      "Epoch 1908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8623 - dice_coef: 0.8623 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8566 - dice_coef: 0.8566 - val_loss: -0.6860 - val_dice_coef: 0.6860\n",
      "Epoch 1910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8841 - dice_coef: 0.8841 - val_loss: -0.6182 - val_dice_coef: 0.6182\n",
      "Epoch 1911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8867 - dice_coef: 0.8867 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8912 - dice_coef: 0.8912 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 1913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8914 - dice_coef: 0.8914 - val_loss: -0.9887 - val_dice_coef: 0.9887\n",
      "Epoch 1914/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8962 - dice_coef: 0.8962 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8970 - dice_coef: 0.8970 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 1916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8941 - dice_coef: 0.8941 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9619 - val_dice_coef: 0.9619\n",
      "Epoch 1919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 1922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 1923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1924/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 1925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8939 - dice_coef: 0.8939 - val_loss: -0.6276 - val_dice_coef: 0.6276\n",
      "Epoch 1926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.3067 - val_dice_coef: 0.3067\n",
      "Epoch 1929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.4411 - val_dice_coef: 0.4411\n",
      "Epoch 1932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8760 - dice_coef: 0.8760 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 1933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8610 - dice_coef: 0.8610 - val_loss: -0.4877 - val_dice_coef: 0.4877\n",
      "Epoch 1935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8807 - dice_coef: 0.8807 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 1936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8883 - dice_coef: 0.8883 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9485 - val_dice_coef: 0.9485\n",
      "Epoch 1938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8948 - dice_coef: 0.8948 - val_loss: -0.9521 - val_dice_coef: 0.9521\n",
      "Epoch 1939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 1941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.9690 - val_dice_coef: 0.9690\n",
      "Epoch 1942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 1943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8944 - dice_coef: 0.8944 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 1944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8949 - dice_coef: 0.8949 - val_loss: -0.9788 - val_dice_coef: 0.9788\n",
      "Epoch 1945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9017 - dice_coef: 0.9017 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 1946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 1947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 1948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 1950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9722 - val_dice_coef: 0.9722\n",
      "Epoch 1951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9008 - dice_coef: 0.9008 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9876 - val_dice_coef: 0.9876\n",
      "Epoch 1954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 1955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 1957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9396 - val_dice_coef: 0.9396\n",
      "Epoch 1958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 1959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9052 - dice_coef: 0.9052 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 1960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 1961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.9805 - val_dice_coef: 0.9805\n",
      "Epoch 1962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9029 - dice_coef: 0.9029 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 1964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 1965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 1966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 1967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 1968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 1969/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 1970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9753 - val_dice_coef: 0.9753\n",
      "Epoch 1971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 1973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 1974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 1975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 1976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 1977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 1978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9037 - dice_coef: 0.9037 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 1979/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 1980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9034 - dice_coef: 0.9034 - val_loss: -0.8670 - val_dice_coef: 0.8670\n",
      "Epoch 1981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.8830 - val_dice_coef: 0.8830\n",
      "Epoch 1982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 1983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9918 - val_dice_coef: 0.9918\n",
      "Epoch 1985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.9545 - val_dice_coef: 0.9545\n",
      "Epoch 1986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 1987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 1988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 1989/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9685 - val_dice_coef: 0.9685\n",
      "Epoch 1990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 1991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 1992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 1993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 1994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 1995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9783 - val_dice_coef: 0.9783\n",
      "Epoch 1996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 1997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8885 - dice_coef: 0.8885 - val_loss: -0.9682 - val_dice_coef: 0.9682\n",
      "Epoch 1998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.2416 - val_dice_coef: 0.2416\n",
      "Epoch 1999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8875 - dice_coef: 0.8875 - val_loss: -0.9894 - val_dice_coef: 0.9894\n",
      "Epoch 2000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9014 - dice_coef: 0.9014 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2001/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.7513 - val_dice_coef: 0.7513\n",
      "Epoch 2002/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8971 - dice_coef: 0.8971 - val_loss: -0.8799 - val_dice_coef: 0.8799\n",
      "Epoch 2003/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2004/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2005/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9047 - dice_coef: 0.9047 - val_loss: -0.9774 - val_dice_coef: 0.9774\n",
      "Epoch 2006/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9044 - dice_coef: 0.9044 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2007/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9032 - dice_coef: 0.9032 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2008/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2009/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2010/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9712 - val_dice_coef: 0.9712\n",
      "Epoch 2011/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2012/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2013/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2014/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2015/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9602 - val_dice_coef: 0.9602\n",
      "Epoch 2016/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 2017/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2018/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2019/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2020/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9911 - val_dice_coef: 0.9911\n",
      "Epoch 2021/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2022/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.9562 - val_dice_coef: 0.9562\n",
      "Epoch 2023/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9831 - val_dice_coef: 0.9831\n",
      "Epoch 2024/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9445 - val_dice_coef: 0.9445\n",
      "Epoch 2025/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9607 - val_dice_coef: 0.9607\n",
      "Epoch 2026/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2027/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9814 - val_dice_coef: 0.9814\n",
      "Epoch 2028/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9624 - val_dice_coef: 0.9624\n",
      "Epoch 2029/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2030/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2031/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2032/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8233 - val_dice_coef: 0.8233\n",
      "Epoch 2033/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.0927 - val_dice_coef: 0.0927\n",
      "Epoch 2034/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2035/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8907 - dice_coef: 0.8907 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2036/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.3486 - val_dice_coef: 0.3486\n",
      "Epoch 2037/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8911 - dice_coef: 0.8911 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 2038/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2039/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2040/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.8120 - val_dice_coef: 0.8120\n",
      "Epoch 2041/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2042/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2043/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2044/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 2045/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.7585 - val_dice_coef: 0.7585\n",
      "Epoch 2046/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9006 - dice_coef: 0.9006 - val_loss: -0.9634 - val_dice_coef: 0.9634\n",
      "Epoch 2047/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2048/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2049/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9001 - dice_coef: 0.9001 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2050/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9299 - val_dice_coef: 0.9299\n",
      "Epoch 2051/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.7435 - val_dice_coef: 0.7435\n",
      "Epoch 2052/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.9863 - val_dice_coef: 0.9863\n",
      "Epoch 2053/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2054/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 2055/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "Epoch 2056/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8979 - dice_coef: 0.8979 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2057/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8844 - dice_coef: 0.8844 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2058/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.0455 - val_dice_coef: 0.0455\n",
      "Epoch 2059/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 2060/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8974 - dice_coef: 0.8974 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2061/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.9754 - val_dice_coef: 0.9754\n",
      "Epoch 2062/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8997 - dice_coef: 0.8997 - val_loss: -0.8678 - val_dice_coef: 0.8678\n",
      "Epoch 2063/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2064/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8917 - dice_coef: 0.8917 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2065/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9033 - dice_coef: 0.9033 - val_loss: -0.6703 - val_dice_coef: 0.6703\n",
      "Epoch 2066/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2067/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2068/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.6828 - val_dice_coef: 0.6828\n",
      "Epoch 2069/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8999 - dice_coef: 0.8999 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2070/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2071/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.6301 - val_dice_coef: 0.6301\n",
      "Epoch 2072/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2073/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 2074/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.3043 - val_dice_coef: 0.3043\n",
      "Epoch 2075/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8938 - dice_coef: 0.8938 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2076/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2077/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.7334 - val_dice_coef: 0.7334\n",
      "Epoch 2078/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9004 - dice_coef: 0.9004 - val_loss: -0.9812 - val_dice_coef: 0.9812\n",
      "Epoch 2079/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2080/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8992 - dice_coef: 0.8992 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2081/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.7743 - val_dice_coef: 0.7743\n",
      "Epoch 2082/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.9696 - val_dice_coef: 0.9696\n",
      "Epoch 2083/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9059 - dice_coef: 0.9059 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2084/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8952 - dice_coef: 0.8952 - val_loss: -0.8784 - val_dice_coef: 0.8784\n",
      "Epoch 2085/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.6214 - val_dice_coef: 0.6214\n",
      "Epoch 2086/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2087/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9931 - val_dice_coef: 0.9931\n",
      "Epoch 2088/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.7279 - val_dice_coef: 0.7279\n",
      "Epoch 2089/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.8486 - val_dice_coef: 0.8486\n",
      "Epoch 2090/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2091/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9018 - dice_coef: 0.9018 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2092/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9022 - dice_coef: 0.9022 - val_loss: -0.5195 - val_dice_coef: 0.5195\n",
      "Epoch 2093/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8963 - dice_coef: 0.8963 - val_loss: -0.9506 - val_dice_coef: 0.9506\n",
      "Epoch 2094/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9005 - dice_coef: 0.9005 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2095/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8980 - dice_coef: 0.8980 - val_loss: -0.6622 - val_dice_coef: 0.6622\n",
      "Epoch 2096/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9161 - val_dice_coef: 0.9161\n",
      "Epoch 2097/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9048 - dice_coef: 0.9048 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2098/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2099/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.4942 - val_dice_coef: 0.4942\n",
      "Epoch 2100/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8958 - dice_coef: 0.8958 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2101/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8835 - dice_coef: 0.8835 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2102/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.0474 - val_dice_coef: 0.0474\n",
      "Epoch 2103/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8718 - dice_coef: 0.8718 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2104/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8758 - dice_coef: 0.8758 - val_loss: -0.9472 - val_dice_coef: 0.9472\n",
      "Epoch 2105/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.0916 - val_dice_coef: 0.0916\n",
      "Epoch 2106/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2107/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8903 - dice_coef: 0.8903 - val_loss: -0.9310 - val_dice_coef: 0.9310\n",
      "Epoch 2108/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -0.9342 - val_dice_coef: 0.9342\n",
      "Epoch 2109/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2110/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.2731 - val_dice_coef: 0.2731\n",
      "Epoch 2111/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2112/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2113/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.8293 - val_dice_coef: 0.8293\n",
      "Epoch 2114/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9751 - val_dice_coef: 0.9751\n",
      "Epoch 2115/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2116/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -0.7519 - val_dice_coef: 0.7519\n",
      "Epoch 2117/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9895 - val_dice_coef: 0.9895\n",
      "Epoch 2118/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2119/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9381 - val_dice_coef: 0.9381\n",
      "Epoch 2120/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2121/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2122/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.9411 - val_dice_coef: 0.9411\n",
      "Epoch 2123/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9028 - dice_coef: 0.9028 - val_loss: -0.6858 - val_dice_coef: 0.6858\n",
      "Epoch 2124/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2125/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8987 - dice_coef: 0.8987 - val_loss: -0.7141 - val_dice_coef: 0.7141\n",
      "Epoch 2126/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9003 - dice_coef: 0.9003 - val_loss: -0.8951 - val_dice_coef: 0.8951\n",
      "Epoch 2127/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2128/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.8321 - val_dice_coef: 0.8321\n",
      "Epoch 2129/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.9957 - val_dice_coef: 0.9957\n",
      "Epoch 2130/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2131/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9442 - val_dice_coef: 0.9442\n",
      "Epoch 2132/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2133/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 2134/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9257 - val_dice_coef: 0.9257\n",
      "Epoch 2135/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2136/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2137/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9563 - val_dice_coef: 0.9563\n",
      "Epoch 2138/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2139/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2140/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9310 - val_dice_coef: 0.9310\n",
      "Epoch 2141/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9590 - val_dice_coef: 0.9590\n",
      "Epoch 2142/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2143/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2144/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9518 - val_dice_coef: 0.9518\n",
      "Epoch 2145/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9400 - val_dice_coef: 0.9400\n",
      "Epoch 2146/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2147/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2148/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2149/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9924 - val_dice_coef: 0.9924\n",
      "Epoch 2150/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9461 - val_dice_coef: 0.9461\n",
      "Epoch 2151/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9562 - val_dice_coef: 0.9562\n",
      "Epoch 2152/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2153/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 2154/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 2155/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9573 - val_dice_coef: 0.9573\n",
      "Epoch 2156/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 2157/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9857 - val_dice_coef: 0.9857\n",
      "Epoch 2158/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2159/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9833 - val_dice_coef: 0.9833\n",
      "Epoch 2160/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.6026 - val_dice_coef: 0.6026\n",
      "Epoch 2161/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.6253 - val_dice_coef: 0.6253\n",
      "Epoch 2162/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9020 - dice_coef: 0.9020 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 2163/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2164/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2165/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9053 - dice_coef: 0.9053 - val_loss: -0.9454 - val_dice_coef: 0.9454\n",
      "Epoch 2166/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9080 - dice_coef: 0.9080 - val_loss: -0.8475 - val_dice_coef: 0.8475\n",
      "Epoch 2167/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2168/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2169/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.9166 - val_dice_coef: 0.9166\n",
      "Epoch 2170/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.6904 - val_dice_coef: 0.6904\n",
      "Epoch 2171/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9019 - dice_coef: 0.9019 - val_loss: -0.9470 - val_dice_coef: 0.9470\n",
      "Epoch 2172/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2173/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9489 - val_dice_coef: 0.9489\n",
      "Epoch 2174/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 2175/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.9977 - val_dice_coef: 0.9977\n",
      "Epoch 2176/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2177/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9062 - dice_coef: 0.9062 - val_loss: -0.8374 - val_dice_coef: 0.8374\n",
      "Epoch 2178/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.6803 - val_dice_coef: 0.6803\n",
      "Epoch 2179/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.9183 - val_dice_coef: 0.9183\n",
      "Epoch 2180/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9088 - dice_coef: 0.9088 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 2181/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9816 - val_dice_coef: 0.9816\n",
      "Epoch 2182/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 2183/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2184/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9761 - val_dice_coef: 0.9761\n",
      "Epoch 2185/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9666 - val_dice_coef: 0.9666\n",
      "Epoch 2186/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 2187/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 2188/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2189/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 2190/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9784 - val_dice_coef: 0.9784\n",
      "Epoch 2191/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 2192/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9600 - val_dice_coef: 0.9600\n",
      "Epoch 2193/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9814 - val_dice_coef: 0.9814\n",
      "Epoch 2194/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2195/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8965 - dice_coef: 0.8965 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2196/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.4542 - val_dice_coef: 0.4542\n",
      "Epoch 2197/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8894 - dice_coef: 0.8894 - val_loss: -0.1773 - val_dice_coef: 0.1773\n",
      "Epoch 2198/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.9964 - val_dice_coef: 0.9964\n",
      "Epoch 2199/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9010 - dice_coef: 0.9010 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2200/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8858 - dice_coef: 0.8858 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 2201/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8940 - dice_coef: 0.8940 - val_loss: -0.0938 - val_dice_coef: 0.0938\n",
      "Epoch 2202/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8713 - dice_coef: 0.8713 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2203/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8848 - dice_coef: 0.8848 - val_loss: -0.9051 - val_dice_coef: 0.9051\n",
      "Epoch 2204/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8954 - dice_coef: 0.8954 - val_loss: -0.1643 - val_dice_coef: 0.1643\n",
      "Epoch 2205/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2206/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9013 - dice_coef: 0.9013 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 2207/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9123 - val_dice_coef: 0.9123\n",
      "Epoch 2208/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2209/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9928 - val_dice_coef: 0.9928\n",
      "Epoch 2210/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 2211/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2212/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9094 - dice_coef: 0.9094 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 2213/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.7664 - val_dice_coef: 0.7664\n",
      "Epoch 2214/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2215/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2216/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.7833 - val_dice_coef: 0.7833\n",
      "Epoch 2217/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9089 - dice_coef: 0.9089 - val_loss: -0.9804 - val_dice_coef: 0.9804\n",
      "Epoch 2218/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2219/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9089 - dice_coef: 0.9089 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2220/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9301 - val_dice_coef: 0.9301\n",
      "Epoch 2221/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.5832 - val_dice_coef: 0.5832\n",
      "Epoch 2222/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9064 - dice_coef: 0.9064 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2223/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2224/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9178 - val_dice_coef: 0.9178\n",
      "Epoch 2225/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.8188 - val_dice_coef: 0.8188\n",
      "Epoch 2226/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9806 - val_dice_coef: 0.9806\n",
      "Epoch 2227/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 2228/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9689 - val_dice_coef: 0.9689\n",
      "Epoch 2229/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2230/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2231/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 2232/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9084 - dice_coef: 0.9084 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2233/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 2234/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9120 - val_dice_coef: 0.9120\n",
      "Epoch 2235/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.8574 - val_dice_coef: 0.8574\n",
      "Epoch 2236/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.6431 - val_dice_coef: 0.6431\n",
      "Epoch 2237/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2238/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9039 - dice_coef: 0.9039 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2239/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 2240/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.9571 - val_dice_coef: 0.9571\n",
      "Epoch 2241/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 2242/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9239 - val_dice_coef: 0.9239\n",
      "Epoch 2243/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9737 - val_dice_coef: 0.9737\n",
      "Epoch 2244/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9133 - dice_coef: 0.9133 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2245/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9028 - val_dice_coef: 0.9028\n",
      "Epoch 2246/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.9756 - val_dice_coef: 0.9756\n",
      "Epoch 2247/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2248/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 2249/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9026 - val_dice_coef: 0.9026\n",
      "Epoch 2250/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.6725 - val_dice_coef: 0.6725\n",
      "Epoch 2251/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9062 - val_dice_coef: 0.9062\n",
      "Epoch 2252/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2253/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 2254/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9123 - dice_coef: 0.9123 - val_loss: -0.9481 - val_dice_coef: 0.9481\n",
      "Epoch 2255/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2256/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2257/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 2258/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2259/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9205 - val_dice_coef: 0.9205\n",
      "Epoch 2260/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.8805 - val_dice_coef: 0.8805\n",
      "Epoch 2261/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2262/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9302 - val_dice_coef: 0.9302\n",
      "Epoch 2263/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9021 - val_dice_coef: 0.9021\n",
      "Epoch 2264/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9340 - val_dice_coef: 0.9340\n",
      "Epoch 2265/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 2266/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9950 - val_dice_coef: 0.9950\n",
      "Epoch 2267/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9082 - val_dice_coef: 0.9082\n",
      "Epoch 2268/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.5658 - val_dice_coef: 0.5658\n",
      "Epoch 2269/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2270/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2271/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9057 - dice_coef: 0.9057 - val_loss: -0.7773 - val_dice_coef: 0.7773\n",
      "Epoch 2272/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9052 - dice_coef: 0.9052 - val_loss: -0.6216 - val_dice_coef: 0.6216\n",
      "Epoch 2273/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.9831 - val_dice_coef: 0.9831\n",
      "Epoch 2274/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2275/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.8679 - val_dice_coef: 0.8679\n",
      "Epoch 2276/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.3709 - val_dice_coef: 0.3709\n",
      "Epoch 2277/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8983 - dice_coef: 0.8983 - val_loss: -0.7028 - val_dice_coef: 0.7028\n",
      "Epoch 2278/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2279/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9086 - dice_coef: 0.9086 - val_loss: -0.9958 - val_dice_coef: 0.9958\n",
      "Epoch 2280/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9097 - dice_coef: 0.9097 - val_loss: -0.8944 - val_dice_coef: 0.8944\n",
      "Epoch 2281/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2282/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9912 - val_dice_coef: 0.9912\n",
      "Epoch 2283/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2284/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2285/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.8804 - val_dice_coef: 0.8804\n",
      "Epoch 2286/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.4114 - val_dice_coef: 0.4114\n",
      "Epoch 2287/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9038 - dice_coef: 0.9038 - val_loss: -0.9617 - val_dice_coef: 0.9617\n",
      "Epoch 2288/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2289/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9088 - dice_coef: 0.9088 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2290/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.7745 - val_dice_coef: 0.7745\n",
      "Epoch 2291/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9046 - dice_coef: 0.9046 - val_loss: -0.2139 - val_dice_coef: 0.2139\n",
      "Epoch 2292/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8990 - dice_coef: 0.8990 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 2293/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2294/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.8347 - val_dice_coef: 0.8347\n",
      "Epoch 2295/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.9288 - val_dice_coef: 0.9288\n",
      "Epoch 2296/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9366 - val_dice_coef: 0.9366\n",
      "Epoch 2297/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9793 - val_dice_coef: 0.9793\n",
      "Epoch 2298/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2299/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9966 - val_dice_coef: 0.9966\n",
      "Epoch 2300/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.9266 - val_dice_coef: 0.9266\n",
      "Epoch 2301/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.5115 - val_dice_coef: 0.5115\n",
      "Epoch 2302/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 2303/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2304/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9819 - val_dice_coef: 0.9819\n",
      "Epoch 2305/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.7982 - val_dice_coef: 0.7982\n",
      "Epoch 2306/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9093 - dice_coef: 0.9093 - val_loss: -0.6480 - val_dice_coef: 0.6480\n",
      "Epoch 2307/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2308/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9036 - dice_coef: 0.9036 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2309/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.5058 - val_dice_coef: 0.5058\n",
      "Epoch 2310/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.6644 - val_dice_coef: 0.6644\n",
      "Epoch 2311/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2312/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8988 - dice_coef: 0.8988 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2313/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.4163 - val_dice_coef: 0.4163\n",
      "Epoch 2314/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.3054 - val_dice_coef: 0.3054\n",
      "Epoch 2315/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9024 - dice_coef: 0.9024 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2316/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9056 - dice_coef: 0.9056 - val_loss: -0.9825 - val_dice_coef: 0.9825\n",
      "Epoch 2317/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.4694 - val_dice_coef: 0.4694\n",
      "Epoch 2318/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.9431 - val_dice_coef: 0.9431\n",
      "Epoch 2319/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2320/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9846 - val_dice_coef: 0.9846\n",
      "Epoch 2321/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 2322/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9565 - val_dice_coef: 0.9565\n",
      "Epoch 2323/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.2464 - val_dice_coef: 0.2464\n",
      "Epoch 2324/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9622 - val_dice_coef: 0.9622\n",
      "Epoch 2325/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2326/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9027 - dice_coef: 0.9027 - val_loss: -0.9629 - val_dice_coef: 0.9629\n",
      "Epoch 2327/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.2290 - val_dice_coef: 0.2290\n",
      "Epoch 2328/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8977 - dice_coef: 0.8977 - val_loss: -0.9703 - val_dice_coef: 0.9703\n",
      "Epoch 2329/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9021 - dice_coef: 0.9021 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2330/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9872 - val_dice_coef: 0.9872\n",
      "Epoch 2331/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.4349 - val_dice_coef: 0.4349\n",
      "Epoch 2332/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.8048 - val_dice_coef: 0.8048\n",
      "Epoch 2333/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2334/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8969 - dice_coef: 0.8969 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 2335/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.6067 - val_dice_coef: 0.6067\n",
      "Epoch 2336/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9059 - dice_coef: 0.9059 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 2337/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2338/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9061 - dice_coef: 0.9061 - val_loss: -0.9525 - val_dice_coef: 0.9525\n",
      "Epoch 2339/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.4830 - val_dice_coef: 0.4830\n",
      "Epoch 2340/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9852 - val_dice_coef: 0.9852\n",
      "Epoch 2341/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2342/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9791 - val_dice_coef: 0.9791\n",
      "Epoch 2343/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.8013 - val_dice_coef: 0.8013\n",
      "Epoch 2344/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2345/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 2346/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9789 - val_dice_coef: 0.9789\n",
      "Epoch 2347/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.7830 - val_dice_coef: 0.7830\n",
      "Epoch 2348/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9232 - val_dice_coef: 0.9232\n",
      "Epoch 2349/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9580 - val_dice_coef: 0.9580\n",
      "Epoch 2350/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9480 - val_dice_coef: 0.9480\n",
      "Epoch 2351/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9031 - val_dice_coef: 0.9031\n",
      "Epoch 2352/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9801 - val_dice_coef: 0.9801\n",
      "Epoch 2353/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2354/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2355/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9660 - val_dice_coef: 0.9660\n",
      "Epoch 2356/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 2357/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9851 - val_dice_coef: 0.9851\n",
      "Epoch 2358/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 2359/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9811 - val_dice_coef: 0.9811\n",
      "Epoch 2360/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9651 - val_dice_coef: 0.9651\n",
      "Epoch 2361/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9843 - val_dice_coef: 0.9843\n",
      "Epoch 2362/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2363/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9917 - val_dice_coef: 0.9917\n",
      "Epoch 2364/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2365/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2366/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9901 - val_dice_coef: 0.9901\n",
      "Epoch 2367/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2368/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2369/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9768 - val_dice_coef: 0.9768\n",
      "Epoch 2370/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.8090 - val_dice_coef: 0.8090\n",
      "Epoch 2371/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.2923 - val_dice_coef: 0.2923\n",
      "Epoch 2372/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8945 - dice_coef: 0.8945 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2373/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2374/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.4193 - val_dice_coef: 0.4193\n",
      "Epoch 2375/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8951 - dice_coef: 0.8951 - val_loss: -0.0492 - val_dice_coef: 0.0492\n",
      "Epoch 2376/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8826 - dice_coef: 0.8826 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2377/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.5547 - val_dice_coef: 0.5547\n",
      "Epoch 2378/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.0490 - val_dice_coef: 0.0490\n",
      "Epoch 2379/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8564 - dice_coef: 0.8564 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2380/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8701 - dice_coef: 0.8701 - val_loss: -0.0556 - val_dice_coef: 0.0556\n",
      "Epoch 2381/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2382/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.9959 - val_dice_coef: 0.9959\n",
      "Epoch 2383/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8991 - dice_coef: 0.8991 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 2384/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9010 - dice_coef: 0.9010 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2385/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9002 - dice_coef: 0.9002 - val_loss: -0.9729 - val_dice_coef: 0.9729\n",
      "Epoch 2386/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.6195 - val_dice_coef: 0.6195\n",
      "Epoch 2387/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9007 - dice_coef: 0.9007 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2388/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.9684 - val_dice_coef: 0.9684\n",
      "Epoch 2389/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9069 - dice_coef: 0.9069 - val_loss: -0.9320 - val_dice_coef: 0.9320\n",
      "Epoch 2390/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9083 - dice_coef: 0.9083 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2391/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2392/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9092 - dice_coef: 0.9092 - val_loss: -0.5473 - val_dice_coef: 0.5473\n",
      "Epoch 2393/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9727 - val_dice_coef: 0.9727\n",
      "Epoch 2394/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2395/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9716 - val_dice_coef: 0.9716\n",
      "Epoch 2396/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2397/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 2398/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2399/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9745 - val_dice_coef: 0.9745\n",
      "Epoch 2400/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2401/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2402/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2403/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9131 - dice_coef: 0.9131 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2404/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.9893 - val_dice_coef: 0.9893\n",
      "Epoch 2405/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 2406/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 2407/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9849 - val_dice_coef: 0.9849\n",
      "Epoch 2408/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9826 - val_dice_coef: 0.9826\n",
      "Epoch 2409/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2410/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2411/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9905 - val_dice_coef: 0.9905\n",
      "Epoch 2412/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9138 - dice_coef: 0.9138 - val_loss: -0.7774 - val_dice_coef: 0.7774\n",
      "Epoch 2413/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2414/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2415/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2416/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9553 - val_dice_coef: 0.9553\n",
      "Epoch 2417/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2418/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2419/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9930 - val_dice_coef: 0.9930\n",
      "Epoch 2420/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 2421/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.8831 - val_dice_coef: 0.8831\n",
      "Epoch 2422/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9748 - val_dice_coef: 0.9748\n",
      "Epoch 2423/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2424/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2425/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.9650 - val_dice_coef: 0.9650\n",
      "Epoch 2426/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.7634 - val_dice_coef: 0.7634\n",
      "Epoch 2427/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9733 - val_dice_coef: 0.9733\n",
      "Epoch 2428/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2429/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2430/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9903 - val_dice_coef: 0.9903\n",
      "Epoch 2431/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "Epoch 2432/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.6367 - val_dice_coef: 0.6367\n",
      "Epoch 2433/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9871 - val_dice_coef: 0.9871\n",
      "Epoch 2434/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2435/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.9941 - val_dice_coef: 0.9941\n",
      "Epoch 2436/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.7614 - val_dice_coef: 0.7614\n",
      "Epoch 2437/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.6913 - val_dice_coef: 0.6913\n",
      "Epoch 2438/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 2439/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2440/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2441/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2442/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.6776 - val_dice_coef: 0.6776\n",
      "Epoch 2443/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.1864 - val_dice_coef: 0.1864\n",
      "Epoch 2444/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8947 - dice_coef: 0.8947 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2445/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8959 - dice_coef: 0.8959 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2446/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9498 - val_dice_coef: 0.9498\n",
      "Epoch 2447/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9039 - val_dice_coef: 0.9039\n",
      "Epoch 2448/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.7625 - val_dice_coef: 0.7625\n",
      "Epoch 2449/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.7575 - val_dice_coef: 0.7575\n",
      "Epoch 2450/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2451/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2452/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9829 - val_dice_coef: 0.9829\n",
      "Epoch 2453/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9336 - val_dice_coef: 0.9336\n",
      "Epoch 2454/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2455/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2456/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2457/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.5875 - val_dice_coef: 0.5875\n",
      "Epoch 2458/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9070 - dice_coef: 0.9070 - val_loss: -0.3099 - val_dice_coef: 0.3099\n",
      "Epoch 2459/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9698 - val_dice_coef: 0.9698\n",
      "Epoch 2460/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2461/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.9670 - val_dice_coef: 0.9670\n",
      "Epoch 2462/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.3318 - val_dice_coef: 0.3318\n",
      "Epoch 2463/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.4738 - val_dice_coef: 0.4738\n",
      "Epoch 2464/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8995 - dice_coef: 0.8995 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2465/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.6963 - val_dice_coef: 0.6963\n",
      "Epoch 2466/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.2105 - val_dice_coef: 0.2105\n",
      "Epoch 2467/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2468/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9067 - dice_coef: 0.9067 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 2469/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.6050 - val_dice_coef: 0.6050\n",
      "Epoch 2470/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9890 - val_dice_coef: 0.9890\n",
      "Epoch 2471/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9969 - val_dice_coef: 0.9969\n",
      "Epoch 2472/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.8910 - val_dice_coef: 0.8910\n",
      "Epoch 2473/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.6591 - val_dice_coef: 0.6591\n",
      "Epoch 2474/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2475/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2476/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8967 - dice_coef: 0.8967 - val_loss: -0.3696 - val_dice_coef: 0.3696\n",
      "Epoch 2477/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9068 - dice_coef: 0.9068 - val_loss: -0.4352 - val_dice_coef: 0.4352\n",
      "Epoch 2478/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2479/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9117 - dice_coef: 0.9117 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2480/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9065 - dice_coef: 0.9065 - val_loss: -0.9402 - val_dice_coef: 0.9402\n",
      "Epoch 2481/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.3410 - val_dice_coef: 0.3410\n",
      "Epoch 2482/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9980 - val_dice_coef: 0.9980\n",
      "Epoch 2483/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2484/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8966 - dice_coef: 0.8966 - val_loss: -0.1221 - val_dice_coef: 0.1221\n",
      "Epoch 2485/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8937 - dice_coef: 0.8937 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2486/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.9983 - val_dice_coef: 0.9983\n",
      "Epoch 2487/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.8153 - val_dice_coef: 0.8153\n",
      "Epoch 2488/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2489/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2490/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9361 - val_dice_coef: 0.9361\n",
      "Epoch 2491/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2492/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9120 - dice_coef: 0.9120 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2493/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 2494/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.8146 - val_dice_coef: 0.8146\n",
      "Epoch 2495/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2496/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2497/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9087 - dice_coef: 0.9087 - val_loss: -0.9127 - val_dice_coef: 0.9127\n",
      "Epoch 2498/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9101 - dice_coef: 0.9101 - val_loss: -0.3409 - val_dice_coef: 0.3409\n",
      "Epoch 2499/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2500/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.9138 - val_dice_coef: 0.9138\n",
      "Epoch 2501/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.5536 - val_dice_coef: 0.5536\n",
      "Epoch 2502/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9060 - dice_coef: 0.9060 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2503/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2504/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.2602 - val_dice_coef: 0.2602\n",
      "Epoch 2505/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9012 - dice_coef: 0.9012 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2506/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9054 - dice_coef: 0.9054 - val_loss: -0.9884 - val_dice_coef: 0.9884\n",
      "Epoch 2507/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9102 - dice_coef: 0.9102 - val_loss: -0.2527 - val_dice_coef: 0.2527\n",
      "Epoch 2508/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9095 - dice_coef: 0.9095 - val_loss: -0.9902 - val_dice_coef: 0.9902\n",
      "Epoch 2509/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2510/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9058 - dice_coef: 0.9058 - val_loss: -0.7993 - val_dice_coef: 0.7993\n",
      "Epoch 2511/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.5294 - val_dice_coef: 0.5294\n",
      "Epoch 2512/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9071 - dice_coef: 0.9071 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2513/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 2514/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.8441 - val_dice_coef: 0.8441\n",
      "Epoch 2515/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9112 - dice_coef: 0.9112 - val_loss: -0.9006 - val_dice_coef: 0.9006\n",
      "Epoch 2516/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9769 - val_dice_coef: 0.9769\n",
      "Epoch 2517/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9760 - val_dice_coef: 0.9760\n",
      "Epoch 2518/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9923 - val_dice_coef: 0.9923\n",
      "Epoch 2519/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2520/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9511 - val_dice_coef: 0.9511\n",
      "Epoch 2521/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8498 - val_dice_coef: 0.8498\n",
      "Epoch 2522/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9099 - dice_coef: 0.9099 - val_loss: -0.9821 - val_dice_coef: 0.9821\n",
      "Epoch 2523/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9138 - dice_coef: 0.9138 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2524/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9794 - val_dice_coef: 0.9794\n",
      "Epoch 2525/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9139 - dice_coef: 0.9139 - val_loss: -0.9584 - val_dice_coef: 0.9584\n",
      "Epoch 2526/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9207 - val_dice_coef: 0.9207\n",
      "Epoch 2527/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9138 - val_dice_coef: 0.9138\n",
      "Epoch 2528/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2529/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9925 - val_dice_coef: 0.9925\n",
      "Epoch 2530/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9818 - val_dice_coef: 0.9818\n",
      "Epoch 2531/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9574 - val_dice_coef: 0.9574\n",
      "Epoch 2532/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2533/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9499 - val_dice_coef: 0.9499\n",
      "Epoch 2534/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9834 - val_dice_coef: 0.9834\n",
      "Epoch 2535/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2536/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9963 - val_dice_coef: 0.9963\n",
      "Epoch 2537/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9387 - val_dice_coef: 0.9387\n",
      "Epoch 2538/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.7852 - val_dice_coef: 0.7852\n",
      "Epoch 2539/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.8365 - val_dice_coef: 0.8365\n",
      "Epoch 2540/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9759 - val_dice_coef: 0.9759\n",
      "Epoch 2541/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9134 - dice_coef: 0.9134 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2542/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.6630 - val_dice_coef: 0.6630\n",
      "Epoch 2543/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.2535 - val_dice_coef: 0.2535\n",
      "Epoch 2544/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8994 - dice_coef: 0.8994 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2545/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8961 - dice_coef: 0.8961 - val_loss: -0.3855 - val_dice_coef: 0.3855\n",
      "Epoch 2546/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8819 - dice_coef: 0.8819 - val_loss: -0.0618 - val_dice_coef: 0.0618\n",
      "Epoch 2547/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2548/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.0220 - val_dice_coef: 0.0220\n",
      "Epoch 2549/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2550/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2551/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8882 - dice_coef: 0.8882 - val_loss: -0.1945 - val_dice_coef: 0.1945\n",
      "Epoch 2552/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2553/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8933 - dice_coef: 0.8933 - val_loss: -0.0718 - val_dice_coef: 0.0718\n",
      "Epoch 2554/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2555/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8976 - dice_coef: 0.8976 - val_loss: -0.8228 - val_dice_coef: 0.8228\n",
      "Epoch 2556/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9055 - dice_coef: 0.9055 - val_loss: -0.9731 - val_dice_coef: 0.9731\n",
      "Epoch 2557/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9103 - dice_coef: 0.9103 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2558/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9115 - dice_coef: 0.9115 - val_loss: -0.9399 - val_dice_coef: 0.9399\n",
      "Epoch 2559/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9932 - val_dice_coef: 0.9932\n",
      "Epoch 2560/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2561/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.9915 - val_dice_coef: 0.9915\n",
      "Epoch 2562/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.8389 - val_dice_coef: 0.8389\n",
      "Epoch 2563/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9125 - dice_coef: 0.9125 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2564/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2565/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.9534 - val_dice_coef: 0.9534\n",
      "Epoch 2566/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9137 - dice_coef: 0.9137 - val_loss: -0.9694 - val_dice_coef: 0.9694\n",
      "Epoch 2567/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2568/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2569/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9149 - dice_coef: 0.9149 - val_loss: -0.9830 - val_dice_coef: 0.9830\n",
      "Epoch 2570/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9725 - val_dice_coef: 0.9725\n",
      "Epoch 2571/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2572/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9883 - val_dice_coef: 0.9883\n",
      "Epoch 2573/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9186 - dice_coef: 0.9186 - val_loss: -0.9791 - val_dice_coef: 0.9791\n",
      "Epoch 2574/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.9965 - val_dice_coef: 0.9965\n",
      "Epoch 2575/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2576/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2577/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9757 - val_dice_coef: 0.9757\n",
      "Epoch 2578/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9523 - val_dice_coef: 0.9523\n",
      "Epoch 2579/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9673 - val_dice_coef: 0.9673\n",
      "Epoch 2580/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9940 - val_dice_coef: 0.9940\n",
      "Epoch 2581/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2582/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9989 - val_dice_coef: 0.9989\n",
      "Epoch 2583/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2584/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9705 - val_dice_coef: 0.9705\n",
      "Epoch 2585/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.7353 - val_dice_coef: 0.7353\n",
      "Epoch 2586/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9090 - dice_coef: 0.9090 - val_loss: -0.9770 - val_dice_coef: 0.9770\n",
      "Epoch 2587/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2588/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9118 - dice_coef: 0.9118 - val_loss: -0.9934 - val_dice_coef: 0.9934\n",
      "Epoch 2589/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2590/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9493 - val_dice_coef: 0.9493\n",
      "Epoch 2591/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9382 - val_dice_coef: 0.9382\n",
      "Epoch 2592/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9844 - val_dice_coef: 0.9844\n",
      "Epoch 2593/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2594/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9159 - dice_coef: 0.9159 - val_loss: -0.9854 - val_dice_coef: 0.9854\n",
      "Epoch 2595/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9117 - val_dice_coef: 0.9117\n",
      "Epoch 2596/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9900 - val_dice_coef: 0.9900\n",
      "Epoch 2597/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2598/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2599/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2600/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9594 - val_dice_coef: 0.9594\n",
      "Epoch 2601/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.8438 - val_dice_coef: 0.8438\n",
      "Epoch 2602/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.9946 - val_dice_coef: 0.9946\n",
      "Epoch 2603/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9967 - val_dice_coef: 0.9967\n",
      "Epoch 2604/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2605/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9817 - val_dice_coef: 0.9817\n",
      "Epoch 2606/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9159 - dice_coef: 0.9159 - val_loss: -0.7647 - val_dice_coef: 0.7647\n",
      "Epoch 2607/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8983 - val_dice_coef: 0.8983\n",
      "Epoch 2608/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9884 - val_dice_coef: 0.9884\n",
      "Epoch 2609/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9188 - dice_coef: 0.9188 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2610/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2611/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9389 - val_dice_coef: 0.9389\n",
      "Epoch 2612/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9502 - val_dice_coef: 0.9502\n",
      "Epoch 2613/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9673 - val_dice_coef: 0.9673\n",
      "Epoch 2614/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 2615/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2616/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2617/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.9213 - val_dice_coef: 0.9213\n",
      "Epoch 2618/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.8335 - val_dice_coef: 0.8335\n",
      "Epoch 2619/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 2620/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9193 - dice_coef: 0.9193 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2621/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 2622/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 2623/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.9428 - val_dice_coef: 0.9428\n",
      "Epoch 2624/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9172 - dice_coef: 0.9172 - val_loss: -0.9559 - val_dice_coef: 0.9559\n",
      "Epoch 2625/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9580 - val_dice_coef: 0.9580\n",
      "Epoch 2626/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9750 - val_dice_coef: 0.9750\n",
      "Epoch 2627/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2628/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9936 - val_dice_coef: 0.9936\n",
      "Epoch 2629/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2630/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 2631/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9049 - val_dice_coef: 0.9049\n",
      "Epoch 2632/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -0.8991 - val_dice_coef: 0.8991\n",
      "Epoch 2633/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9495 - val_dice_coef: 0.9495\n",
      "Epoch 2634/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9885 - val_dice_coef: 0.9885\n",
      "Epoch 2635/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2636/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9079 - dice_coef: 0.9079 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2637/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9096 - dice_coef: 0.9096 - val_loss: -0.2885 - val_dice_coef: 0.2885\n",
      "Epoch 2638/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9045 - dice_coef: 0.9045 - val_loss: -0.2576 - val_dice_coef: 0.2576\n",
      "Epoch 2639/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9031 - dice_coef: 0.9031 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2640/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9048 - dice_coef: 0.9048 - val_loss: -0.9985 - val_dice_coef: 0.9985\n",
      "Epoch 2641/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9642 - val_dice_coef: 0.9642\n",
      "Epoch 2642/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.8795 - val_dice_coef: 0.8795\n",
      "Epoch 2643/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9816 - val_dice_coef: 0.9816\n",
      "Epoch 2644/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9156 - dice_coef: 0.9156 - val_loss: -0.9978 - val_dice_coef: 0.9978\n",
      "Epoch 2645/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9150 - dice_coef: 0.9150 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2646/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.7112 - val_dice_coef: 0.7112\n",
      "Epoch 2647/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9147 - dice_coef: 0.9147 - val_loss: -0.7026 - val_dice_coef: 0.7026\n",
      "Epoch 2648/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.7975 - val_dice_coef: 0.7975\n",
      "Epoch 2649/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9131 - dice_coef: 0.9131 - val_loss: -0.9988 - val_dice_coef: 0.9988\n",
      "Epoch 2650/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9041 - dice_coef: 0.9041 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2651/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 2652/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9450 - val_dice_coef: 0.9450\n",
      "Epoch 2653/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9080 - val_dice_coef: 0.9080\n",
      "Epoch 2654/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9741 - val_dice_coef: 0.9741\n",
      "Epoch 2655/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9870 - val_dice_coef: 0.9870\n",
      "Epoch 2656/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 2657/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9289 - val_dice_coef: 0.9289\n",
      "Epoch 2658/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 2659/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2660/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9929 - val_dice_coef: 0.9929\n",
      "Epoch 2661/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9839 - val_dice_coef: 0.9839\n",
      "Epoch 2662/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9582 - val_dice_coef: 0.9582\n",
      "Epoch 2663/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.8275 - val_dice_coef: 0.8275\n",
      "Epoch 2664/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.7169 - val_dice_coef: 0.7169\n",
      "Epoch 2665/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2666/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2667/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.9956 - val_dice_coef: 0.9956\n",
      "Epoch 2668/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2669/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9465 - val_dice_coef: 0.9465\n",
      "Epoch 2670/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.6517 - val_dice_coef: 0.6517\n",
      "Epoch 2671/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.6271 - val_dice_coef: 0.6271\n",
      "Epoch 2672/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2673/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9987 - val_dice_coef: 0.9987\n",
      "Epoch 2674/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 2675/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9111 - dice_coef: 0.9111 - val_loss: -0.8553 - val_dice_coef: 0.8553\n",
      "Epoch 2676/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.6418 - val_dice_coef: 0.6418\n",
      "Epoch 2677/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9132 - dice_coef: 0.9132 - val_loss: -0.9451 - val_dice_coef: 0.9451\n",
      "Epoch 2678/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9378 - val_dice_coef: 0.9378\n",
      "Epoch 2679/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9155 - dice_coef: 0.9155 - val_loss: -0.9907 - val_dice_coef: 0.9907\n",
      "Epoch 2680/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2681/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9139 - dice_coef: 0.9139 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2682/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2683/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9474 - val_dice_coef: 0.9474\n",
      "Epoch 2684/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2685/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9631 - val_dice_coef: 0.9631\n",
      "Epoch 2686/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.9537 - val_dice_coef: 0.9537\n",
      "Epoch 2687/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9874 - val_dice_coef: 0.9874\n",
      "Epoch 2688/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9706 - val_dice_coef: 0.9706\n",
      "Epoch 2689/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2690/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2691/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2692/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2693/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9370 - val_dice_coef: 0.9370\n",
      "Epoch 2694/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.9513 - val_dice_coef: 0.9513\n",
      "Epoch 2695/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.8110 - val_dice_coef: 0.8110\n",
      "Epoch 2696/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9871 - val_dice_coef: 0.9871\n",
      "Epoch 2697/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2698/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9968 - val_dice_coef: 0.9968\n",
      "Epoch 2699/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9516 - val_dice_coef: 0.9516\n",
      "Epoch 2700/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 2701/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2702/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2703/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9530 - val_dice_coef: 0.9530\n",
      "Epoch 2704/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9678 - val_dice_coef: 0.9678\n",
      "Epoch 2705/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2706/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9263 - val_dice_coef: 0.9263\n",
      "Epoch 2707/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9615 - val_dice_coef: 0.9615\n",
      "Epoch 2708/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9825 - val_dice_coef: 0.9825\n",
      "Epoch 2709/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9718 - val_dice_coef: 0.9718\n",
      "Epoch 2710/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9606 - val_dice_coef: 0.9606\n",
      "Epoch 2711/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9210 - dice_coef: 0.9210 - val_loss: -0.9876 - val_dice_coef: 0.9876\n",
      "Epoch 2712/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.9686 - val_dice_coef: 0.9686\n",
      "Epoch 2713/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.9230 - val_dice_coef: 0.9230\n",
      "Epoch 2714/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.6055 - val_dice_coef: 0.6055\n",
      "Epoch 2715/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.7039 - val_dice_coef: 0.7039\n",
      "Epoch 2716/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9888 - val_dice_coef: 0.9888\n",
      "Epoch 2717/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.9797 - val_dice_coef: 0.9797\n",
      "Epoch 2718/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9753 - val_dice_coef: 0.9753\n",
      "Epoch 2719/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9210 - dice_coef: 0.9210 - val_loss: -0.9767 - val_dice_coef: 0.9767\n",
      "Epoch 2720/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9862 - val_dice_coef: 0.9862\n",
      "Epoch 2721/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9204 - dice_coef: 0.9204 - val_loss: -0.9916 - val_dice_coef: 0.9916\n",
      "Epoch 2722/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2723/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9181 - dice_coef: 0.9181 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2724/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9895 - val_dice_coef: 0.9895\n",
      "Epoch 2725/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 2726/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9553 - val_dice_coef: 0.9553\n",
      "Epoch 2727/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9170 - dice_coef: 0.9170 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 2728/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9174 - dice_coef: 0.9174 - val_loss: -0.9823 - val_dice_coef: 0.9823\n",
      "Epoch 2729/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.5576 - val_dice_coef: 0.5576\n",
      "Epoch 2730/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8978 - dice_coef: 0.8978 - val_loss: -0.0683 - val_dice_coef: 0.0683\n",
      "Epoch 2731/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.9993 - val_dice_coef: 0.9993\n",
      "Epoch 2732/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9944 - val_dice_coef: 0.9944\n",
      "Epoch 2733/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.2141 - val_dice_coef: 0.2141\n",
      "Epoch 2734/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.5150 - val_dice_coef: 0.5150\n",
      "Epoch 2735/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9075 - dice_coef: 0.9075 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2736/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9049 - dice_coef: 0.9049 - val_loss: -0.9897 - val_dice_coef: 0.9897\n",
      "Epoch 2737/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.4916 - val_dice_coef: 0.4916\n",
      "Epoch 2738/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 2739/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9206 - dice_coef: 0.9206 - val_loss: -0.9910 - val_dice_coef: 0.9910\n",
      "Epoch 2740/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9186 - dice_coef: 0.9186 - val_loss: -0.9832 - val_dice_coef: 0.9832\n",
      "Epoch 2741/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9199 - dice_coef: 0.9199 - val_loss: -0.9775 - val_dice_coef: 0.9775\n",
      "Epoch 2742/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2743/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 2744/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9837 - val_dice_coef: 0.9837\n",
      "Epoch 2745/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9886 - val_dice_coef: 0.9886\n",
      "Epoch 2746/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9938 - val_dice_coef: 0.9938\n",
      "Epoch 2747/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9182 - dice_coef: 0.9182 - val_loss: -0.9773 - val_dice_coef: 0.9773\n",
      "Epoch 2748/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9449 - val_dice_coef: 0.9449\n",
      "Epoch 2749/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.6856 - val_dice_coef: 0.6856\n",
      "Epoch 2750/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9023 - dice_coef: 0.9023 - val_loss: -0.1605 - val_dice_coef: 0.1605\n",
      "Epoch 2751/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9042 - dice_coef: 0.9042 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2752/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8943 - dice_coef: 0.8943 - val_loss: -0.9913 - val_dice_coef: 0.9913\n",
      "Epoch 2753/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.1673 - val_dice_coef: 0.1673\n",
      "Epoch 2754/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8998 - dice_coef: 0.8998 - val_loss: -0.9840 - val_dice_coef: 0.9840\n",
      "Epoch 2755/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2756/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.8341 - val_dice_coef: 0.8341\n",
      "Epoch 2757/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9121 - dice_coef: 0.9121 - val_loss: -0.3254 - val_dice_coef: 0.3254\n",
      "Epoch 2758/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9074 - dice_coef: 0.9074 - val_loss: -0.9945 - val_dice_coef: 0.9945\n",
      "Epoch 2759/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9110 - dice_coef: 0.9110 - val_loss: -0.9972 - val_dice_coef: 0.9972\n",
      "Epoch 2760/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.6873 - val_dice_coef: 0.6873\n",
      "Epoch 2761/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.2790 - val_dice_coef: 0.2790\n",
      "Epoch 2762/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9081 - dice_coef: 0.9081 - val_loss: -0.9970 - val_dice_coef: 0.9970\n",
      "Epoch 2763/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9973 - val_dice_coef: 0.9973\n",
      "Epoch 2764/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.8434 - val_dice_coef: 0.8434\n",
      "Epoch 2765/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.6315 - val_dice_coef: 0.6315\n",
      "Epoch 2766/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9126 - dice_coef: 0.9126 - val_loss: -0.8974 - val_dice_coef: 0.8974\n",
      "Epoch 2767/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.9986 - val_dice_coef: 0.9986\n",
      "Epoch 2768/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9656 - val_dice_coef: 0.9656\n",
      "Epoch 2769/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.8982 - val_dice_coef: 0.8982\n",
      "Epoch 2770/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9206 - dice_coef: 0.9206 - val_loss: -0.8701 - val_dice_coef: 0.8701\n",
      "Epoch 2771/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 2772/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 2773/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.8602 - val_dice_coef: 0.8602\n",
      "Epoch 2774/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.9125 - val_dice_coef: 0.9125\n",
      "Epoch 2775/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9891 - val_dice_coef: 0.9891\n",
      "Epoch 2776/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9193 - dice_coef: 0.9193 - val_loss: -0.9947 - val_dice_coef: 0.9947\n",
      "Epoch 2777/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9188 - dice_coef: 0.9188 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2778/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2779/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9551 - val_dice_coef: 0.9551\n",
      "Epoch 2780/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9194 - dice_coef: 0.9194 - val_loss: -0.9799 - val_dice_coef: 0.9799\n",
      "Epoch 2781/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.8195 - val_dice_coef: 0.8195\n",
      "Epoch 2782/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.8337 - val_dice_coef: 0.8337\n",
      "Epoch 2783/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.9586 - val_dice_coef: 0.9586\n",
      "Epoch 2784/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.8526 - val_dice_coef: 0.8526\n",
      "Epoch 2785/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9198 - dice_coef: 0.9198 - val_loss: -0.9293 - val_dice_coef: 0.9293\n",
      "Epoch 2786/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 2787/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9813 - val_dice_coef: 0.9813\n",
      "Epoch 2788/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9604 - val_dice_coef: 0.9604\n",
      "Epoch 2789/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9183 - dice_coef: 0.9183 - val_loss: -0.9026 - val_dice_coef: 0.9026\n",
      "Epoch 2790/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.8888 - val_dice_coef: 0.8888\n",
      "Epoch 2791/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9153 - dice_coef: 0.9153 - val_loss: -0.4764 - val_dice_coef: 0.4764\n",
      "Epoch 2792/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2793/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8953 - dice_coef: 0.8953 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2794/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9072 - dice_coef: 0.9072 - val_loss: -0.5740 - val_dice_coef: 0.5740\n",
      "Epoch 2795/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.9747 - val_dice_coef: 0.9747\n",
      "Epoch 2796/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2797/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9098 - dice_coef: 0.9098 - val_loss: -0.3430 - val_dice_coef: 0.3430\n",
      "Epoch 2798/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9141 - dice_coef: 0.9141 - val_loss: -0.5994 - val_dice_coef: 0.5994\n",
      "Epoch 2799/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9040 - dice_coef: 0.9040 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2800/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9105 - dice_coef: 0.9105 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2801/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.6466 - val_dice_coef: 0.6466\n",
      "Epoch 2802/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.8355 - val_dice_coef: 0.8355\n",
      "Epoch 2803/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9594 - val_dice_coef: 0.9594\n",
      "Epoch 2804/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.7488 - val_dice_coef: 0.7488\n",
      "Epoch 2805/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9708 - val_dice_coef: 0.9708\n",
      "Epoch 2806/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2807/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9026 - dice_coef: 0.9026 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2808/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8968 - dice_coef: 0.8968 - val_loss: -0.0411 - val_dice_coef: 0.0411\n",
      "Epoch 2809/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8950 - dice_coef: 0.8950 - val_loss: -0.5443 - val_dice_coef: 0.5443\n",
      "Epoch 2810/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9998 - val_dice_coef: 0.9998\n",
      "Epoch 2811/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9078 - dice_coef: 0.9078 - val_loss: -0.8374 - val_dice_coef: 0.8374\n",
      "Epoch 2812/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9146 - dice_coef: 0.9146 - val_loss: -0.9044 - val_dice_coef: 0.9044\n",
      "Epoch 2813/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2814/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.9197 - val_dice_coef: 0.9197\n",
      "Epoch 2815/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9160 - dice_coef: 0.9160 - val_loss: -0.6469 - val_dice_coef: 0.6469\n",
      "Epoch 2816/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2817/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9114 - dice_coef: 0.9114 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2818/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.7670 - val_dice_coef: 0.7670\n",
      "Epoch 2819/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9133 - dice_coef: 0.9133 - val_loss: -0.3303 - val_dice_coef: 0.3303\n",
      "Epoch 2820/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8993 - dice_coef: 0.8993 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2821/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8931 - dice_coef: 0.8931 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2822/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8811 - dice_coef: 0.8811 - val_loss: -0.0246 - val_dice_coef: 0.0246\n",
      "Epoch 2823/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2824/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8921 - dice_coef: 0.8921 - val_loss: -0.3323 - val_dice_coef: 0.3323\n",
      "Epoch 2825/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8900 - dice_coef: 0.8900 - val_loss: -0.0754 - val_dice_coef: 0.0754\n",
      "Epoch 2826/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8906 - dice_coef: 0.8906 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2827/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9044 - dice_coef: 0.9044 - val_loss: -0.2435 - val_dice_coef: 0.2435\n",
      "Epoch 2828/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8922 - dice_coef: 0.8922 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2829/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2830/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9116 - dice_coef: 0.9116 - val_loss: -0.9496 - val_dice_coef: 0.9496\n",
      "Epoch 2831/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9145 - dice_coef: 0.9145 - val_loss: -0.9773 - val_dice_coef: 0.9773\n",
      "Epoch 2832/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9168 - dice_coef: 0.9168 - val_loss: -0.9979 - val_dice_coef: 0.9979\n",
      "Epoch 2833/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.7813 - val_dice_coef: 0.7813\n",
      "Epoch 2834/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9454 - val_dice_coef: 0.9454\n",
      "Epoch 2835/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2836/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2837/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.8028 - val_dice_coef: 0.8028\n",
      "Epoch 2838/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9778 - val_dice_coef: 0.9778\n",
      "Epoch 2839/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9881 - val_dice_coef: 0.9881\n",
      "Epoch 2840/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9359 - val_dice_coef: 0.9359\n",
      "Epoch 2841/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9202 - val_dice_coef: 0.9202\n",
      "Epoch 2842/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9776 - val_dice_coef: 0.9776\n",
      "Epoch 2843/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9974 - val_dice_coef: 0.9974\n",
      "Epoch 2844/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9943 - val_dice_coef: 0.9943\n",
      "Epoch 2845/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9515 - val_dice_coef: 0.9515\n",
      "Epoch 2846/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9691 - val_dice_coef: 0.9691\n",
      "Epoch 2847/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9216 - dice_coef: 0.9216 - val_loss: -0.9468 - val_dice_coef: 0.9468\n",
      "Epoch 2848/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9197 - dice_coef: 0.9197 - val_loss: -0.7922 - val_dice_coef: 0.7922\n",
      "Epoch 2849/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9071 - val_dice_coef: 0.9071\n",
      "Epoch 2850/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9181 - dice_coef: 0.9181 - val_loss: -0.9984 - val_dice_coef: 0.9984\n",
      "Epoch 2851/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9140 - dice_coef: 0.9140 - val_loss: -1.0000 - val_dice_coef: 1.0000\n",
      "Epoch 2852/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9077 - dice_coef: 0.9077 - val_loss: -0.6913 - val_dice_coef: 0.6913\n",
      "Epoch 2853/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.2032 - val_dice_coef: 0.2032\n",
      "Epoch 2854/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9043 - dice_coef: 0.9043 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2855/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9037 - dice_coef: 0.9037 - val_loss: -0.8833 - val_dice_coef: 0.8833\n",
      "Epoch 2856/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.1882 - val_dice_coef: 0.1882\n",
      "Epoch 2857/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9076 - dice_coef: 0.9076 - val_loss: -0.9899 - val_dice_coef: 0.9899\n",
      "Epoch 2858/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9162 - dice_coef: 0.9162 - val_loss: -0.9981 - val_dice_coef: 0.9981\n",
      "Epoch 2859/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9154 - dice_coef: 0.9154 - val_loss: -0.8098 - val_dice_coef: 0.8098\n",
      "Epoch 2860/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9142 - dice_coef: 0.9142 - val_loss: -0.4437 - val_dice_coef: 0.4437\n",
      "Epoch 2861/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9127 - dice_coef: 0.9127 - val_loss: -0.9990 - val_dice_coef: 0.9990\n",
      "Epoch 2862/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9091 - dice_coef: 0.9091 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2863/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9161 - dice_coef: 0.9161 - val_loss: -0.7748 - val_dice_coef: 0.7748\n",
      "Epoch 2864/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9109 - dice_coef: 0.9109 - val_loss: -0.7879 - val_dice_coef: 0.7879\n",
      "Epoch 2865/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9178 - dice_coef: 0.9178 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2866/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9185 - dice_coef: 0.9185 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2867/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.2887 - val_dice_coef: 0.2887\n",
      "Epoch 2868/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9104 - dice_coef: 0.9104 - val_loss: -0.9497 - val_dice_coef: 0.9497\n",
      "Epoch 2869/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9171 - dice_coef: 0.9171 - val_loss: -0.9995 - val_dice_coef: 0.9995\n",
      "Epoch 2870/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9258 - val_dice_coef: 0.9258\n",
      "Epoch 2871/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9148 - dice_coef: 0.9148 - val_loss: -0.6020 - val_dice_coef: 0.6020\n",
      "Epoch 2872/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9130 - dice_coef: 0.9130 - val_loss: -0.9416 - val_dice_coef: 0.9416\n",
      "Epoch 2873/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9144 - dice_coef: 0.9144 - val_loss: -0.9942 - val_dice_coef: 0.9942\n",
      "Epoch 2874/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.9841 - val_dice_coef: 0.9841\n",
      "Epoch 2875/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.7869 - val_dice_coef: 0.7869\n",
      "Epoch 2876/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9667 - val_dice_coef: 0.9667\n",
      "Epoch 2877/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.9856 - val_dice_coef: 0.9856\n",
      "Epoch 2878/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9676 - val_dice_coef: 0.9676\n",
      "Epoch 2879/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 2880/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9508 - val_dice_coef: 0.9508\n",
      "Epoch 2881/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.9433 - val_dice_coef: 0.9433\n",
      "Epoch 2882/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9675 - val_dice_coef: 0.9675\n",
      "Epoch 2883/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9897 - val_dice_coef: 0.9897\n",
      "Epoch 2884/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9507 - val_dice_coef: 0.9507\n",
      "Epoch 2885/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9471 - val_dice_coef: 0.9471\n",
      "Epoch 2886/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9889 - val_dice_coef: 0.9889\n",
      "Epoch 2887/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9220 - dice_coef: 0.9220 - val_loss: -0.9919 - val_dice_coef: 0.9919\n",
      "Epoch 2888/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9233 - dice_coef: 0.9233 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 2889/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9916 - val_dice_coef: 0.9916\n",
      "Epoch 2890/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2891/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.9962 - val_dice_coef: 0.9962\n",
      "Epoch 2892/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9199 - dice_coef: 0.9199 - val_loss: -0.9949 - val_dice_coef: 0.9949\n",
      "Epoch 2893/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.9610 - val_dice_coef: 0.9610\n",
      "Epoch 2894/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9166 - dice_coef: 0.9166 - val_loss: -0.5778 - val_dice_coef: 0.5778\n",
      "Epoch 2895/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.7792 - val_dice_coef: 0.7792\n",
      "Epoch 2896/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 2897/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9201 - dice_coef: 0.9201 - val_loss: -0.9939 - val_dice_coef: 0.9939\n",
      "Epoch 2898/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9975 - val_dice_coef: 0.9975\n",
      "Epoch 2899/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9207 - dice_coef: 0.9207 - val_loss: -0.9850 - val_dice_coef: 0.9850\n",
      "Epoch 2900/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9542 - val_dice_coef: 0.9542\n",
      "Epoch 2901/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.9624 - val_dice_coef: 0.9624\n",
      "Epoch 2902/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9215 - dice_coef: 0.9215 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2903/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9920 - val_dice_coef: 0.9920\n",
      "Epoch 2904/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9190 - dice_coef: 0.9190 - val_loss: -0.9961 - val_dice_coef: 0.9961\n",
      "Epoch 2905/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9195 - dice_coef: 0.9195 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2906/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9208 - dice_coef: 0.9208 - val_loss: -0.9867 - val_dice_coef: 0.9867\n",
      "Epoch 2907/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9230 - dice_coef: 0.9230 - val_loss: -0.9935 - val_dice_coef: 0.9935\n",
      "Epoch 2908/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.8969 - val_dice_coef: 0.8969\n",
      "Epoch 2909/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.7985 - val_dice_coef: 0.7985\n",
      "Epoch 2910/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9008 - val_dice_coef: 0.9008\n",
      "Epoch 2911/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.8960 - val_dice_coef: 0.8960\n",
      "Epoch 2912/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9213 - dice_coef: 0.9213 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 2913/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.9976 - val_dice_coef: 0.9976\n",
      "Epoch 2914/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9991 - val_dice_coef: 0.9991\n",
      "Epoch 2915/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9122 - dice_coef: 0.9122 - val_loss: -0.9954 - val_dice_coef: 0.9954\n",
      "Epoch 2916/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9157 - dice_coef: 0.9157 - val_loss: -0.5299 - val_dice_coef: 0.5299\n",
      "Epoch 2917/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9128 - dice_coef: 0.9128 - val_loss: -0.4511 - val_dice_coef: 0.4511\n",
      "Epoch 2918/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9926 - val_dice_coef: 0.9926\n",
      "Epoch 2919/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9175 - dice_coef: 0.9175 - val_loss: -0.9960 - val_dice_coef: 0.9960\n",
      "Epoch 2920/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2921/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9202 - dice_coef: 0.9202 - val_loss: -0.9904 - val_dice_coef: 0.9904\n",
      "Epoch 2922/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9224 - dice_coef: 0.9224 - val_loss: -0.9183 - val_dice_coef: 0.9183\n",
      "Epoch 2923/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9228 - dice_coef: 0.9228 - val_loss: -0.8274 - val_dice_coef: 0.8274\n",
      "Epoch 2924/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9805 - val_dice_coef: 0.9805\n",
      "Epoch 2925/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.9952 - val_dice_coef: 0.9952\n",
      "Epoch 2926/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9173 - dice_coef: 0.9173 - val_loss: -0.9997 - val_dice_coef: 0.9997\n",
      "Epoch 2927/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9143 - dice_coef: 0.9143 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2928/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9176 - dice_coef: 0.9176 - val_loss: -0.9467 - val_dice_coef: 0.9467\n",
      "Epoch 2929/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9199 - val_dice_coef: 0.9199\n",
      "Epoch 2930/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9224 - dice_coef: 0.9224 - val_loss: -0.9598 - val_dice_coef: 0.9598\n",
      "Epoch 2931/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9249 - val_dice_coef: 0.9249\n",
      "Epoch 2932/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9215 - dice_coef: 0.9215 - val_loss: -0.9779 - val_dice_coef: 0.9779\n",
      "Epoch 2933/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9232 - dice_coef: 0.9232 - val_loss: -0.9848 - val_dice_coef: 0.9848\n",
      "Epoch 2934/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9229 - dice_coef: 0.9229 - val_loss: -0.9809 - val_dice_coef: 0.9809\n",
      "Epoch 2935/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9227 - dice_coef: 0.9227 - val_loss: -0.9853 - val_dice_coef: 0.9853\n",
      "Epoch 2936/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9232 - dice_coef: 0.9232 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 2937/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9238 - dice_coef: 0.9238 - val_loss: -0.9717 - val_dice_coef: 0.9717\n",
      "Epoch 2938/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9040 - val_dice_coef: 0.9040\n",
      "Epoch 2939/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9218 - dice_coef: 0.9218 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 2940/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9207 - dice_coef: 0.9207 - val_loss: -0.9860 - val_dice_coef: 0.9860\n",
      "Epoch 2941/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9951 - val_dice_coef: 0.9951\n",
      "Epoch 2942/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9184 - dice_coef: 0.9184 - val_loss: -0.9948 - val_dice_coef: 0.9948\n",
      "Epoch 2943/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9196 - dice_coef: 0.9196 - val_loss: -0.9576 - val_dice_coef: 0.9576\n",
      "Epoch 2944/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9229 - dice_coef: 0.9229 - val_loss: -0.8049 - val_dice_coef: 0.8049\n",
      "Epoch 2945/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.4973 - val_dice_coef: 0.4973\n",
      "Epoch 2946/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9085 - dice_coef: 0.9085 - val_loss: -0.5387 - val_dice_coef: 0.5387\n",
      "Epoch 2947/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9163 - dice_coef: 0.9163 - val_loss: -0.9992 - val_dice_coef: 0.9992\n",
      "Epoch 2948/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9136 - dice_coef: 0.9136 - val_loss: -0.9914 - val_dice_coef: 0.9914\n",
      "Epoch 2949/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.6299 - val_dice_coef: 0.6299\n",
      "Epoch 2950/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9177 - dice_coef: 0.9177 - val_loss: -0.5632 - val_dice_coef: 0.5632\n",
      "Epoch 2951/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9124 - dice_coef: 0.9124 - val_loss: -0.9418 - val_dice_coef: 0.9418\n",
      "Epoch 2952/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9158 - dice_coef: 0.9158 - val_loss: -0.9999 - val_dice_coef: 0.9999\n",
      "Epoch 2953/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9035 - dice_coef: 0.9035 - val_loss: -0.7234 - val_dice_coef: 0.7234\n",
      "Epoch 2954/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9100 - dice_coef: 0.9100 - val_loss: -0.0527 - val_dice_coef: 0.0527\n",
      "Epoch 2955/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.8957 - dice_coef: 0.8957 - val_loss: -0.9922 - val_dice_coef: 0.9922\n",
      "Epoch 2956/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9063 - dice_coef: 0.9063 - val_loss: -0.9994 - val_dice_coef: 0.9994\n",
      "Epoch 2957/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9113 - dice_coef: 0.9113 - val_loss: -0.8292 - val_dice_coef: 0.8292\n",
      "Epoch 2958/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9169 - dice_coef: 0.9169 - val_loss: -0.5083 - val_dice_coef: 0.5083\n",
      "Epoch 2959/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9135 - dice_coef: 0.9135 - val_loss: -0.9955 - val_dice_coef: 0.9955\n",
      "Epoch 2960/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9129 - dice_coef: 0.9129 - val_loss: -0.9996 - val_dice_coef: 0.9996\n",
      "Epoch 2961/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9107 - dice_coef: 0.9107 - val_loss: -0.2455 - val_dice_coef: 0.2455\n",
      "Epoch 2962/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9106 - dice_coef: 0.9106 - val_loss: -0.7099 - val_dice_coef: 0.7099\n",
      "Epoch 2963/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9982 - val_dice_coef: 0.9982\n",
      "Epoch 2964/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9152 - dice_coef: 0.9152 - val_loss: -0.9864 - val_dice_coef: 0.9864\n",
      "Epoch 2965/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9200 - dice_coef: 0.9200 - val_loss: -0.8014 - val_dice_coef: 0.8014\n",
      "Epoch 2966/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9203 - dice_coef: 0.9203 - val_loss: -0.8227 - val_dice_coef: 0.8227\n",
      "Epoch 2967/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9204 - dice_coef: 0.9204 - val_loss: -0.9774 - val_dice_coef: 0.9774\n",
      "Epoch 2968/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9796 - val_dice_coef: 0.9796\n",
      "Epoch 2969/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9223 - dice_coef: 0.9223 - val_loss: -0.9790 - val_dice_coef: 0.9790\n",
      "Epoch 2970/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9908 - val_dice_coef: 0.9908\n",
      "Epoch 2971/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9222 - dice_coef: 0.9222 - val_loss: -0.9882 - val_dice_coef: 0.9882\n",
      "Epoch 2972/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9236 - dice_coef: 0.9236 - val_loss: -0.9933 - val_dice_coef: 0.9933\n",
      "Epoch 2973/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9242 - dice_coef: 0.9242 - val_loss: -0.9597 - val_dice_coef: 0.9597\n",
      "Epoch 2974/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9817 - val_dice_coef: 0.9817\n",
      "Epoch 2975/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9859 - val_dice_coef: 0.9859\n",
      "Epoch 2976/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9244 - dice_coef: 0.9244 - val_loss: -0.9927 - val_dice_coef: 0.9927\n",
      "Epoch 2977/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9234 - dice_coef: 0.9234 - val_loss: -0.9896 - val_dice_coef: 0.9896\n",
      "Epoch 2978/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.9798 - val_dice_coef: 0.9798\n",
      "Epoch 2979/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.9339 - val_dice_coef: 0.9339\n",
      "Epoch 2980/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9235 - dice_coef: 0.9235 - val_loss: -0.8915 - val_dice_coef: 0.8915\n",
      "Epoch 2981/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.6100 - val_dice_coef: 0.6100\n",
      "Epoch 2982/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9167 - dice_coef: 0.9167 - val_loss: -0.8801 - val_dice_coef: 0.8801\n",
      "Epoch 2983/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9189 - dice_coef: 0.9189 - val_loss: -0.9374 - val_dice_coef: 0.9374\n",
      "Epoch 2984/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9235 - dice_coef: 0.9235 - val_loss: -0.9898 - val_dice_coef: 0.9898\n",
      "Epoch 2985/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9192 - dice_coef: 0.9192 - val_loss: -0.9561 - val_dice_coef: 0.9561\n",
      "Epoch 2986/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9179 - dice_coef: 0.9179 - val_loss: -0.6162 - val_dice_coef: 0.6162\n",
      "Epoch 2987/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9180 - dice_coef: 0.9180 - val_loss: -0.4257 - val_dice_coef: 0.4257\n",
      "Epoch 2988/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9187 - dice_coef: 0.9187 - val_loss: -0.8258 - val_dice_coef: 0.8258\n",
      "Epoch 2989/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9219 - dice_coef: 0.9219 - val_loss: -0.9841 - val_dice_coef: 0.9841\n",
      "Epoch 2990/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9220 - dice_coef: 0.9220 - val_loss: -0.9869 - val_dice_coef: 0.9869\n",
      "Epoch 2991/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9212 - dice_coef: 0.9212 - val_loss: -0.9971 - val_dice_coef: 0.9971\n",
      "Epoch 2992/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9209 - dice_coef: 0.9209 - val_loss: -0.9827 - val_dice_coef: 0.9827\n",
      "Epoch 2993/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9205 - dice_coef: 0.9205 - val_loss: -0.8863 - val_dice_coef: 0.8863\n",
      "Epoch 2994/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.8742 - val_dice_coef: 0.8742\n",
      "Epoch 2995/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9217 - dice_coef: 0.9217 - val_loss: -0.9785 - val_dice_coef: 0.9785\n",
      "Epoch 2996/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9214 - dice_coef: 0.9214 - val_loss: -0.8957 - val_dice_coef: 0.8957\n",
      "Epoch 2997/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9191 - dice_coef: 0.9191 - val_loss: -0.9598 - val_dice_coef: 0.9598\n",
      "Epoch 2998/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9226 - dice_coef: 0.9226 - val_loss: -0.9350 - val_dice_coef: 0.9350\n",
      "Epoch 2999/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9240 - dice_coef: 0.9240 - val_loss: -0.9408 - val_dice_coef: 0.9408\n",
      "Epoch 3000/3000\n",
      "92/92 [==============================] - 1s 6ms/step - loss: -0.9225 - dice_coef: 0.9225 - val_loss: -0.8405 - val_dice_coef: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff126c17748>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "model = get_unet()\n",
    "print(model.summary())\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "model.fit(train_z, train_z_m, batch_size=32, epochs=3000, verbose=1, shuffle=True,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weights.h5',custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_train = model.predict(train_z[:int(train_z.shape[0]*0.9)], verbose=1)\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val = model.predict(train_z[int(train_z.shape[0]*0.9):], verbose=1)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Low image data range; displaying image with stretched contrast.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAEYCAYAAAAkpo9KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFvBJREFUeJzt3X+MXeV95/H3BxvsQkKM45Z1bLe4itvUpWmDLH6I1ZaNyWJoBFltFNlNG5PSWpUgpUm2jSlV2GVVKWy6SROJkM4GFxqxUOqmxWKduMQBRa2K46FEBNtxmJoG7JoYgkOjooDt+fSP84y5Hmbm3pn749w783lJR3PPj3vO18eer5/nPD+ObBMREXBa3QFERPSLJMSIiCIJMSKiSEKMiCiSECMiiiTEiIgiCTEiBpKkLZKOSHpykv2S9FlJI5KekHRBs3N2LSFKWidpfwlmc7euExFz1l3Auin2XwmsKssm4I5mJ+xKQpQ0D7i9BLQa2CBpdTeuFRFzk+2vAy9Occg1wJ+78iiwSNLSqc45v5MBNrgQGLF9AEDSfSW4vRMdfIYWeCFndSmUiKjDDzn6gu0fB7jiP5/l7794ouXvPvbEK3uAHzVsGrI9NM0QlgHPNqwfLNsOT/aFbiXEiQK5qPEASZuoirEs5Ewu0touhRIRdfiqt3537PP3XzzBN3b8ZMvfnbf0qR/ZXtOVwKbQrYTYVMn2QwBna3EGVEfMYgZGGe31ZQ8BKxrWl5dtk+pWo8q0A4mI2cyc8GjLS4dsAz5QWpsvBl6yPWl1GbpXQtwNrJK0kioRrgd+tUvXiog+V5UQO1sRlHQvcBmwRNJB4BbgdADbnwe2A1cBI8DLwAebnbMrCdH2cUk3ADuAecAW23u6ca2IGAydrjLb3tBkv4Hrp3POrj1DtL2dKkNHxBxnzIkBmHu1tkaViJhbOl1l7oYkxIjoOgMnkhAjIiopIUZEUJUQj+UZYkREaVRJCTEiAjCc6P98mIQYEd1Xdczuf0mIEdED4gSqO4imkhAjousMjKbKHBFRSQkxIoKxjtlJiBERAIw6CTEiIiXEiIgxRpwYgLceJyFGRE+kyhwRQarMERENxAmnyhwRUYbuJSFGRACpMkdEAGCnyhwRcdJoSogREWOtzCkhRkSQVuaIiCKtzBERDU5kpEpERMYyR0ScVL2GtP/TTf9HGBEDzyhV5oiIMWlUiYgAbAai282MI5S0QtLDkvZK2iPpxrJ9saSHJD1Vfp7TuXAjYjCJ0WksdWknZR8HPmp7NXAxcL2k1cBmYKftVcDOsh4Rc5ipSoitLnWZcZXZ9mHgcPn8Q0n7gGXANcBl5bC7gUeAj7UVZUQMvDnT7UbSecA7gF3AuSVZAjwHnDvJdzYBmwAWcmYnwoiIPmU0N14hIOkNwF8Bv2v7X6XX/tC2LckTfc/2EDAEcLYWT3hMRMwes76EKOl0qmR4j+0vlc3fk7TU9mFJS4Ej7QYZEYPNwOgsb2UWcCewz/anGnZtAzaWzxuBB2YeXkTMDuLENJa6tFNCvBT4deBbkr5Ztv0B8AngfknXAd8F3tdeiBEx6AalhNhOK/PfwaSpfO1MzxsRs9MgvFOl/1N2RAw8W4z6tJaXVkhaJ2m/pBFJr+vvLOkny+CRxyU9IemqZufM0L2I6IlOdriWNA+4HXgXcBDYLWmb7b0Nh/0hcL/tO8qgke3AeVOdNyXEiOi6asbsjg7duxAYsX3A9qvAfVSDQsZf9uzy+U3AvzQ7aUqIEdED036nyhJJww3rQ6Xv8phlwLMN6weBi8ad438AfyvpQ8BZwOXNLpqEGBFdV7UyT6tR5QXba9q87AbgLtv/R9IlwBclnW97dLIvJCFGRE90eKTKIWBFw/rysq3RdcA6ANv/IGkhsIQpBovkGWJEdN3YWOZWlxbsBlZJWinpDGA91aCQRs9QugBK+jlgIfD8VCdNCTEieqKTM2bbPi7pBmAHMA/YYnuPpFuBYdvbgI8C/1fSh6lq7dfannLehCTEiOi6asbsznbMtr2dqitN47aPN3zeSzWirmVJiBHRE3Ni+q+IiGaMOOZ5dYfRVBJiRHTdDLrd1CIJMSJ6QLN7tpuIiOmo8216rUpCjIiu60YrczckIUZET6TKHBHBHHrrXkREK/IMMSKCdLuJiDhFniFGRAC0PotNrZIQI6Lrxl4h0O+SECOiJ1JCjIggjSoREadIQoyIIB2zIyJOkUaViAgAp8ocEQEMTqNK213HJc2T9LikB8v6Skm7JI1I+ovyisCImOM6/BrSrujEWJobgX0N67cBn7b9VuAo1cuiI2IO68J7mbuirYQoaTnwK8AXyrqAdwJbyyF3A+9p5xoRMTvYanmpS7vPEP8E+H3gjWX9zcAPbB8v6weBZRN9UdImYBPAQs5sM4yI6HeD0Mo84xKipHcDR2w/NpPv2x6yvcb2mtNZMNMwImIA2IPxDLGdEuKlwNWSrgIWAmcDnwEWSZpfSonLgUPthxkRg02cGO3/6b9mHKHtm2wvt30esB74mu33Aw8D7y2HbQQeaDvKiBh4g/AMsRsp+2PARySNUD1TvLML14iIATLWD3E2V5lPsv0I8Ej5fAC4sBPnjYhZwtVzxH6XkSoR0ROD0MqchBgRXWeo9dlgq5IQI6IHMv1XRMRJeYYYEVGkyhwRQVU6TEKMiCjyDDEiosgzxIiIIlXmiAiqCWKTECMiigGoMXdlcoeIiFO587PdSFonaX95f9PmSY55n6S9kvZI+n/NzpkSYkT0RgeLiJLmAbcD76KamX+3pG229zYcswq4CbjU9lFJP9HsvCkhRkRPdLiEeCEwYvuA7VeB+4Brxh3zW8Dtto9W1/eRZidNQoyInrBbX1qwDHi2YX2i9zf9DPAzkv5e0qOS1jU7aarMEdF1M5jtZomk4Yb1IdtD07zsfGAVcBnV60y+LukXbP9gqi9EzNiOf/nmhNuveMsv9TiS6GsGppcQX7C9Zor9h4AVDesTvb/pILDL9jHgaUnfoUqQuyc7aarMEdETHa4y7wZWSVop6Qyq9zptG3fM31CVDpG0hKoKfWCqk6aEGNM2WalwusdMJSXMWaiDrcy2j0u6AdgBzAO22N4j6VZg2Pa2su+/SNoLnAB+z/b3pzpvEmJE9IDwaGdHqtjeDmwft+3jDZ8NfKQsLUlCjL40VsJMSXGWyPRfERENBmDsXhJiRPRISogREZWUECMiiiTEiAhm0jG7FkmIEdETeYVARMSYJMSIiGIAqsxtjWWWtEjSVknflrRP0iWSFkt6SNJT5ec5nQo2IgaX3PpSl3Ynd/gM8BXbbwN+EdgHbAZ22l4F7CzrETGXeZpLTWZcZZb0JuA/AdcClFlrX5V0DWWGCeBu4BHgY+0EGf2h3QkbWpGherOVZn2VeSXwPPBnkh6X9AVJZwHn2j5cjnkOOHeiL0vaJGlY0vAxXmkjjIgYCLO5hFi+ewHwIdu7JH2GcdVj25YmfiJQZr8dAjhbiweg/SnakZJfDEIrczslxIPAQdu7yvpWqgT5PUlLAcrPpi92iYg5YDaXEG0/J+lZST9rez+wFthblo3AJ8rPBzoSadQupbyYsTkyUuVDwD1lCu8DwAepSp33S7oO+C7wvjavERGzQJ3daVrVVkK0/U1gohfBrG3nvBExCw1AQsxLpiIiigzdi4iemPVV5oiIls2BRpWIiOZq7k7TqiTEiOgJjdYdQXNJiBHRGykhRkQUSYgREfXPc9iqJMSI6I20MkdEFCkhRkRUUmWOiBiThBgRAaRRJSKiQRJiRESRhBgRURmEKnPmQ4yIKFJCjIjeGIASYhJiRHRfWpkjIhokIUZEFEmIEREgBqPKnFbmiOgNT2NpgaR1kvZLGpG0eYrj/pskS5rolcmnSEKMiO7za3MitrI0I2kecDtwJbAa2CBp9QTHvRG4EdjVSphJiBHRG50tIV4IjNg+YPtV4D7gmgmO+1/AbcCPWjlpEmJE9EZnE+Iy4NmG9YNl20mSLgBW2P7/rYaYRpWI6IlpNqoskTTcsD5ke6jla0mnAZ8Crp3ORZMQI6L7DEzvNaQv2J6qEeQQsKJhfXnZNuaNwPnAI5IA/gOwTdLVthsT7SmSECOiJzrc7WY3sErSSqpEuB741bGdtl8Clpy8tvQI8N+nSoaQZ4gR0SsdfIZo+zhwA7AD2Afcb3uPpFslXT3TENsqIUr6MPCbVH+EbwEfBJZStfi8GXgM+PXSChQRc1inO2bb3g5sH7ft45Mce1kr55xxCVHSMuB3gDW2zwfmURVbbwM+bfutwFHgupleIyJmkQ53zO6GdqvM84EfkzQfOBM4DLwT2Fr23w28p81rRMSgm04yHMSEaPsQ8MfAM1SJ8CWqKvIPSv0eJugbNEbSJknDkoaP8cpMw4iIAaBpLnVpp8p8DlXP8JXAW4CzgHWtft/2kO01tteczoKZhhERg2IASojtNKpcDjxt+3kASV8CLgUWSZpfSonj+wZFxBw122e7eQa4WNKZqno+rgX2Ag8D7y3HbAQeaC/EiJgVBqCE2M4zxF1UjSf/SNXl5jRgCPgY8BFJI1Rdb+7sQJwRMegGICG21Q/R9i3ALeM2H6CaiSIiopJ3qkRENEhCjIiopIQYETEmCTEiopISYkQE1N563KokxIjojSTEiIjBeS9zEmJE9EYSYkRERe7/jJiEGBHdl0aViIjX5BliRESh6b2GtBZJiBHRGykhRkSQ2W4iIk6RhBgRkY7ZERGnSj/EiIhKSogREZCO2RERjdIPMSJiTEqIERGVPEOMiIDyDLH/M2ISYkT0REqIERFjkhAjIjJSJSLiNXaeIUZEjEkJMSJizAAkxNOaHSBpi6Qjkp5s2LZY0kOSnio/zynbJemzkkYkPSHpgm4GHxGDQ259qUvThAjcBawbt20zsNP2KmBnWQe4ElhVlk3AHZ0JMyIGmoFRt77UpGlCtP114MVxm68B7i6f7wbe07D9z115FFgkaWmngo2IAeZpLDVppYQ4kXNtHy6fnwPOLZ+XAc82HHewbHsdSZskDUsaPsYrMwwjIgbFbKkyT8n2jHK67SHba2yvOZ0F7YYREf1urOtNK0sLJK2TtL+0WWyeYP9HJO0t7Rk7Jf1Us3PONCF+b6wqXH4eKdsPASsajltetkXEXOZq+q9Wl2YkzQNup2q3WA1skLR63GGPA2tsvx3YCvzvZuedaULcBmwsnzcCDzRs/0Bpbb4YeKmhah0Rc1Q1UsUtLy24EBixfcD2q8B9VG0YJ9l+2PbLZfVRqgLalJr2Q5R0L3AZsETSQeAW4BPA/ZKuA74LvK8cvh24ChgBXgY+2PzPFRFzwvQmiF0iabhhfcj2UMP6RO0VF01xvuuALze7aNOEaHvDJLvWTnCsgeubnTMi5p4WS35jXrC9piPXlX4NWAP8crNjM1IlIrqv891pWmqvkHQ5cDPwy7abdmdpu5U5IqK5abQwt1aS3A2skrRS0hnAeqo2jJMkvQP4U+Bq20cmOMfrpIQYET3Ryf6Fto9LugHYAcwDttjeI+lWYNj2NuCTwBuAv5QE8Iztq6c6bxJiRPRGh6f/sr2dqiG3cdvHGz5fPt1zJiFGRPc5ryGNiHhNJoiNiCj6Px8mIUZEb0yzH2ItkhAjojeSECMiKBPE1h1Ec0mIEdF1ouVJG2qVhBgRvZGEGBFRJCFGRJBniBERjfIMMSJiTBJiRAScnP6rzyUhRkT3mSTEiIiT0qgSEVHRaP9nxCTEiOg+A6OpMkdEkEaViIhGSYgREUUSYkQEeYYYEfEag9PKHBFRSZU5IoJUmSMiTjEAJcTTmh0gaYukI5KebNj2SUnflvSEpL+WtKhh302SRiTtl3RFtwKPiAFjt77UpGlCBO4C1o3b9hBwvu23A98BbgKQtBpYD/x8+c7nJM3rWLQRMaCmkQz7OSHa/jrw4rhtf2v7eFl9FFhePl8D3Gf7FdtPAyPAhR2MNyIGkYHR0daXmrRSQmzmN4Avl8/LgGcb9h0s215H0iZJw5KGj/FKB8KIiL42ACXEthpVJN0MHAfume53bQ8BQwBna3H/P22NiPYMQKPKjBOipGuBdwNr7ZN/0kPAiobDlpdtETGneSC63cyoyixpHfD7wNW2X27YtQ1YL2mBpJXAKuAb7YcZEQPNYI+2vNSlaQlR0r3AZcASSQeBW6halRcAD0kCeNT2b9veI+l+YC9VVfp62ye6FXxEDJABKCE2TYi2N0yw+c4pjv8j4I/aCSoiZqHZ/AwxIqJldq3daVqVhBgRvZESYkRExSkhRkRA3qkSETEm039FRFQM+ET/98DrxFjmiIipubxCoNWlBZLWlWkGRyRtnmD/Akl/UfbvknRes3MmIUZET3jULS/NlGkFbweuBFYDG8r0g42uA47afivwaeC2ZudNQoyI3uhsCfFCYMT2AduvAvdRTT/Y6Brg7vJ5K7BWZWjdZPriGeIPOfrCV73134AX6o5lEkvoz9gS1/T1a2yzMa6fGvvwQ47u+Kq3LpnGdxdKGm5YHyozZI2ZaKrBi8ad4+Qxto9Legl4M1P8efoiIdr+cUnDttfUHctE+jW2xDV9/RrbbI/L9vhZ9/tSqswRMYhamWrw5DGS5gNvAr4/1UmTECNiEO0GVklaKekMqnc5bRt3zDZgY/n8XuBrDXO3TqgvqszFUPNDatOvsSWu6evX2BLXNJRngjcAO4B5wJYy/eCtwLDtbVSzcn1R0gjVe6HWNzuvmiTMiIg5I1XmiIgiCTEiouiLhNhsCE4P41gh6WFJeyXtkXRj2b5Y0kOSnio/z6kpvnmSHpf0YFlfWYYkjZQhSmfUFNciSVslfVvSPkmX9MM9k/Th8vf4pKR7JS2s655J2iLpiKQnG7ZNeI9U+WyJ8QlJF/Q4rk+Wv8snJP21pEUN+24qce2XdEW34qpL7QmxxSE4vXIc+Kjt1cDFwPUlls3ATturgJ1lvQ43Avsa1m8DPl2GJh2lGqpUh88AX7H9NuAXqWKs9Z5JWgb8DrDG9vlUD97XU989uwsY3xdvsnt0JdUL2lYBm4A7ehzXQ8D5tt8OfIfqHUqU34X1wM+X73yu/P7OHrZrXYBLgB0N6zcBN9UdV4nlAeBdwH5gadm2FNhfQyzLqX5p3gk8CIiqx/38ie5jD+N6E/A0pYGuYXut94zXRikspupN8SBwRZ33DDgPeLLZPQL+FNgw0XG9iGvcvv8K3FM+n/K7SdXCe0mv/811c6m9hMjEQ3CW1RTLSWVmjHcAu4BzbR8uu54Dzq0hpD+hevXr2EDPNwM/sH28rNd131YCzwN/VqrzX5B0FjXfM9uHgD8GngEOAy8Bj9Ef92zMZPeon34nfgP4cvncT3F1RT8kxL4j6Q3AXwG/a/tfG/e5+q+xp32VJL0bOGL7sV5et0XzgQuAO2y/A/g3xlWPa7pn51AN7l8JvAU4i9dXDftGHfeoGUk3Uz1GuqfuWHqlHxJiK0NwekbS6VTJ8B7bXyqbvydpadm/FDjS47AuBa6W9M9Us3q8k+q53aIyJAnqu28HgYO2d5X1rVQJsu57djnwtO3nbR8DvkR1H/vhno2Z7B7V/jsh6Vrg3cD7S7Lui7i6rR8SYitDcHqiTA10J7DP9qcadjUOAdpI9WyxZ2zfZHu57fOo7s/XbL8feJhqSFItcZXYngOelfSzZdNaYC813zOqqvLFks4sf69jcdV+zxpMdo+2AR8orc0XAy81VK27TtI6qsczV9t+eVy861VNvLqSqtHnG72KqyfqfohZ/vO5iqo165+Am2uM4z9SVVueAL5ZlquontftBJ4CvgosrjHGy4AHy+efpvoHOQL8JbCgpph+CRgu9+1vgHP64Z4B/xP4NvAk8EVgQV33DLiX6lnmMapS9XWT3SOqBrPby+/Dt6haynsZ1wjVs8Kx34HPNxx/c4lrP3BlHf/eurlk6F5ERNEPVeaIiL6QhBgRUSQhRkQUSYgREUUSYkREkYQYEVEkIUZEFP8O8R6m7suNLBkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "ix = 70\n",
    "imshow(np.squeeze(train_z[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(train_z_m[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((IMG_H, IMG_W, 1))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "local_conv1 = Conv2D(64, (7, 7), activation='relu', padding='same')(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(64)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(128), Dimension(1)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_18/Max:0' shape=(?, 1, 64, 64) dtype=float32>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_231/Relu:0' shape=(?, 64, 64, 64) dtype=float32>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('img3d_train', img_array)\n",
    "np.save('msk3d_train', msk_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 320, 232)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
